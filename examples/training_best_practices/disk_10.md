[33mTailing logs of job 1 on cluster 'dd'...[0m
[2mâ”œâ”€â”€ [0m[2mWaiting for task resources on 2 nodes.[0m
[2mâ””â”€â”€ [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3451)[0m Channels:
[36m(setup pid=3451)[0m  - nvidia
[36m(setup pid=3451)[0m  - defaults
[36m(setup pid=3451)[0m Platform: linux-64
[36m(setup pid=2564, ip=10.102.30.211)[0m Channels:
[36m(setup pid=2564, ip=10.102.30.211)[0m  - nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m  - defaults
[36m(setup pid=2564, ip=10.102.30.211)[0m Platform: linux-64
[36m(setup pid=3451)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3451)[0m Solving environment: ...working... done
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m ## Package Plan ##
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m   environment location: /root/miniconda3
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m   added / updated specs:
[36m(setup pid=3451)[0m     - cuda
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m The following packages will be downloaded:
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m     package                    |            build
[36m(setup pid=3451)[0m     ---------------------------|-----------------
[36m(setup pid=3451)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3451)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3451)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3451)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3451)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3451)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3451)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3451)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3451)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3451)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3451)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3451)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3451)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3451)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3451)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3451)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3451)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3451)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3451)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3451)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3451)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3451)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3451)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3451)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3451)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3451)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3451)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3451)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3451)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3451)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3451)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3451)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3451)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3451)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3451)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3451)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3451)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3451)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3451)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3451)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3451)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3451)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3451)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3451)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3451)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3451)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3451)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3451)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3451)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3451)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3451)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3451)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3451)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3451)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3451)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3451)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3451)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3451)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3451)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3451)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3451)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3451)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3451)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3451)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3451)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3451)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3451)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3451)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3451)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3451)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3451)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3451)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3451)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3451)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3451)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3451)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3451)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3451)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3451)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3451)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3451)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3451)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3451)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3451)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3451)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3451)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3451)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3451)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3451)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3451)[0m     ------------------------------------------------------------
[36m(setup pid=3451)[0m                                            Total:        2.06 GB
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3451)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3451)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3451)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3451)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3451)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3451)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3451)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3451)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3451)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3451)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3451)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3451)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3451)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3451)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3451)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3451)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3451)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3451)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3451)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3451)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3451)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3451)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3451)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3451)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3451)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3451)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3451)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3451)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3451)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3451)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3451)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3451)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3451)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3451)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3451)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3451)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3451)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3451)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3451)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3451)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3451)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3451)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3451)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3451)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3451)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3451)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3451)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3451)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3451)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3451)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3451)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3451)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3451)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3451)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3451)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3451)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3451)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3451)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3451)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3451)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3451)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3451)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3451)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3451)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3451)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3451)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3451)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3451)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3451)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3451)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3451)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3451)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3451)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3451)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3451)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m The following packages will be UPDATED:
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3451)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3451)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3451)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3451)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3451)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3451)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3451)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3451)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3451)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3451)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m Proceed ([y]/n)? 
[36m(setup pid=3451)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2564, ip=10.102.30.211)[0m Solving environment: ...working... done
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m ## Package Plan ##
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m   environment location: /root/miniconda3
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m   added / updated specs:
[36m(setup pid=2564, ip=10.102.30.211)[0m     - cuda
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m The following packages will be downloaded:
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m     package                    |            build
[36m(setup pid=2564, ip=10.102.30.211)[0m     ---------------------------|-----------------
[36m(setup pid=2564, ip=10.102.30.211)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2564, ip=10.102.30.211)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2564, ip=10.102.30.211)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2564, ip=10.102.30.211)[0m     ------------------------------------------------------------
[36m(setup pid=2564, ip=10.102.30.211)[0m                                            Total:        2.06 GB
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2564, ip=10.102.30.211)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2564, ip=10.102.30.211)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2564, ip=10.102.30.211)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2564, ip=10.102.30.211)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2564, ip=10.102.30.211)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m The following packages will be UPDATED:
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2564, ip=10.102.30.211)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Proceed ([y]/n)? 
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=3451)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3451)[0m Preparing transaction: ...working... done
[36m(setup pid=3451)[0m Verifying transaction: ...working... done
[36m(setup pid=3451)[0m Executing transaction: ...working... done
[36m(setup pid=3451)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3451)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3451)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3451)[0m  + pip==25.2
[36m(setup pid=3451)[0m  + setuptools==80.9.0
[36m(setup pid=3451)[0m  + wheel==0.45.1
[36m(setup pid=3451)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3451)[0m Resolved 29 packages in 114ms
[36m(setup pid=3451)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3451)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3451)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3451)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3451)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3451)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3451)[0m Downloading triton (148.4MiB)
[36m(setup pid=3451)[0m Downloading torch (783.1MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3451)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3451)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3451)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing transaction: ...working... done
[36m(setup pid=3451)[0m  Downloading torchaudio
[36m(setup pid=3451)[0m  Downloading pillow
[36m(setup pid=3451)[0m  Downloading torchvision
[36m(setup pid=3451)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m Verifying transaction: ...working... done
[36m(setup pid=3451)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3451)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m Executing transaction: ...working... done
[36m(setup pid=2564, ip=10.102.30.211)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2564, ip=10.102.30.211)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2564, ip=10.102.30.211)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pip==25.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + setuptools==80.9.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + wheel==0.45.1
[36m(setup pid=2564, ip=10.102.30.211)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2564, ip=10.102.30.211)[0m Resolved 29 packages in 95ms
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading triton (148.4MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading torch (783.1MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading torchaudio
[36m(setup pid=3451)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading torchvision
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading pillow
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=3451)[0m  Downloading sympy
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading sympy
[36m(setup pid=3451)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=3451)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3451)[0m  Downloading triton
[36m(setup pid=3451)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3451)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3451)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3451)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading triton
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=3451)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3451)[0m  Downloading torch
[36m(setup pid=3451)[0m Prepared 22 packages in 22.10s
[36m(setup pid=3451)[0m Installed 28 packages in 170ms
[36m(setup pid=3451)[0m  + filelock==3.18.0
[36m(setup pid=3451)[0m  + fsspec==2025.7.0
[36m(setup pid=3451)[0m  + jinja2==3.1.6
[36m(setup pid=3451)[0m  + markupsafe==3.0.2
[36m(setup pid=3451)[0m  + mpmath==1.3.0
[36m(setup pid=3451)[0m  + networkx==3.4.2
[36m(setup pid=3451)[0m  + numpy==2.2.6
[36m(setup pid=3451)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3451)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3451)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3451)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3451)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3451)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3451)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3451)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3451)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3451)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3451)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3451)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3451)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3451)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3451)[0m  + pillow==11.3.0
[36m(setup pid=3451)[0m  + sympy==1.14.0
[36m(setup pid=3451)[0m  + torch==2.7.1
[36m(setup pid=3451)[0m  + torchaudio==2.7.1
[36m(setup pid=3451)[0m  + torchvision==0.22.1
[36m(setup pid=3451)[0m  + triton==3.3.1
[36m(setup pid=3451)[0m  + typing-extensions==4.14.1
[36m(setup pid=3451)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3451)[0m Resolved 73 packages in 383ms
[36m(setup pid=3451)[0m    Building deepspeed==0.17.4
[36m(setup pid=3451)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3451)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3451)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3451)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=3451)[0m  Downloading tokenizers
[36m(setup pid=3451)[0m  Downloading hf-xet
[36m(setup pid=3451)[0m  Downloading pyarrow
[36m(setup pid=3451)[0m  Downloading transformers
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading torch
[36m(setup pid=2564, ip=10.102.30.211)[0m Prepared 22 packages in 20.57s
[36m(setup pid=3451)[0m       Built deepspeed==0.17.4
[36m(setup pid=3451)[0m Prepared 21 packages in 1.45s
[36m(setup pid=3451)[0m Uninstalled 1 package in 0.97ms
[36m(setup pid=2564, ip=10.102.30.211)[0m Installed 28 packages in 157ms
[36m(setup pid=2564, ip=10.102.30.211)[0m  + filelock==3.18.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + fsspec==2025.7.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + jinja2==3.1.6
[36m(setup pid=2564, ip=10.102.30.211)[0m  + markupsafe==3.0.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + mpmath==1.3.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + networkx==3.4.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + numpy==2.2.6
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pillow==11.3.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + sympy==1.14.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + torch==2.7.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + torchaudio==2.7.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + torchvision==0.22.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + triton==3.3.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + typing-extensions==4.14.1
[36m(setup pid=2564, ip=10.102.30.211)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3451)[0m Installed 48 packages in 59ms
[36m(setup pid=3451)[0m  + accelerate==1.9.0
[36m(setup pid=3451)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3451)[0m  + aiohttp==3.12.15
[36m(setup pid=3451)[0m  + aiosignal==1.4.0
[36m(setup pid=3451)[0m  + annotated-types==0.7.0
[36m(setup pid=3451)[0m  + async-timeout==5.0.1
[36m(setup pid=3451)[0m  + attrs==25.3.0
[36m(setup pid=3451)[0m  + certifi==2025.8.3
[36m(setup pid=3451)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3451)[0m  + datasets==4.0.0
[36m(setup pid=3451)[0m  + deepspeed==0.17.4
[36m(setup pid=3451)[0m  + dill==0.3.8
[36m(setup pid=3451)[0m  + einops==0.8.1
[36m(setup pid=3451)[0m  + frozenlist==1.7.0
[36m(setup pid=3451)[0m  - fsspec==2025.7.0
[36m(setup pid=3451)[0m  + fsspec==2025.3.0
[36m(setup pid=3451)[0m  + hf-xet==1.1.5
[36m(setup pid=3451)[0m  + hjson==3.1.0
[36m(setup pid=3451)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3451)[0m  + idna==3.10
[36m(setup pid=3451)[0m  + liger-kernel==0.6.1
[36m(setup pid=3451)[0m  + msgpack==1.1.1
[36m(setup pid=3451)[0m  + multidict==6.6.3
[36m(setup pid=3451)[0m  + multiprocess==0.70.16
[36m(setup pid=3451)[0m  + ninja==1.11.1.4
[36m(setup pid=3451)[0m  + packaging==25.0
[36m(setup pid=3451)[0m  + pandas==2.3.1
[36m(setup pid=3451)[0m  + propcache==0.3.2
[36m(setup pid=3451)[0m  + psutil==7.0.0
[36m(setup pid=3451)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3451)[0m  + pyarrow==21.0.0
[36m(setup pid=3451)[0m  + pydantic==2.11.7
[36m(setup pid=3451)[0m  + pydantic-core==2.33.2
[36m(setup pid=3451)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3451)[0m  + pytz==2025.2
[36m(setup pid=3451)[0m  + pyyaml==6.0.2
[36m(setup pid=3451)[0m  + regex==2025.7.34
[36m(setup pid=3451)[0m  + requests==2.32.4
[36m(setup pid=3451)[0m  + safetensors==0.5.3
[36m(setup pid=3451)[0m  + six==1.17.0
[36m(setup pid=3451)[0m  + tokenizers==0.21.4
[36m(setup pid=3451)[0m  + tqdm==4.67.1
[36m(setup pid=3451)[0m  + transformers==4.54.1
[36m(setup pid=3451)[0m  + trl==0.20.0
[36m(setup pid=3451)[0m  + typing-inspection==0.4.1
[36m(setup pid=3451)[0m  + tzdata==2025.2
[36m(setup pid=3451)[0m  + urllib3==2.5.0
[36m(setup pid=3451)[0m  + xxhash==3.5.0
[36m(setup pid=3451)[0m  + yarl==1.20.1
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3451)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Resolved 73 packages in 283ms
[36m(setup pid=2564, ip=10.102.30.211)[0m    Building deepspeed==0.17.4
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading tokenizers
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading hf-xet
[36m(setup pid=3451)[0m Reading package lists...
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading pyarrow
[36m(setup pid=3451)[0m Building dependency tree...
[36m(setup pid=3451)[0m Reading state information...
[36m(setup pid=3451)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3451)[0m   libfuse2
[36m(setup pid=3451)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3451)[0m The following additional packages will be installed:
[36m(setup pid=3451)[0m   vim-common vim-runtime
[36m(setup pid=3451)[0m Suggested packages:
[36m(setup pid=3451)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3451)[0m The following NEW packages will be installed:
[36m(setup pid=3451)[0m   vmtouch
[36m(setup pid=3451)[0m The following packages will be upgraded:
[36m(setup pid=3451)[0m   vim vim-common vim-runtime
[36m(setup pid=2564, ip=10.102.30.211)[0m  Downloading transformers
[36m(setup pid=3451)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=3451)[0m Need to get 8664 kB of archives.
[36m(setup pid=3451)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3451)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=3451)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=3451)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m       Built deepspeed==0.17.4
[36m(setup pid=2564, ip=10.102.30.211)[0m Prepared 21 packages in 1.50s
[36m(setup pid=2564, ip=10.102.30.211)[0m Uninstalled 1 package in 0.98ms
[36m(setup pid=3451)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Installed 48 packages in 81ms
[36m(setup pid=2564, ip=10.102.30.211)[0m  + accelerate==1.9.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + aiohttp==3.12.15
[36m(setup pid=2564, ip=10.102.30.211)[0m  + aiosignal==1.4.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + annotated-types==0.7.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + async-timeout==5.0.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + attrs==25.3.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + certifi==2025.8.3
[36m(setup pid=2564, ip=10.102.30.211)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + datasets==4.0.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + deepspeed==0.17.4
[36m(setup pid=2564, ip=10.102.30.211)[0m  + dill==0.3.8
[36m(setup pid=2564, ip=10.102.30.211)[0m  + einops==0.8.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + frozenlist==1.7.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  - fsspec==2025.7.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + fsspec==2025.3.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + hf-xet==1.1.5
[36m(setup pid=2564, ip=10.102.30.211)[0m  + hjson==3.1.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2564, ip=10.102.30.211)[0m  + idna==3.10
[36m(setup pid=2564, ip=10.102.30.211)[0m  + liger-kernel==0.6.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + msgpack==1.1.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + multidict==6.6.3
[36m(setup pid=2564, ip=10.102.30.211)[0m  + multiprocess==0.70.16
[36m(setup pid=2564, ip=10.102.30.211)[0m  + ninja==1.11.1.4
[36m(setup pid=2564, ip=10.102.30.211)[0m  + packaging==25.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pandas==2.3.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + propcache==0.3.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + psutil==7.0.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pyarrow==21.0.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pydantic==2.11.7
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pydantic-core==2.33.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pytz==2025.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + pyyaml==6.0.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + regex==2025.7.34
[36m(setup pid=2564, ip=10.102.30.211)[0m  + requests==2.32.4
[36m(setup pid=2564, ip=10.102.30.211)[0m  + safetensors==0.5.3
[36m(setup pid=2564, ip=10.102.30.211)[0m  + six==1.17.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + tokenizers==0.21.4
[36m(setup pid=2564, ip=10.102.30.211)[0m  + tqdm==4.67.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + transformers==4.54.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + trl==0.20.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + typing-inspection==0.4.1
[36m(setup pid=2564, ip=10.102.30.211)[0m  + tzdata==2025.2
[36m(setup pid=2564, ip=10.102.30.211)[0m  + urllib3==2.5.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + xxhash==3.5.0
[36m(setup pid=2564, ip=10.102.30.211)[0m  + yarl==1.20.1
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=3451)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3451)[0m Fetched 8664 kB in 1s (16.5 MB/s)
[36m(setup pid=3451)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3451)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=3451)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3451)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3451)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3451)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Reading package lists...
[36m(setup pid=2564, ip=10.102.30.211)[0m Building dependency tree...
[36m(setup pid=2564, ip=10.102.30.211)[0m Reading state information...
[36m(setup pid=2564, ip=10.102.30.211)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2564, ip=10.102.30.211)[0m   libfuse2
[36m(setup pid=2564, ip=10.102.30.211)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2564, ip=10.102.30.211)[0m The following additional packages will be installed:
[36m(setup pid=2564, ip=10.102.30.211)[0m   vim-common vim-runtime
[36m(setup pid=2564, ip=10.102.30.211)[0m Suggested packages:
[36m(setup pid=2564, ip=10.102.30.211)[0m   ctags vim-doc vim-scripts
[36m(setup pid=2564, ip=10.102.30.211)[0m The following NEW packages will be installed:
[36m(setup pid=2564, ip=10.102.30.211)[0m   vmtouch
[36m(setup pid=2564, ip=10.102.30.211)[0m The following packages will be upgraded:
[36m(setup pid=2564, ip=10.102.30.211)[0m   vim vim-common vim-runtime
[36m(setup pid=2564, ip=10.102.30.211)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=2564, ip=10.102.30.211)[0m Need to get 8664 kB of archives.
[36m(setup pid=2564, ip=10.102.30.211)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2564, ip=10.102.30.211)[0m Fetched 8664 kB in 0s (18.3 MB/s)
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2564, ip=10.102.30.211)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3451)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3451)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3451)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3451)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=3451)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3451)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3451)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3451)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3451)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2564, ip=10.102.30.211)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=3451)[0m Reading package lists...
[36m(setup pid=3451)[0m Building dependency tree...
[36m(setup pid=3451)[0m Reading state information...
[36m(setup pid=3451)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3451)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3451)[0m   libfuse2
[36m(setup pid=3451)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3451)[0m The following additional packages will be installed:
[36m(setup pid=3451)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3451)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3451)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3451)[0m   python3.10 python3.10-minimal
[36m(setup pid=3451)[0m Suggested packages:
[36m(setup pid=3451)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2564, ip=10.102.30.211)[0m Reading package lists...
[36m(setup pid=3451)[0m The following NEW packages will be installed:
[36m(setup pid=3451)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3451)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3451)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3451)[0m The following packages will be upgraded:
[36m(setup pid=3451)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3451)[0m   python3.10 python3.10-minimal
[36m(setup pid=3451)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=3451)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3451)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3451)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Building dependency tree...
[36m(setup pid=2564, ip=10.102.30.211)[0m Reading state information...
[36m(setup pid=2564, ip=10.102.30.211)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2564, ip=10.102.30.211)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2564, ip=10.102.30.211)[0m   libfuse2
[36m(setup pid=2564, ip=10.102.30.211)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2564, ip=10.102.30.211)[0m The following additional packages will be installed:
[36m(setup pid=2564, ip=10.102.30.211)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2564, ip=10.102.30.211)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2564, ip=10.102.30.211)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2564, ip=10.102.30.211)[0m   python3.10 python3.10-minimal
[36m(setup pid=2564, ip=10.102.30.211)[0m Suggested packages:
[36m(setup pid=2564, ip=10.102.30.211)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=3451)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m The following NEW packages will be installed:
[36m(setup pid=2564, ip=10.102.30.211)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2564, ip=10.102.30.211)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2564, ip=10.102.30.211)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2564, ip=10.102.30.211)[0m The following packages will be upgraded:
[36m(setup pid=2564, ip=10.102.30.211)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2564, ip=10.102.30.211)[0m   python3.10 python3.10-minimal
[36m(setup pid=2564, ip=10.102.30.211)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=2564, ip=10.102.30.211)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2564, ip=10.102.30.211)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3451)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3451)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3451)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=3451)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=3451)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3451)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3451)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3451)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=3451)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3451)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=3451)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3451)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3451)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3451)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3451)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3451)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3451)[0m Fetched 13.7 MB in 1s (22.9 MB/s)
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3451)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=3451)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3451)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3451)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3451)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2564, ip=10.102.30.211)[0m Fetched 13.7 MB in 1s (25.2 MB/s)
[36m(setup pid=2564, ip=10.102.30.211)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3451)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3451)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3451)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3451)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3451)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3451)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3451)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3451)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3451)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3451)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3451)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3451)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3451)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3451)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3451)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3451)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3451)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3451)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3451)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3451)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3451)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3451)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3451)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=3451)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3451)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3451)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3451)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3451)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3451)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Reading package lists...
[36m(setup pid=2564, ip=10.102.30.211)[0m Building dependency tree...
[36m(setup pid=2564, ip=10.102.30.211)[0m Reading state information...
[36m(setup pid=2564, ip=10.102.30.211)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2564, ip=10.102.30.211)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2564, ip=10.102.30.211)[0m   libfuse2
[36m(setup pid=2564, ip=10.102.30.211)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2564, ip=10.102.30.211)[0m The following additional packages will be installed:
[36m(setup pid=2564, ip=10.102.30.211)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2564, ip=10.102.30.211)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2564, ip=10.102.30.211)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2564, ip=10.102.30.211)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2564, ip=10.102.30.211)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2564, ip=10.102.30.211)[0m   xdg-user-dirs
[36m(setup pid=2564, ip=10.102.30.211)[0m Suggested packages:
[36m(setup pid=2564, ip=10.102.30.211)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2564, ip=10.102.30.211)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2564, ip=10.102.30.211)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=2564, ip=10.102.30.211)[0m The following NEW packages will be installed:
[36m(setup pid=2564, ip=10.102.30.211)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2564, ip=10.102.30.211)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2564, ip=10.102.30.211)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2564, ip=10.102.30.211)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2564, ip=10.102.30.211)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2564, ip=10.102.30.211)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2564, ip=10.102.30.211)[0m The following packages will be upgraded:
[36m(setup pid=2564, ip=10.102.30.211)[0m   libsystemd0 net-tools
[36m(setup pid=2564, ip=10.102.30.211)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2564, ip=10.102.30.211)[0m Need to get 10.6 MB of archives.
[36m(setup pid=2564, ip=10.102.30.211)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3451)[0m Reading package lists...
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3451)[0m Building dependency tree...
[36m(setup pid=3451)[0m Reading state information...
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3451)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3451)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3451)[0m   libfuse2
[36m(setup pid=3451)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3451)[0m The following additional packages will be installed:
[36m(setup pid=3451)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3451)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3451)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3451)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3451)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3451)[0m   xdg-user-dirs
[36m(setup pid=3451)[0m Suggested packages:
[36m(setup pid=3451)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3451)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3451)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=2564, ip=10.102.30.211)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2564, ip=10.102.30.211)[0m Fetched 10.6 MB in 1s (16.4 MB/s)
[36m(setup pid=3451)[0m The following NEW packages will be installed:
[36m(setup pid=3451)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3451)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3451)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3451)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3451)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3451)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3451)[0m The following packages will be upgraded:
[36m(setup pid=3451)[0m   libsystemd0 net-tools
[36m(setup pid=2564, ip=10.102.30.211)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3451)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3451)[0m Need to get 10.6 MB of archives.
[36m(setup pid=3451)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3451)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package systemd.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3451)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3451)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3451)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=3451)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=3451)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package dbus.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3451)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3451)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3451)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3451)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3451)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3451)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3451)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3451)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3451)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3451)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3451)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=3451)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3451)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3451)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3451)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3451)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3451)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3451)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3451)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3451)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3451)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=3451)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=3451)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3451)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3451)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3451)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3451)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package htop.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3451)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3451)[0m Fetched 10.6 MB in 1s (16.3 MB/s)
[36m(setup pid=3451)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3451)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3451)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3451)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3451)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package systemd.
[36m(setup pid=3451)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package dbus.
[36m(setup pid=3451)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=3451)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3451)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3451)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3451)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3451)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3451)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3451)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3451)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3451)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3451)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3451)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3451)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2564, ip=10.102.30.211)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3451)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3451)[0m Selecting previously unselected package htop.
[36m(setup pid=3451)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3451)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3451)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3451)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3451)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3451)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3451)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3451)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3451)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3451)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3451)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3451)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3451)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3451)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3451)[0m No schema files found: doing nothing.
[36m(setup pid=3451)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3451)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3451)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3451)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3451)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3451)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m No schema files found: doing nothing.
[36m(setup pid=3451)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3451)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3451)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3451)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3451)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3451)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3451)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3451)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3451)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3451)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3451)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3451)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3451)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2564, ip=10.102.30.211)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2564, ip=10.102.30.211)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=3451)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer â†’ /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2564, ip=10.102.30.211)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer â†’ /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3451)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer â†’ /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2564, ip=10.102.30.211)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer â†’ /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2564, ip=10.102.30.211)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service â†’ /lib/systemd/system/sysstat.service.
[36m(setup pid=3451)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service â†’ /lib/systemd/system/sysstat.service.
[36m(setup pid=3451)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3451)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3451)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3451)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3451)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3451)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3451)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3451)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3451)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3451)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3451)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3451)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3451)[0m       D     : show the differences between the versions
[36m(setup pid=3451)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3451)[0m  The default action is to keep your current version.
[36m(setup pid=3451)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3451)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3451)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2564, ip=10.102.30.211)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2564, ip=10.102.30.211)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2564, ip=10.102.30.211)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2564, ip=10.102.30.211)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2564, ip=10.102.30.211)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2564, ip=10.102.30.211)[0m       D     : show the differences between the versions
[36m(setup pid=2564, ip=10.102.30.211)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2564, ip=10.102.30.211)[0m  The default action is to keep your current version.
[36m(setup pid=2564, ip=10.102.30.211)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2564, ip=10.102.30.211)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3451)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3451)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3451)[0m   Package systemd is not configured yet.
[36m(setup pid=3451)[0m 
[36m(setup pid=3451)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3451)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3451)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2564, ip=10.102.30.211)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2564, ip=10.102.30.211)[0m   Package systemd is not configured yet.
[36m(setup pid=2564, ip=10.102.30.211)[0m 
[36m(setup pid=2564, ip=10.102.30.211)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2564, ip=10.102.30.211)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2564, ip=10.102.30.211)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service â†’ /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2564, ip=10.102.30.211)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3451)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service â†’ /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3451)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2564, ip=10.102.30.211)[0m Errors were encountered while processing:
[36m(setup pid=2564, ip=10.102.30.211)[0m  systemd
[36m(setup pid=2564, ip=10.102.30.211)[0m  systemd-timesyncd
[36m(setup pid=2564, ip=10.102.30.211)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2564, ip=10.102.30.211)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3451)[0m Errors were encountered while processing:
[36m(setup pid=3451)[0m  systemd
[36m(setup pid=3451)[0m  systemd-timesyncd
[36m(setup pid=3451)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3451)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3451)[0m Resolved 3 packages in 137ms
[36m(setup pid=2564, ip=10.102.30.211)[0m Resolved 3 packages in 145ms
[36m(setup pid=2564, ip=10.102.30.211)[0m Prepared 1 package in 10ms
[36m(setup pid=2564, ip=10.102.30.211)[0m Installed 2 packages in 18ms
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2564, ip=10.102.30.211)[0m  + nvitop==1.5.2
[36m(setup pid=3451)[0m Prepared 1 package in 12ms
[36m(setup pid=3451)[0m Installed 2 packages in 16ms
[36m(setup pid=3451)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3451)[0m  + nvitop==1.5.2
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(head, rank=0, pid=3451)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3451)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:   2%|â–         | 1000/47780 [00:00<00:25, 1867.67 examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:  15%|â–ˆâ–        | 7000/47780 [00:00<00:02, 13645.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:  23%|â–ˆâ–ˆâ–Ž       | 11000/47780 [00:00<00:01, 19246.62 examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17000/47780 [00:00<00:01, 28773.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22000/47780 [00:01<00:00, 29495.64 examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29000/47780 [00:01<00:00, 38305.54 examples/s]
[36m(head, rank=0, pid=3451)[0m Generating train split:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36778/47780 [00:01<00:00, 48049.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Generating train split:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45446/47780 [00:01<00:00, 57551.40 examples/s]
Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:01<00:00, 32682.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3451)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:   2%|â–         | 1000/47780 [00:00<00:28, 1653.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  15%|â–ˆâ–        | 7000/47780 [00:00<00:03, 12117.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  23%|â–ˆâ–ˆâ–Ž       | 11000/47780 [00:00<00:02, 17021.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  31%|â–ˆâ–ˆâ–ˆâ–      | 15000/47780 [00:00<00:01, 20812.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19000/47780 [00:01<00:01, 24853.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23778/47780 [00:01<00:00, 29993.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30890/47780 [00:01<00:00, 40070.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36446/47780 [00:01<00:00, 36717.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41446/47780 [00:01<00:00, 25793.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Generating train split:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45224/47780 [00:01<00:00, 25198.86 examples/s]
Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:02<00:00, 22327.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3451)[0m vmtouch output: Files: 14
[36m(head, rank=0, pid=3451)[0m      Directories: 5
[36m(head, rank=0, pid=3451)[0m    Evicted Pages: 1212952 (4G)
[36m(head, rank=0, pid=3451)[0m          Elapsed: 3.699 seconds
[36m(head, rank=0, pid=3451)[0m Downloading and caching model...
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m vmtouch output: Files: 14
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m      Directories: 5
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m    Evicted Pages: 1212952 (4G)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m          Elapsed: 3.6791 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Fetching 5 files:  20%|â–ˆâ–ˆ        | 1/5 [00:25<01:40, 25.22s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Fetching 5 files:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:25<00:13,  6.75s/it]
Fetching 5 files:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:04,  4.70s/it]
Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.32s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Fetching 5 files:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.65s/it]
Fetching 5 files:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:37<00:07,  7.21s/it]
Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37<00:00,  7.60s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:17,  4.41s/it]
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08<00:12,  4.32s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12<00:08,  4.29s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:18,  4.56s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:04,  4.26s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.15s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.22s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09<00:13,  4.49s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m      Directories: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m          Elapsed: 3.4898 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed processing directory 1/2
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m vmtouch output: Files: 32
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m      Directories: 15
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m    Evicted Pages: 7163861 (27G)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m          Elapsed: 0.001281 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Processing directory 2/2: /mnt/data ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13<00:08,  4.39s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m vmtouch output: Files: 78
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m      Directories: 5
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m    Evicted Pages: 4617819 (17G)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m          Elapsed: 0.31971 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:04,  4.34s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.18s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.29s/it]
[36m(head, rank=0, pid=3451)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3451)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3451)[0m      Directories: 10
[36m(head, rank=0, pid=3451)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3451)[0m          Elapsed: 2.654 seconds
[36m(head, rank=0, pid=3451)[0m Completed processing directory 1/2
[36m(head, rank=0, pid=3451)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3451)[0m vmtouch output: Files: 32
[36m(head, rank=0, pid=3451)[0m      Directories: 15
[36m(head, rank=0, pid=3451)[0m    Evicted Pages: 7163861 (27G)
[36m(head, rank=0, pid=3451)[0m          Elapsed: 0.001297 seconds
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Processing directory 2/2: /mnt/data ===
[36m(head, rank=0, pid=3451)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3451)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3451)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3451)[0m vmtouch output: Files: 78
[36m(head, rank=0, pid=3451)[0m      Directories: 5
[36m(head, rank=0, pid=3451)[0m    Evicted Pages: 4617819 (17G)
[36m(head, rank=0, pid=3451)[0m          Elapsed: 0.2893 seconds
[36m(head, rank=0, pid=3451)[0m Downloading and caching model...
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:24,  6.12s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  5.84s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:22,  5.65s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  5.75s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:15,  5.25s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:05,  5.71s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  5.52s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  5.65s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:15<00:10,  5.11s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m      Directories: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m          Elapsed: 1.4243 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed processing directory 2/2
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m vmtouch output: Files: 96
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m      Directories: 15
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m    Evicted Pages: 10568728 (40G)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m          Elapsed: 0.11537 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Copying cached data to S3 directories ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:20<00:05,  5.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.18s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.19s/it]
[36m(head, rank=0, pid=3451)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3451)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3451)[0m      Directories: 10
[36m(head, rank=0, pid=3451)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3451)[0m          Elapsed: 1.1141 seconds
[36m(head, rank=0, pid=3451)[0m Completed processing directory 2/2
[36m(head, rank=0, pid=3451)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3451)[0m vmtouch output: Files: 96
[36m(head, rank=0, pid=3451)[0m      Directories: 15
[36m(head, rank=0, pid=3451)[0m    Evicted Pages: 10568728 (40G)
[36m(head, rank=0, pid=3451)[0m          Elapsed: 0.11304 seconds
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Copying cached data to S3 directories ===
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(head, rank=0, pid=3451)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3451)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Model cache copied successfully
[36m(head, rank=0, pid=3451)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3451)[0m Completed copying to S3 directory 1/2
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(head, rank=0, pid=3451)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3451)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed copying to S3 directory 1/2
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Model cache copied successfully
[36m(head, rank=0, pid=3451)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3451)[0m Completed copying to S3 directory 2/2
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Download and caching completed ===
[36m(head, rank=0, pid=3451)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed copying to S3 directory 2/2
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Download and caching completed ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.11 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.13 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.13 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.13 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.14 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.14 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.20 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.20 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.25 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.32 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.38 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.41 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.43 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.62 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.57 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.67 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 128.25it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 126.92it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 128.71it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 120.78it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 128.49it/s]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 0.94 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 0.93 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 0.93 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.04 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 129.37it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 130.32it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 123.97it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 123.81it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 124.26it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 126.64it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 125.36it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.18 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.11 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.32 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 133.08it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.06 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.02 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.05 seconds
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Starting Training...
[36m(head, rank=0, pid=3451)[0m Completed Load model in 0.93 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 125.17it/s]
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 0.96 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.00 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:18,  4.64s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:20,  5.13s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08<00:13,  4.38s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09<00:14,  4.77s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12<00:08,  4.24s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13<00:09,  4.51s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:04,  4.19s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.05s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.16s/it]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 21.67 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:18<00:04,  4.40s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  4.26s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  4.42s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 23.32 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:14<39:17:07,  2.96s/ examples]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:15<8:07:13,  1.63 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   0%|          | 60/47780 [00:15<1:57:06,  6.79 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   0%|          | 106/47780 [00:15<55:38, 14.28 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   0%|          | 181/47780 [00:16<26:18, 30.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   1%|          | 255/47780 [00:16<16:16, 48.68 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   1%|          | 340/47780 [00:16<10:41, 73.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   1%|          | 442/47780 [00:17<07:15, 108.60 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 603/47780 [00:17<04:29, 174.81 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 736/47780 [00:17<03:34, 219.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 893/47780 [00:18<02:53, 270.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1064/47780 [00:18<02:23, 326.20 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1246/47780 [00:18<02:03, 377.00 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1452/47780 [00:19<01:49, 423.11 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1678/47780 [00:19<01:35, 482.07 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1906/47780 [00:19<01:26, 528.18 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2157/47780 [00:20<01:19, 577.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2400/47780 [00:20<01:14, 605.73 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2651/47780 [00:21<01:11, 630.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2912/47780 [00:21<01:07, 664.85 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3196/47780 [00:21<01:06, 670.71 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3527/47780 [00:22<01:00, 729.67 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3864/47780 [00:22<01:01, 719.46 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4244/47780 [00:23<00:58, 741.90 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4704/47780 [00:23<00:52, 813.90 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5164/47780 [00:24<00:50, 849.92 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5629/47780 [00:24<00:46, 899.38 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6134/47780 [00:24<00:33, 1250.19 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6344/47780 [00:24<00:34, 1201.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6523/47780 [00:25<00:35, 1146.35 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6677/47780 [00:25<00:36, 1141.68 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6818/47780 [00:25<00:36, 1129.33 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6957/47780 [00:25<00:35, 1141.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7087/47780 [00:25<00:36, 1111.54 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7207/47780 [00:25<00:36, 1096.62 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7333/47780 [00:25<00:35, 1127.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7453/47780 [00:25<00:35, 1142.07 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7572/47780 [00:26<00:35, 1141.00 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7709/47780 [00:26<00:33, 1190.59 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7838/47780 [00:26<00:32, 1211.68 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7977/47780 [00:26<00:31, 1256.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8108/47780 [00:26<00:32, 1229.45 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8234/47780 [00:26<00:32, 1227.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8358/47780 [00:26<00:33, 1159.94 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8485/47780 [00:26<00:33, 1182.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8609/47780 [00:26<00:32, 1192.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8739/47780 [00:26<00:32, 1219.13 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8864/47780 [00:27<00:32, 1212.60 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8987/47780 [00:27<00:33, 1167.39 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9106/47780 [00:27<00:33, 1161.40 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9224/47780 [00:27<00:33, 1147.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9342/47780 [00:27<00:33, 1154.38 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9459/47780 [00:27<00:33, 1157.38 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9575/47780 [00:27<00:34, 1100.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9692/47780 [00:27<00:34, 1118.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9806/47780 [00:27<00:34, 1095.64 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9926/47780 [00:28<00:33, 1121.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10041/47780 [00:28<00:33, 1115.59 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10155/47780 [00:28<00:34, 1081.28 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10269/47780 [00:28<00:34, 1089.35 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10399/47780 [00:28<00:33, 1129.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10522/47780 [00:28<00:32, 1137.46 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10640/47780 [00:28<00:33, 1112.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10773/47780 [00:28<00:31, 1172.90 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10892/47780 [00:28<00:33, 1103.86 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11016/47780 [00:29<00:32, 1137.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11134/47780 [00:29<00:31, 1145.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11260/47780 [00:29<00:31, 1166.47 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11378/47780 [00:29<00:31, 1158.87 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11495/47780 [00:29<00:31, 1154.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11611/47780 [00:29<00:32, 1129.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11735/47780 [00:29<00:31, 1159.18 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11852/47780 [00:29<00:31, 1153.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11969/47780 [00:29<00:31, 1146.43 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12098/47780 [00:29<00:30, 1185.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12218/47780 [00:30<00:30, 1175.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12342/47780 [00:30<00:29, 1192.86 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12470/47780 [00:30<00:29, 1193.88 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12591/47780 [00:30<00:29, 1173.04 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12724/47780 [00:30<00:28, 1211.08 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12848/47780 [00:30<00:29, 1193.77 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12968/47780 [00:30<00:29, 1173.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13099/47780 [00:30<00:28, 1204.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13221/47780 [00:30<00:29, 1189.27 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13343/47780 [00:31<00:29, 1170.79 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13462/47780 [00:31<00:30, 1118.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13575/47780 [00:31<00:31, 1083.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13688/47780 [00:31<00:32, 1061.87 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13795/47780 [00:31<00:32, 1038.67 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13917/47780 [00:31<00:31, 1080.12 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14029/47780 [00:31<00:31, 1087.24 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14138/47780 [00:31<00:31, 1058.57 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14249/47780 [00:31<00:32, 1041.19 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14375/47780 [00:31<00:30, 1098.42 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14487/47780 [00:32<00:30, 1101.60 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14618/47780 [00:32<00:28, 1158.22 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14745/47780 [00:32<00:27, 1185.29 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14866/47780 [00:32<00:27, 1183.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14991/47780 [00:32<00:27, 1194.05 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15112/47780 [00:32<00:28, 1141.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15238/47780 [00:32<00:28, 1161.39 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15358/47780 [00:32<00:28, 1153.22 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15474/47780 [00:32<00:28, 1135.46 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15591/47780 [00:33<00:28, 1144.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15714/47780 [00:33<00:27, 1156.26 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15830/47780 [00:33<00:27, 1147.85 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15951/47780 [00:33<00:27, 1161.80 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16087/47780 [00:33<00:26, 1203.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16208/47780 [00:33<00:26, 1196.41 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16354/47780 [00:33<00:24, 1271.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16484/47780 [00:33<00:25, 1233.17 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16613/47780 [00:33<00:25, 1246.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16738/47780 [00:33<00:25, 1198.38 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16859/47780 [00:34<00:26, 1180.78 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16980/47780 [00:34<00:26, 1176.36 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17103/47780 [00:34<00:25, 1184.77 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17224/47780 [00:34<00:25, 1191.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17350/47780 [00:34<00:25, 1205.69 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17471/47780 [00:34<00:25, 1200.37 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17599/47780 [00:34<00:24, 1220.66 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17722/47780 [00:34<00:24, 1209.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17847/47780 [00:34<00:25, 1184.92 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17968/47780 [00:35<00:25, 1154.88 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18085/47780 [00:35<00:25, 1155.84 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18201/47780 [00:35<00:26, 1113.14 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18325/47780 [00:35<00:25, 1144.19 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18441/47780 [00:35<00:26, 1108.08 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18565/47780 [00:35<00:25, 1144.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18680/47780 [00:35<00:25, 1126.98 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18794/47780 [00:35<00:26, 1114.12 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18922/47780 [00:35<00:25, 1144.12 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19041/47780 [00:35<00:24, 1156.91 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19157/47780 [00:36<00:24, 1150.05 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19273/47780 [00:36<00:24, 1142.12 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19389/47780 [00:36<00:25, 1124.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19516/47780 [00:36<00:24, 1155.94 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19636/47780 [00:36<00:24, 1166.65 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19759/47780 [00:36<00:23, 1178.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19877/47780 [00:36<00:23, 1167.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19994/47780 [00:36<00:23, 1161.12 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20114/47780 [00:36<00:23, 1163.96 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20232/47780 [00:36<00:23, 1159.32 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20352/47780 [00:37<00:23, 1168.41 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20470/47780 [00:37<00:24, 1123.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20583/47780 [00:37<00:25, 1081.66 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20693/47780 [00:37<00:24, 1084.17 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20802/47780 [00:37<00:24, 1083.26 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20912/47780 [00:37<00:25, 1058.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21019/47780 [00:37<00:25, 1056.83 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21127/47780 [00:37<00:25, 1046.05 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21237/47780 [00:37<00:25, 1061.51 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21375/47780 [00:38<00:22, 1150.25 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21494/47780 [00:38<00:22, 1155.83 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21611/47780 [00:38<00:22, 1149.96 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21729/47780 [00:38<00:22, 1155.46 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21846/47780 [00:38<00:22, 1141.52 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21963/47780 [00:38<00:23, 1089.61 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22079/47780 [00:38<00:23, 1105.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22206/47780 [00:38<00:22, 1151.79 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22323/47780 [00:38<00:22, 1135.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22437/47780 [00:38<00:22, 1108.83 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22550/47780 [00:39<00:22, 1097.47 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22673/47780 [00:39<00:22, 1124.86 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22810/47780 [00:39<00:20, 1192.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22932/47780 [00:39<00:21, 1180.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23052/47780 [00:39<00:21, 1126.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23169/47780 [00:39<00:21, 1135.56 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23284/47780 [00:39<00:21, 1124.81 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23415/47780 [00:39<00:20, 1177.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23536/47780 [00:39<00:20, 1166.71 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23668/47780 [00:40<00:20, 1196.50 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23789/47780 [00:40<00:20, 1144.28 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23905/47780 [00:40<00:22, 1047.65 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24013/47780 [00:40<00:23, 1030.88 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24119/47780 [00:40<00:23, 1012.20 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24224/47780 [00:40<00:23, 990.72 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24324/47780 [00:40<00:23, 980.43 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24424/47780 [00:40<00:24, 968.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24528/47780 [00:40<00:23, 987.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24627/47780 [00:41<00:24, 944.29 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24740/47780 [00:41<00:23, 996.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24842/47780 [00:41<00:23, 992.96 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24942/47780 [00:41<00:24, 946.80 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25049/47780 [00:41<00:23, 977.82 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25158/47780 [00:41<00:22, 995.71 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25261/47780 [00:41<00:23, 977.27 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25366/47780 [00:41<00:22, 984.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25482/47780 [00:41<00:22, 986.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25587/47780 [00:42<00:22, 997.65 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25694/47780 [00:42<00:21, 1017.09 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25797/47780 [00:42<00:22, 994.18 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25905/47780 [00:42<00:21, 1013.03 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26008/47780 [00:42<00:22, 977.89 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26109/47780 [00:42<00:22, 984.82 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26208/47780 [00:42<00:23, 935.46 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26303/47780 [00:42<00:24, 883.66 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26398/47780 [00:42<00:23, 900.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26490/47780 [00:42<00:24, 875.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26579/47780 [00:43<00:25, 832.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26667/47780 [00:43<00:25, 838.86 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26752/47780 [00:43<00:25, 811.19 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26835/47780 [00:43<00:26, 795.39 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26915/47780 [00:43<00:26, 795.84 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26995/47780 [00:43<00:27, 759.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27072/47780 [00:43<00:27, 755.57 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27153/47780 [00:43<00:26, 769.78 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27246/47780 [00:43<00:25, 811.56 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27344/47780 [00:44<00:23, 855.22 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27431/47780 [00:44<00:24, 814.28 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27513/47780 [00:44<00:25, 783.66 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27602/47780 [00:44<00:24, 807.17 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27688/47780 [00:44<00:24, 814.22 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27784/47780 [00:44<00:23, 853.78 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27882/47780 [00:44<00:22, 884.66 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27972/47780 [00:44<00:22, 864.48 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28080/47780 [00:44<00:21, 926.40 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28175/47780 [00:45<00:21, 916.94 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28279/47780 [00:45<00:20, 951.61 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28386/47780 [00:45<00:19, 977.39 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28485/47780 [00:45<00:20, 938.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28587/47780 [00:45<00:19, 959.67 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28684/47780 [00:45<00:20, 935.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28790/47780 [00:45<00:19, 962.73 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28895/47780 [00:45<00:19, 983.24 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28997/47780 [00:45<00:18, 992.92 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29102/47780 [00:45<00:18, 998.91 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29203/47780 [00:46<00:18, 977.90 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29304/47780 [00:46<00:19, 928.99 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29402/47780 [00:46<00:19, 928.71 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29497/47780 [00:46<00:20, 908.95 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29591/47780 [00:46<00:19, 910.48 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29687/47780 [00:46<00:19, 917.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29780/47780 [00:46<00:20, 869.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29869/47780 [00:46<00:20, 853.01 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29956/47780 [00:46<00:21, 826.05 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30042/47780 [00:47<00:21, 834.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30127/47780 [00:47<00:21, 814.76 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30209/47780 [00:47<00:21, 800.25 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30291/47780 [00:47<00:22, 786.91 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30371/47780 [00:47<00:23, 756.20 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30463/47780 [00:47<00:21, 799.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30569/47780 [00:47<00:19, 863.60 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30665/47780 [00:47<00:19, 890.29 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30762/47780 [00:47<00:18, 908.33 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30867/47780 [00:47<00:17, 949.50 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30971/47780 [00:48<00:17, 952.67 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31068/47780 [00:48<00:18, 925.19 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31162/47780 [00:48<00:18, 900.00 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31257/47780 [00:48<00:18, 898.85 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31352/47780 [00:48<00:18, 901.81 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31444/47780 [00:48<00:18, 876.25 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31541/47780 [00:48<00:18, 899.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31650/47780 [00:48<00:17, 941.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31745/47780 [00:48<00:17, 921.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31847/47780 [00:49<00:16, 949.75 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31944/47780 [00:49<00:17, 923.07 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32046/47780 [00:49<00:16, 949.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32150/47780 [00:49<00:16, 967.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32251/47780 [00:49<00:15, 976.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32350/47780 [00:49<00:16, 911.42 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32443/47780 [00:49<00:17, 886.96 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32553/47780 [00:49<00:16, 914.27 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32649/47780 [00:49<00:16, 914.68 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32741/47780 [00:50<00:16, 898.09 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32833/47780 [00:50<00:17, 869.38 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32924/47780 [00:50<00:17, 847.91 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33027/47780 [00:50<00:16, 882.30 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33140/47780 [00:50<00:15, 947.67 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33263/47780 [00:50<00:14, 1026.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33372/47780 [00:50<00:14, 1019.11 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33476/47780 [00:50<00:14, 1002.99 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33577/47780 [00:50<00:14, 956.53 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33690/47780 [00:51<00:14, 997.27 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33795/47780 [00:51<00:14, 959.83 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33893/47780 [00:51<00:14, 948.37 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33990/47780 [00:51<00:14, 922.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34084/47780 [00:51<00:15, 896.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34190/47780 [00:51<00:14, 939.41 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34285/47780 [00:51<00:14, 929.68 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34388/47780 [00:51<00:14, 952.69 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34485/47780 [00:51<00:14, 921.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34586/47780 [00:52<00:14, 925.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34680/47780 [00:52<00:14, 929.17 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34774/47780 [00:52<00:14, 921.04 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34880/47780 [00:52<00:13, 932.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34978/47780 [00:52<00:13, 931.14 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35083/47780 [00:52<00:13, 963.98 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35184/47780 [00:52<00:12, 970.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35282/47780 [00:52<00:12, 964.79 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35388/47780 [00:52<00:12, 985.86 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35507/47780 [00:52<00:11, 1036.99 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35612/47780 [00:53<00:12, 954.21 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35712/47780 [00:53<00:12, 949.94 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35809/47780 [00:53<00:13, 901.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35905/47780 [00:53<00:12, 914.45 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36003/47780 [00:53<00:12, 915.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36097/47780 [00:53<00:12, 912.35 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36191/47780 [00:53<00:12, 908.75 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36294/47780 [00:53<00:12, 942.36 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36395/47780 [00:53<00:12, 931.88 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36499/47780 [00:54<00:11, 949.56 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36609/47780 [00:54<00:11, 981.52 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36710/47780 [00:54<00:11, 974.76 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36809/47780 [00:54<00:11, 944.27 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36905/47780 [00:54<00:11, 941.61 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37017/47780 [00:54<00:10, 986.16 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37117/47780 [00:54<00:10, 984.15 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37216/47780 [00:54<00:11, 945.25 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37316/47780 [00:54<00:11, 938.17 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37423/47780 [00:54<00:10, 966.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37533/47780 [00:55<00:10, 988.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37637/47780 [00:55<00:10, 1003.28 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37748/47780 [00:55<00:09, 1031.78 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37871/47780 [00:55<00:09, 1084.80 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37981/47780 [00:55<00:09, 1030.28 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38088/47780 [00:55<00:09, 1020.14 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38192/47780 [00:55<00:09, 979.20 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38291/47780 [00:55<00:09, 972.46 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38389/47780 [00:55<00:09, 964.15 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38505/47780 [00:56<00:09, 1018.63 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38618/47780 [00:56<00:08, 1043.40 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38724/47780 [00:56<00:09, 963.20 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38841/47780 [00:56<00:08, 1010.83 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38957/47780 [00:56<00:08, 1049.85 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39078/47780 [00:56<00:07, 1094.81 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39190/47780 [00:56<00:08, 1029.88 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39295/47780 [00:56<00:08, 977.51 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39395/47780 [00:56<00:08, 976.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39494/47780 [00:57<00:08, 945.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39614/47780 [00:57<00:08, 1009.73 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39717/47780 [00:57<00:08, 984.20 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39820/47780 [00:57<00:08, 978.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39932/47780 [00:57<00:07, 1013.32 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40035/47780 [00:57<00:07, 1014.72 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40152/47780 [00:57<00:07, 1049.29 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40258/47780 [00:57<00:07, 1015.52 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40364/47780 [00:57<00:07, 1021.07 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40471/47780 [00:57<00:07, 983.14 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40590/47780 [00:58<00:06, 1041.00 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40695/47780 [00:58<00:07, 1009.27 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40799/47780 [00:58<00:07, 989.33 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40899/47780 [00:58<00:07, 980.79 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41004/47780 [00:58<00:06, 1000.13 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41107/47780 [00:58<00:06, 1001.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41208/47780 [00:58<00:06, 976.17 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41309/47780 [00:58<00:06, 978.94 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41413/47780 [00:58<00:06, 990.30 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41529/47780 [00:59<00:06, 1005.08 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41632/47780 [00:59<00:06, 982.00 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41732/47780 [00:59<00:06, 964.09 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41830/47780 [00:59<00:06, 930.91 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41925/47780 [00:59<00:06, 924.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42035/47780 [00:59<00:05, 963.78 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42149/47780 [00:59<00:05, 1003.41 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42251/47780 [00:59<00:05, 961.71 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42353/47780 [00:59<00:05, 924.90 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42447/47780 [01:00<00:05, 916.26 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42539/47780 [01:00<00:05, 898.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42634/47780 [01:00<00:05, 906.52 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42742/47780 [01:00<00:05, 952.98 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42839/47780 [01:00<00:05, 942.54 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42937/47780 [01:00<00:05, 949.66 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43052/47780 [01:00<00:04, 997.61 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43152/47780 [01:00<00:04, 952.97 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43248/47780 [01:00<00:04, 922.71 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43367/47780 [01:00<00:04, 990.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43467/47780 [01:01<00:04, 959.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43566/47780 [01:01<00:04, 904.25 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43659/47780 [01:01<00:04, 906.19 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43751/47780 [01:01<00:04, 856.91 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43838/47780 [01:01<00:05, 774.79 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43920/47780 [01:01<00:04, 773.55 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43999/47780 [01:01<00:05, 740.73 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44090/47780 [01:01<00:04, 768.09 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44169/47780 [01:02<00:04, 747.57 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44246/47780 [01:02<00:04, 739.28 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44322/47780 [01:02<00:05, 686.31 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44392/47780 [01:02<00:05, 673.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44469/47780 [01:02<00:04, 679.04 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44538/47780 [01:02<00:04, 673.47 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44607/47780 [01:02<00:04, 657.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44674/47780 [01:02<00:04, 630.22 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44744/47780 [01:02<00:04, 640.97 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44818/47780 [01:03<00:04, 660.36 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44887/47780 [01:03<00:04, 654.65 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44954/47780 [01:03<00:04, 654.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45027/47780 [01:03<00:04, 670.94 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45105/47780 [01:03<00:03, 695.15 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45176/47780 [01:03<00:04, 649.59 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45248/47780 [01:03<00:03, 662.62 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45321/47780 [01:03<00:03, 679.50 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45390/47780 [01:03<00:03, 657.07 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45457/47780 [01:04<00:03, 644.95 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45522/47780 [01:04<00:03, 620.24 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45585/47780 [01:04<00:03, 612.44 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45660/47780 [01:04<00:03, 649.25 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45726/47780 [01:04<00:03, 645.00 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45793/47780 [01:04<00:03, 632.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45857/47780 [01:04<00:03, 571.93 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45917/47780 [01:04<00:03, 576.32 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45977/47780 [01:04<00:03, 572.32 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46035/47780 [01:05<00:03, 536.64 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46091/47780 [01:05<00:03, 514.60 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46144/47780 [01:05<00:03, 511.20 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46196/47780 [01:05<00:03, 511.14 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46250/47780 [01:05<00:03, 479.56 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46310/47780 [01:05<00:02, 506.02 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46363/47780 [01:05<00:02, 499.52 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46416/47780 [01:05<00:02, 479.87 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46466/47780 [01:05<00:02, 459.87 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46514/47780 [01:06<00:03, 416.11 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46558/47780 [01:06<00:03, 401.36 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46603/47780 [01:06<00:02, 402.70 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46646/47780 [01:06<00:02, 400.87 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46687/47780 [01:06<00:02, 391.50 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46727/47780 [01:06<00:02, 381.84 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46767/47780 [01:06<00:02, 369.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46812/47780 [01:06<00:02, 386.15 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46854/47780 [01:06<00:02, 392.40 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46896/47780 [01:07<00:02, 374.81 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46934/47780 [01:07<00:02, 344.21 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46971/47780 [01:07<00:02, 332.43 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47010/47780 [01:07<00:02, 329.80 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47058/47780 [01:07<00:01, 366.58 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47099/47780 [01:07<00:01, 353.74 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47136/47780 [01:07<00:01, 344.52 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47172/47780 [01:07<00:01, 319.77 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47206/47780 [01:08<00:01, 294.75 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47239/47780 [01:08<00:01, 290.40 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47269/47780 [01:08<00:01, 284.68 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47298/47780 [01:08<00:01, 247.13 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47324/47780 [01:08<00:01, 235.08 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47349/47780 [01:08<00:02, 208.35 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47372/47780 [01:08<00:02, 191.63 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47395/47780 [01:09<00:02, 191.64 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47416/47780 [01:09<00:02, 175.53 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47434/47780 [01:09<00:02, 161.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47453/47780 [01:09<00:02, 154.65 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47470/47780 [01:09<00:02, 145.98 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47486/47780 [01:09<00:02, 136.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47501/47780 [01:09<00:02, 127.65 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47520/47780 [01:09<00:01, 138.10 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47539/47780 [01:10<00:01, 147.85 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47555/47780 [01:10<00:01, 150.87 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47571/47780 [01:10<00:01, 148.17 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47593/47780 [01:10<00:01, 159.06 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47610/47780 [01:10<00:01, 140.41 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47628/47780 [01:10<00:01, 129.11 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47642/47780 [01:10<00:01, 125.64 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47657/47780 [01:11<00:01, 121.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47674/47780 [01:11<00:00, 126.86 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47687/47780 [01:11<00:00, 120.12 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47701/47780 [01:11<00:00, 111.45 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47713/47780 [01:11<00:00, 105.23 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47725/47780 [01:11<00:00, 100.96 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47738/47780 [01:11<00:00, 87.10 examples/s] 
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47749/47780 [01:11<00:00, 85.33 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47760/47780 [01:12<00:00, 83.34 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47771/47780 [01:12<00:00, 84.11 examples/s]
[36m(head, rank=0, pid=3451)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [01:13<00:00, 21.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [01:15<00:00, 630.47 examples/s]
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3451)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:13<10:25, 74.78 examples/s]
[36m(head, rank=0, pid=3451)[0m Truncating train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13000/47780 [00:13<00:25, 1341.26 examples/s]
[36m(head, rank=0, pid=3451)[0m Truncating train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35946/47780 [00:13<00:02, 4731.27 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:20<00:00, 2355.54 examples/s]
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:27,894] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3451)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,585] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,597] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,600] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,606] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,612] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,619] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:28,637] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,289] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,289] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,289] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,289] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,289] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,289] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,290] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 18:52:30,290] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:02<6:29:01,  2.05 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:39:33,  2.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:02<6:54:30,  1.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:39:39,  2.34 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:47:46,  2.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 18/47780 [00:02<1:33:30,  8.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:58:14,  2.22 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<6:23:44,  2.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 33/47780 [00:02<55:24, 14.36 examples/s] 
Tokenizing train dataset (num_proc=32):   0%|          | 11/47780 [00:02<3:05:20,  4.30 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 15/47780 [00:02<2:10:21,  6.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:02<2:02:33,  6.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 30/47780 [00:03<1:00:16, 13.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 22/47780 [00:03<1:31:29,  8.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 35/47780 [00:03<58:35, 13.58 examples/s] 
Tokenizing train dataset (num_proc=32):   0%|          | 33/47780 [00:03<53:21, 14.91 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 44/47780 [00:03<40:46, 19.51 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 40/47780 [00:03<45:11, 17.61 examples/s]  
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 75/47780 [00:03<25:23, 31.31 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 59/47780 [00:03<32:09, 24.73 examples/s]  
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 44/47780 [00:03<46:04, 17.27 examples/s]  
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 61/47780 [00:03<28:37, 27.78 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 67/47780 [00:03<31:13, 25.47 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 78/47780 [00:03<23:20, 34.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 77/47780 [00:03<22:57, 34.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 153/47780 [00:03<12:39, 62.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 107/47780 [00:04<18:06, 43.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 106/47780 [00:04<16:53, 47.02 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 121/47780 [00:04<16:43, 47.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 122/47780 [00:04<14:19, 55.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 154/47780 [00:04<11:21, 69.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 153/47780 [00:04<11:53, 66.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 245/47780 [00:04<08:33, 92.55 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 215/47780 [00:04<07:54, 100.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 218/47780 [00:04<07:47, 101.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 196/47780 [00:04<10:28, 75.68 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 229/47780 [00:04<08:31, 92.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 188/47780 [00:04<12:00, 66.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 227/47780 [00:04<09:19, 84.95 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 335/47780 [00:04<06:44, 117.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 285/47780 [00:05<06:44, 117.38 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 301/47780 [00:05<06:50, 115.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 290/47780 [00:05<07:39, 103.25 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 261/47780 [00:05<08:53, 89.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 310/47780 [00:05<06:54, 114.49 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 416/47780 [00:05<05:51, 134.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 361/47780 [00:05<05:54, 133.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 371/47780 [00:05<06:00, 131.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 429/47780 [00:05<04:43, 166.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 412/47780 [00:05<05:26, 145.03 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 395/47780 [00:05<06:43, 117.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 358/47780 [00:05<07:19, 107.95 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 501/47780 [00:06<04:36, 171.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 491/47780 [00:06<06:08, 128.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 543/47780 [00:06<04:10, 188.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 449/47780 [00:06<06:33, 120.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 512/47780 [00:06<05:01, 156.77 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 554/47780 [00:06<04:47, 164.33 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 689/47780 [00:06<03:23, 231.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 689/47780 [00:06<03:49, 205.08 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 641/47780 [00:06<04:15, 184.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 476/47780 [00:06<06:09, 128.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 620/47780 [00:06<03:42, 211.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 652/47780 [00:06<04:10, 187.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 650/47780 [00:06<04:33, 172.50 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 829/47780 [00:07<03:25, 228.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 838/47780 [00:07<03:41, 212.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 676/47780 [00:07<04:47, 163.84 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 836/47780 [00:07<03:34, 218.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 674/47780 [00:07<04:39, 168.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 812/47780 [00:07<03:49, 204.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 851/47780 [00:07<03:41, 211.47 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:07<03:11, 243.70 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1009/47780 [00:07<03:02, 256.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1031/47780 [00:07<02:28, 314.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1028/47780 [00:07<03:17, 236.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 790/47780 [00:07<04:26, 176.36 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 886/47780 [00:08<03:54, 200.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 950/47780 [00:08<02:48, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1079/47780 [00:08<02:36, 297.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1007/47780 [00:08<03:20, 232.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1146/47780 [00:08<03:15, 239.06 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1098/47780 [00:08<03:16, 237.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1135/47780 [00:08<03:21, 231.90 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1207/47780 [00:08<03:10, 244.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1257/47780 [00:08<02:17, 339.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1018/47780 [00:08<03:37, 214.66 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1146/47780 [00:08<02:34, 301.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1141/47780 [00:08<03:24, 227.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1177/47780 [00:08<03:16, 237.40 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1324/47780 [00:09<03:05, 250.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1316/47780 [00:09<03:06, 249.00 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1499/47780 [00:09<02:11, 352.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1414/47780 [00:09<02:56, 263.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1335/47780 [00:09<03:16, 236.93 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1497/47780 [00:09<02:12, 348.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1216/47780 [00:09<03:31, 220.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1330/47780 [00:09<02:34, 300.45 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1355/47780 [00:09<03:11, 242.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1286/47780 [00:09<03:47, 204.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1550/47780 [00:09<02:43, 282.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1532/47780 [00:09<02:15, 341.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1589/47780 [00:09<02:57, 259.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1586/47780 [00:09<02:58, 258.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1572/47780 [00:10<03:21, 228.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1401/47780 [00:10<03:37, 213.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1501/47780 [00:10<02:43, 283.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1573/47780 [00:10<02:57, 260.73 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1741/47780 [00:10<02:45, 278.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1757/47780 [00:10<02:10, 352.46 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1986/47780 [00:10<01:51, 412.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1623/47780 [00:10<03:02, 252.96 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1767/47780 [00:10<02:19, 330.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1789/47780 [00:10<02:54, 263.14 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1726/47780 [00:10<03:16, 234.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2037/47780 [00:10<01:56, 391.27 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1953/47780 [00:10<02:00, 381.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1771/47780 [00:10<03:11, 240.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2052/47780 [00:11<01:55, 396.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1829/47780 [00:11<03:00, 254.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2049/47780 [00:11<01:57, 387.83 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1569/47780 [00:11<04:55, 156.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2075/47780 [00:11<02:43, 278.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2049/47780 [00:11<02:41, 283.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2217/47780 [00:11<01:54, 396.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2122/47780 [00:11<02:51, 265.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2348/47780 [00:11<01:55, 393.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1849/47780 [00:11<04:02, 189.25 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1622/47780 [00:12<06:41, 114.98 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2157/47780 [00:12<03:47, 200.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2317/47780 [00:12<02:41, 281.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1863/47780 [00:12<03:02, 252.00 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2397/47780 [00:12<02:23, 315.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2154/47780 [00:12<03:42, 205.09 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2459/47780 [00:12<02:40, 282.47 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2153/47780 [00:12<03:33, 213.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2600/47780 [00:12<01:47, 418.68 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2455/47780 [00:12<02:00, 375.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1909/47780 [00:12<05:17, 144.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2446/47780 [00:12<01:44, 433.30 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2276/47780 [00:13<04:03, 186.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2467/47780 [00:13<03:19, 226.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2708/47780 [00:13<01:49, 413.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2315/47780 [00:13<04:04, 185.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2629/47780 [00:13<03:02, 247.53 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2693/47780 [00:13<02:49, 265.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2777/47780 [00:13<02:21, 318.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2919/47780 [00:13<01:46, 421.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2597/47780 [00:13<02:53, 260.49 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2737/47780 [00:13<02:18, 325.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2632/47780 [00:13<02:24, 311.49 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2824/47780 [00:14<01:52, 399.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3028/47780 [00:14<01:55, 387.14 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1954/47780 [00:14<05:46, 132.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2813/47780 [00:14<02:57, 253.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3023/47780 [00:14<01:54, 392.44 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2348/47780 [00:14<06:19, 119.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2421/47780 [00:14<04:52, 154.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2947/47780 [00:14<02:38, 282.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3198/47780 [00:14<01:50, 401.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2968/47780 [00:14<02:21, 316.70 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3088/47780 [00:14<01:59, 373.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3140/47780 [00:14<02:37, 283.78 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3336/47780 [00:15<02:13, 333.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2486/47780 [00:15<06:14, 120.80 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 2021/47780 [00:15<07:21, 103.63 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2909/47780 [00:15<01:57, 383.35 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3441/47780 [00:15<02:01, 364.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2850/47780 [00:15<04:03, 184.26 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2679/47780 [00:15<01:59, 376.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3021/47780 [00:15<02:52, 259.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2967/47780 [00:15<01:26, 516.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3269/47780 [00:15<02:59, 248.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3537/47780 [00:15<01:45, 419.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3196/47780 [00:16<03:14, 229.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3426/47780 [00:16<02:04, 355.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3130/47780 [00:16<03:24, 218.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3531/47780 [00:16<03:09, 233.95 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3780/47780 [00:16<01:56, 376.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3462/47780 [00:16<01:42, 431.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3587/47780 [00:16<01:32, 476.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3857/47780 [00:16<01:07, 649.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3114/47780 [00:16<06:16, 118.56 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3478/47780 [00:16<02:55, 252.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3209/47780 [00:16<02:10, 341.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3401/47780 [00:17<01:44, 423.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3237/47780 [00:17<04:01, 184.17 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3592/47780 [00:17<01:58, 373.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3662/47780 [00:17<03:20, 220.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3810/47780 [00:17<02:31, 289.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3550/47780 [00:17<03:28, 212.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3944/47780 [00:17<01:46, 410.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3630/47780 [00:17<03:22, 218.16 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3894/47780 [00:17<03:28, 210.73 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 4020/47780 [00:17<02:02, 357.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 4048/47780 [00:17<01:47, 407.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4272/47780 [00:18<01:48, 402.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3737/47780 [00:18<02:30, 292.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3893/47780 [00:18<01:58, 371.45 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4436/47780 [00:18<01:45, 409.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3932/47780 [00:18<03:32, 206.17 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3580/47780 [00:18<02:53, 254.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 4012/47780 [00:18<03:04, 237.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3884/47780 [00:18<01:54, 384.20 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4274/47780 [00:18<02:08, 337.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4224/47780 [00:18<01:16, 568.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4466/47780 [00:18<01:40, 430.31 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 4011/47780 [00:18<02:29, 292.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4589/47780 [00:18<01:29, 484.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4243/47780 [00:19<02:28, 293.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4639/47780 [00:19<01:30, 477.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4266/47780 [00:19<02:46, 261.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4420/47780 [00:19<02:07, 340.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4564/47780 [00:19<03:00, 239.99 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4446/47780 [00:19<01:50, 391.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4794/47780 [00:19<02:03, 347.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4776/47780 [00:19<01:15, 567.58 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4706/47780 [00:20<03:02, 236.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4243/47780 [00:20<03:26, 211.31 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4890/47780 [00:20<02:11, 326.76 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4493/47780 [00:20<02:15, 320.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4986/47780 [00:20<01:29, 477.72 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4856/47780 [00:20<02:13, 320.98 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5116/47780 [00:20<01:30, 470.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4614/47780 [00:20<01:54, 376.96 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5153/47780 [00:20<01:34, 451.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4114/47780 [00:20<04:35, 158.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4503/47780 [00:20<02:38, 273.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4505/47780 [00:20<03:58, 181.45 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4914/47780 [00:21<01:50, 388.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4921/47780 [00:21<03:06, 229.95 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5139/47780 [00:21<01:22, 516.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5311/47780 [00:21<01:40, 423.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5262/47780 [00:22<02:47, 253.15 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5143/47780 [00:22<02:34, 276.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5575/47780 [00:22<01:40, 419.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4733/47780 [00:22<03:56, 182.11 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5021/47780 [00:22<02:18, 307.72 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4700/47780 [00:22<03:30, 204.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5319/47780 [00:22<02:28, 286.57 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4842/47780 [00:22<02:53, 246.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5717/47780 [00:22<01:25, 491.59 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5233/47780 [00:22<01:41, 419.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5951/47780 [00:22<01:06, 626.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5486/47780 [00:22<02:55, 240.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5257/47780 [00:23<03:22, 210.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5654/47780 [00:23<01:52, 376.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5741/47780 [00:23<02:42, 258.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6074/47780 [00:23<01:39, 417.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5350/47780 [00:24<03:59, 177.20 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5654/47780 [00:24<03:25, 205.11 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5828/47780 [00:24<02:10, 322.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5673/47780 [00:24<02:38, 265.06 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5915/47780 [00:24<02:17, 303.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6198/47780 [00:24<01:21, 510.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6301/47780 [00:24<01:22, 500.75 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5166/47780 [00:24<03:58, 178.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5447/47780 [00:24<02:41, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5668/47780 [00:24<01:52, 373.44 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5825/47780 [00:24<01:41, 412.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6166/47780 [00:24<02:24, 287.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6086/47780 [00:24<01:17, 538.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6608/47780 [00:24<01:24, 484.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5850/47780 [00:25<02:49, 247.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6368/47780 [00:25<01:31, 452.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6255/47780 [00:25<02:46, 249.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6664/47780 [00:25<01:36, 425.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6392/47780 [00:25<02:14, 307.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6672/47780 [00:25<01:35, 429.97 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6876/47780 [00:25<01:41, 401.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6514/47780 [00:26<02:23, 287.83 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6766/47780 [00:26<01:44, 390.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6614/47780 [00:26<01:47, 381.17 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5968/47780 [00:26<02:24, 288.83 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6312/47780 [00:26<02:06, 326.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6940/47780 [00:26<01:17, 526.63 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6132/47780 [00:26<02:01, 343.42 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6842/47780 [00:26<02:08, 318.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6475/47780 [00:26<01:47, 383.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7118/47780 [00:26<01:34, 430.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7035/47780 [00:26<01:48, 377.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6623/47780 [00:26<01:47, 382.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6769/47780 [00:26<01:28, 460.96 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7155/47780 [00:26<01:51, 364.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6431/47780 [00:26<01:50, 374.35 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6884/47780 [00:27<01:06, 612.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7318/47780 [00:27<01:42, 393.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7249/47780 [00:27<01:53, 358.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6846/47780 [00:27<02:32, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7325/47780 [00:27<01:55, 349.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7182/47780 [00:27<01:38, 411.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6946/47780 [00:27<02:33, 266.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7467/47780 [00:27<01:48, 371.21 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7077/47780 [00:27<02:09, 313.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7390/47780 [00:27<01:57, 343.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7504/47780 [00:27<01:11, 560.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7444/47780 [00:27<01:59, 338.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7581/47780 [00:27<01:51, 360.13 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7157/47780 [00:27<02:13, 305.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7491/47780 [00:27<02:02, 328.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7335/47780 [00:28<01:49, 370.23 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7534/47780 [00:28<02:05, 321.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7528/47780 [00:28<01:27, 461.96 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7670/47780 [00:28<01:55, 346.84 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7572/47780 [00:28<02:04, 321.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7715/47780 [00:28<01:22, 485.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7609/47780 [00:28<02:06, 316.72 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7644/47780 [00:28<02:07, 315.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7742/47780 [00:28<02:01, 330.35 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7678/47780 [00:28<02:07, 314.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7105/47780 [00:28<01:56, 350.09 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7696/47780 [00:28<01:34, 423.44 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6893/47780 [00:28<03:23, 201.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7711/47780 [00:28<02:16, 293.12 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7264/47780 [00:28<01:41, 399.58 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7800/47780 [00:28<02:09, 307.75 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7295/47780 [00:28<01:45, 385.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7873/47780 [00:28<01:31, 436.95 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7742/47780 [00:28<02:21, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7622/47780 [00:28<01:06, 602.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7858/47780 [00:28<01:58, 335.85 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7771/47780 [00:28<02:23, 278.73 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7932/47780 [00:28<00:49, 808.70 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7365/47780 [00:28<02:32, 265.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7909/47780 [00:28<01:55, 344.11 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7802/47780 [00:29<02:19, 286.45 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7824/47780 [00:29<01:39, 401.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7668/47780 [00:29<01:42, 390.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7956/47780 [00:29<01:56, 340.51 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7838/47780 [00:29<02:13, 299.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7993/47780 [00:29<01:35, 417.26 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7873/47780 [00:29<02:07, 313.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7999/47780 [00:29<01:54, 347.93 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7909/47780 [00:29<02:03, 322.74 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7925/47780 [00:29<01:44, 382.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8041/47780 [00:29<01:57, 338.79 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7944/47780 [00:29<02:00, 330.15 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8088/47780 [00:29<01:41, 389.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8081/47780 [00:29<01:56, 340.62 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7981/47780 [00:29<01:56, 341.58 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8119/47780 [00:29<01:55, 342.91 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8005/47780 [00:29<01:48, 365.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8167/47780 [00:29<01:06, 596.27 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8016/47780 [00:29<01:58, 335.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8163/47780 [00:29<01:45, 377.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8156/47780 [00:29<01:53, 348.37 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8050/47780 [00:29<02:04, 319.59 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8195/47780 [00:29<01:50, 356.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8070/47780 [00:29<01:51, 357.13 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8089/47780 [00:29<01:56, 339.29 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8226/47780 [00:29<01:47, 366.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8232/47780 [00:29<01:54, 345.46 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8124/47780 [00:30<02:02, 323.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8125/47780 [00:30<01:54, 345.68 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8268/47780 [00:30<02:02, 321.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8280/47780 [00:30<01:49, 359.77 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8161/47780 [00:30<01:58, 335.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8341/47780 [00:30<01:15, 524.44 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8174/47780 [00:30<01:55, 341.55 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8301/47780 [00:30<02:04, 317.81 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8211/47780 [00:30<01:45, 375.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8328/47780 [00:30<01:54, 345.79 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8217/47780 [00:30<01:54, 344.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8334/47780 [00:30<02:14, 292.32 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8251/47780 [00:30<01:51, 354.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8370/47780 [00:30<01:54, 344.18 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8377/47780 [00:30<02:02, 322.03 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8258/47780 [00:30<01:56, 339.36 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8291/47780 [00:30<01:48, 362.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8410/47780 [00:30<01:53, 347.00 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8426/47780 [00:30<01:48, 362.58 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8474/47780 [00:30<01:23, 472.91 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7476/47780 [00:30<02:52, 233.62 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8297/47780 [00:30<01:57, 336.17 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8329/47780 [00:30<01:47, 366.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8450/47780 [00:30<01:51, 351.76 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7640/47780 [00:30<02:16, 293.89 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8465/47780 [00:30<01:48, 362.06 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8334/47780 [00:30<01:54, 343.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8494/47780 [00:30<01:46, 367.77 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8366/47780 [00:30<01:59, 330.83 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8374/47780 [00:30<01:51, 353.06 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8502/47780 [00:30<01:57, 334.82 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7851/47780 [00:30<02:43, 243.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8541/47780 [00:30<01:41, 388.21 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8403/47780 [00:30<01:58, 331.75 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8578/47780 [00:30<01:26, 451.39 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8416/47780 [00:30<01:47, 365.71 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8556/47780 [00:30<01:40, 389.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8040/47780 [00:30<02:07, 312.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8584/47780 [00:30<01:39, 394.17 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8443/47780 [00:30<01:53, 345.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8597/47780 [00:30<01:42, 383.28 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8307/47780 [00:30<01:28, 446.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8455/47780 [00:30<01:52, 349.71 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8626/47780 [00:31<01:40, 388.96 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8479/47780 [00:31<01:53, 345.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8662/47780 [00:31<01:32, 423.09 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8493/47780 [00:31<01:51, 350.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8637/47780 [00:31<01:44, 374.59 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8514/47780 [00:31<01:54, 342.55 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8667/47780 [00:31<01:44, 375.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8529/47780 [00:31<01:54, 342.52 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8552/47780 [00:31<01:51, 353.17 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8706/47780 [00:31<01:43, 378.95 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8677/47780 [00:31<01:57, 333.83 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8730/47780 [00:31<01:36, 405.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8570/47780 [00:31<01:48, 360.33 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8592/47780 [00:31<01:50, 354.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8745/47780 [00:31<01:42, 381.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8726/47780 [00:31<01:44, 373.63 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8608/47780 [00:31<01:52, 346.94 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8630/47780 [00:31<01:48, 361.84 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8784/47780 [00:31<01:49, 356.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8788/47780 [00:31<01:41, 383.84 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8645/47780 [00:31<01:50, 352.57 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8765/47780 [00:31<02:06, 308.76 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8673/47780 [00:31<01:43, 377.47 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8487/47780 [00:31<01:37, 402.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8838/47780 [00:31<01:40, 386.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8821/47780 [00:31<01:59, 325.82 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8685/47780 [00:31<01:47, 362.33 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8829/47780 [00:31<01:40, 387.57 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8711/47780 [00:31<01:46, 365.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8892/47780 [00:31<01:31, 424.11 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8722/47780 [00:31<01:49, 356.39 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8748/47780 [00:31<01:47, 362.64 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8872/47780 [00:31<01:46, 364.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8887/47780 [00:31<01:57, 332.14 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8761/47780 [00:31<01:47, 361.87 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8937/47780 [00:31<01:42, 380.02 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8790/47780 [00:31<01:42, 378.78 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8912/47780 [00:31<01:51, 349.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8966/47780 [00:31<01:36, 403.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8622/47780 [00:31<01:39, 394.47 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8978/47780 [00:31<01:47, 361.94 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8829/47780 [00:31<01:50, 353.62 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8798/47780 [00:32<02:09, 302.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8950/47780 [00:31<01:53, 343.19 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9017/47780 [00:32<01:38, 394.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8871/47780 [00:32<01:44, 371.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9016/47780 [00:32<01:50, 350.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8851/47780 [00:32<01:48, 359.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8987/47780 [00:32<01:54, 338.61 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9064/47780 [00:32<01:37, 396.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8909/47780 [00:32<01:47, 362.13 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9053/47780 [00:32<01:53, 341.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8891/47780 [00:32<01:47, 362.67 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8728/47780 [00:32<01:41, 383.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9023/47780 [00:32<01:56, 331.41 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7879/47780 [00:32<03:01, 219.75 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9109/47780 [00:32<01:38, 394.28 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9095/47780 [00:32<01:48, 358.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8933/47780 [00:32<01:45, 367.16 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9062/47780 [00:32<01:52, 343.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8946/47780 [00:32<02:10, 297.41 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8254/47780 [00:32<01:47, 367.94 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9152/47780 [00:32<01:38, 391.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9135/47780 [00:32<01:44, 369.38 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9097/47780 [00:32<01:53, 341.16 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8971/47780 [00:32<01:51, 346.76 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9033/47780 [00:32<01:29, 434.46 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8813/47780 [00:32<01:44, 372.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9173/47780 [00:32<01:45, 364.37 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9007/47780 [00:32<01:51, 347.01 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9132/47780 [00:32<01:56, 331.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9194/47780 [00:32<01:50, 348.64 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9081/47780 [00:32<01:34, 407.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9210/47780 [00:32<01:45, 365.74 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9171/47780 [00:32<01:51, 345.35 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9052/47780 [00:32<01:44, 371.11 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9239/47780 [00:32<01:44, 368.67 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9125/47780 [00:32<01:35, 405.46 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9254/47780 [00:32<01:40, 382.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8882/47780 [00:32<01:48, 357.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9216/47780 [00:32<01:43, 372.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9102/47780 [00:32<01:36, 402.67 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9284/47780 [00:32<01:39, 385.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9293/47780 [00:32<01:47, 359.33 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9168/47780 [00:32<01:46, 361.20 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9254/47780 [00:32<01:46, 360.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9328/47780 [00:32<01:37, 394.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9143/47780 [00:32<01:45, 366.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8940/47780 [00:32<01:51, 347.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9330/47780 [00:32<01:54, 336.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9291/47780 [00:32<01:46, 361.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9371/47780 [00:32<01:35, 403.57 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9182/47780 [00:33<01:44, 369.80 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9207/47780 [00:32<01:52, 341.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8990/47780 [00:33<01:51, 349.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9334/47780 [00:33<01:41, 378.52 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9365/47780 [00:33<01:54, 336.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9413/47780 [00:33<01:37, 395.03 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9221/47780 [00:33<01:43, 371.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9243/47780 [00:33<01:55, 333.15 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9037/47780 [00:33<01:49, 354.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9404/47780 [00:33<01:49, 350.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9374/47780 [00:33<01:43, 371.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9454/47780 [00:33<01:41, 378.41 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9259/47780 [00:33<01:45, 365.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9278/47780 [00:33<01:59, 322.15 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9443/47780 [00:33<01:45, 361.93 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9412/47780 [00:33<01:47, 357.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9080/47780 [00:33<01:51, 348.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9493/47780 [00:33<01:41, 377.33 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9302/47780 [00:33<01:41, 379.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9316/47780 [00:33<01:54, 336.10 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9480/47780 [00:33<01:47, 355.81 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8437/47780 [00:33<02:14, 293.50 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9448/47780 [00:33<01:49, 350.58 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9534/47780 [00:33<01:39, 382.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9341/47780 [00:33<01:43, 369.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9120/47780 [00:33<01:56, 333.20 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9351/47780 [00:33<02:02, 312.57 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9516/47780 [00:33<01:54, 334.63 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8777/47780 [00:33<01:26, 448.84 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9493/47780 [00:33<01:44, 366.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9379/47780 [00:33<01:45, 365.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9573/47780 [00:33<01:48, 352.83 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9388/47780 [00:33<01:59, 321.28 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9157/47780 [00:33<02:00, 319.76 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9550/47780 [00:33<02:00, 318.16 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9609/47780 [00:33<01:48, 351.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9530/47780 [00:33<01:52, 340.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9416/47780 [00:33<01:51, 342.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9421/47780 [00:33<02:08, 298.22 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9191/47780 [00:33<02:05, 306.31 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9585/47780 [00:33<01:57, 323.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9645/47780 [00:33<01:52, 338.06 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9565/47780 [00:33<02:01, 315.69 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9451/47780 [00:33<01:59, 319.61 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9223/47780 [00:33<02:04, 309.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8973/47780 [00:33<01:20, 479.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9618/47780 [00:33<01:58, 321.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9452/47780 [00:33<02:19, 275.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9680/47780 [00:33<01:54, 334.16 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9597/47780 [00:33<02:05, 303.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9484/47780 [00:33<02:04, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9255/47780 [00:33<02:05, 306.14 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9485/47780 [00:33<02:12, 289.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9652/47780 [00:33<02:03, 309.72 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9714/47780 [00:34<01:59, 318.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9633/47780 [00:33<02:00, 315.72 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9289/47780 [00:34<02:03, 311.51 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9516/47780 [00:34<02:07, 299.57 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9695/47780 [00:34<01:51, 342.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9515/47780 [00:34<02:15, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9747/47780 [00:34<02:02, 311.55 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9666/47780 [00:34<02:00, 316.06 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9553/47780 [00:34<02:01, 315.13 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9328/47780 [00:34<01:57, 328.59 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9741/47780 [00:34<01:42, 371.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9544/47780 [00:34<02:17, 279.02 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9783/47780 [00:34<01:56, 324.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9698/47780 [00:34<02:04, 306.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9368/47780 [00:34<01:52, 340.82 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9585/47780 [00:34<02:04, 306.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9789/47780 [00:34<01:34, 402.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9578/47780 [00:34<02:12, 289.28 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9129/47780 [00:34<01:27, 440.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9816/47780 [00:34<02:01, 312.19 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9408/47780 [00:34<01:47, 356.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9739/47780 [00:34<01:57, 322.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9623/47780 [00:34<01:58, 323.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9830/47780 [00:34<01:35, 395.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9619/47780 [00:34<01:58, 322.40 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9848/47780 [00:34<02:04, 304.26 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9453/47780 [00:34<01:41, 378.84 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9656/47780 [00:34<02:00, 316.99 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9874/47780 [00:34<01:32, 408.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9652/47780 [00:34<01:57, 323.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9775/47780 [00:34<02:12, 286.51 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9493/47780 [00:34<01:40, 380.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9884/47780 [00:34<02:00, 315.57 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9691/47780 [00:34<01:57, 325.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9916/47780 [00:34<01:32, 407.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9688/47780 [00:34<01:58, 320.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9837/47780 [00:34<01:43, 364.84 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9926/47780 [00:34<01:50, 341.50 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9724/47780 [00:34<01:57, 324.98 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9532/47780 [00:34<01:48, 351.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9959/47780 [00:34<01:32, 408.57 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9248/47780 [00:34<01:35, 404.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9724/47780 [00:34<01:55, 328.17 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9876/47780 [00:34<01:44, 363.20 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9963/47780 [00:34<01:49, 346.00 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9757/47780 [00:34<01:57, 322.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9568/47780 [00:34<01:50, 345.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9766/47780 [00:34<01:49, 345.91 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10000/47780 [00:34<01:40, 374.39 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9918/47780 [00:34<01:40, 375.19 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9999/47780 [00:34<01:48, 349.59 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9603/47780 [00:34<01:55, 330.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9790/47780 [00:34<02:13, 285.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9802/47780 [00:34<01:50, 342.93 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10040/47780 [00:34<01:41, 372.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10035/47780 [00:34<01:48, 348.92 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9957/47780 [00:34<01:50, 341.17 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9342/47780 [00:34<01:37, 392.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9645/47780 [00:35<01:47, 353.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9823/47780 [00:35<02:09, 294.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9838/47780 [00:35<01:50, 343.74 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10078/47780 [00:35<01:44, 359.39 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10087/47780 [00:35<01:34, 398.46 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9999/47780 [00:35<01:45, 358.44 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9681/47780 [00:35<01:48, 351.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9863/47780 [00:35<01:57, 322.91 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9879/47780 [00:35<01:45, 358.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10115/47780 [00:35<01:45, 357.73 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10036/47780 [00:35<01:44, 361.13 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10128/47780 [00:35<01:39, 379.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9721/47780 [00:35<01:44, 363.59 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9901/47780 [00:35<01:51, 338.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9417/47780 [00:35<01:43, 372.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9915/47780 [00:35<01:46, 353.89 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10151/47780 [00:35<01:46, 354.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10073/47780 [00:35<01:49, 344.88 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10167/47780 [00:35<01:40, 373.09 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9758/47780 [00:35<01:46, 357.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9941/47780 [00:35<01:48, 348.48 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9952/47780 [00:35<01:50, 343.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10118/47780 [00:35<01:40, 373.59 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10187/47780 [00:35<01:57, 320.21 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10205/47780 [00:35<01:40, 372.26 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9797/47780 [00:35<01:44, 363.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9977/47780 [00:35<01:47, 351.52 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9479/47780 [00:35<01:48, 352.54 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9990/47780 [00:35<01:48, 349.91 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10157/47780 [00:35<01:41, 369.62 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10220/47780 [00:35<02:00, 312.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10243/47780 [00:35<01:46, 353.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10013/47780 [00:35<01:49, 346.20 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9834/47780 [00:35<01:51, 340.78 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10026/47780 [00:35<01:52, 336.93 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9532/47780 [00:35<01:46, 360.21 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10196/47780 [00:35<01:41, 371.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10254/47780 [00:35<01:59, 313.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10280/47780 [00:35<01:44, 358.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10053/47780 [00:35<01:46, 353.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9870/47780 [00:35<01:50, 343.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10060/47780 [00:35<01:52, 335.96 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10234/47780 [00:35<01:44, 360.80 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9580/47780 [00:35<01:46, 358.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10286/47780 [00:35<02:02, 304.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10317/47780 [00:35<01:46, 352.45 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10089/47780 [00:35<01:47, 350.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9905/47780 [00:35<01:57, 323.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10097/47780 [00:35<01:55, 324.86 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10273/47780 [00:35<01:43, 361.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10318/47780 [00:35<02:03, 303.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10355/47780 [00:35<01:45, 353.33 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9625/47780 [00:35<01:50, 345.10 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10126/47780 [00:35<01:52, 333.30 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9951/47780 [00:35<01:44, 360.51 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10133/47780 [00:35<01:54, 328.24 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10349/47780 [00:35<02:04, 301.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10391/47780 [00:35<01:47, 347.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10310/47780 [00:35<01:51, 337.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10160/47780 [00:35<01:52, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9666/47780 [00:35<01:49, 346.75 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9988/47780 [00:35<01:46, 355.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10166/47780 [00:35<01:54, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10380/47780 [00:36<02:03, 302.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10433/47780 [00:36<01:41, 367.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10345/47780 [00:35<01:51, 337.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10194/47780 [00:36<02:01, 309.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10024/47780 [00:36<01:50, 340.79 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9705/47780 [00:36<01:53, 336.55 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10199/47780 [00:36<02:01, 308.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10413/47780 [00:36<02:02, 304.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10379/47780 [00:36<01:53, 330.35 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10470/47780 [00:36<01:51, 334.29 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10064/47780 [00:36<01:46, 353.94 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9744/47780 [00:36<01:50, 345.17 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10226/47780 [00:36<02:04, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10243/47780 [00:36<01:49, 344.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10449/47780 [00:36<01:56, 320.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:36<480:55:27, 36.24s/ examples]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10413/47780 [00:36<01:52, 332.03 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10522/47780 [00:36<01:37, 380.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10260/47780 [00:36<02:00, 312.43 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10100/47780 [00:36<01:49, 343.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10285/47780 [00:36<01:42, 365.60 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9781/47780 [00:36<01:56, 326.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10482/47780 [00:36<02:00, 309.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10454/47780 [00:36<01:47, 347.72 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 13/47780 [00:36<26:37:10,  2.01s/ examples]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10561/47780 [00:36<01:42, 362.20 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10293/47780 [00:36<01:59, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10136/47780 [00:36<01:49, 344.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10323/47780 [00:36<01:43, 361.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9824/47780 [00:36<01:48, 349.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10515/47780 [00:36<02:00, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10502/47780 [00:36<01:38, 376.82 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10601/47780 [00:36<01:41, 365.38 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10176/47780 [00:36<01:46, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10325/47780 [00:36<02:02, 304.82 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9863/47780 [00:36<01:47, 354.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10361/47780 [00:36<01:50, 339.74 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10541/47780 [00:36<01:40, 371.76 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10548/47780 [00:36<02:08, 290.71 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10638/47780 [00:36<01:44, 354.90 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10359/47780 [00:36<02:00, 310.54 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10212/47780 [00:36<01:48, 346.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9900/47780 [00:36<01:45, 358.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10399/47780 [00:36<01:51, 335.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10584/47780 [00:36<01:36, 384.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10591/47780 [00:36<01:53, 328.66 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10681/47780 [00:36<01:39, 371.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10401/47780 [00:36<01:53, 328.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10247/47780 [00:36<01:51, 335.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9937/47780 [00:36<01:48, 350.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10437/47780 [00:36<01:48, 344.35 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10623/47780 [00:36<01:36, 385.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10719/47780 [00:36<01:45, 350.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10625/47780 [00:36<02:08, 289.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10437/47780 [00:36<01:53, 329.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10281/47780 [00:36<01:54, 326.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9973/47780 [00:36<01:47, 352.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10484/47780 [00:36<01:38, 379.31 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10668/47780 [00:36<01:31, 403.86 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10755/47780 [00:36<01:48, 341.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10670/47780 [00:36<01:55, 321.24 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10472/47780 [00:36<01:51, 335.09 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10315/47780 [00:36<01:53, 329.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10018/47780 [00:36<01:41, 372.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10714/47780 [00:36<01:28, 416.51 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10524/47780 [00:36<01:42, 364.42 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10796/47780 [00:37<01:42, 360.12 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10709/47780 [00:37<01:49, 337.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10509/47780 [00:37<01:49, 341.47 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10350/47780 [00:37<01:52, 332.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10060/47780 [00:37<01:38, 381.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10765/47780 [00:37<01:23, 443.85 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10562/47780 [00:37<01:44, 356.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10755/47780 [00:37<01:41, 365.12 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10833/47780 [00:37<01:44, 354.93 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10545/47780 [00:37<01:52, 331.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10101/47780 [00:37<01:37, 385.01 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10384/47780 [00:37<02:02, 306.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10811/47780 [00:37<01:27, 423.38 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10598/47780 [00:37<01:47, 346.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10797/47780 [00:37<01:40, 368.07 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10601/47780 [00:37<01:33, 395.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10869/47780 [00:37<01:48, 340.62 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10440/47780 [00:37<01:40, 371.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10854/47780 [00:37<01:27, 420.25 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10140/47780 [00:37<01:48, 346.16 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10633/47780 [00:37<01:48, 343.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10904/47780 [00:37<01:48, 340.12 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10646/47780 [00:37<01:32, 402.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10835/47780 [00:37<01:41, 363.16 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10481/47780 [00:37<01:39, 373.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10184/47780 [00:37<01:43, 364.20 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10669/47780 [00:37<01:48, 340.61 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10897/47780 [00:37<01:34, 391.77 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10689/47780 [00:37<01:31, 405.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10941/47780 [00:37<01:46, 344.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10872/47780 [00:37<01:43, 356.76 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10519/47780 [00:37<01:40, 371.09 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:37<12:39:31,  1.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10704/47780 [00:37<01:51, 331.93 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10223/47780 [00:37<01:47, 348.30 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10937/47780 [00:37<01:43, 355.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10730/47780 [00:37<01:33, 397.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10908/47780 [00:37<01:46, 346.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10976/47780 [00:37<01:51, 331.16 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10557/47780 [00:37<01:44, 357.38 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 41/47780 [00:37<5:45:11,  2.30 examples/s] 
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10742/47780 [00:37<01:49, 337.92 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10273/47780 [00:37<01:37, 384.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10974/47780 [00:37<01:43, 355.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10772/47780 [00:37<01:32, 400.72 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10947/47780 [00:37<01:44, 350.92 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11010/47780 [00:37<01:54, 322.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10602/47780 [00:37<01:39, 375.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10314/47780 [00:37<01:37, 383.43 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10776/47780 [00:37<01:56, 317.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11012/47780 [00:37<01:47, 343.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10813/47780 [00:37<01:35, 388.50 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10993/47780 [00:37<01:37, 377.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11045/47780 [00:37<01:53, 323.21 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10643/47780 [00:37<01:37, 380.68 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10809/47780 [00:37<01:55, 320.39 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10353/47780 [00:37<01:43, 362.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11052/47780 [00:37<01:43, 355.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11031/47780 [00:37<01:37, 377.40 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11078/47780 [00:37<01:55, 318.09 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10853/47780 [00:37<01:41, 363.14 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10682/47780 [00:37<01:36, 383.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10846/47780 [00:37<01:51, 330.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10397/47780 [00:37<01:39, 373.88 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11089/47780 [00:37<01:47, 342.64 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11080/47780 [00:38<01:32, 396.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11114/47780 [00:38<01:51, 329.71 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10894/47780 [00:38<01:39, 372.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10725/47780 [00:38<01:37, 379.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10880/47780 [00:38<01:50, 333.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10440/47780 [00:38<01:35, 389.26 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11138/47780 [00:38<01:36, 380.28 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11123/47780 [00:38<01:30, 406.20 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11150/47780 [00:38<01:48, 338.34 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10932/47780 [00:38<01:41, 362.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10764/47780 [00:38<01:40, 370.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10914/47780 [00:38<01:55, 320.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10485/47780 [00:38<01:34, 393.18 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11164/47780 [00:38<01:30, 404.56 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11186/47780 [00:38<01:48, 337.00 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11177/47780 [00:38<01:43, 354.64 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10970/47780 [00:38<01:42, 358.69 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10948/47780 [00:38<01:56, 315.38 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10526/47780 [00:38<01:34, 392.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10802/47780 [00:38<01:56, 318.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11208/47780 [00:38<01:28, 413.23 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11220/47780 [00:38<01:48, 337.26 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11219/47780 [00:38<01:40, 364.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11012/47780 [00:38<01:39, 370.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10986/47780 [00:38<01:50, 331.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10567/47780 [00:38<01:36, 385.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10840/47780 [00:38<01:51, 331.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11252/47780 [00:38<01:30, 401.85 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11256/47780 [00:38<01:48, 336.67 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11256/47780 [00:38<01:40, 362.19 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 51/47780 [00:38<4:17:22,  3.09 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11050/47780 [00:38<01:49, 336.52 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11020/47780 [00:38<01:53, 324.43 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10877/47780 [00:38<01:48, 341.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10607/47780 [00:38<01:37, 380.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11297/47780 [00:38<01:41, 357.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11295/47780 [00:38<01:39, 367.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11293/47780 [00:38<01:36, 378.13 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11089/47780 [00:38<01:44, 350.64 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10918/47780 [00:38<01:42, 360.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11053/47780 [00:38<01:57, 312.32 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10646/47780 [00:38<01:41, 366.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11333/47780 [00:38<01:45, 345.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11336/47780 [00:38<01:36, 377.93 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11333/47780 [00:38<01:38, 371.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10962/47780 [00:38<01:36, 382.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11125/47780 [00:38<01:52, 324.72 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11091/47780 [00:38<01:53, 323.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10689/47780 [00:38<01:37, 380.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11376/47780 [00:38<01:39, 366.56 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11375/47780 [00:38<01:44, 348.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11372/47780 [00:38<01:45, 345.67 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11003/47780 [00:38<01:35, 387.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11161/47780 [00:38<01:49, 334.09 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11125/47780 [00:38<01:54, 320.99 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10732/47780 [00:38<01:34, 390.03 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11414/47780 [00:38<01:38, 368.65 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11409/47780 [00:38<01:45, 345.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11411/47780 [00:38<01:48, 333.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11196/47780 [00:38<01:48, 338.31 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10772/47780 [00:38<01:34, 391.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11044/47780 [00:38<01:40, 367.25 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11158/47780 [00:38<01:55, 316.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11453/47780 [00:39<01:47, 336.79 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11453/47780 [00:39<01:38, 367.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11445/47780 [00:38<01:51, 324.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11233/47780 [00:39<01:48, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11193/47780 [00:39<01:52, 325.59 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10813/47780 [00:39<01:34, 392.50 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11090/47780 [00:39<01:35, 384.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11488/47780 [00:39<01:48, 333.22 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11481/47780 [00:39<01:49, 331.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11491/47780 [00:39<01:43, 350.77 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11279/47780 [00:39<01:40, 362.78 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11226/47780 [00:39<01:55, 316.49 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11129/47780 [00:39<01:38, 373.37 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10854/47780 [00:39<01:39, 372.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11522/47780 [00:39<01:54, 317.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11525/47780 [00:39<01:40, 361.03 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11527/47780 [00:39<01:45, 342.71 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11321/47780 [00:39<01:37, 374.54 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11259/47780 [00:39<01:55, 316.72 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11168/47780 [00:39<01:37, 374.04 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10892/47780 [00:39<01:48, 340.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11562/47780 [00:39<01:43, 351.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11566/47780 [00:39<01:42, 351.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11360/47780 [00:39<01:36, 378.60 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11299/47780 [00:39<01:47, 340.55 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11207/47780 [00:39<01:41, 361.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11555/47780 [00:39<02:17, 263.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 58/47780 [00:39<3:40:44,  3.60 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11607/47780 [00:39<01:39, 363.99 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11400/47780 [00:39<01:36, 376.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11334/47780 [00:39<01:46, 342.69 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11598/47780 [00:39<01:51, 325.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11249/47780 [00:39<01:36, 377.87 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10927/47780 [00:39<02:11, 280.42 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11610/47780 [00:39<01:51, 323.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   0%|          | 104/47780 [00:39<1:09:10, 11.49 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11646/47780 [00:39<01:38, 366.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11370/47780 [00:39<01:48, 336.32 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11438/47780 [00:39<01:41, 357.14 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11001/47780 [00:39<01:35, 385.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11290/47780 [00:39<01:38, 369.59 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11653/47780 [00:39<01:43, 350.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11632/47780 [00:39<02:11, 275.65 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11683/47780 [00:39<01:40, 359.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11406/47780 [00:39<01:46, 340.49 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11499/47780 [00:39<01:24, 427.76 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11044/47780 [00:39<01:34, 388.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11328/47780 [00:39<01:38, 369.37 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11694/47780 [00:39<01:38, 365.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11706/47780 [00:39<01:32, 388.30 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11724/47780 [00:39<01:36, 374.11 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11444/47780 [00:39<01:44, 346.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11366/47780 [00:39<01:38, 367.97 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11734/47780 [00:39<01:37, 371.38 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11544/47780 [00:39<01:33, 387.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11086/47780 [00:39<01:38, 373.89 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11762/47780 [00:39<01:42, 350.78 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11749/47780 [00:39<01:42, 351.90 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11479/47780 [00:39<01:54, 318.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11586/47780 [00:39<01:31, 394.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11405/47780 [00:39<01:40, 360.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11774/47780 [00:39<01:38, 366.46 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11126/47780 [00:39<01:50, 330.88 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11798/47780 [00:40<01:42, 350.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11788/47780 [00:39<01:42, 350.89 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11520/47780 [00:40<01:45, 343.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11449/47780 [00:40<01:34, 382.47 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11812/47780 [00:40<01:39, 363.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11627/47780 [00:40<01:37, 371.73 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11181/47780 [00:40<01:37, 375.00 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11834/47780 [00:40<01:48, 330.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11826/47780 [00:40<01:44, 344.76 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11488/47780 [00:40<01:37, 373.29 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11850/47780 [00:40<01:38, 365.91 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11556/47780 [00:40<01:51, 326.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11678/47780 [00:40<01:29, 404.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11870/47780 [00:40<01:46, 338.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11862/47780 [00:40<01:43, 348.19 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11592/47780 [00:40<01:47, 335.31 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11526/47780 [00:40<01:39, 363.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11887/47780 [00:40<01:41, 352.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11720/47780 [00:40<01:33, 384.98 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11221/47780 [00:40<01:59, 306.92 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11905/47780 [00:40<01:47, 334.28 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11898/47780 [00:40<01:43, 347.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11628/47780 [00:40<01:51, 323.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11924/47780 [00:40<01:45, 338.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11565/47780 [00:40<01:45, 344.00 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11290/47780 [00:40<01:32, 393.33 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11760/47780 [00:40<01:38, 365.85 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11943/47780 [00:40<01:44, 343.39 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11934/47780 [00:40<01:49, 326.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11670/47780 [00:40<01:44, 347.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11609/47780 [00:40<01:37, 369.86 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11340/47780 [00:40<01:26, 419.29 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11960/47780 [00:40<01:56, 306.97 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11798/47780 [00:40<01:41, 353.79 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11978/47780 [00:40<01:46, 337.68 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11968/47780 [00:40<01:53, 315.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11649/47780 [00:40<01:36, 374.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11707/47780 [00:40<01:46, 338.16 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11836/47780 [00:40<01:40, 357.75 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11995/47780 [00:40<01:53, 314.46 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11387/47780 [00:40<01:31, 399.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12012/47780 [00:40<01:54, 312.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11687/47780 [00:40<01:36, 375.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11749/47780 [00:40<01:42, 353.06 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12001/47780 [00:40<02:03, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11876/47780 [00:40<01:38, 365.38 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 120/47780 [00:40<1:06:49, 11.89 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12028/47780 [00:40<01:56, 306.11 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11431/47780 [00:40<01:33, 389.94 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12050/47780 [00:40<01:48, 328.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11725/47780 [00:40<01:35, 376.59 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 184/47780 [00:40<27:50, 28.49 examples/s]  
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11785/47780 [00:40<01:53, 316.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12031/47780 [00:40<02:12, 270.43 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11914/47780 [00:40<01:42, 349.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12060/47780 [00:40<02:00, 296.85 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11473/47780 [00:40<01:38, 366.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11771/47780 [00:40<01:31, 392.45 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11822/47780 [00:40<01:50, 326.84 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12081/47780 [00:40<01:48, 327.76 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12094/47780 [00:40<01:56, 305.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11955/47780 [00:40<01:43, 347.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11816/47780 [00:41<01:28, 404.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11512/47780 [00:40<01:48, 335.72 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12084/47780 [00:41<02:35, 229.24 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11856/47780 [00:41<01:52, 320.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12122/47780 [00:41<01:43, 345.43 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12125/47780 [00:41<01:56, 306.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12008/47780 [00:41<01:31, 392.55 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11857/47780 [00:41<01:31, 392.07 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11550/47780 [00:41<01:46, 340.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12193/47780 [00:41<01:26, 411.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12164/47780 [00:41<01:47, 330.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11891/47780 [00:41<01:54, 314.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12049/47780 [00:41<01:31, 391.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12158/47780 [00:41<01:49, 325.21 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11586/47780 [00:41<01:44, 345.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11897/47780 [00:41<01:39, 362.15 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11925/47780 [00:41<01:51, 321.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12201/47780 [00:41<01:46, 334.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12097/47780 [00:41<01:27, 408.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12206/47780 [00:41<01:38, 362.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12244/47780 [00:41<01:33, 380.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11624/47780 [00:41<01:43, 349.56 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11942/47780 [00:41<01:33, 381.29 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11960/47780 [00:41<01:48, 328.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12241/47780 [00:41<01:41, 348.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12139/47780 [00:41<01:34, 378.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12245/47780 [00:41<01:45, 336.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12289/47780 [00:41<01:35, 373.16 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11981/47780 [00:41<01:33, 383.67 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11660/47780 [00:41<01:45, 341.41 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12000/47780 [00:41<01:43, 345.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12277/47780 [00:41<01:44, 339.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12281/47780 [00:41<01:44, 339.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12178/47780 [00:41<01:35, 372.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12331/47780 [00:41<01:34, 373.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11701/47780 [00:41<01:40, 357.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12021/47780 [00:41<01:35, 374.92 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12038/47780 [00:41<01:40, 355.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12312/47780 [00:41<01:44, 339.32 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12216/47780 [00:41<01:38, 362.62 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12316/47780 [00:41<01:48, 328.04 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11738/47780 [00:41<01:40, 360.11 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12061/47780 [00:41<01:34, 378.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12372/47780 [00:41<01:38, 361.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12355/47780 [00:41<01:37, 361.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12074/47780 [00:41<01:50, 323.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12262/47780 [00:41<01:32, 385.41 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12358/47780 [00:41<01:43, 341.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11776/47780 [00:41<01:39, 362.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12411/47780 [00:41<01:36, 368.21 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12100/47780 [00:41<01:40, 354.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12109/47780 [00:41<01:48, 330.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12392/47780 [00:41<01:51, 316.58 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12400/47780 [00:41<01:38, 359.28 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11831/47780 [00:41<01:27, 411.74 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12302/47780 [00:41<01:37, 363.60 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12450/47780 [00:41<01:40, 352.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12136/47780 [00:41<01:42, 347.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12143/47780 [00:41<01:48, 329.07 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12446/47780 [00:41<01:37, 363.98 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11873/47780 [00:41<01:27, 411.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12339/47780 [00:41<01:39, 355.27 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12437/47780 [00:41<01:43, 342.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12487/47780 [00:42<01:39, 352.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12177/47780 [00:42<01:40, 352.92 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12177/47780 [00:42<01:59, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12484/47780 [00:42<01:38, 359.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12378/47780 [00:42<01:37, 364.56 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11915/47780 [00:42<01:33, 385.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12480/47780 [00:42<01:39, 355.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12524/47780 [00:42<01:43, 339.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12213/47780 [00:42<01:46, 332.43 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12214/47780 [00:42<01:54, 311.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12527/47780 [00:42<01:36, 363.62 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12415/47780 [00:42<01:37, 361.59 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11954/47780 [00:42<01:33, 382.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12516/47780 [00:42<01:45, 334.09 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12575/47780 [00:42<01:31, 383.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12247/47780 [00:42<01:46, 334.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12256/47780 [00:42<01:44, 340.81 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 212/47780 [00:42<31:20, 25.30 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12464/47780 [00:42<01:30, 389.94 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12572/47780 [00:42<01:32, 378.92 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11993/47780 [00:42<01:34, 380.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12550/47780 [00:42<01:49, 322.62 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12282/47780 [00:42<01:45, 335.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12617/47780 [00:42<01:34, 370.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12291/47780 [00:42<01:43, 342.61 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 278/47780 [00:42<16:57, 46.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12511/47780 [00:42<01:27, 403.54 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12611/47780 [00:42<01:36, 365.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12034/47780 [00:42<01:34, 380.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12662/47780 [00:42<01:29, 391.64 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12316/47780 [00:42<01:47, 329.50 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12583/47780 [00:42<01:53, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12331/47780 [00:42<01:38, 358.73 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12653/47780 [00:42<01:32, 380.69 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12077/47780 [00:42<01:30, 393.99 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12552/47780 [00:42<01:32, 379.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12702/47780 [00:42<01:30, 389.72 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12619/47780 [00:42<01:49, 321.15 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12350/47780 [00:42<01:49, 324.63 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12368/47780 [00:42<01:40, 350.81 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12696/47780 [00:42<01:28, 394.29 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12117/47780 [00:42<01:32, 387.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12591/47780 [00:42<01:35, 369.54 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12656/47780 [00:42<01:47, 327.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12743/47780 [00:42<01:33, 374.14 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12383/47780 [00:42<01:53, 311.71 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12404/47780 [00:42<01:41, 349.02 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12738/47780 [00:42<01:28, 397.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12156/47780 [00:42<01:39, 359.12 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12629/47780 [00:42<01:41, 347.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12689/47780 [00:42<01:49, 321.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12781/47780 [00:42<01:37, 359.93 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12440/47780 [00:42<01:44, 336.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12415/47780 [00:42<02:02, 289.03 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12782/47780 [00:42<01:26, 404.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12193/47780 [00:42<01:39, 358.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12665/47780 [00:42<01:42, 343.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12724/47780 [00:42<01:51, 314.88 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12829/47780 [00:42<01:30, 384.68 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12478/47780 [00:42<01:42, 345.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12449/47780 [00:42<01:58, 299.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12234/47780 [00:42<01:35, 372.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12823/47780 [00:42<01:35, 366.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12709/47780 [00:42<01:35, 366.17 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12769/47780 [00:42<01:40, 348.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12871/47780 [00:43<01:30, 386.20 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12527/47780 [00:42<01:32, 382.05 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12481/47780 [00:43<01:56, 301.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12273/47780 [00:43<01:34, 377.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12746/47780 [00:43<01:35, 365.26 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12861/47780 [00:43<01:45, 330.23 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12566/47780 [00:43<01:32, 380.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12805/47780 [00:43<01:45, 333.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12514/47780 [00:43<01:55, 306.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12910/47780 [00:43<01:37, 358.96 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12785/47780 [00:43<01:37, 360.32 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12311/47780 [00:43<01:44, 339.67 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12610/47780 [00:43<01:28, 397.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12848/47780 [00:43<01:39, 351.93 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12545/47780 [00:43<01:57, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12947/47780 [00:43<01:37, 356.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12897/47780 [00:43<01:52, 310.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   1%|          | 312/47780 [00:43<17:41, 44.72 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12824/47780 [00:43<01:35, 364.56 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12346/47780 [00:43<01:45, 336.59 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12657/47780 [00:43<01:24, 413.91 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12888/47780 [00:43<01:35, 365.27 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12578/47780 [00:43<01:54, 308.72 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 360/47780 [00:43<12:10, 64.94 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12931/47780 [00:43<01:51, 312.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12983/47780 [00:43<01:41, 344.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12861/47780 [00:43<01:37, 357.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12381/47780 [00:43<01:48, 327.29 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12925/47780 [00:43<01:38, 354.59 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12699/47780 [00:43<01:31, 384.34 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12963/47780 [00:43<01:50, 314.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12610/47780 [00:43<01:59, 295.16 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13018/47780 [00:43<01:54, 302.60 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12417/47780 [00:43<01:46, 332.69 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12897/47780 [00:43<01:42, 339.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12963/47780 [00:43<01:36, 360.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12648/47780 [00:43<01:50, 318.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12996/47780 [00:43<01:50, 314.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12738/47780 [00:43<01:32, 377.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13066/47780 [00:43<01:41, 343.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12452/47780 [00:43<01:44, 337.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12935/47780 [00:43<01:39, 350.59 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12700/47780 [00:43<01:33, 375.35 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13001/47780 [00:43<01:40, 347.58 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13039/47780 [00:43<01:41, 343.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12777/47780 [00:43<01:36, 364.56 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13108/47780 [00:43<01:36, 361.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12487/47780 [00:43<01:43, 340.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12971/47780 [00:43<01:42, 338.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13077/47780 [00:43<01:38, 353.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12739/47780 [00:43<01:33, 376.42 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13037/47780 [00:43<01:43, 335.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12814/47780 [00:43<01:38, 354.41 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12526/47780 [00:43<01:40, 351.53 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13146/47780 [00:43<01:42, 336.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13006/47780 [00:43<01:45, 330.00 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12777/47780 [00:43<01:34, 369.71 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13071/47780 [00:43<01:44, 333.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12850/47780 [00:43<01:38, 353.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13113/47780 [00:43<01:50, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12577/47780 [00:43<01:29, 392.95 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13182/47780 [00:43<01:40, 342.58 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13042/47780 [00:43<01:44, 331.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12815/47780 [00:43<01:36, 362.40 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13108/47780 [00:43<01:41, 342.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12892/47780 [00:43<01:35, 366.53 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13160/47780 [00:44<01:37, 353.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12617/47780 [00:44<01:34, 372.14 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13217/47780 [00:44<01:43, 333.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13079/47780 [00:44<01:42, 338.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13150/47780 [00:44<01:38, 350.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12929/47780 [00:44<01:39, 351.06 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12852/47780 [00:44<01:47, 324.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13198/47780 [00:44<01:42, 338.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12655/47780 [00:44<01:34, 371.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13262/47780 [00:44<01:35, 362.19 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 392/47780 [00:44<14:10, 55.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13194/47780 [00:44<01:32, 375.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13113/47780 [00:44<01:48, 320.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12965/47780 [00:44<01:39, 350.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12887/47780 [00:44<01:45, 330.35 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13236/47780 [00:44<01:38, 349.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12707/47780 [00:44<01:25, 409.05 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13299/47780 [00:44<01:39, 345.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13154/47780 [00:44<01:40, 345.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12922/47780 [00:44<01:44, 334.78 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13232/47780 [00:44<01:41, 341.56 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13272/47780 [00:44<01:39, 348.26 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13001/47780 [00:44<01:45, 330.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12749/47780 [00:44<01:25, 409.70 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13334/47780 [00:44<01:40, 342.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13197/47780 [00:44<01:34, 365.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13271/47780 [00:44<01:37, 354.41 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12956/47780 [00:44<01:52, 310.27 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13308/47780 [00:44<01:42, 336.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13035/47780 [00:44<01:51, 312.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12791/47780 [00:44<01:29, 389.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13369/47780 [00:44<01:42, 336.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13236/47780 [00:44<01:34, 367.01 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13308/47780 [00:44<01:39, 347.47 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13343/47780 [00:44<01:44, 329.64 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13068/47780 [00:44<01:50, 313.83 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12988/47780 [00:44<01:56, 299.93 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13275/47780 [00:44<01:33, 370.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12831/47780 [00:44<01:37, 359.00 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13403/47780 [00:44<01:49, 313.60 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13021/47780 [00:44<01:53, 304.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13344/47780 [00:44<01:46, 322.20 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13107/47780 [00:44<01:47, 323.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13313/47780 [00:44<01:35, 360.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13437/47780 [00:44<01:47, 320.71 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12868/47780 [00:44<01:40, 346.94 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13379/47780 [00:44<02:02, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13055/47780 [00:44<01:50, 314.40 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13380/47780 [00:44<01:43, 332.18 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13140/47780 [00:44<01:48, 318.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13353/47780 [00:44<01:33, 368.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12904/47780 [00:44<01:41, 342.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13470/47780 [00:44<01:52, 305.75 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13429/47780 [00:44<01:45, 326.02 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13088/47780 [00:44<01:49, 316.16 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13416/47780 [00:44<01:42, 336.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13173/47780 [00:44<01:51, 311.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13393/47780 [00:44<01:32, 372.92 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12939/47780 [00:44<01:41, 344.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13506/47780 [00:44<01:49, 314.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13468/47780 [00:44<01:42, 335.68 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13120/47780 [00:44<01:53, 306.01 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13459/47780 [00:44<01:36, 354.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13205/47780 [00:44<01:51, 310.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13433/47780 [00:45<01:30, 380.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12978/47780 [00:45<01:40, 346.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13541/47780 [00:45<01:45, 323.84 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13503/47780 [00:45<01:44, 328.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13152/47780 [00:45<01:51, 309.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13237/47780 [00:45<01:51, 309.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13495/47780 [00:45<01:41, 336.82 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13472/47780 [00:45<01:34, 362.26 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 416/47780 [00:45<17:54, 44.08 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13019/47780 [00:45<01:35, 363.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13574/47780 [00:45<01:50, 308.40 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13538/47780 [00:45<01:45, 324.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13186/47780 [00:45<01:49, 314.92 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13530/47780 [00:45<01:41, 337.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13278/47780 [00:45<01:44, 330.75 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 462/47780 [00:45<12:02, 65.52 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13057/47780 [00:45<01:37, 356.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13517/47780 [00:45<01:33, 366.46 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13612/47780 [00:45<01:45, 324.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13571/47780 [00:45<01:47, 319.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13219/47780 [00:45<01:48, 319.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13316/47780 [00:45<01:39, 344.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13566/47780 [00:45<01:41, 335.78 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13093/47780 [00:45<01:38, 353.46 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13554/47780 [00:45<01:38, 347.88 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13646/47780 [00:45<01:49, 311.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13606/47780 [00:45<01:46, 320.14 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13351/47780 [00:45<01:39, 345.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13600/47780 [00:45<01:45, 322.67 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13253/47780 [00:45<02:05, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13130/47780 [00:45<01:42, 338.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13589/47780 [00:45<01:40, 341.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13640/47780 [00:45<01:44, 325.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13679/47780 [00:45<01:50, 309.64 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13386/47780 [00:45<01:48, 316.77 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13633/47780 [00:45<01:50, 309.89 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13300/47780 [00:45<01:47, 321.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13168/47780 [00:45<01:39, 348.51 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13677/47780 [00:45<01:41, 334.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13626/47780 [00:45<01:41, 338.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13711/47780 [00:45<01:52, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13336/47780 [00:45<01:44, 328.51 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13665/47780 [00:45<01:54, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13419/47780 [00:45<01:55, 298.32 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13204/47780 [00:45<01:41, 341.89 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13748/47780 [00:45<01:45, 321.16 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13660/47780 [00:45<01:45, 324.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13711/47780 [00:45<01:47, 317.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13699/47780 [00:45<01:51, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13453/47780 [00:45<01:50, 309.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13240/47780 [00:45<01:40, 343.17 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13694/47780 [00:45<01:43, 328.60 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13370/47780 [00:45<01:59, 287.32 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13746/47780 [00:45<01:44, 326.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13781/47780 [00:45<01:47, 316.57 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13485/47780 [00:45<01:49, 312.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13733/47780 [00:45<01:49, 311.74 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13276/47780 [00:45<01:43, 332.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13411/47780 [00:45<01:47, 318.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13779/47780 [00:45<01:45, 323.78 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13818/47780 [00:45<01:43, 328.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13727/47780 [00:45<01:48, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13771/47780 [00:45<01:43, 327.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13518/47780 [00:45<01:55, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13310/47780 [00:45<01:43, 334.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13854/47780 [00:46<01:40, 337.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13813/47780 [00:46<01:44, 325.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13447/47780 [00:46<01:47, 319.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13761/47780 [00:46<01:46, 318.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13810/47780 [00:46<01:38, 345.07 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13555/47780 [00:46<01:49, 313.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13345/47780 [00:46<01:46, 324.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13846/47780 [00:46<01:46, 319.14 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13888/47780 [00:46<01:43, 326.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13482/47780 [00:46<01:50, 310.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13803/47780 [00:46<01:45, 321.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13846/47780 [00:46<01:38, 345.38 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13588/47780 [00:46<01:48, 314.84 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13931/47780 [00:46<01:37, 348.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13881/47780 [00:46<01:45, 321.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13378/47780 [00:46<01:49, 315.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13515/47780 [00:46<01:48, 316.05 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13839/47780 [00:46<01:43, 328.95 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13881/47780 [00:46<01:45, 320.73 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13620/47780 [00:46<01:57, 289.68 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13410/47780 [00:46<01:48, 316.48 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13975/47780 [00:46<01:30, 372.24 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13914/47780 [00:46<01:47, 316.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13548/47780 [00:46<01:48, 315.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13877/47780 [00:46<01:42, 332.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13915/47780 [00:46<01:45, 322.47 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13650/47780 [00:46<01:57, 289.66 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14013/47780 [00:46<01:31, 367.98 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13581/47780 [00:46<01:47, 316.95 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13442/47780 [00:46<01:51, 307.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13947/47780 [00:46<01:49, 309.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13913/47780 [00:46<01:39, 339.32 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 487/47780 [00:46<18:02, 43.69 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13687/47780 [00:46<01:50, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13948/47780 [00:46<01:53, 297.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14050/47780 [00:46<01:33, 360.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13986/47780 [00:46<01:44, 324.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13474/47780 [00:46<01:56, 294.31 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13614/47780 [00:46<01:52, 303.15 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13950/47780 [00:46<01:39, 340.16 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 600/47780 [00:46<07:50, 100.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13992/47780 [00:46<01:41, 332.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13719/47780 [00:46<01:54, 298.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14087/47780 [00:46<01:37, 347.06 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13650/47780 [00:46<01:47, 318.85 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14019/47780 [00:46<01:45, 318.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13504/47780 [00:46<01:58, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13991/47780 [00:46<01:33, 359.78 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 647/47780 [00:46<06:20, 123.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14026/47780 [00:46<01:44, 323.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14052/47780 [00:46<01:45, 318.78 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13750/47780 [00:46<01:59, 283.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13683/47780 [00:46<01:50, 307.44 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13543/47780 [00:46<01:51, 307.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14028/47780 [00:46<01:35, 354.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14122/47780 [00:46<01:47, 312.59 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14086/47780 [00:46<01:43, 324.72 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13781/47780 [00:46<01:58, 286.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13718/47780 [00:46<01:48, 313.16 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14059/47780 [00:46<01:54, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14067/47780 [00:46<01:34, 356.90 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13580/47780 [00:46<01:49, 311.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14168/47780 [00:46<01:37, 344.34 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14124/47780 [00:46<01:41, 333.11 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13818/47780 [00:46<01:52, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14103/47780 [00:47<01:35, 353.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13612/47780 [00:46<01:48, 313.47 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13750/47780 [00:47<01:54, 297.89 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14205/47780 [00:47<01:36, 348.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14090/47780 [00:47<02:15, 247.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13850/47780 [00:47<01:51, 304.43 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14158/47780 [00:47<01:44, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14140/47780 [00:47<01:34, 354.35 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13648/47780 [00:47<01:45, 323.05 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13781/47780 [00:47<01:53, 298.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14241/47780 [00:47<01:37, 343.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14177/47780 [00:47<01:25, 392.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14182/47780 [00:47<01:30, 373.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14201/47780 [00:47<01:37, 343.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13881/47780 [00:47<01:56, 291.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13691/47780 [00:47<01:37, 349.54 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13813/47780 [00:47<01:53, 299.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14280/47780 [00:47<01:34, 356.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14221/47780 [00:47<01:31, 367.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13911/47780 [00:47<01:58, 285.41 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14221/47780 [00:47<01:33, 360.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14236/47780 [00:47<01:41, 329.06 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13727/47780 [00:47<01:41, 337.02 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14316/47780 [00:47<01:36, 345.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13844/47780 [00:47<01:58, 287.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13946/47780 [00:47<01:51, 303.05 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14270/47780 [00:47<01:41, 329.56 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14258/47780 [00:47<01:35, 351.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13761/47780 [00:47<01:43, 330.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13873/47780 [00:47<01:58, 285.04 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14351/47780 [00:47<01:40, 331.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14262/47780 [00:47<01:40, 332.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13986/47780 [00:47<01:44, 323.64 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14304/47780 [00:47<01:45, 318.38 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13803/47780 [00:47<01:37, 347.84 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13907/47780 [00:47<01:56, 290.97 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14385/47780 [00:47<01:40, 333.67 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14296/47780 [00:47<01:39, 336.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14303/47780 [00:47<01:35, 350.40 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14019/47780 [00:47<01:47, 314.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14336/47780 [00:47<01:45, 318.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13842/47780 [00:47<01:34, 357.89 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13939/47780 [00:47<01:53, 298.91 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14332/47780 [00:47<01:39, 336.27 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14353/47780 [00:47<01:26, 384.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14419/47780 [00:47<01:48, 307.79 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14053/47780 [00:47<01:47, 314.86 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13878/47780 [00:47<01:35, 356.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14368/47780 [00:47<01:47, 312.19 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13969/47780 [00:47<01:54, 295.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14370/47780 [00:47<01:35, 348.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14468/47780 [00:47<01:33, 357.12 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14394/47780 [00:47<01:32, 360.75 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14402/47780 [00:47<01:45, 316.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14091/47780 [00:47<01:42, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13914/47780 [00:47<01:39, 341.17 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14408/47780 [00:47<01:36, 345.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13999/47780 [00:47<02:00, 280.55 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14432/47780 [00:47<01:33, 358.33 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14505/47780 [00:47<01:47, 309.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14131/47780 [00:47<01:36, 349.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13949/47780 [00:47<01:39, 339.79 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14434/47780 [00:47<01:52, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14443/47780 [00:47<01:37, 341.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14029/47780 [00:47<01:59, 283.50 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14469/47780 [00:47<01:38, 336.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14554/47780 [00:48<01:33, 355.14 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14168/47780 [00:48<01:35, 351.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13987/47780 [00:48<01:37, 347.85 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14470/47780 [00:48<01:48, 307.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14058/47780 [00:48<01:59, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 691/47780 [00:48<11:06, 70.66 examples/s] 
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14478/47780 [00:48<01:41, 326.69 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14504/47780 [00:48<01:37, 339.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14592/47780 [00:48<01:35, 348.15 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14204/47780 [00:48<01:39, 338.31 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14024/47780 [00:48<01:36, 349.99 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14091/47780 [00:48<01:55, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14506/47780 [00:48<01:46, 311.89 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14513/47780 [00:48<01:40, 329.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 853/47780 [00:48<04:59, 156.86 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14539/47780 [00:48<01:38, 338.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14629/47780 [00:48<01:36, 343.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14060/47780 [00:48<01:37, 344.37 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14123/47780 [00:48<01:53, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14240/47780 [00:48<01:45, 318.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14543/47780 [00:48<01:43, 321.01 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14547/47780 [00:48<01:43, 321.78 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14574/47780 [00:48<01:45, 314.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14097/47780 [00:48<01:36, 348.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14665/47780 [00:48<01:40, 328.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14169/47780 [00:48<01:37, 344.08 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14274/47780 [00:48<01:44, 321.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14576/47780 [00:48<01:42, 323.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14584/47780 [00:48<01:39, 335.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14610/47780 [00:48<01:43, 319.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14138/47780 [00:48<01:32, 361.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14207/47780 [00:48<01:34, 354.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14703/47780 [00:48<01:36, 342.10 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14614/47780 [00:48<01:37, 339.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14307/47780 [00:48<01:44, 320.33 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14619/47780 [00:48<01:38, 335.74 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14178/47780 [00:48<01:31, 368.83 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14643/47780 [00:48<01:46, 311.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14340/47780 [00:48<01:45, 316.76 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14243/47780 [00:48<01:40, 332.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14649/47780 [00:48<01:41, 327.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14738/47780 [00:48<01:43, 319.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14660/47780 [00:48<01:33, 352.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14215/47780 [00:48<01:31, 368.71 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14677/47780 [00:48<01:44, 316.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14378/47780 [00:48<01:41, 329.91 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14279/47780 [00:48<01:39, 336.74 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14775/47780 [00:48<01:39, 331.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14699/47780 [00:48<01:31, 359.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14683/47780 [00:48<01:42, 323.86 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14253/47780 [00:48<01:31, 368.09 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14712/47780 [00:48<01:41, 325.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14413/47780 [00:48<01:40, 331.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14314/47780 [00:48<01:39, 336.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14809/47780 [00:48<01:40, 327.49 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14736/47780 [00:48<01:33, 353.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14723/47780 [00:48<01:39, 332.50 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14290/47780 [00:48<01:30, 368.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14757/47780 [00:48<01:32, 357.39 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14776/47780 [00:48<01:31, 359.43 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14348/47780 [00:48<01:43, 322.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14449/47780 [00:48<01:44, 319.63 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14843/47780 [00:48<01:48, 304.70 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14757/47780 [00:48<01:48, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14793/47780 [00:48<01:33, 353.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14334/47780 [00:48<01:29, 372.22 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14813/47780 [00:49<01:31, 362.08 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14386/47780 [00:49<01:38, 338.27 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14498/47780 [00:49<01:31, 364.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14875/47780 [00:49<01:46, 308.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14812/47780 [00:49<01:31, 359.55 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14831/47780 [00:49<01:31, 361.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14373/47780 [00:49<01:28, 377.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14421/47780 [00:49<01:40, 330.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14910/47780 [00:49<01:42, 320.01 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14535/47780 [00:49<01:37, 339.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14850/47780 [00:49<01:41, 325.64 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14849/47780 [00:49<01:35, 343.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14875/47780 [00:49<01:25, 384.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14411/47780 [00:49<01:32, 361.15 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14455/47780 [00:49<01:41, 329.12 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14943/47780 [00:49<01:46, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14571/47780 [00:49<01:38, 337.98 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14889/47780 [00:49<01:37, 336.84 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14884/47780 [00:49<01:41, 323.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14915/47780 [00:49<01:30, 363.51 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14489/47780 [00:49<01:42, 324.88 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14448/47780 [00:49<01:43, 323.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14975/47780 [00:49<01:47, 305.10 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14607/47780 [00:49<01:38, 336.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14926/47780 [00:49<01:37, 338.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14926/47780 [00:49<01:35, 343.59 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14952/47780 [00:49<01:33, 352.56 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14525/47780 [00:49<01:39, 334.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14484/47780 [00:49<01:39, 333.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15011/47780 [00:49<01:43, 317.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14644/47780 [00:49<01:37, 338.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14968/47780 [00:49<01:31, 357.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14962/47780 [00:49<01:35, 343.55 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14989/47780 [00:49<01:32, 354.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14562/47780 [00:49<01:38, 338.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14684/47780 [00:49<01:34, 351.66 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15043/47780 [00:49<01:46, 307.17 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14518/47780 [00:49<01:47, 310.64 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15005/47780 [00:49<01:33, 350.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 926/47780 [00:49<07:45, 100.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15003/47780 [00:49<01:31, 358.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15025/47780 [00:49<01:38, 332.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14596/47780 [00:49<01:42, 322.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14726/47780 [00:49<01:29, 369.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15076/47780 [00:49<01:45, 310.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14551/47780 [00:49<01:46, 312.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15041/47780 [00:49<01:39, 329.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1040/47780 [00:49<05:07, 151.92 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15041/47780 [00:49<01:37, 337.17 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15063/47780 [00:49<01:37, 335.27 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14651/47780 [00:49<01:26, 382.13 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15113/47780 [00:49<01:39, 326.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14590/47780 [00:49<01:42, 323.42 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15075/47780 [00:49<01:39, 328.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14764/47780 [00:49<01:39, 331.98 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15076/47780 [00:49<01:39, 329.52 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15108/47780 [00:49<01:30, 362.77 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14690/47780 [00:49<01:28, 372.73 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15155/47780 [00:49<01:33, 350.33 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14623/47780 [00:49<01:43, 321.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14800/47780 [00:49<01:38, 335.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15109/47780 [00:49<01:45, 310.97 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15110/47780 [00:50<01:42, 319.30 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14730/47780 [00:50<01:27, 376.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15145/47780 [00:49<01:35, 341.49 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15191/47780 [00:50<01:37, 333.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14656/47780 [00:50<01:46, 309.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14835/47780 [00:50<01:41, 324.14 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15145/47780 [00:50<01:43, 314.36 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15147/47780 [00:50<01:40, 326.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14768/47780 [00:50<01:27, 377.56 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15182/47780 [00:50<01:34, 345.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15229/47780 [00:50<01:34, 342.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14689/47780 [00:50<01:50, 299.33 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15179/47780 [00:50<01:42, 317.94 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14868/47780 [00:50<01:45, 313.04 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14806/47780 [00:50<01:28, 373.66 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15218/47780 [00:50<01:34, 344.83 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15180/47780 [00:50<01:45, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15266/47780 [00:50<01:33, 346.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14738/47780 [00:50<01:35, 347.41 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15211/47780 [00:50<01:42, 318.48 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14905/47780 [00:50<01:42, 321.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15261/47780 [00:50<01:28, 365.91 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14844/47780 [00:50<01:31, 361.62 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15222/47780 [00:50<01:36, 336.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14780/47780 [00:50<01:31, 359.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15301/47780 [00:50<01:42, 318.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15256/47780 [00:50<01:32, 351.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14943/47780 [00:50<01:38, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15298/47780 [00:50<01:28, 366.85 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15262/47780 [00:50<01:32, 350.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14881/47780 [00:50<01:38, 334.48 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15337/47780 [00:50<01:41, 320.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15293/47780 [00:50<01:33, 348.93 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14817/47780 [00:50<01:37, 339.30 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14985/47780 [00:50<01:32, 354.42 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15335/47780 [00:50<01:31, 353.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15298/47780 [00:50<01:42, 317.28 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15370/47780 [00:50<01:40, 321.82 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14916/47780 [00:50<01:45, 311.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15329/47780 [00:50<01:33, 346.77 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15021/47780 [00:50<01:34, 348.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14852/47780 [00:50<01:41, 324.89 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1106/47780 [00:50<06:25, 120.97 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15371/47780 [00:50<01:36, 334.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15337/47780 [00:50<01:36, 336.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15403/47780 [00:50<01:41, 318.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14950/47780 [00:50<01:42, 319.29 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15364/47780 [00:50<01:36, 337.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14896/47780 [00:50<01:32, 355.81 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15056/47780 [00:50<01:37, 337.09 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1163/47780 [00:50<05:17, 146.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15406/47780 [00:50<01:39, 324.74 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14983/47780 [00:50<01:41, 321.61 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15437/47780 [00:50<01:43, 313.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15398/47780 [00:50<01:36, 334.46 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15373/47780 [00:50<01:43, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15093/47780 [00:50<01:36, 338.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14933/47780 [00:50<01:38, 333.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15439/47780 [00:50<01:40, 320.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15471/47780 [00:50<01:41, 319.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15016/47780 [00:50<01:45, 310.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15432/47780 [00:50<01:37, 332.23 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15128/47780 [00:50<01:35, 341.94 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15406/47780 [00:50<01:45, 307.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14967/47780 [00:50<01:38, 331.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15478/47780 [00:50<01:36, 334.43 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15518/47780 [00:51<01:28, 362.71 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15056/47780 [00:51<01:37, 335.37 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15466/47780 [00:51<01:36, 334.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15441/47780 [00:51<01:41, 318.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15163/47780 [00:51<01:39, 328.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15512/47780 [00:51<01:36, 335.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15555/47780 [00:51<01:30, 355.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15002/47780 [00:51<01:55, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15480/47780 [00:51<01:35, 336.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15090/47780 [00:51<01:44, 311.71 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15501/47780 [00:51<01:41, 317.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15197/47780 [00:51<01:49, 298.63 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15546/47780 [00:51<01:40, 322.08 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15049/47780 [00:51<01:39, 329.99 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15591/47780 [00:51<01:35, 336.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15122/47780 [00:51<01:46, 307.59 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15543/47780 [00:51<01:33, 345.79 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15515/47780 [00:51<01:40, 320.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15240/47780 [00:51<01:39, 326.53 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15580/47780 [00:51<01:40, 320.32 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15086/47780 [00:51<01:37, 337.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15636/47780 [00:51<01:27, 368.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15578/47780 [00:51<01:35, 338.94 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15154/47780 [00:51<01:48, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15548/47780 [00:51<01:40, 319.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15286/47780 [00:51<01:29, 362.42 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15619/47780 [00:51<01:36, 332.36 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15123/47780 [00:51<01:37, 334.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15674/47780 [00:51<01:28, 360.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15613/47780 [00:51<01:37, 330.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15584/47780 [00:51<01:40, 320.15 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15186/47780 [00:51<01:52, 290.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1215/47780 [00:51<06:33, 118.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15324/47780 [00:51<01:35, 340.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15655/47780 [00:51<01:35, 336.46 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15158/47780 [00:51<01:43, 315.17 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15647/47780 [00:51<01:37, 329.82 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15618/47780 [00:51<01:39, 322.08 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15216/47780 [00:51<01:51, 292.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15712/47780 [00:51<01:37, 328.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1265/47780 [00:51<05:22, 144.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15360/47780 [00:51<01:36, 334.96 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15689/47780 [00:51<01:37, 329.88 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15191/47780 [00:51<01:44, 311.88 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15651/47780 [00:51<01:40, 320.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15246/47780 [00:51<01:51, 292.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15746/47780 [00:51<01:40, 318.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15681/47780 [00:51<01:46, 302.01 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15400/47780 [00:51<01:33, 345.59 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15728/47780 [00:51<01:34, 339.53 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15684/47780 [00:51<01:40, 320.78 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15228/47780 [00:51<01:42, 317.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15276/47780 [00:51<01:53, 286.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15728/47780 [00:51<01:33, 343.56 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15779/47780 [00:51<01:46, 299.20 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15444/47780 [00:51<01:29, 359.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15762/47780 [00:51<01:36, 331.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15721/47780 [00:51<01:35, 333.97 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15263/47780 [00:51<01:41, 319.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15318/47780 [00:51<01:41, 321.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15486/47780 [00:51<01:26, 374.34 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15803/47780 [00:51<01:31, 350.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15764/47780 [00:51<01:50, 290.39 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15755/47780 [00:52<01:36, 331.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15301/47780 [00:51<01:37, 332.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15351/47780 [00:51<01:40, 323.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15810/47780 [00:52<02:04, 256.33 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15524/47780 [00:52<01:27, 369.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15849/47780 [00:52<01:24, 377.27 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15815/47780 [00:52<01:32, 344.68 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15338/47780 [00:52<01:34, 342.85 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15789/47780 [00:52<01:39, 322.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15384/47780 [00:52<01:44, 311.17 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15569/47780 [00:52<01:23, 383.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15889/47780 [00:52<01:25, 374.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15838/47780 [00:52<02:23, 223.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15856/47780 [00:52<01:30, 354.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15824/47780 [00:52<01:37, 326.84 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15373/47780 [00:52<01:36, 337.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15419/47780 [00:52<01:41, 318.41 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15608/47780 [00:52<01:23, 383.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15922/47780 [00:52<01:28, 359.92 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15928/47780 [00:52<01:29, 355.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15898/47780 [00:52<01:27, 363.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15857/47780 [00:52<01:39, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15407/47780 [00:52<01:38, 327.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15452/47780 [00:52<01:41, 318.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15647/47780 [00:52<01:28, 361.58 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15965/47780 [00:52<01:29, 354.64 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15936/47780 [00:52<01:28, 360.70 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15964/47780 [00:52<01:31, 347.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15890/47780 [00:52<01:38, 322.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15441/47780 [00:52<01:38, 327.34 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15485/47780 [00:52<01:46, 304.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15973/47780 [00:52<01:27, 362.64 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16003/47780 [00:52<01:32, 344.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16002/47780 [00:52<01:36, 328.72 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15684/47780 [00:52<01:37, 328.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15522/47780 [00:52<01:40, 322.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15923/47780 [00:52<01:47, 297.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15474/47780 [00:52<01:46, 303.51 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16010/47780 [00:52<01:30, 349.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16040/47780 [00:52<01:30, 350.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16050/47780 [00:52<01:26, 366.80 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15718/47780 [00:52<01:39, 321.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15961/47780 [00:52<01:40, 316.82 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15513/47780 [00:52<01:38, 327.16 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15555/47780 [00:52<01:51, 288.55 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1306/47780 [00:52<08:48, 87.90 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16046/47780 [00:52<01:33, 340.80 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16089/47780 [00:52<01:26, 365.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15994/47780 [00:52<01:39, 320.32 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15751/47780 [00:52<01:39, 322.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15547/47780 [00:52<01:41, 316.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15592/47780 [00:52<01:44, 306.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16078/47780 [00:52<01:43, 306.71 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1450/47780 [00:52<04:29, 171.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16081/47780 [00:52<01:34, 336.07 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16127/47780 [00:52<01:28, 357.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15784/47780 [00:52<01:44, 305.18 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16027/47780 [00:52<01:44, 302.56 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15580/47780 [00:52<01:42, 313.02 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16117/47780 [00:52<01:39, 317.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15624/47780 [00:52<01:47, 298.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16116/47780 [00:52<01:36, 328.36 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15614/47780 [00:52<01:41, 317.49 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15815/47780 [00:52<01:47, 296.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16164/47780 [00:52<01:35, 331.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16151/47780 [00:53<01:37, 323.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16058/47780 [00:53<01:53, 279.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15655/47780 [00:53<01:49, 293.76 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16158/47780 [00:53<01:32, 342.16 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15646/47780 [00:53<01:42, 314.57 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15845/47780 [00:53<01:49, 291.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16185/47780 [00:53<01:37, 324.49 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16097/47780 [00:53<01:43, 306.59 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16198/47780 [00:53<01:41, 310.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15687/47780 [00:53<01:46, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16193/47780 [00:53<01:33, 337.25 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15684/47780 [00:53<01:36, 332.84 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15723/47780 [00:53<01:41, 314.76 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16230/47780 [00:53<01:41, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16130/47780 [00:53<01:46, 296.14 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15875/47780 [00:53<01:57, 272.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16219/47780 [00:53<01:45, 299.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16231/47780 [00:53<01:30, 349.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15718/47780 [00:53<01:38, 324.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16264/47780 [00:53<01:40, 314.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15906/47780 [00:53<01:55, 276.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16162/47780 [00:53<01:46, 296.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15755/47780 [00:53<01:50, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16271/47780 [00:53<01:27, 360.20 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15756/47780 [00:53<01:34, 337.47 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16250/47780 [00:53<02:07, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16299/47780 [00:53<01:40, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16195/47780 [00:53<01:44, 302.14 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15796/47780 [00:53<01:40, 319.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15934/47780 [00:53<02:07, 250.52 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15802/47780 [00:53<01:27, 366.91 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16308/47780 [00:53<01:31, 343.02 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16307/47780 [00:53<01:39, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16226/47780 [00:53<01:46, 297.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16331/47780 [00:53<01:45, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15829/47780 [00:53<01:44, 305.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15977/47780 [00:53<01:48, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15841/47780 [00:53<01:26, 369.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16343/47780 [00:53<01:36, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16346/47780 [00:53<01:34, 332.06 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16258/47780 [00:53<01:44, 300.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16363/47780 [00:53<01:43, 302.69 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16010/47780 [00:53<01:44, 303.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1511/47780 [00:53<06:00, 128.50 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15861/47780 [00:53<01:53, 280.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15879/47780 [00:53<01:28, 359.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16376/47780 [00:53<01:36, 324.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16397/47780 [00:53<01:42, 307.41 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16289/47780 [00:53<01:49, 286.96 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1600/47780 [00:53<04:17, 179.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16042/47780 [00:53<01:45, 301.28 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16384/47780 [00:53<01:47, 292.16 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15902/47780 [00:53<01:42, 312.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16409/47780 [00:53<01:37, 321.95 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15918/47780 [00:53<01:30, 352.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16320/47780 [00:53<01:48, 290.12 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16073/47780 [00:53<01:47, 293.99 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16428/47780 [00:53<01:50, 283.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16440/47780 [00:53<01:29, 350.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15942/47780 [00:53<01:35, 332.29 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16443/47780 [00:53<01:36, 325.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15954/47780 [00:53<01:30, 350.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16352/47780 [00:54<01:48, 288.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16103/47780 [00:53<01:47, 294.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16457/47780 [00:53<01:53, 276.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16484/47780 [00:54<01:25, 368.07 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16476/47780 [00:54<01:38, 317.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15976/47780 [00:54<01:43, 307.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15990/47780 [00:54<01:36, 330.44 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16394/47780 [00:54<01:37, 321.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16133/47780 [00:54<01:47, 294.07 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16486/47780 [00:54<01:56, 267.92 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16523/47780 [00:54<01:25, 363.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16508/47780 [00:54<01:39, 314.51 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16008/47780 [00:54<01:43, 307.12 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16031/47780 [00:54<01:32, 345.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16167/47780 [00:54<01:42, 307.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16436/47780 [00:54<01:29, 349.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16515/47780 [00:54<01:55, 271.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16561/47780 [00:54<01:25, 363.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16542/47780 [00:54<01:39, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16048/47780 [00:54<01:37, 327.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16067/47780 [00:54<01:32, 341.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16474/47780 [00:54<01:27, 357.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16200/47780 [00:54<01:41, 310.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16551/47780 [00:54<01:47, 289.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16599/47780 [00:54<01:29, 348.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16581/47780 [00:54<01:33, 332.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16083/47780 [00:54<01:37, 324.72 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16102/47780 [00:54<01:34, 335.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16510/47780 [00:54<01:30, 346.88 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16239/47780 [00:54<01:40, 315.38 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16590/47780 [00:54<01:39, 314.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16620/47780 [00:54<01:29, 349.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16635/47780 [00:54<01:30, 344.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16116/47780 [00:54<01:37, 323.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16136/47780 [00:54<01:34, 333.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16545/47780 [00:54<01:32, 336.59 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16274/47780 [00:54<01:38, 321.44 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16631/47780 [00:54<01:32, 337.21 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16671/47780 [00:54<01:29, 348.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16149/47780 [00:54<01:39, 317.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16171/47780 [00:54<01:34, 336.06 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16579/47780 [00:54<01:33, 333.45 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16307/47780 [00:54<01:38, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16656/47780 [00:54<01:49, 283.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16665/47780 [00:54<01:35, 327.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16713/47780 [00:54<01:25, 364.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16186/47780 [00:54<01:38, 321.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16214/47780 [00:54<01:29, 351.10 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16613/47780 [00:54<01:33, 335.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16341/47780 [00:54<01:36, 325.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16714/47780 [00:54<01:26, 357.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16698/47780 [00:54<01:35, 327.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16757/47780 [00:54<01:21, 382.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16259/47780 [00:54<01:23, 377.72 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16220/47780 [00:54<01:45, 298.92 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16753/47780 [00:54<01:29, 347.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16647/47780 [00:54<01:45, 295.85 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16731/47780 [00:54<01:37, 316.99 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16374/47780 [00:54<01:49, 287.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16798/47780 [00:54<01:23, 369.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16305/47780 [00:54<01:18, 398.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16266/47780 [00:54<01:32, 339.43 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16792/47780 [00:54<01:26, 358.60 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16679/47780 [00:54<01:45, 295.89 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16408/47780 [00:54<01:45, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16768/47780 [00:54<01:36, 321.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16836/47780 [00:55<01:23, 370.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16346/47780 [00:54<01:18, 399.18 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16301/47780 [00:55<01:36, 327.34 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16830/47780 [00:55<01:27, 352.85 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16719/47780 [00:55<01:36, 320.77 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16809/47780 [00:55<01:29, 346.12 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16448/47780 [00:55<01:36, 324.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16874/47780 [00:55<01:24, 365.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16387/47780 [00:55<01:19, 396.41 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16874/47780 [00:55<01:22, 372.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16484/47780 [00:55<01:34, 332.07 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16752/47780 [00:55<01:38, 316.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16335/47780 [00:55<01:46, 295.52 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1660/47780 [00:55<07:37, 100.77 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16849/47780 [00:55<01:29, 346.02 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16427/47780 [00:55<01:19, 392.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16913/47780 [00:55<01:28, 348.80 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16913/47780 [00:55<01:24, 365.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16790/47780 [00:55<01:33, 332.85 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1869/47780 [00:55<03:38, 209.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16518/47780 [00:55<01:36, 323.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16366/47780 [00:55<01:47, 293.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16468/47780 [00:55<01:20, 390.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16949/47780 [00:55<01:32, 333.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16884/47780 [00:55<01:51, 277.46 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16826/47780 [00:55<01:31, 338.16 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16951/47780 [00:55<01:24, 365.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16561/47780 [00:55<01:28, 351.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16396/47780 [00:55<01:49, 285.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16512/47780 [00:55<01:18, 400.66 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17000/47780 [00:55<01:21, 377.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16931/47780 [00:55<01:35, 322.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16865/47780 [00:55<01:27, 352.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16989/47780 [00:55<01:29, 345.55 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16429/47780 [00:55<01:46, 294.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16597/47780 [00:55<01:34, 329.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16553/47780 [00:55<01:20, 389.66 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17039/47780 [00:55<01:27, 353.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16985/47780 [00:55<01:21, 377.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16901/47780 [00:55<01:29, 346.77 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16463/47780 [00:55<01:42, 305.55 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17027/47780 [00:55<01:28, 348.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16631/47780 [00:55<01:34, 328.25 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16593/47780 [00:55<01:21, 383.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17075/47780 [00:55<01:29, 344.35 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17026/47780 [00:55<01:23, 369.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16936/47780 [00:55<01:30, 339.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16495/47780 [00:55<01:42, 304.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17066/47780 [00:55<01:27, 351.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16665/47780 [00:55<01:43, 301.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17110/47780 [00:55<01:29, 341.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16632/47780 [00:55<01:31, 342.20 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16528/47780 [00:55<01:41, 308.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16972/47780 [00:55<01:31, 338.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17065/47780 [00:55<01:26, 353.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17115/47780 [00:55<01:19, 386.20 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16706/47780 [00:55<01:35, 326.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16667/47780 [00:55<01:32, 337.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17145/47780 [00:55<01:32, 329.77 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17008/47780 [00:55<01:29, 344.10 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16564/47780 [00:55<01:36, 322.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17106/47780 [00:55<01:24, 364.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17154/47780 [00:55<01:19, 386.04 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16740/47780 [00:55<01:35, 323.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17185/47780 [00:56<01:29, 341.71 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16702/47780 [00:55<01:34, 329.80 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17043/47780 [00:56<01:29, 341.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16605/47780 [00:56<01:30, 344.32 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17146/47780 [00:55<01:22, 370.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17195/47780 [00:56<01:18, 388.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16778/47780 [00:56<01:34, 328.25 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17227/47780 [00:56<01:24, 359.55 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16736/47780 [00:56<01:34, 328.97 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17087/47780 [00:56<01:24, 362.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16640/47780 [00:56<01:31, 341.71 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17190/47780 [00:56<01:18, 389.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17235/47780 [00:56<01:18, 388.21 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16812/47780 [00:56<01:35, 323.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16770/47780 [00:56<01:34, 328.67 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17264/47780 [00:56<01:28, 343.07 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16675/47780 [00:56<01:32, 336.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17124/47780 [00:56<01:27, 348.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17274/47780 [00:56<01:23, 366.27 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17230/47780 [00:56<01:28, 344.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16852/47780 [00:56<01:30, 341.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16812/47780 [00:56<01:28, 350.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17299/47780 [00:56<01:28, 344.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17159/47780 [00:56<01:28, 344.37 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16709/47780 [00:56<01:38, 315.85 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17313/47780 [00:56<01:23, 366.04 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17272/47780 [00:56<01:26, 354.15 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16887/47780 [00:56<01:34, 325.22 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16856/47780 [00:56<01:22, 374.82 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17334/47780 [00:56<01:29, 338.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17199/47780 [00:56<01:25, 356.75 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16750/47780 [00:56<01:30, 341.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17354/47780 [00:56<01:21, 373.88 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17310/47780 [00:56<01:26, 352.70 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16897/47780 [00:56<01:20, 382.11 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16930/47780 [00:56<01:28, 347.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17370/47780 [00:56<01:30, 337.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16785/47780 [00:56<01:31, 340.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17235/47780 [00:56<01:29, 342.03 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1959/47780 [00:56<05:27, 139.77 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17392/47780 [00:56<01:27, 348.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17346/47780 [00:56<01:27, 347.85 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16965/47780 [00:56<01:32, 332.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17411/47780 [00:56<01:24, 357.62 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17270/47780 [00:56<01:29, 340.30 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 2117/47780 [00:56<03:31, 215.90 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16936/47780 [00:56<01:31, 336.64 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16820/47780 [00:56<01:37, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17428/47780 [00:56<01:31, 333.23 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17382/47780 [00:56<01:31, 333.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17000/47780 [00:56<01:32, 334.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17447/47780 [00:56<01:24, 357.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17306/47780 [00:56<01:29, 341.95 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16971/47780 [00:56<01:32, 333.87 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16859/47780 [00:56<01:33, 330.32 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17463/47780 [00:56<01:30, 333.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17421/47780 [00:56<01:28, 344.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17483/47780 [00:56<01:26, 350.85 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17341/47780 [00:56<01:33, 325.68 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17006/47780 [00:56<01:34, 324.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16894/47780 [00:56<01:32, 332.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17497/47780 [00:56<01:31, 332.27 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17456/47780 [00:56<01:32, 328.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17521/47780 [00:56<01:25, 355.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17034/47780 [00:56<02:06, 242.99 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17374/47780 [00:57<01:33, 324.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17040/47780 [00:56<01:34, 324.90 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16928/47780 [00:57<01:34, 326.79 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17532/47780 [00:57<01:29, 336.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17562/47780 [00:57<01:21, 370.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17490/47780 [00:57<01:34, 320.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17103/47780 [00:57<01:29, 343.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17413/47780 [00:57<01:29, 337.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17073/47780 [00:57<01:34, 325.04 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16969/47780 [00:57<01:30, 338.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17566/47780 [00:57<01:35, 316.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17524/47780 [00:57<01:36, 312.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17600/47780 [00:57<01:26, 349.20 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17110/47780 [00:57<01:31, 335.30 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17010/47780 [00:57<01:25, 358.50 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17447/47780 [00:57<01:39, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17144/47780 [00:57<01:38, 309.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17600/47780 [00:57<01:35, 315.98 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17556/47780 [00:57<01:38, 307.76 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17144/47780 [00:57<01:32, 332.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17636/47780 [00:57<01:33, 323.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17051/47780 [00:57<01:25, 361.46 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17493/47780 [00:57<01:29, 338.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17632/47780 [00:57<01:38, 306.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17180/47780 [00:57<01:42, 298.19 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17587/47780 [00:57<01:42, 295.25 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17669/47780 [00:57<01:33, 321.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17179/47780 [00:57<01:35, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17091/47780 [00:57<01:22, 372.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17528/47780 [00:57<01:32, 327.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17214/47780 [00:57<01:41, 302.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17663/47780 [00:57<01:42, 294.17 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17617/47780 [00:57<01:45, 286.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17212/47780 [00:57<01:37, 313.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17129/47780 [00:57<01:25, 358.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17702/47780 [00:57<01:42, 292.12 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17698/47780 [00:57<01:38, 306.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17247/47780 [00:57<01:39, 306.14 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17563/47780 [00:57<01:41, 297.98 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17649/47780 [00:57<01:42, 293.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17248/47780 [00:57<01:33, 325.04 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17744/47780 [00:57<01:32, 325.52 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17166/47780 [00:57<01:30, 338.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17734/47780 [00:57<01:33, 321.52 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17281/47780 [00:57<01:38, 308.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17607/47780 [00:57<01:31, 330.71 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17686/47780 [00:57<01:35, 314.60 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17283/47780 [00:57<01:33, 324.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17201/47780 [00:57<01:33, 327.11 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17322/47780 [00:57<01:31, 332.25 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17778/47780 [00:57<01:42, 291.44 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17767/47780 [00:57<01:41, 296.97 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17736/47780 [00:57<01:24, 355.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17641/47780 [00:57<01:39, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17319/47780 [00:57<01:31, 334.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17238/47780 [00:57<01:31, 335.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17359/47780 [00:57<01:29, 338.78 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17829/47780 [00:57<01:27, 343.91 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17798/47780 [00:57<01:42, 293.89 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17775/47780 [00:57<01:22, 364.89 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17353/47780 [00:57<01:31, 331.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17674/47780 [00:57<01:38, 304.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17272/47780 [00:58<01:32, 328.56 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17397/47780 [00:58<01:28, 342.65 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17867/47780 [00:58<01:25, 349.51 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17812/47780 [00:57<01:23, 358.40 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17828/47780 [00:58<01:45, 285.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17706/47780 [00:58<01:37, 307.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17387/47780 [00:58<01:33, 323.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17905/47780 [00:58<01:23, 357.61 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17432/47780 [00:58<01:29, 340.62 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17306/47780 [00:58<01:37, 312.36 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17851/47780 [00:58<01:22, 362.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17857/47780 [00:58<01:47, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17422/47780 [00:58<01:34, 320.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17738/47780 [00:58<01:42, 292.26 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17471/47780 [00:58<01:26, 350.98 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17341/47780 [00:58<01:34, 321.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17893/47780 [00:58<01:39, 300.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17942/47780 [00:58<01:33, 318.58 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2210/47780 [00:58<05:52, 129.42 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17888/47780 [00:58<01:30, 330.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17772/47780 [00:58<01:39, 302.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17455/47780 [00:58<01:36, 315.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17374/47780 [00:58<01:34, 323.06 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17507/47780 [00:58<01:28, 341.84 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17924/47780 [00:58<01:43, 289.81 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17976/47780 [00:58<01:34, 314.05 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2485/47780 [00:58<03:00, 250.80 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17922/47780 [00:58<01:30, 330.19 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17487/47780 [00:58<01:36, 313.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17808/47780 [00:58<01:36, 311.50 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17543/47780 [00:58<01:28, 343.05 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17407/47780 [00:58<01:37, 311.66 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17955/47780 [00:58<01:42, 289.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18009/47780 [00:58<01:37, 305.45 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17525/47780 [00:58<01:34, 321.40 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17844/47780 [00:58<01:34, 317.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17956/47780 [00:58<01:34, 315.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17578/47780 [00:58<01:27, 344.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17445/47780 [00:58<01:31, 330.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17985/47780 [00:58<01:47, 276.92 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17567/47780 [00:58<01:27, 345.25 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17994/47780 [00:58<01:30, 329.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17876/47780 [00:58<01:36, 310.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18041/47780 [00:58<01:42, 290.81 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17484/47780 [00:58<01:28, 341.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17623/47780 [00:58<01:23, 362.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18016/47780 [00:58<01:45, 283.00 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17603/47780 [00:58<01:28, 341.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17912/47780 [00:58<01:33, 318.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18028/47780 [00:58<01:32, 321.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18071/47780 [00:58<01:45, 280.81 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17661/47780 [00:58<01:22, 363.07 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17519/47780 [00:58<01:41, 297.56 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18056/47780 [00:58<01:35, 312.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17641/47780 [00:58<01:26, 350.27 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17951/47780 [00:58<01:28, 338.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18071/47780 [00:58<01:25, 348.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18104/47780 [00:58<01:41, 291.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17700/47780 [00:58<01:21, 370.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18089/47780 [00:58<01:34, 313.75 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17572/47780 [00:58<01:26, 348.39 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17988/47780 [00:58<01:26, 343.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18110/47780 [00:58<01:23, 355.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18147/47780 [00:58<01:30, 325.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17677/47780 [00:58<01:34, 318.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17738/47780 [00:58<01:23, 359.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18123/47780 [00:59<01:32, 321.12 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18024/47780 [00:59<01:26, 342.11 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2610/47780 [00:59<03:13, 234.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18146/47780 [00:58<01:23, 354.02 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17608/47780 [00:59<01:31, 329.94 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18184/47780 [00:59<01:30, 327.10 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17713/47780 [00:59<01:33, 322.94 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17775/47780 [00:59<01:25, 352.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18156/47780 [00:59<01:34, 313.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18182/47780 [00:59<01:27, 339.12 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18059/47780 [00:59<01:33, 316.93 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17642/47780 [00:59<01:35, 316.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18218/47780 [00:59<01:34, 313.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17746/47780 [00:59<01:36, 311.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17812/47780 [00:59<01:24, 353.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18218/47780 [00:59<01:28, 333.75 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18093/47780 [00:59<01:32, 320.09 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18189/47780 [00:59<01:43, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18259/47780 [00:59<01:26, 339.72 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17676/47780 [00:59<01:36, 313.38 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17784/47780 [00:59<01:31, 326.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17848/47780 [00:59<01:28, 339.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18221/47780 [00:59<01:40, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18295/47780 [00:59<01:25, 345.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18252/47780 [00:59<01:32, 320.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18126/47780 [00:59<01:37, 305.66 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17708/47780 [00:59<01:37, 307.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17817/47780 [00:59<01:37, 306.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17883/47780 [00:59<01:30, 331.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18262/47780 [00:59<01:31, 323.29 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18174/47780 [00:59<01:24, 349.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17739/47780 [00:59<01:38, 304.94 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18330/47780 [00:59<01:31, 320.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17855/47780 [00:59<01:34, 316.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17931/47780 [00:59<01:21, 367.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18285/47780 [00:59<01:43, 285.75 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18298/47780 [00:59<01:28, 333.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17771/47780 [00:59<01:38, 306.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18210/47780 [00:59<01:27, 337.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18364/47780 [00:59<01:32, 318.70 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17887/47780 [00:59<01:37, 307.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18315/47780 [00:59<01:46, 277.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17969/47780 [00:59<01:26, 344.94 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18342/47780 [00:59<01:21, 359.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17803/47780 [00:59<01:39, 301.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18246/47780 [00:59<01:27, 336.49 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17926/47780 [00:59<01:32, 323.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18397/47780 [00:59<01:38, 299.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18344/47780 [00:59<01:45, 278.29 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18004/47780 [00:59<01:31, 324.14 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18379/47780 [00:59<01:25, 342.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17834/47780 [00:59<01:40, 298.75 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17961/47780 [00:59<01:32, 323.42 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18280/47780 [00:59<01:36, 306.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18384/47780 [00:59<01:35, 307.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18432/47780 [00:59<01:37, 300.08 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18037/47780 [00:59<01:36, 306.97 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18415/47780 [00:59<01:26, 340.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17865/47780 [00:59<01:39, 300.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17994/47780 [00:59<01:34, 314.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18416/47780 [00:59<01:38, 297.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18312/47780 [00:59<01:40, 294.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18463/47780 [00:59<01:42, 286.96 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18069/47780 [00:59<01:39, 297.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17896/47780 [01:00<01:41, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18450/47780 [01:00<01:29, 328.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18034/47780 [01:00<01:27, 338.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18450/47780 [01:00<01:37, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18342/47780 [01:00<01:42, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18492/47780 [01:00<01:43, 281.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18101/47780 [01:00<01:38, 300.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17931/47780 [01:00<01:37, 306.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18484/47780 [01:00<01:34, 310.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18070/47780 [01:00<01:30, 329.56 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18483/47780 [01:00<01:35, 307.45 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18373/47780 [01:00<01:42, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18521/47780 [01:00<01:50, 265.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18132/47780 [01:00<01:39, 296.72 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17967/47780 [01:00<01:32, 321.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18520/47780 [01:00<01:33, 313.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18106/47780 [01:00<01:27, 337.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18522/47780 [01:00<01:29, 327.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18402/47780 [01:00<01:44, 281.62 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18173/47780 [01:00<01:32, 320.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18559/47780 [01:00<01:44, 279.52 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18000/47780 [01:00<01:35, 313.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18556/47780 [01:00<01:33, 313.29 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18141/47780 [01:00<01:28, 334.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18555/47780 [01:00<01:30, 323.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18431/47780 [01:00<01:44, 281.11 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18591/47780 [01:00<01:41, 287.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18032/47780 [01:00<01:34, 314.97 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18206/47780 [01:00<01:33, 315.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2704/47780 [01:00<04:57, 151.61 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18593/47780 [01:00<01:31, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18590/47780 [01:00<01:28, 330.45 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18176/47780 [01:00<01:30, 327.00 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18468/47780 [01:00<01:37, 301.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18620/47780 [01:00<01:42, 285.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18245/47780 [01:00<01:28, 333.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18064/47780 [01:00<01:36, 309.36 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2979/47780 [01:00<02:44, 271.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18625/47780 [01:00<01:33, 311.78 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18628/47780 [01:00<01:28, 330.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18209/47780 [01:00<01:39, 297.68 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18651/47780 [01:00<01:39, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18499/47780 [01:00<01:45, 276.59 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18279/47780 [01:00<01:34, 310.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18096/47780 [01:00<01:45, 282.02 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18657/47780 [01:00<01:34, 308.31 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18664/47780 [01:00<01:26, 338.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18530/47780 [01:00<01:43, 282.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18684/47780 [01:00<01:38, 295.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18241/47780 [01:00<01:42, 287.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18311/47780 [01:00<01:37, 303.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18132/47780 [01:00<01:39, 297.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18698/47780 [01:00<01:26, 337.75 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18688/47780 [01:00<01:38, 294.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18563/47780 [01:00<01:39, 292.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18714/47780 [01:00<01:40, 290.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18271/47780 [01:00<01:42, 288.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18342/47780 [01:00<01:38, 298.68 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18164/47780 [01:00<01:40, 293.90 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18732/47780 [01:00<01:28, 328.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18723/47780 [01:00<01:34, 306.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18593/47780 [01:00<01:40, 291.14 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18744/47780 [01:00<01:39, 292.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18304/47780 [01:00<01:40, 293.28 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18376/47780 [01:00<01:36, 303.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18203/47780 [01:01<01:32, 319.45 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18754/47780 [01:01<01:39, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18765/47780 [01:00<01:37, 298.30 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18628/47780 [01:01<01:35, 304.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18774/47780 [01:01<01:40, 288.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18334/47780 [01:01<01:45, 279.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18239/47780 [01:01<01:29, 330.85 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18407/47780 [01:01<01:38, 298.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18784/47780 [01:01<01:38, 293.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18798/47780 [01:01<01:34, 306.67 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18661/47780 [01:01<01:34, 308.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18803/47780 [01:01<01:42, 282.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18366/47780 [01:01<01:45, 278.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18286/47780 [01:01<01:20, 368.12 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18439/47780 [01:01<01:37, 301.38 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18694/47780 [01:01<01:32, 314.51 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18830/47780 [01:01<01:36, 300.16 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18814/47780 [01:01<01:46, 271.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18833/47780 [01:01<01:47, 269.25 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18400/47780 [01:01<01:42, 285.98 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18470/47780 [01:01<01:43, 284.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18325/47780 [01:01<01:27, 335.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18862/47780 [01:01<01:35, 302.63 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18726/47780 [01:01<01:35, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18850/47780 [01:01<01:38, 294.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18861/47780 [01:01<01:48, 266.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18436/47780 [01:01<01:36, 304.81 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18511/47780 [01:01<01:31, 318.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18360/47780 [01:01<01:31, 321.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18880/47780 [01:01<01:39, 291.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18893/47780 [01:01<01:39, 291.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18888/47780 [01:01<01:50, 262.61 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18471/47780 [01:01<01:33, 311.92 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18758/47780 [01:01<01:48, 267.02 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18544/47780 [01:01<01:36, 301.56 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18399/47780 [01:01<01:27, 337.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18923/47780 [01:01<01:40, 287.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18910/47780 [01:01<01:47, 268.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18915/47780 [01:01<01:50, 260.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18503/47780 [01:01<01:38, 297.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18575/47780 [01:01<01:37, 300.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18786/47780 [01:01<02:02, 235.91 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18436/47780 [01:01<01:31, 321.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18959/47780 [01:01<01:35, 300.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18948/47780 [01:01<01:43, 277.85 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18938/47780 [01:01<01:49, 263.32 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18533/47780 [01:01<01:39, 295.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18618/47780 [01:01<01:27, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18846/47780 [01:01<01:29, 323.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18469/47780 [01:01<01:31, 319.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18996/47780 [01:01<01:32, 310.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18981/47780 [01:01<01:39, 288.78 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18965/47780 [01:01<01:53, 253.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18571/47780 [01:01<01:31, 318.68 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18653/47780 [01:01<01:28, 330.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18894/47780 [01:01<01:20, 358.60 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19028/47780 [01:01<01:32, 309.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18503/47780 [01:01<01:33, 313.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19002/47780 [01:01<01:41, 284.87 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3109/47780 [01:01<03:58, 187.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19012/47780 [01:01<01:43, 278.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18604/47780 [01:01<01:31, 318.35 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18692/47780 [01:01<01:24, 343.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18933/47780 [01:02<01:23, 344.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19059/47780 [01:01<01:35, 301.93 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18536/47780 [01:02<01:39, 294.48 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3282/47780 [01:02<02:51, 259.23 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18639/47780 [01:02<01:30, 323.73 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19040/47780 [01:02<01:48, 265.07 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18731/47780 [01:02<01:23, 348.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19096/47780 [01:02<01:30, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18970/47780 [01:02<01:27, 329.77 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18566/47780 [01:02<01:38, 295.51 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19031/47780 [01:02<02:11, 218.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19072/47780 [01:02<01:44, 273.59 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18673/47780 [01:02<01:34, 306.76 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18767/47780 [01:02<01:26, 336.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19128/47780 [01:02<01:30, 315.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18596/47780 [01:02<01:39, 293.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19075/47780 [01:02<01:46, 269.27 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19005/47780 [01:02<01:30, 317.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19100/47780 [01:02<01:47, 266.06 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18706/47780 [01:02<01:35, 303.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18801/47780 [01:02<01:33, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18626/47780 [01:02<01:38, 295.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19039/47780 [01:02<01:31, 315.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19160/47780 [01:02<01:43, 275.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18737/47780 [01:02<01:38, 295.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19127/47780 [01:02<01:51, 255.85 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18835/47780 [01:02<01:32, 311.57 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18657/47780 [01:02<01:38, 296.14 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19106/47780 [01:02<02:10, 219.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19076/47780 [01:02<01:28, 323.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19158/47780 [01:02<01:46, 268.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18770/47780 [01:02<01:36, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18691/47780 [01:02<01:37, 298.48 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18867/47780 [01:02<01:38, 294.46 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19121/47780 [01:02<01:20, 353.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19189/47780 [01:02<02:13, 213.96 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18802/47780 [01:02<01:35, 303.38 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19185/47780 [01:02<01:50, 259.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19132/47780 [01:02<02:28, 192.77 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18726/47780 [01:02<01:33, 309.63 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18897/47780 [01:02<01:40, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19157/47780 [01:02<01:26, 331.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18835/47780 [01:02<01:33, 307.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19217/47780 [01:02<01:43, 276.59 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19182/47780 [01:02<01:52, 254.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19263/47780 [01:02<01:26, 328.73 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18762/47780 [01:02<01:30, 320.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18926/47780 [01:02<01:41, 284.36 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19194/47780 [01:02<01:23, 341.08 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18867/47780 [01:02<01:32, 310.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19253/47780 [01:02<01:37, 293.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19302/47780 [01:02<01:27, 324.35 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19212/47780 [01:02<01:59, 238.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18955/47780 [01:02<01:48, 264.62 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18795/47780 [01:02<01:40, 288.05 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18899/47780 [01:02<01:36, 299.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19283/47780 [01:02<01:37, 291.83 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19339/47780 [01:02<01:30, 313.99 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19243/47780 [01:03<01:51, 254.98 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18992/47780 [01:03<01:38, 290.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18825/47780 [01:03<01:41, 286.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19229/47780 [01:03<01:50, 259.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18930/47780 [01:02<01:35, 302.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19319/47780 [01:03<01:32, 308.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19373/47780 [01:03<01:32, 305.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19272/47780 [01:03<01:48, 263.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18858/47780 [01:03<01:37, 295.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19287/47780 [01:03<01:26, 330.28 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19022/47780 [01:03<01:42, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19350/47780 [01:03<01:34, 301.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18961/47780 [01:03<01:43, 279.70 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19409/47780 [01:03<01:28, 319.26 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19301/47780 [01:03<01:46, 266.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18891/47780 [01:03<01:34, 304.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19053/47780 [01:03<01:39, 288.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19383/47780 [01:03<01:32, 306.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19325/47780 [01:03<01:30, 314.59 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18996/47780 [01:03<01:38, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19443/47780 [01:03<01:31, 308.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19336/47780 [01:03<01:40, 284.01 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18924/47780 [01:03<01:32, 310.61 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19088/47780 [01:03<01:35, 300.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19414/47780 [01:03<01:36, 293.44 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19026/47780 [01:03<01:39, 288.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19476/47780 [01:03<01:31, 310.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19360/47780 [01:03<01:36, 295.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19366/47780 [01:03<01:43, 275.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18956/47780 [01:03<01:33, 307.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19119/47780 [01:03<01:39, 289.21 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19058/47780 [01:03<01:36, 296.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19444/47780 [01:03<01:43, 273.93 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3397/47780 [01:03<04:19, 171.04 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19511/47780 [01:03<01:27, 321.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19393/47780 [01:03<01:33, 302.72 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19403/47780 [01:03<01:35, 295.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18988/47780 [01:03<01:34, 304.52 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19088/47780 [01:03<01:38, 290.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19479/47780 [01:03<01:36, 294.53 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19153/47780 [01:03<01:43, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3631/47780 [01:03<02:43, 270.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19545/47780 [01:03<01:31, 309.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19425/47780 [01:03<01:36, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19438/47780 [01:03<01:32, 307.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19019/47780 [01:03<01:34, 305.76 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19118/47780 [01:03<01:38, 290.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19202/47780 [01:03<01:26, 329.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19509/47780 [01:03<01:39, 283.54 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19577/47780 [01:03<01:31, 307.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19463/47780 [01:03<01:29, 315.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19470/47780 [01:03<01:31, 310.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19050/47780 [01:03<01:39, 287.79 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19155/47780 [01:03<01:31, 312.92 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19545/47780 [01:03<01:33, 301.52 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19236/47780 [01:03<01:29, 320.16 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19508/47780 [01:03<01:25, 329.82 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19496/47780 [01:03<01:32, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19609/47780 [01:03<01:35, 293.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19086/47780 [01:03<01:33, 307.52 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19193/47780 [01:03<01:28, 321.54 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19269/47780 [01:03<01:30, 316.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19578/47780 [01:03<01:34, 299.32 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19640/47780 [01:03<01:34, 297.20 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19542/47780 [01:03<01:27, 321.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19528/47780 [01:03<01:34, 298.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19120/47780 [01:03<01:31, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19229/47780 [01:03<01:25, 332.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19306/47780 [01:04<01:25, 331.28 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19614/47780 [01:04<01:29, 316.03 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19671/47780 [01:03<01:35, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19559/47780 [01:04<01:34, 298.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19152/47780 [01:04<01:30, 314.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19575/47780 [01:04<01:32, 305.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19342/47780 [01:04<01:24, 335.76 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19263/47780 [01:04<01:31, 312.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19658/47780 [01:04<01:23, 337.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19592/47780 [01:04<01:32, 303.94 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19701/47780 [01:04<01:38, 285.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19185/47780 [01:04<01:31, 311.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19606/47780 [01:04<01:36, 291.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19704/47780 [01:04<01:15, 370.62 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19295/47780 [01:04<01:33, 303.07 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19376/47780 [01:04<01:29, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19221/47780 [01:04<01:28, 322.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19730/47780 [01:04<01:41, 277.70 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19636/47780 [01:04<01:39, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19623/47780 [01:04<01:44, 268.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19412/47780 [01:04<01:26, 326.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19742/47780 [01:04<01:19, 354.76 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19326/47780 [01:04<01:42, 278.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19254/47780 [01:04<01:28, 323.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19765/47780 [01:04<01:34, 295.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19666/47780 [01:04<01:38, 286.53 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19658/47780 [01:04<01:37, 287.85 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19778/47780 [01:04<01:23, 335.75 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19295/47780 [01:04<01:22, 345.52 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19799/47780 [01:04<01:31, 305.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19445/47780 [01:04<01:38, 288.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19355/47780 [01:04<01:49, 259.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19696/47780 [01:04<01:36, 289.90 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19693/47780 [01:04<01:32, 304.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19832/47780 [01:04<01:30, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19333/47780 [01:04<01:21, 347.40 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19812/47780 [01:04<01:27, 319.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19478/47780 [01:04<01:35, 296.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19382/47780 [01:04<01:49, 259.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19729/47780 [01:04<01:27, 319.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19728/47780 [01:04<01:39, 283.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19873/47780 [01:04<01:23, 333.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19510/47780 [01:04<01:34, 299.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19845/47780 [01:04<01:28, 315.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19762/47780 [01:04<01:26, 322.63 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19409/47780 [01:04<01:50, 257.03 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19369/47780 [01:04<01:27, 324.77 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3751/47780 [01:04<03:39, 200.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19768/47780 [01:04<01:29, 312.29 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19907/47780 [01:04<01:24, 331.09 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19548/47780 [01:04<01:28, 320.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19877/47780 [01:04<01:29, 313.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19799/47780 [01:04<01:23, 336.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19435/47780 [01:04<01:51, 255.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19402/47780 [01:04<01:27, 325.47 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3927/47780 [01:04<02:36, 279.54 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19811/47780 [01:04<01:21, 341.63 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19944/47780 [01:04<01:22, 338.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19581/47780 [01:04<01:28, 318.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19920/47780 [01:04<01:21, 343.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19461/47780 [01:04<01:51, 253.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19435/47780 [01:04<01:31, 309.91 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19833/47780 [01:04<01:28, 315.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19846/47780 [01:04<01:24, 328.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19616/47780 [01:04<01:26, 326.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19958/47780 [01:05<01:21, 339.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19495/47780 [01:04<01:42, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19978/47780 [01:04<01:27, 316.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19467/47780 [01:05<01:32, 305.66 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19866/47780 [01:05<01:31, 305.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19880/47780 [01:05<01:26, 321.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19649/47780 [01:05<01:28, 316.42 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20008/47780 [01:05<01:12, 381.81 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19526/47780 [01:05<01:41, 278.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20010/47780 [01:05<01:33, 297.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19913/47780 [01:05<01:27, 319.97 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19498/47780 [01:05<01:38, 286.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19897/47780 [01:05<01:36, 289.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19690/47780 [01:05<01:21, 342.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19557/47780 [01:05<01:41, 278.05 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20047/47780 [01:05<01:17, 359.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20042/47780 [01:05<01:34, 294.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19946/47780 [01:05<01:27, 319.47 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19930/47780 [01:05<01:37, 286.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19527/47780 [01:05<01:44, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19726/47780 [01:05<01:22, 340.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19585/47780 [01:05<01:43, 272.45 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19983/47780 [01:05<01:26, 322.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20072/47780 [01:05<01:38, 280.38 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20084/47780 [01:05<01:23, 329.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19571/47780 [01:05<01:32, 303.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19959/47780 [01:05<01:44, 267.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19761/47780 [01:05<01:29, 314.06 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19617/47780 [01:05<01:39, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20017/47780 [01:05<01:26, 320.42 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20118/47780 [01:05<01:24, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20101/47780 [01:05<01:40, 275.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19602/47780 [01:05<01:32, 304.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19998/47780 [01:05<01:32, 299.69 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19648/47780 [01:05<01:38, 285.69 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19793/47780 [01:05<01:32, 303.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20056/47780 [01:05<01:22, 336.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20131/47780 [01:05<01:42, 268.92 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20152/47780 [01:05<01:28, 312.30 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19638/47780 [01:05<01:29, 312.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20029/47780 [01:05<01:32, 299.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19681/47780 [01:05<01:35, 293.28 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19824/47780 [01:05<01:37, 285.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20091/47780 [01:05<01:23, 332.30 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20174/47780 [01:05<01:29, 309.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20060/47780 [01:05<01:32, 299.95 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 4039/47780 [01:05<03:21, 217.03 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19670/47780 [01:05<01:36, 292.56 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19712/47780 [01:05<01:36, 291.49 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20184/47780 [01:05<01:47, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19853/47780 [01:05<01:38, 283.70 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20212/47780 [01:05<01:23, 328.93 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20126/47780 [01:05<01:27, 315.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20092/47780 [01:05<01:32, 299.69 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19704/47780 [01:05<01:32, 302.82 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4188/47780 [01:05<02:30, 290.37 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19742/47780 [01:05<01:35, 293.72 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20238/47780 [01:05<01:25, 320.83 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19882/47780 [01:05<01:38, 283.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20160/47780 [01:05<01:28, 312.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20248/47780 [01:05<01:28, 309.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19741/47780 [01:05<01:28, 317.27 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20123/47780 [01:06<01:44, 264.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19772/47780 [01:05<01:37, 285.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19911/47780 [01:05<01:39, 280.73 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20273/47780 [01:06<01:28, 309.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20192/47780 [01:06<01:29, 308.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20281/47780 [01:06<01:32, 298.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19778/47780 [01:06<01:27, 321.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20152/47780 [01:06<01:43, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19945/47780 [01:06<01:34, 294.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19801/47780 [01:06<01:45, 265.71 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20308/47780 [01:06<01:26, 317.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20223/47780 [01:06<01:29, 307.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20313/47780 [01:06<01:33, 295.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19812/47780 [01:06<01:29, 313.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19975/47780 [01:06<01:37, 286.31 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19832/47780 [01:06<01:42, 271.83 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20342/47780 [01:06<01:25, 319.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20256/47780 [01:06<01:28, 311.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20180/47780 [01:06<01:57, 234.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19847/47780 [01:06<01:27, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20344/47780 [01:06<01:37, 282.74 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20004/47780 [01:06<01:36, 287.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20375/47780 [01:06<01:25, 321.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20294/47780 [01:06<01:23, 330.78 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19860/47780 [01:06<01:52, 249.05 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20205/47780 [01:06<02:00, 228.89 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19879/47780 [01:06<01:28, 316.29 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20378/47780 [01:06<01:33, 293.09 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20036/47780 [01:06<01:34, 293.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20408/47780 [01:06<01:28, 310.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20338/47780 [01:06<01:16, 358.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19887/47780 [01:06<01:50, 253.08 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20311/47780 [01:06<01:02, 437.18 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20410/47780 [01:06<01:31, 300.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19911/47780 [01:06<01:32, 302.89 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4286/47780 [01:06<03:02, 237.84 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20066/47780 [01:06<01:41, 273.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20374/47780 [01:06<01:16, 358.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20441/47780 [01:06<01:29, 306.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19915/47780 [01:06<01:47, 259.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20444/47780 [01:06<01:28, 307.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19943/47780 [01:06<01:32, 301.55 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4370/47780 [01:06<02:34, 280.48 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20097/47780 [01:06<01:37, 283.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19946/47780 [01:06<01:42, 270.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20410/47780 [01:06<01:21, 337.26 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20473/47780 [01:06<01:35, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20359/47780 [01:06<01:21, 337.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20477/47780 [01:06<01:27, 310.76 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19974/47780 [01:06<01:34, 293.98 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20128/47780 [01:06<01:35, 290.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19982/47780 [01:06<01:34, 292.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20507/47780 [01:06<01:32, 295.76 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20509/47780 [01:06<01:28, 309.88 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20004/47780 [01:06<01:35, 292.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20165/47780 [01:06<01:28, 313.37 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20446/47780 [01:06<01:38, 276.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20014/47780 [01:06<01:32, 300.45 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20537/47780 [01:06<01:33, 292.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20543/47780 [01:06<01:25, 318.21 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20034/47780 [01:06<01:38, 281.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20399/47780 [01:06<01:44, 261.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20505/47780 [01:06<01:17, 349.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20199/47780 [01:06<01:30, 303.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20046/47780 [01:06<01:33, 295.96 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20567/47780 [01:07<01:34, 289.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20577/47780 [01:06<01:28, 308.67 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20072/47780 [01:07<01:30, 305.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20544/47780 [01:07<01:15, 360.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20432/47780 [01:07<01:43, 263.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20230/47780 [01:07<01:30, 303.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20076/47780 [01:07<01:36, 286.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20597/47780 [01:07<01:35, 286.03 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20609/47780 [01:07<01:29, 302.75 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20108/47780 [01:07<01:27, 317.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20533/47780 [01:07<01:05, 416.15 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20583/47780 [01:07<01:18, 345.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20268/47780 [01:07<01:27, 312.92 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20105/47780 [01:07<01:39, 278.33 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20629/47780 [01:07<01:31, 295.49 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20149/47780 [01:07<01:21, 340.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20640/47780 [01:07<01:34, 288.25 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20302/47780 [01:07<01:26, 319.27 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20135/47780 [01:07<01:38, 281.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20585/47780 [01:07<01:08, 399.74 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20659/47780 [01:07<01:33, 290.26 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20185/47780 [01:07<01:21, 337.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20670/47780 [01:07<01:33, 289.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20620/47780 [01:07<01:35, 283.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20339/47780 [01:07<01:22, 331.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20701/47780 [01:07<01:22, 327.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20166/47780 [01:07<01:39, 276.95 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20633/47780 [01:07<01:12, 373.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20659/47780 [01:07<01:27, 308.30 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20219/47780 [01:07<01:26, 320.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20376/47780 [01:07<01:20, 342.27 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20700/47780 [01:07<01:43, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20734/47780 [01:07<01:25, 316.95 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20194/47780 [01:07<01:42, 270.10 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20693/47780 [01:07<01:25, 315.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20676/47780 [01:07<01:13, 369.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20252/47780 [01:07<01:29, 306.00 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20736/47780 [01:07<01:35, 282.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20411/47780 [01:07<01:25, 318.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20766/47780 [01:07<01:26, 310.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20236/47780 [01:07<01:32, 297.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20717/47780 [01:07<01:13, 368.19 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20727/47780 [01:07<01:30, 297.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20295/47780 [01:07<01:22, 332.66 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20444/47780 [01:07<01:26, 314.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20765/47780 [01:07<01:39, 272.02 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20798/47780 [01:07<01:29, 302.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20268/47780 [01:07<01:31, 302.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20759/47780 [01:07<01:31, 294.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20329/47780 [01:07<01:27, 313.82 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20757/47780 [01:07<01:19, 339.81 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20793/47780 [01:07<01:43, 260.77 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20477/47780 [01:07<01:31, 299.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20835/47780 [01:07<01:25, 314.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20299/47780 [01:07<01:38, 280.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20793/47780 [01:07<01:28, 306.11 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20793/47780 [01:07<01:18, 344.30 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20361/47780 [01:07<01:28, 311.51 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20822/47780 [01:07<01:41, 265.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20508/47780 [01:07<01:31, 298.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20867/47780 [01:07<01:26, 312.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20328/47780 [01:07<01:37, 282.75 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20832/47780 [01:08<01:22, 327.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20393/47780 [01:08<01:30, 301.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20540/47780 [01:08<01:31, 298.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20849/47780 [01:08<01:44, 258.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20829/47780 [01:08<01:23, 322.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20899/47780 [01:08<01:29, 301.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20363/47780 [01:08<01:34, 288.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20428/47780 [01:08<01:28, 310.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20878/47780 [01:08<01:40, 267.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20571/47780 [01:08<01:31, 297.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20863/47780 [01:08<01:24, 320.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20934/47780 [01:08<01:26, 311.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20397/47780 [01:08<01:32, 296.15 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20866/47780 [01:08<01:44, 257.63 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20460/47780 [01:08<01:28, 310.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20909/47780 [01:08<01:37, 274.78 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20601/47780 [01:08<01:33, 292.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20899/47780 [01:08<01:22, 326.40 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20966/47780 [01:08<01:26, 310.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20427/47780 [01:08<01:32, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20921/47780 [01:08<01:22, 326.89 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4447/47780 [01:08<05:31, 130.76 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20944/47780 [01:08<01:31, 294.52 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20492/47780 [01:08<01:30, 303.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20631/47780 [01:08<01:35, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20933/47780 [01:08<01:23, 320.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20998/47780 [01:08<01:27, 306.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20457/47780 [01:08<01:33, 292.30 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4855/47780 [01:08<02:10, 327.99 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20958/47780 [01:08<01:27, 306.72 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20979/47780 [01:08<01:27, 306.85 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20524/47780 [01:08<01:29, 304.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20668/47780 [01:08<01:28, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21034/47780 [01:08<01:23, 321.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20966/47780 [01:08<01:25, 312.95 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20487/47780 [01:08<01:36, 281.62 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21014/47780 [01:08<01:24, 315.82 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20993/47780 [01:08<01:29, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20556/47780 [01:08<01:33, 291.82 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20702/47780 [01:08<01:26, 311.52 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21000/47780 [01:08<01:23, 320.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21067/47780 [01:08<01:29, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20517/47780 [01:08<01:36, 283.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20737/47780 [01:08<01:24, 318.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21046/47780 [01:08<01:29, 299.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21025/47780 [01:08<01:30, 295.37 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20588/47780 [01:08<01:32, 293.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21033/47780 [01:08<01:23, 319.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21099/47780 [01:08<01:28, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20546/47780 [01:08<01:40, 270.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21057/47780 [01:08<01:29, 299.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21085/47780 [01:08<01:23, 317.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20618/47780 [01:08<01:36, 282.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20769/47780 [01:08<01:32, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21131/47780 [01:08<01:29, 296.71 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20583/47780 [01:08<01:32, 294.70 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21066/47780 [01:08<01:37, 273.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21117/47780 [01:08<01:24, 314.83 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20652/47780 [01:08<01:32, 293.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21088/47780 [01:08<01:34, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20808/47780 [01:08<01:28, 305.78 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21161/47780 [01:08<01:35, 278.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20613/47780 [01:08<01:36, 280.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21110/47780 [01:09<01:29, 297.50 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21151/47780 [01:08<01:24, 314.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21121/47780 [01:09<01:30, 293.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20682/47780 [01:09<01:33, 290.64 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20839/47780 [01:09<01:30, 296.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21194/47780 [01:09<01:31, 289.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20642/47780 [01:09<01:40, 270.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21141/47780 [01:09<01:33, 285.45 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21183/47780 [01:09<01:24, 314.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20713/47780 [01:09<01:31, 295.83 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21154/47780 [01:09<01:33, 284.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20873/47780 [01:09<01:28, 305.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21224/47780 [01:09<01:34, 280.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20670/47780 [01:09<01:40, 270.39 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21186/47780 [01:09<01:32, 287.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21171/47780 [01:09<01:43, 257.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20904/47780 [01:09<01:31, 293.80 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21215/47780 [01:09<01:38, 270.72 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21253/47780 [01:09<01:37, 270.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20698/47780 [01:09<01:39, 272.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20743/47780 [01:09<02:03, 219.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21217/47780 [01:09<01:31, 290.77 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21210/47780 [01:09<01:32, 287.61 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21256/47780 [01:09<01:26, 305.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20941/47780 [01:09<01:26, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20726/47780 [01:09<01:40, 269.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21288/47780 [01:09<01:32, 286.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20801/47780 [01:09<01:29, 299.94 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21243/47780 [01:09<01:28, 298.57 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21249/47780 [01:09<01:30, 292.41 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21291/47780 [01:09<01:24, 312.94 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20976/47780 [01:09<01:24, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20757/47780 [01:09<01:36, 280.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21318/47780 [01:09<01:34, 280.95 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20835/47780 [01:09<01:32, 292.82 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21274/47780 [01:09<01:30, 291.98 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21009/47780 [01:09<01:23, 321.85 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21324/47780 [01:09<01:27, 301.83 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20786/47780 [01:09<01:36, 280.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21279/47780 [01:09<01:40, 262.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21347/47780 [01:09<01:37, 271.06 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21304/47780 [01:09<01:34, 278.86 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20868/47780 [01:09<01:34, 285.57 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21043/47780 [01:09<01:26, 309.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20821/47780 [01:09<01:29, 300.57 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21356/47780 [01:09<01:27, 302.65 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21314/47780 [01:09<01:33, 282.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21376/47780 [01:09<01:37, 270.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 5010/47780 [01:09<03:09, 226.10 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21334/47780 [01:09<01:33, 281.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21075/47780 [01:09<01:25, 312.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20899/47780 [01:09<01:33, 288.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21343/47780 [01:09<01:35, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20852/47780 [01:09<01:36, 280.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21387/47780 [01:09<01:35, 276.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21404/47780 [01:09<01:43, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5122/47780 [01:09<02:40, 265.09 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21365/47780 [01:09<01:31, 289.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20930/47780 [01:09<01:31, 294.01 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21108/47780 [01:09<01:25, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21373/47780 [01:09<01:33, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20882/47780 [01:09<01:35, 282.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21417/47780 [01:09<01:33, 281.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21437/47780 [01:09<01:36, 272.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21399/47780 [01:10<01:26, 303.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20961/47780 [01:10<01:30, 297.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21141/47780 [01:10<01:25, 312.21 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5277/47780 [01:10<02:03, 344.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21405/47780 [01:10<01:31, 289.04 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20914/47780 [01:10<01:31, 292.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21446/47780 [01:10<01:35, 276.38 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21465/47780 [01:10<01:38, 266.14 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21433/47780 [01:10<01:24, 310.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20992/47780 [01:10<01:28, 301.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21174/47780 [01:10<01:23, 317.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20944/47780 [01:10<01:32, 288.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21436/47780 [01:10<01:32, 283.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21480/47780 [01:10<01:30, 291.78 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21029/47780 [01:10<01:24, 317.76 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21492/47780 [01:10<01:48, 243.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21465/47780 [01:10<01:27, 300.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21206/47780 [01:10<01:31, 291.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20977/47780 [01:10<01:29, 300.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21465/47780 [01:10<01:34, 277.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21515/47780 [01:10<01:26, 303.57 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21062/47780 [01:10<01:24, 317.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21524/47780 [01:10<01:40, 260.98 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21497/47780 [01:10<01:26, 305.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21236/47780 [01:10<01:31, 290.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21554/47780 [01:10<01:20, 324.45 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21009/47780 [01:10<01:35, 279.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21493/47780 [01:10<01:40, 262.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21553/47780 [01:10<01:37, 268.76 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21102/47780 [01:10<01:19, 333.73 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21530/47780 [01:10<01:24, 312.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21266/47780 [01:10<01:34, 280.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21587/47780 [01:10<01:23, 311.87 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21523/47780 [01:10<01:36, 271.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21047/47780 [01:10<01:31, 291.74 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21581/47780 [01:10<01:38, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21576/47780 [01:10<01:15, 347.32 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21136/47780 [01:10<01:25, 310.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21295/47780 [01:10<01:35, 277.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21552/47780 [01:10<01:34, 276.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21624/47780 [01:10<01:22, 317.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21077/47780 [01:10<01:36, 276.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21612/47780 [01:10<01:14, 350.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21608/47780 [01:10<01:45, 247.76 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21169/47780 [01:10<01:27, 303.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21323/47780 [01:10<01:37, 271.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21663/47780 [01:10<01:17, 337.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21580/47780 [01:10<01:39, 262.25 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21105/47780 [01:10<01:37, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21648/47780 [01:10<01:19, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21634/47780 [01:10<01:45, 248.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21207/47780 [01:10<01:22, 323.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21354/47780 [01:10<01:34, 279.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21608/47780 [01:10<01:38, 264.38 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21698/47780 [01:10<01:23, 311.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21133/47780 [01:10<01:37, 272.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21682/47780 [01:10<01:19, 330.25 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21661/47780 [01:10<01:43, 251.64 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21240/47780 [01:10<01:23, 318.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21387/47780 [01:10<01:29, 293.60 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21637/47780 [01:10<01:38, 265.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21731/47780 [01:10<01:22, 315.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21161/47780 [01:10<01:37, 271.85 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21688/47780 [01:10<01:41, 256.79 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21720/47780 [01:11<01:19, 326.14 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21273/47780 [01:10<01:24, 313.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21417/47780 [01:11<01:33, 282.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21665/47780 [01:11<01:36, 269.66 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21195/47780 [01:11<01:32, 287.75 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21764/47780 [01:10<01:24, 309.36 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21715/47780 [01:11<01:42, 254.14 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21756/47780 [01:11<01:17, 335.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21306/47780 [01:11<01:25, 308.05 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21446/47780 [01:11<01:33, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21694/47780 [01:11<01:40, 260.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21229/47780 [01:11<01:28, 299.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21796/47780 [01:11<01:25, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21744/47780 [01:11<01:40, 259.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21796/47780 [01:11<01:14, 348.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21479/47780 [01:11<01:30, 292.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21731/47780 [01:11<01:32, 281.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21260/47780 [01:11<01:30, 291.92 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21338/47780 [01:11<01:43, 255.96 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21774/47780 [01:11<01:38, 264.72 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21827/47780 [01:11<01:37, 267.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21832/47780 [01:11<01:17, 333.99 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21509/47780 [01:11<01:31, 287.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21760/47780 [01:11<01:32, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21290/47780 [01:11<01:31, 288.00 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21385/47780 [01:11<01:27, 301.36 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21803/47780 [01:11<01:35, 271.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21872/47780 [01:11<01:23, 311.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21867/47780 [01:11<01:20, 320.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21543/47780 [01:11<01:26, 302.38 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21797/47780 [01:11<01:25, 302.93 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21320/47780 [01:11<01:31, 288.15 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21837/47780 [01:11<01:29, 288.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21417/47780 [01:11<01:28, 296.54 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21576/47780 [01:11<01:27, 300.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21905/47780 [01:11<01:28, 291.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21900/47780 [01:11<01:23, 309.27 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21351/47780 [01:11<01:29, 294.21 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21869/47780 [01:11<01:27, 297.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21828/47780 [01:11<01:36, 270.29 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5387/47780 [01:11<03:53, 181.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21448/47780 [01:11<01:32, 285.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21936/47780 [01:11<01:28, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21614/47780 [01:11<01:23, 312.43 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21933/47780 [01:11<01:23, 308.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21383/47780 [01:11<01:31, 288.50 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5714/47780 [01:11<02:04, 338.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21856/47780 [01:11<01:36, 267.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21899/47780 [01:11<01:31, 281.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21478/47780 [01:11<01:36, 272.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21651/47780 [01:11<01:19, 327.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21967/47780 [01:11<01:28, 290.85 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21965/47780 [01:11<01:25, 302.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21412/47780 [01:11<01:34, 279.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21937/47780 [01:11<01:24, 306.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21884/47780 [01:11<01:37, 265.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21506/47780 [01:11<01:37, 268.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21692/47780 [01:11<01:15, 344.57 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21996/47780 [01:11<01:27, 294.67 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21997/47780 [01:11<01:33, 274.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21441/47780 [01:11<01:38, 267.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21911/47780 [01:11<01:39, 260.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21968/47780 [01:11<01:26, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21541/47780 [01:11<01:33, 281.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21727/47780 [01:11<01:16, 338.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22032/47780 [01:11<01:29, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22026/47780 [01:12<01:32, 279.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21471/47780 [01:11<01:35, 274.70 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21939/47780 [01:12<01:40, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21998/47780 [01:12<01:31, 281.97 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21570/47780 [01:12<01:35, 274.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22072/47780 [01:12<01:21, 317.10 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21761/47780 [01:12<01:23, 309.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22059/47780 [01:12<01:28, 290.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21499/47780 [01:12<01:39, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21974/47780 [01:12<01:31, 280.62 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22027/47780 [01:12<01:30, 283.92 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21598/47780 [01:12<01:39, 261.87 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22092/47780 [01:12<01:26, 298.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21793/47780 [01:12<01:27, 296.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22105/47780 [01:12<01:32, 277.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21526/47780 [01:12<01:42, 256.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22058/47780 [01:12<01:30, 285.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22013/47780 [01:12<01:29, 288.39 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5867/47780 [01:12<02:12, 317.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21625/47780 [01:12<01:41, 258.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22122/47780 [01:12<01:27, 291.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22152/47780 [01:12<01:19, 324.31 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21563/47780 [01:12<01:31, 287.54 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21824/47780 [01:12<01:39, 260.43 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22047/47780 [01:12<01:25, 299.33 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22087/47780 [01:12<01:33, 273.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21651/47780 [01:12<01:44, 251.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22153/47780 [01:12<01:29, 287.64 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21597/47780 [01:12<01:27, 299.19 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22186/47780 [01:12<01:22, 311.40 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21867/47780 [01:12<01:26, 300.54 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22084/47780 [01:12<01:20, 318.78 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22115/47780 [01:12<01:34, 272.83 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21680/47780 [01:12<01:40, 258.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22188/47780 [01:12<01:25, 300.04 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21628/47780 [01:12<01:28, 295.15 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22151/47780 [01:12<01:27, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22220/47780 [01:12<01:23, 304.64 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21899/47780 [01:12<01:29, 290.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22118/47780 [01:12<01:23, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21712/47780 [01:12<01:34, 275.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22219/47780 [01:12<01:26, 294.04 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 5983/47780 [01:12<02:12, 315.44 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21661/47780 [01:12<01:26, 302.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22184/47780 [01:12<01:25, 301.04 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21934/47780 [01:12<01:26, 299.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22252/47780 [01:12<01:26, 296.12 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21741/47780 [01:12<01:33, 279.88 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22149/47780 [01:12<01:31, 280.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22250/47780 [01:12<01:26, 295.80 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21695/47780 [01:12<01:24, 309.44 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22216/47780 [01:12<01:25, 299.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21966/47780 [01:12<01:27, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22283/47780 [01:12<01:28, 288.73 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21772/47780 [01:12<01:32, 282.13 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22182/47780 [01:12<01:27, 291.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22281/47780 [01:12<01:26, 296.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21727/47780 [01:12<01:25, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22262/47780 [01:12<01:14, 341.63 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22005/47780 [01:12<01:21, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22313/47780 [01:12<01:32, 274.12 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22213/47780 [01:12<01:28, 288.84 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21801/47780 [01:12<01:36, 268.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22312/47780 [01:12<01:25, 296.88 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21762/47780 [01:12<01:23, 310.95 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6073/47780 [01:12<02:16, 305.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22297/47780 [01:13<01:20, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22038/47780 [01:13<01:22, 310.51 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22342/47780 [01:12<01:31, 277.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22250/47780 [01:13<01:23, 304.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22347/47780 [01:13<01:21, 311.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21833/47780 [01:13<01:33, 277.10 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21815/47780 [01:13<01:11, 365.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22292/47780 [01:13<01:16, 332.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22388/47780 [01:13<01:16, 333.17 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22329/47780 [01:13<01:28, 288.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22371/47780 [01:13<01:36, 264.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22070/47780 [01:13<01:30, 283.62 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21861/47780 [01:13<01:37, 265.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21852/47780 [01:13<01:12, 358.42 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22331/47780 [01:13<01:13, 345.32 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22424/47780 [01:13<01:14, 340.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6144/47780 [01:13<02:20, 296.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22100/47780 [01:13<01:29, 286.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21891/47780 [01:13<01:34, 273.56 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22360/47780 [01:13<01:29, 284.78 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22398/47780 [01:13<01:38, 256.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21888/47780 [01:13<01:12, 358.42 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22367/47780 [01:13<01:12, 349.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22130/47780 [01:13<01:29, 287.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22460/47780 [01:13<01:16, 331.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21926/47780 [01:13<01:29, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22429/47780 [01:13<01:34, 269.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22389/47780 [01:13<01:31, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21924/47780 [01:13<01:14, 346.96 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6202/47780 [01:13<02:19, 297.07 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22404/47780 [01:13<01:14, 339.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22169/47780 [01:13<01:21, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21956/47780 [01:13<01:29, 290.07 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22462/47780 [01:13<01:29, 282.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22494/47780 [01:13<01:18, 321.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21964/47780 [01:13<01:11, 361.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22417/47780 [01:13<01:38, 258.25 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22440/47780 [01:13<01:15, 333.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21986/47780 [01:13<01:30, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22530/47780 [01:13<01:17, 324.67 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22498/47780 [01:13<01:25, 295.95 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22201/47780 [01:13<01:27, 290.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22001/47780 [01:13<01:11, 361.75 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6252/47780 [01:13<02:19, 298.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22452/47780 [01:13<01:30, 278.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22016/47780 [01:13<01:29, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22565/47780 [01:13<01:16, 329.47 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22538/47780 [01:13<01:18, 323.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22474/47780 [01:13<01:18, 321.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22231/47780 [01:13<01:29, 284.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22038/47780 [01:13<01:12, 354.08 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22481/47780 [01:13<01:34, 268.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6296/47780 [01:13<02:14, 308.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22604/47780 [01:13<01:12, 346.69 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22571/47780 [01:13<01:18, 322.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22047/47780 [01:13<01:29, 286.86 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22514/47780 [01:13<01:14, 339.55 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22263/47780 [01:13<01:27, 290.82 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22077/47780 [01:13<01:11, 361.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22510/47780 [01:13<01:33, 270.97 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22639/47780 [01:13<01:13, 343.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22608/47780 [01:13<01:15, 332.02 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6338/47780 [01:13<02:21, 293.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22085/47780 [01:13<01:24, 303.10 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22549/47780 [01:13<01:16, 331.33 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22297/47780 [01:13<01:24, 301.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22114/47780 [01:13<01:13, 351.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22539/47780 [01:13<01:32, 273.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22644/47780 [01:13<01:16, 328.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22674/47780 [01:14<01:16, 326.97 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22589/47780 [01:14<01:13, 342.98 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22127/47780 [01:14<01:19, 323.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22330/47780 [01:14<01:24, 302.39 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22570/47780 [01:14<01:28, 283.31 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6376/47780 [01:14<02:23, 288.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22150/47780 [01:14<01:21, 316.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22638/47780 [01:14<01:05, 384.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22714/47780 [01:14<01:13, 342.89 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22160/47780 [01:14<01:21, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22677/47780 [01:14<01:21, 308.20 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6415/47780 [01:14<02:14, 307.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22361/47780 [01:14<01:29, 285.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22599/47780 [01:14<01:30, 278.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22183/47780 [01:14<01:24, 301.98 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22677/47780 [01:14<01:08, 367.66 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22711/47780 [01:14<01:20, 313.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22195/47780 [01:14<01:23, 306.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22628/47780 [01:14<01:30, 278.81 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6451/47780 [01:14<02:15, 305.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22390/47780 [01:14<01:33, 271.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22749/47780 [01:14<01:23, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22214/47780 [01:14<01:30, 283.14 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22716/47780 [01:14<01:09, 362.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22743/47780 [01:14<01:21, 307.77 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22661/47780 [01:14<01:28, 283.78 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22418/47780 [01:14<01:33, 271.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22784/47780 [01:14<01:20, 310.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6485/47780 [01:14<02:14, 307.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22226/47780 [01:14<01:33, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22249/47780 [01:14<01:26, 294.34 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22774/47780 [01:14<01:21, 308.31 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22753/47780 [01:14<01:10, 353.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22693/47780 [01:14<01:26, 290.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22817/47780 [01:14<01:19, 312.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6519/47780 [01:14<02:13, 309.32 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22262/47780 [01:14<01:28, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22446/47780 [01:14<01:51, 228.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22805/47780 [01:14<01:26, 289.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22723/47780 [01:14<01:27, 287.99 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22279/47780 [01:14<01:36, 264.57 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6554/47780 [01:14<02:10, 316.25 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22849/47780 [01:14<01:22, 301.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22789/47780 [01:14<01:18, 318.26 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22293/47780 [01:14<01:27, 290.59 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22478/47780 [01:14<01:40, 250.64 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22836/47780 [01:14<01:25, 291.76 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22754/47780 [01:14<01:25, 293.33 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6588/47780 [01:14<02:09, 319.04 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22825/47780 [01:14<01:17, 323.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22307/47780 [01:14<01:42, 248.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22880/47780 [01:14<01:27, 284.68 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22323/47780 [01:14<01:29, 283.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22514/47780 [01:14<01:31, 276.50 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22793/47780 [01:14<01:18, 317.61 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22866/47780 [01:14<01:27, 284.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6626/47780 [01:14<02:05, 328.50 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22858/47780 [01:14<01:19, 314.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22359/47780 [01:14<01:24, 301.46 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22345/47780 [01:14<01:34, 268.10 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22909/47780 [01:14<01:34, 263.49 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22543/47780 [01:14<01:34, 267.09 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22825/47780 [01:14<01:21, 307.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6660/47780 [01:14<02:09, 317.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22896/47780 [01:14<01:33, 265.33 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22391/47780 [01:14<01:23, 303.20 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22373/47780 [01:14<01:35, 265.73 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22890/47780 [01:14<01:22, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22946/47780 [01:14<01:25, 289.56 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22579/47780 [01:14<01:27, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22857/47780 [01:15<01:21, 307.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22924/47780 [01:14<01:32, 269.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6699/47780 [01:15<02:03, 332.97 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22424/47780 [01:15<01:21, 310.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22400/47780 [01:15<01:37, 261.37 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22921/47780 [01:15<01:25, 289.97 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22976/47780 [01:15<01:28, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22613/47780 [01:15<01:23, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22888/47780 [01:15<01:24, 294.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22955/47780 [01:15<01:28, 280.23 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6733/47780 [01:15<02:09, 318.06 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22456/47780 [01:15<01:23, 301.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22430/47780 [01:15<01:35, 266.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22956/47780 [01:15<01:21, 304.36 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23008/47780 [01:15<01:24, 291.79 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22645/47780 [01:15<01:26, 290.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22918/47780 [01:15<01:25, 289.44 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22984/47780 [01:15<01:35, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22458/47780 [01:15<01:34, 267.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22487/47780 [01:15<01:26, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6766/47780 [01:15<02:16, 301.34 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23040/47780 [01:15<01:23, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22992/47780 [01:15<01:22, 300.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22677/47780 [01:15<01:24, 295.53 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22948/47780 [01:15<01:28, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23019/47780 [01:15<01:28, 281.14 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22491/47780 [01:15<01:29, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6800/47780 [01:15<02:11, 311.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22517/47780 [01:15<01:26, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23072/47780 [01:15<01:26, 284.19 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23032/47780 [01:15<01:19, 312.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22707/47780 [01:15<01:27, 286.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22980/47780 [01:15<01:26, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6832/47780 [01:15<02:11, 310.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22548/47780 [01:15<01:26, 293.03 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22520/47780 [01:15<01:31, 277.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23106/47780 [01:15<01:23, 296.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23048/47780 [01:15<01:39, 247.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23064/47780 [01:15<01:21, 304.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22739/47780 [01:15<01:26, 289.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23009/47780 [01:15<01:26, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22579/47780 [01:15<01:24, 297.48 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22554/47780 [01:15<01:26, 291.92 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6867/47780 [01:15<02:11, 311.26 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23137/47780 [01:15<01:23, 295.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23103/47780 [01:15<01:16, 324.26 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23112/47780 [01:15<01:12, 341.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22771/47780 [01:15<01:24, 295.06 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6899/47780 [01:15<02:13, 306.92 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22594/47780 [01:15<01:20, 312.03 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23038/47780 [01:15<01:36, 256.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22609/47780 [01:15<01:30, 278.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23167/47780 [01:15<01:22, 296.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23136/47780 [01:15<01:15, 325.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22801/47780 [01:15<01:30, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23148/47780 [01:15<01:18, 313.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22633/47780 [01:15<01:15, 334.07 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6933/47780 [01:15<02:12, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23073/47780 [01:15<01:29, 276.56 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22640/47780 [01:15<01:27, 286.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23197/47780 [01:15<01:25, 288.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23169/47780 [01:15<01:19, 309.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22832/47780 [01:15<01:27, 284.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23181/47780 [01:15<01:22, 299.42 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22669/47780 [01:15<01:15, 333.88 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6968/47780 [01:15<02:07, 320.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23108/47780 [01:15<01:23, 296.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22676/47780 [01:15<01:22, 305.36 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23227/47780 [01:15<01:26, 282.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23202/47780 [01:15<01:19, 308.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22861/47780 [01:15<01:33, 265.21 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22703/47780 [01:15<01:14, 335.36 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23140/47780 [01:16<01:22, 300.05 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22707/47780 [01:16<01:22, 303.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23213/47780 [01:15<01:25, 285.77 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7001/47780 [01:16<02:16, 299.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23260/47780 [01:16<01:22, 295.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23233/47780 [01:16<01:22, 298.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22893/47780 [01:16<01:28, 279.92 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22737/47780 [01:16<01:16, 325.42 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22738/47780 [01:16<01:24, 297.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23171/47780 [01:16<01:25, 286.54 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7035/47780 [01:16<02:12, 308.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23243/47780 [01:16<01:30, 271.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23290/47780 [01:16<01:26, 284.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23264/47780 [01:16<01:23, 292.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22922/47780 [01:16<01:28, 279.71 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22768/47780 [01:16<01:24, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22775/47780 [01:16<01:17, 322.87 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7070/47780 [01:16<02:07, 318.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23202/47780 [01:16<01:25, 286.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23319/47780 [01:16<01:31, 266.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23298/47780 [01:16<01:20, 302.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23271/47780 [01:16<01:38, 248.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22953/47780 [01:16<01:26, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22802/47780 [01:16<01:22, 301.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23232/47780 [01:16<01:25, 287.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22816/47780 [01:16<01:14, 335.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7104/47780 [01:16<02:15, 300.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23347/47780 [01:16<01:32, 265.38 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23329/47780 [01:16<01:22, 297.03 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22983/47780 [01:16<01:26, 288.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23297/47780 [01:16<01:43, 237.13 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22834/47780 [01:16<01:22, 303.48 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23268/47780 [01:16<01:20, 304.39 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7158/47780 [01:16<01:52, 362.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22850/47780 [01:16<01:18, 319.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23374/47780 [01:16<01:32, 263.95 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23325/47780 [01:16<01:38, 247.86 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23014/47780 [01:16<01:26, 287.87 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23359/47780 [01:16<01:26, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22869/47780 [01:16<01:19, 313.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23299/47780 [01:16<01:20, 302.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22885/47780 [01:16<01:16, 325.28 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7195/47780 [01:16<01:57, 344.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23402/47780 [01:16<01:33, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23045/47780 [01:16<01:24, 293.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23351/47780 [01:16<01:37, 250.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23393/47780 [01:16<01:22, 295.13 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22904/47780 [01:16<01:16, 323.80 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23331/47780 [01:16<01:24, 287.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22920/47780 [01:16<01:16, 325.68 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7232/47780 [01:16<01:57, 344.48 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23430/47780 [01:16<01:31, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23428/47780 [01:16<01:18, 310.16 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23380/47780 [01:16<01:37, 251.30 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23075/47780 [01:16<01:32, 267.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22937/47780 [01:16<01:18, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23361/47780 [01:16<01:29, 273.32 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7277/47780 [01:16<01:50, 365.70 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22953/47780 [01:16<01:22, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23463/47780 [01:16<01:17, 314.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23457/47780 [01:16<01:40, 241.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22969/47780 [01:16<01:18, 316.23 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23406/47780 [01:16<01:44, 232.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23103/47780 [01:16<01:36, 256.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23389/47780 [01:16<01:31, 265.45 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22984/47780 [01:16<01:22, 300.29 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7314/47780 [01:16<01:56, 347.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23496/47780 [01:16<01:29, 272.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23495/47780 [01:16<01:23, 292.50 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23130/47780 [01:16<01:37, 252.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23001/47780 [01:16<01:23, 296.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23430/47780 [01:16<01:55, 210.38 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23420/47780 [01:17<01:31, 266.61 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23015/47780 [01:16<01:24, 293.38 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7350/47780 [01:17<02:01, 332.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23525/47780 [01:17<01:22, 294.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23527/47780 [01:17<01:26, 278.88 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23033/47780 [01:17<01:21, 303.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23156/47780 [01:17<01:41, 241.73 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23479/47780 [01:17<01:27, 278.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23055/47780 [01:17<01:18, 315.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23447/47780 [01:17<01:33, 258.87 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7399/47780 [01:17<01:48, 371.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23562/47780 [01:17<01:21, 296.11 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23555/47780 [01:17<01:29, 272.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23066/47780 [01:17<01:21, 303.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23185/47780 [01:17<01:37, 252.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23513/47780 [01:17<01:23, 290.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23087/47780 [01:17<01:19, 309.73 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23476/47780 [01:17<01:32, 261.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23599/47780 [01:17<01:17, 312.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7437/47780 [01:17<01:53, 354.06 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23215/47780 [01:17<01:33, 262.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23097/47780 [01:17<01:25, 289.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23583/47780 [01:17<01:34, 254.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23545/47780 [01:17<01:23, 290.11 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23503/47780 [01:17<01:32, 261.35 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23119/47780 [01:17<01:25, 290.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23631/47780 [01:17<01:19, 302.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23242/47780 [01:17<01:32, 264.13 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7473/47780 [01:17<02:04, 323.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23609/47780 [01:17<01:36, 250.72 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23127/47780 [01:17<01:28, 279.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23537/47780 [01:17<01:25, 283.38 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23575/47780 [01:17<01:29, 269.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23666/47780 [01:17<01:17, 312.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23154/47780 [01:17<01:25, 287.80 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7512/47780 [01:17<01:59, 337.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23283/47780 [01:17<01:21, 299.30 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23635/47780 [01:17<01:37, 248.14 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23156/47780 [01:17<01:29, 276.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23570/47780 [01:17<01:22, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23609/47780 [01:17<01:25, 283.26 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23698/47780 [01:17<01:19, 303.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23193/47780 [01:17<01:18, 311.77 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23323/47780 [01:17<01:15, 324.51 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7547/47780 [01:17<02:03, 326.93 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23185/47780 [01:17<01:29, 273.81 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23660/47780 [01:17<01:41, 237.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23603/47780 [01:17<01:19, 303.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23638/47780 [01:17<01:30, 266.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23229/47780 [01:17<01:15, 324.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23729/47780 [01:17<01:20, 300.00 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23687/47780 [01:17<01:38, 244.28 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7581/47780 [01:17<02:12, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23356/47780 [01:17<01:25, 286.10 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23213/47780 [01:17<01:36, 255.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23634/47780 [01:17<01:23, 288.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23666/47780 [01:17<01:32, 261.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23263/47780 [01:17<01:14, 328.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23760/47780 [01:17<01:21, 294.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23713/47780 [01:17<01:36, 248.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23390/47780 [01:17<01:21, 297.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23245/47780 [01:17<01:32, 264.81 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7612/47780 [01:17<02:18, 290.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23672/47780 [01:17<01:19, 304.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23297/47780 [01:17<01:16, 321.23 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23693/47780 [01:17<01:38, 245.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23738/47780 [01:17<01:39, 240.77 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23790/47780 [01:17<01:31, 261.03 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7643/47780 [01:17<02:15, 295.66 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23274/47780 [01:17<01:31, 268.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23704/47780 [01:18<01:18, 308.65 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23421/47780 [01:17<01:26, 282.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23331/47780 [01:17<01:14, 326.42 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23725/47780 [01:17<01:31, 262.50 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23822/47780 [01:18<01:26, 276.48 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23771/47780 [01:18<01:30, 264.85 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23309/47780 [01:18<01:24, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7673/47780 [01:18<02:18, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23735/47780 [01:18<01:18, 305.33 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23452/47780 [01:18<01:24, 286.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23364/47780 [01:18<01:16, 319.68 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23753/47780 [01:18<01:31, 263.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23798/47780 [01:18<01:30, 264.64 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7710/47780 [01:18<02:09, 309.10 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23851/47780 [01:18<01:33, 255.20 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23339/47780 [01:18<01:27, 278.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23766/47780 [01:18<01:20, 296.80 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23485/47780 [01:18<01:24, 289.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23404/47780 [01:18<01:11, 338.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23783/47780 [01:18<01:29, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23830/47780 [01:18<01:27, 274.10 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7743/47780 [01:18<02:07, 314.70 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23883/47780 [01:18<01:28, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23374/47780 [01:18<01:22, 297.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23801/47780 [01:18<01:17, 308.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23515/47780 [01:18<01:29, 270.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23438/47780 [01:18<01:15, 322.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23816/47780 [01:18<01:24, 283.51 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23860/47780 [01:18<01:24, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7782/47780 [01:18<02:00, 332.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23406/47780 [01:18<01:20, 301.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23912/47780 [01:18<01:29, 266.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23833/47780 [01:18<01:18, 304.91 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23553/47780 [01:18<01:21, 297.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23850/47780 [01:18<01:20, 297.07 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23471/47780 [01:18<01:17, 312.75 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23893/47780 [01:18<01:20, 295.54 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7816/47780 [01:18<02:00, 331.01 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23941/47780 [01:18<01:28, 269.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23438/47780 [01:18<01:21, 298.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23869/47780 [01:18<01:15, 317.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23586/47780 [01:18<01:24, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23880/47780 [01:18<01:24, 282.97 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23930/47780 [01:18<01:16, 313.81 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23503/47780 [01:18<01:24, 288.66 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23975/47780 [01:18<01:22, 289.19 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23472/47780 [01:18<01:18, 308.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23902/47780 [01:18<01:14, 320.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7850/47780 [01:18<02:08, 311.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23618/47780 [01:18<01:22, 293.00 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23909/47780 [01:18<01:26, 275.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23963/47780 [01:18<01:15, 314.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23538/47780 [01:18<01:19, 304.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23508/47780 [01:18<01:15, 321.66 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24011/47780 [01:18<01:18, 302.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7882/47780 [01:18<02:08, 310.36 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23936/47780 [01:18<01:24, 283.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23648/47780 [01:18<01:23, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23937/47780 [01:18<01:26, 276.76 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24000/47780 [01:18<01:13, 323.50 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23573/47780 [01:18<01:17, 311.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23546/47780 [01:18<01:12, 336.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24048/47780 [01:18<01:14, 318.17 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7914/47780 [01:18<02:17, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23988/47780 [01:18<01:09, 342.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23967/47780 [01:18<01:24, 280.26 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23679/47780 [01:18<01:23, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24034/47780 [01:18<01:13, 324.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23606/47780 [01:18<01:16, 316.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23580/47780 [01:18<01:15, 321.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24081/47780 [01:18<01:17, 304.16 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7946/47780 [01:18<02:13, 298.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24028/47780 [01:18<01:07, 354.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24073/47780 [01:19<01:10, 335.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23708/47780 [01:18<01:28, 273.28 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23639/47780 [01:18<01:18, 309.33 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23996/47780 [01:18<01:35, 248.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23614/47780 [01:19<01:14, 323.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24115/47780 [01:19<01:15, 314.14 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7978/47780 [01:19<02:11, 303.40 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24065/47780 [01:19<01:06, 354.61 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24109/47780 [01:19<01:09, 338.95 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23749/47780 [01:19<01:17, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23671/47780 [01:19<01:18, 306.44 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24045/47780 [01:19<01:15, 312.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23651/47780 [01:19<01:11, 336.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24148/47780 [01:19<01:14, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8016/47780 [01:19<02:03, 322.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23781/47780 [01:19<01:17, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24079/47780 [01:19<01:14, 320.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24102/47780 [01:19<01:14, 319.19 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24143/47780 [01:19<01:15, 314.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23702/47780 [01:19<01:24, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23701/47780 [01:19<01:05, 367.63 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24182/47780 [01:19<01:15, 310.81 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8050/47780 [01:19<02:04, 319.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23814/47780 [01:19<01:21, 295.47 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24175/47780 [01:19<01:15, 311.24 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24135/47780 [01:19<01:16, 309.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23742/47780 [01:19<01:16, 315.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24112/47780 [01:19<01:18, 302.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23740/47780 [01:19<01:04, 373.97 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24214/47780 [01:19<01:18, 299.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8083/47780 [01:19<02:09, 305.95 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23847/47780 [01:19<01:20, 298.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23775/47780 [01:19<01:16, 312.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24144/47780 [01:19<01:17, 303.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23782/47780 [01:19<01:02, 386.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24246/47780 [01:19<01:18, 299.04 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24167/47780 [01:19<01:24, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24207/47780 [01:19<01:29, 263.78 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8114/47780 [01:19<02:20, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23878/47780 [01:19<01:22, 289.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23814/47780 [01:19<01:13, 327.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24178/47780 [01:19<01:17, 303.87 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23821/47780 [01:19<01:06, 362.36 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24196/47780 [01:19<01:23, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24278/47780 [01:19<01:20, 291.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24235/47780 [01:19<01:31, 257.19 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8143/47780 [01:19<02:24, 275.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23848/47780 [01:19<01:13, 327.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24212/47780 [01:19<01:15, 310.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23922/47780 [01:19<01:16, 313.18 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24225/47780 [01:19<01:24, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23859/47780 [01:19<01:08, 348.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24309/47780 [01:19<01:19, 293.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24265/47780 [01:19<01:28, 265.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8171/47780 [01:19<02:26, 270.31 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23961/47780 [01:19<01:12, 330.50 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23881/47780 [01:19<01:16, 313.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24244/47780 [01:19<01:20, 293.41 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23898/47780 [01:19<01:06, 359.39 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24339/47780 [01:19<01:20, 291.88 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24296/47780 [01:19<01:26, 271.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24256/47780 [01:19<01:30, 259.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8199/47780 [01:19<02:32, 258.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23917/47780 [01:19<01:13, 323.02 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23995/47780 [01:19<01:14, 318.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23937/47780 [01:19<01:06, 360.25 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24282/47780 [01:19<01:18, 300.60 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24369/47780 [01:19<01:25, 275.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24325/47780 [01:19<01:26, 271.76 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24287/47780 [01:19<01:30, 259.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8228/47780 [01:19<02:31, 261.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23953/47780 [01:19<01:13, 326.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24028/47780 [01:19<01:16, 311.36 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23980/47780 [01:20<01:03, 375.80 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24313/47780 [01:19<01:24, 279.01 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24314/47780 [01:20<01:30, 258.57 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24397/47780 [01:20<01:31, 254.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24353/47780 [01:20<01:33, 251.06 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8255/47780 [01:20<02:36, 252.65 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23998/47780 [01:20<01:06, 357.30 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24068/47780 [01:20<01:12, 325.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24018/47780 [01:20<01:08, 348.24 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24342/47780 [01:20<01:25, 273.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24391/47780 [01:20<01:22, 284.86 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24342/47780 [01:20<01:37, 241.18 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24423/47780 [01:20<01:41, 231.14 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24034/47780 [01:20<01:10, 337.69 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24101/47780 [01:20<01:12, 326.63 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8303/47780 [01:20<02:23, 275.19 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24057/47780 [01:20<01:06, 356.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24374/47780 [01:20<01:21, 285.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24421/47780 [01:20<01:23, 280.02 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24367/47780 [01:20<01:39, 236.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24447/47780 [01:20<01:42, 226.60 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24082/47780 [01:20<01:04, 370.17 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8348/47780 [01:20<02:04, 317.34 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24134/47780 [01:20<01:18, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24403/47780 [01:20<01:21, 286.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24094/47780 [01:20<01:11, 330.42 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24450/47780 [01:20<01:27, 267.75 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24393/47780 [01:20<01:36, 242.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24472/47780 [01:20<01:40, 232.55 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24120/47780 [01:20<01:07, 351.26 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24168/47780 [01:20<01:16, 310.63 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8381/47780 [01:20<02:09, 304.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24439/47780 [01:20<01:17, 300.76 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24128/47780 [01:20<01:15, 314.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24490/47780 [01:20<01:17, 300.82 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24420/47780 [01:20<01:34, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24496/47780 [01:20<01:41, 229.57 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24163/47780 [01:20<01:03, 370.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24475/47780 [01:20<01:15, 308.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8412/47780 [01:20<02:17, 285.77 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24200/47780 [01:20<01:24, 277.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24160/47780 [01:20<01:18, 301.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24446/47780 [01:20<01:35, 245.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24530/47780 [01:20<01:31, 254.55 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24521/47780 [01:20<01:26, 269.87 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24201/47780 [01:20<01:08, 345.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24508/47780 [01:20<01:15, 309.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8445/47780 [01:20<02:12, 295.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24232/47780 [01:20<01:22, 284.89 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24481/47780 [01:20<01:26, 268.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24191/47780 [01:20<01:19, 295.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24556/47780 [01:20<01:34, 244.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24553/47780 [01:20<01:23, 279.59 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8478/47780 [01:20<02:11, 299.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24540/47780 [01:20<01:17, 297.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24262/47780 [01:20<01:22, 285.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24509/47780 [01:20<01:25, 271.66 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24222/47780 [01:20<01:18, 298.34 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24237/47780 [01:20<01:18, 301.06 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24584/47780 [01:20<01:22, 282.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24581/47780 [01:20<01:41, 228.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8510/47780 [01:20<02:09, 303.62 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24570/47780 [01:20<01:22, 282.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24537/47780 [01:20<01:27, 264.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24252/47780 [01:20<01:21, 289.12 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24269/47780 [01:20<01:19, 296.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24613/47780 [01:20<01:22, 281.58 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24293/47780 [01:20<01:35, 246.48 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24610/47780 [01:21<01:35, 242.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8548/47780 [01:20<02:03, 316.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24611/47780 [01:20<01:13, 315.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24564/47780 [01:21<01:30, 257.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24282/47780 [01:21<01:25, 273.86 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24334/47780 [01:21<01:21, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24642/47780 [01:21<01:25, 271.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24635/47780 [01:21<01:37, 236.90 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8582/47780 [01:21<02:01, 322.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24300/47780 [01:21<01:30, 259.55 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24643/47780 [01:21<01:15, 306.52 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24310/47780 [01:21<01:25, 275.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24590/47780 [01:21<01:34, 244.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24366/47780 [01:21<01:20, 292.61 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24671/47780 [01:21<01:24, 273.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8615/47780 [01:21<02:04, 313.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24659/47780 [01:21<01:44, 220.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24674/47780 [01:21<01:15, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24336/47780 [01:21<01:28, 264.18 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24615/47780 [01:21<01:36, 240.76 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24399/47780 [01:21<01:17, 302.53 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24339/47780 [01:21<01:30, 259.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24699/47780 [01:21<01:31, 252.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24684/47780 [01:21<01:42, 226.18 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8647/47780 [01:21<02:09, 301.93 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24707/47780 [01:21<01:14, 310.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24365/47780 [01:21<01:28, 265.22 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24641/47780 [01:21<01:34, 243.57 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24443/47780 [01:21<01:10, 330.06 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24370/47780 [01:21<01:26, 269.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24715/47780 [01:21<01:32, 249.15 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24394/47780 [01:21<01:26, 270.28 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24739/47780 [01:21<01:16, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8678/47780 [01:21<02:17, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24725/47780 [01:21<01:40, 230.00 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24668/47780 [01:21<01:34, 245.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24477/47780 [01:21<01:10, 329.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24400/47780 [01:21<01:25, 272.68 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24741/47780 [01:21<01:34, 243.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24426/47780 [01:21<01:22, 281.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24770/47780 [01:21<01:17, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24752/47780 [01:21<01:36, 238.25 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8708/47780 [01:21<02:16, 285.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24701/47780 [01:21<01:25, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24431/47780 [01:21<01:22, 282.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24524/47780 [01:21<01:05, 352.95 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24773/47780 [01:21<01:29, 257.07 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24455/47780 [01:21<01:24, 275.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24800/47780 [01:21<01:17, 295.09 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24777/47780 [01:21<01:37, 236.27 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8737/47780 [01:21<02:19, 280.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24730/47780 [01:21<01:23, 275.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24460/47780 [01:21<01:24, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24561/47780 [01:21<01:10, 328.49 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24487/47780 [01:21<01:21, 287.32 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8768/47780 [01:21<02:16, 286.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24799/47780 [01:21<01:35, 241.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24813/47780 [01:21<01:26, 264.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24830/47780 [01:21<01:23, 274.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24758/47780 [01:21<01:24, 273.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24496/47780 [01:21<01:21, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24601/47780 [01:21<01:08, 340.29 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24522/47780 [01:21<01:16, 304.91 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24825/47780 [01:21<01:35, 241.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24843/47780 [01:21<01:25, 267.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24858/47780 [01:21<01:23, 275.82 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8797/47780 [01:21<02:26, 265.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24786/47780 [01:21<01:26, 266.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24532/47780 [01:21<01:17, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24636/47780 [01:21<01:11, 321.98 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24559/47780 [01:21<01:14, 312.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24872/47780 [01:22<01:24, 271.26 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24889/47780 [01:21<01:22, 276.28 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8830/47780 [01:21<02:17, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24814/47780 [01:22<01:26, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24850/47780 [01:22<01:47, 213.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24564/47780 [01:22<01:15, 306.18 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24591/47780 [01:22<01:14, 311.19 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24671/47780 [01:22<01:12, 318.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24900/47780 [01:22<01:24, 270.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24922/47780 [01:22<01:19, 288.21 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8859/47780 [01:22<02:21, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24841/47780 [01:22<01:30, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24891/47780 [01:22<01:26, 263.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24595/47780 [01:22<01:17, 300.33 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24929/47780 [01:22<01:23, 274.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24623/47780 [01:22<01:17, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24704/47780 [01:22<01:13, 312.20 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24953/47780 [01:22<01:17, 294.39 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8887/47780 [01:22<02:24, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24868/47780 [01:22<01:28, 257.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24920/47780 [01:22<01:25, 267.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24626/47780 [01:22<01:23, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24656/47780 [01:22<01:16, 302.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24983/47780 [01:22<01:17, 295.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24736/47780 [01:22<01:17, 298.73 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24957/47780 [01:22<01:27, 259.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24900/47780 [01:22<01:24, 269.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8915/47780 [01:22<02:27, 262.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24948/47780 [01:22<01:35, 239.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24655/47780 [01:22<01:24, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24687/47780 [01:22<01:20, 288.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24984/47780 [01:22<01:28, 256.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24768/47780 [01:22<01:18, 294.20 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25013/47780 [01:22<01:22, 274.33 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24927/47780 [01:22<01:25, 267.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8942/47780 [01:22<02:27, 263.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24694/47780 [01:22<01:15, 304.24 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24975/47780 [01:22<01:35, 237.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24800/47780 [01:22<01:16, 301.01 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25010/47780 [01:22<01:31, 249.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24717/47780 [01:22<01:22, 279.43 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25041/47780 [01:22<01:23, 273.15 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24954/47780 [01:22<01:27, 260.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8969/47780 [01:22<02:30, 257.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24729/47780 [01:22<01:13, 313.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25003/47780 [01:22<01:33, 243.55 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24831/47780 [01:22<01:16, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25036/47780 [01:22<01:31, 249.33 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24985/47780 [01:22<01:23, 271.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24746/47780 [01:22<01:26, 267.23 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9002/47780 [01:22<02:25, 266.35 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25069/47780 [01:22<01:29, 254.96 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24761/47780 [01:22<01:14, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25029/47780 [01:22<01:34, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24863/47780 [01:22<01:15, 303.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25063/47780 [01:22<01:29, 253.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25013/47780 [01:22<01:24, 270.87 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24778/47780 [01:22<01:24, 273.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9033/47780 [01:22<02:20, 275.48 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25100/47780 [01:22<01:26, 261.49 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25055/47780 [01:22<01:33, 243.29 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24793/47780 [01:22<01:21, 282.80 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24896/47780 [01:22<01:16, 299.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25089/47780 [01:22<01:30, 251.52 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9071/47780 [01:22<02:09, 298.33 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25131/47780 [01:22<01:24, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25041/47780 [01:22<01:31, 248.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24806/47780 [01:22<01:29, 255.43 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25080/47780 [01:22<01:36, 236.44 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24830/47780 [01:22<01:14, 306.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25129/47780 [01:22<01:17, 291.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24932/47780 [01:22<01:12, 313.20 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9101/47780 [01:22<02:09, 298.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25158/47780 [01:22<01:24, 266.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25068/47780 [01:23<01:29, 253.97 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24841/47780 [01:22<01:22, 277.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25112/47780 [01:23<01:32, 246.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24974/47780 [01:23<01:08, 333.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24863/47780 [01:23<01:18, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9141/47780 [01:23<01:59, 324.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25159/47780 [01:23<01:24, 268.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25185/47780 [01:23<01:25, 264.75 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25094/47780 [01:23<01:30, 249.96 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24880/47780 [01:23<01:15, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25140/47780 [01:23<01:28, 255.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24893/47780 [01:23<01:18, 290.10 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25008/47780 [01:23<01:11, 319.56 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25188/47780 [01:23<01:22, 274.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25214/47780 [01:23<01:24, 265.74 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9174/47780 [01:23<02:13, 289.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24911/47780 [01:23<01:21, 281.47 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25170/47780 [01:23<01:24, 267.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25120/47780 [01:23<01:44, 216.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25044/47780 [01:23<01:08, 330.69 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25218/47780 [01:23<01:21, 275.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24923/47780 [01:23<01:24, 270.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25246/47780 [01:23<01:20, 278.26 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24944/47780 [01:23<01:18, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9204/47780 [01:23<02:20, 274.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25143/47780 [01:23<01:45, 215.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25198/47780 [01:23<01:27, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24952/47780 [01:23<01:22, 275.81 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25078/47780 [01:23<01:13, 309.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25246/47780 [01:23<01:26, 259.16 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25274/47780 [01:23<01:25, 263.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24974/47780 [01:23<01:22, 275.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25182/47780 [01:23<01:26, 261.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25225/47780 [01:23<01:27, 258.69 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9232/47780 [01:23<02:36, 246.86 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25112/47780 [01:23<01:12, 310.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24980/47780 [01:23<01:27, 260.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25301/47780 [01:23<01:27, 256.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25273/47780 [01:23<01:33, 240.99 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25210/47780 [01:23<01:30, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25004/47780 [01:23<01:26, 262.09 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9260/47780 [01:23<02:33, 250.42 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25252/47780 [01:23<01:31, 245.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25008/47780 [01:23<01:25, 265.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25144/47780 [01:23<01:13, 306.29 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25301/47780 [01:23<01:29, 251.25 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25327/47780 [01:23<01:31, 246.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25031/47780 [01:23<01:26, 263.98 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9286/47780 [01:23<02:32, 252.89 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25239/47780 [01:23<01:29, 252.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25284/47780 [01:23<01:25, 263.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25036/47780 [01:23<01:26, 263.12 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25353/47780 [01:23<01:31, 244.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25327/47780 [01:23<01:36, 232.81 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25311/47780 [01:23<01:25, 262.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25058/47780 [01:23<01:29, 254.82 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9316/47780 [01:23<02:28, 259.65 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25175/47780 [01:23<01:32, 244.84 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25265/47780 [01:23<01:32, 244.48 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25070/47780 [01:23<01:20, 281.73 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25385/47780 [01:23<01:24, 265.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25351/47780 [01:23<01:36, 231.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25089/47780 [01:23<01:24, 267.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9344/47780 [01:23<02:26, 262.75 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25342/47780 [01:23<01:24, 266.90 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25290/47780 [01:23<01:36, 233.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25202/47780 [01:23<01:41, 222.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25415/47780 [01:23<01:23, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25099/47780 [01:24<01:32, 245.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25375/47780 [01:24<01:36, 232.48 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25119/47780 [01:23<01:23, 270.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25376/47780 [01:24<01:17, 287.27 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9373/47780 [01:24<02:26, 261.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25315/47780 [01:24<01:36, 232.51 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25446/47780 [01:24<01:20, 277.89 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25304/47780 [01:24<00:55, 401.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25399/47780 [01:24<01:38, 226.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25125/47780 [01:24<01:34, 239.17 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25147/47780 [01:24<01:25, 264.10 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9401/47780 [01:24<02:27, 260.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25405/47780 [01:24<01:23, 269.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25343/47780 [01:24<01:32, 242.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25475/47780 [01:24<01:19, 281.04 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25154/47780 [01:24<01:29, 252.45 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25429/47780 [01:24<01:32, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25351/47780 [01:24<01:00, 370.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25182/47780 [01:24<01:18, 288.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9430/47780 [01:24<02:23, 267.60 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25433/47780 [01:24<01:22, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25370/47780 [01:24<01:29, 250.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25504/47780 [01:24<01:24, 262.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25459/47780 [01:24<01:26, 256.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25180/47780 [01:24<01:31, 246.00 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9461/47780 [01:24<02:17, 278.31 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25212/47780 [01:24<01:19, 284.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25410/47780 [01:24<01:17, 289.81 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25461/47780 [01:24<01:26, 257.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25392/47780 [01:24<01:05, 339.30 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25538/47780 [01:24<01:18, 283.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25492/47780 [01:24<01:20, 276.67 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9489/47780 [01:24<02:19, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25243/47780 [01:24<01:18, 288.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25488/47780 [01:24<01:27, 254.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25441/47780 [01:24<01:22, 270.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25430/47780 [01:24<01:07, 332.53 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25206/47780 [01:24<01:49, 205.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25568/47780 [01:24<01:17, 286.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25520/47780 [01:24<01:24, 262.58 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9517/47780 [01:24<02:21, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25273/47780 [01:24<01:23, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25480/47780 [01:24<01:14, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25514/47780 [01:24<01:31, 243.99 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25245/47780 [01:24<01:30, 249.93 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25466/47780 [01:24<01:05, 338.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25597/47780 [01:24<01:19, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9549/47780 [01:24<02:15, 281.62 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25547/47780 [01:24<01:29, 247.51 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25301/47780 [01:24<01:24, 267.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25539/47780 [01:24<01:31, 242.18 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25274/47780 [01:24<01:27, 257.84 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25504/47780 [01:24<01:04, 342.98 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25630/47780 [01:24<01:16, 291.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25511/47780 [01:24<01:19, 281.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25573/47780 [01:24<01:29, 248.40 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9579/47780 [01:24<02:20, 271.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25328/47780 [01:24<01:25, 262.26 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25568/47780 [01:24<01:27, 253.56 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25303/47780 [01:24<01:24, 266.33 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25544/47780 [01:24<01:02, 354.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25662/47780 [01:24<01:14, 296.07 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25540/47780 [01:24<01:20, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25599/47780 [01:24<01:30, 246.20 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9607/47780 [01:24<02:22, 267.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25596/47780 [01:24<01:25, 260.99 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25335/47780 [01:24<01:20, 278.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25355/47780 [01:24<01:32, 242.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25582/47780 [01:24<01:02, 353.30 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25569/47780 [01:24<01:20, 276.55 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25692/47780 [01:24<01:17, 283.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25624/47780 [01:24<01:31, 241.58 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9634/47780 [01:24<02:25, 261.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25364/47780 [01:25<01:19, 281.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25624/47780 [01:25<01:26, 257.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25381/47780 [01:25<01:33, 239.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25598/47780 [01:25<01:20, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25723/47780 [01:24<01:17, 283.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25618/47780 [01:25<01:08, 322.23 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25649/47780 [01:25<01:32, 238.65 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9664/47780 [01:25<02:25, 261.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25400/47780 [01:25<01:13, 303.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25650/47780 [01:25<01:25, 258.07 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25755/47780 [01:25<01:15, 292.10 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25626/47780 [01:25<01:22, 267.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25659/47780 [01:25<01:05, 339.31 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25683/47780 [01:25<01:23, 264.65 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25406/47780 [01:25<01:48, 206.68 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9699/47780 [01:25<02:13, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25431/47780 [01:25<01:14, 298.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25676/47780 [01:25<01:27, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25787/47780 [01:25<01:14, 296.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25694/47780 [01:25<01:04, 340.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25653/47780 [01:25<01:26, 257.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25719/47780 [01:25<01:15, 291.60 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25457/47780 [01:25<01:20, 279.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9728/47780 [01:25<02:13, 284.14 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25466/47780 [01:25<01:11, 310.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25703/47780 [01:25<01:27, 252.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25818/47780 [01:25<01:15, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25682/47780 [01:25<01:23, 266.12 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25751/47780 [01:25<01:14, 296.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25729/47780 [01:25<01:09, 319.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25487/47780 [01:25<01:18, 284.26 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9758/47780 [01:25<02:11, 288.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25731/47780 [01:25<01:25, 257.20 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25498/47780 [01:25<01:16, 292.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25848/47780 [01:25<01:15, 289.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25711/47780 [01:25<01:21, 269.87 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25798/47780 [01:25<01:04, 342.92 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25517/47780 [01:25<01:17, 285.67 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25762/47780 [01:25<01:13, 300.05 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9788/47780 [01:25<02:16, 278.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25773/47780 [01:25<01:12, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25532/47780 [01:25<01:13, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25743/47780 [01:25<01:19, 277.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25878/47780 [01:25<01:17, 281.29 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25833/47780 [01:25<01:07, 326.01 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25547/47780 [01:25<01:19, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9825/47780 [01:25<02:07, 298.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25807/47780 [01:25<01:09, 314.49 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25563/47780 [01:25<01:13, 300.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25793/47780 [01:25<01:19, 276.33 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25773/47780 [01:25<01:17, 284.20 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25907/47780 [01:25<01:17, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25576/47780 [01:25<01:19, 278.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25866/47780 [01:25<01:11, 308.54 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25840/47780 [01:25<01:12, 304.30 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9855/47780 [01:25<02:15, 279.68 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25825/47780 [01:25<01:17, 281.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25594/47780 [01:25<01:16, 290.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25939/47780 [01:25<01:15, 289.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25808/47780 [01:25<01:14, 296.26 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25611/47780 [01:25<01:14, 297.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25898/47780 [01:25<01:13, 299.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25876/47780 [01:25<01:09, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9889/47780 [01:25<02:09, 293.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25858/47780 [01:25<01:14, 294.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25625/47780 [01:25<01:15, 292.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25840/47780 [01:25<01:12, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25642/47780 [01:25<01:16, 290.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25969/47780 [01:25<01:28, 247.16 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25929/47780 [01:25<01:13, 295.79 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9923/47780 [01:25<02:05, 302.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25659/47780 [01:25<01:13, 302.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25908/47780 [01:26<01:14, 294.18 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25888/47780 [01:25<01:19, 276.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25871/47780 [01:26<01:12, 300.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25676/47780 [01:26<01:12, 304.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26019/47780 [01:26<01:10, 310.61 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9955/47780 [01:26<02:06, 298.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25943/47780 [01:26<01:10, 308.41 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25690/47780 [01:26<01:15, 291.29 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25910/47780 [01:26<01:07, 323.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25919/47780 [01:26<01:18, 277.76 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25960/47780 [01:26<01:21, 268.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25711/47780 [01:26<01:10, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26053/47780 [01:26<01:10, 306.80 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25975/47780 [01:26<01:12, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25956/47780 [01:26<01:12, 299.49 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9985/47780 [01:26<02:16, 276.26 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25943/47780 [01:26<01:10, 311.31 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25988/47780 [01:26<01:23, 262.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25720/47780 [01:26<01:23, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25743/47780 [01:26<01:17, 285.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26089/47780 [01:26<01:09, 311.56 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10025/47780 [01:26<02:04, 303.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26015/47780 [01:26<01:24, 258.67 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25987/47780 [01:26<01:17, 281.36 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25975/47780 [01:26<01:13, 296.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25747/47780 [01:26<01:23, 263.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26006/47780 [01:26<01:20, 269.41 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25773/47780 [01:26<01:17, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26121/47780 [01:26<01:10, 305.41 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10059/47780 [01:26<02:01, 309.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26047/47780 [01:26<01:20, 268.93 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25778/47780 [01:26<01:19, 276.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26010/47780 [01:26<01:11, 304.78 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26043/47780 [01:26<01:13, 295.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26016/47780 [01:26<01:21, 265.80 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25806/47780 [01:26<01:14, 293.19 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26153/47780 [01:26<01:11, 301.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10091/47780 [01:26<02:05, 299.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26076/47780 [01:26<01:20, 269.35 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25809/47780 [01:26<01:20, 273.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26041/47780 [01:26<01:14, 291.30 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26043/47780 [01:26<01:27, 248.44 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26074/47780 [01:26<01:20, 269.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25836/47780 [01:26<01:18, 279.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26184/47780 [01:26<01:16, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10123/47780 [01:26<02:04, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26104/47780 [01:26<01:22, 263.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25838/47780 [01:26<01:19, 274.78 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26074/47780 [01:26<01:23, 260.78 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26102/47780 [01:26<01:22, 263.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25867/47780 [01:26<01:16, 287.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26071/47780 [01:26<01:28, 244.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26216/47780 [01:26<01:14, 288.98 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10157/47780 [01:26<02:00, 312.38 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26133/47780 [01:26<01:20, 269.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25870/47780 [01:26<01:17, 284.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26104/47780 [01:26<01:20, 270.57 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26129/47780 [01:26<01:23, 257.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25899/47780 [01:26<01:15, 290.37 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26252/47780 [01:26<01:10, 305.21 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10193/47780 [01:26<01:56, 323.17 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26119/47780 [01:26<01:14, 290.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26161/47780 [01:26<01:24, 257.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25899/47780 [01:26<01:21, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26137/47780 [01:26<01:15, 284.84 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26165/47780 [01:26<01:17, 279.57 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25931/47780 [01:26<01:13, 295.43 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26283/47780 [01:26<01:11, 299.34 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10226/47780 [01:26<02:02, 306.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26150/47780 [01:26<01:15, 286.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26196/47780 [01:26<01:16, 281.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26166/47780 [01:26<01:18, 276.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25963/47780 [01:26<01:12, 299.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25927/47780 [01:27<01:31, 238.91 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26194/47780 [01:27<01:21, 264.98 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10257/47780 [01:27<02:03, 304.40 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26180/47780 [01:27<01:17, 278.90 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26314/47780 [01:27<01:18, 273.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26229/47780 [01:27<01:14, 288.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26206/47780 [01:27<01:09, 309.40 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25996/47780 [01:27<01:11, 304.44 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25968/47780 [01:27<01:17, 280.67 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26221/47780 [01:27<01:21, 263.54 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10289/47780 [01:27<02:02, 305.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26220/47780 [01:27<01:10, 307.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26262/47780 [01:27<01:12, 297.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26342/47780 [01:27<01:19, 268.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26238/47780 [01:27<01:11, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26255/47780 [01:27<01:15, 284.53 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25998/47780 [01:27<01:17, 279.65 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26028/47780 [01:27<01:15, 289.03 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10321/47780 [01:27<02:05, 298.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26297/47780 [01:27<01:08, 311.91 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26370/47780 [01:27<01:24, 254.81 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26280/47780 [01:27<01:04, 331.65 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26252/47780 [01:27<01:18, 275.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26287/47780 [01:27<01:13, 291.26 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26066/47780 [01:27<01:09, 314.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26027/47780 [01:27<01:21, 268.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10353/47780 [01:27<02:03, 303.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26332/47780 [01:27<01:10, 305.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26285/47780 [01:27<01:14, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26314/47780 [01:27<01:07, 319.43 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26104/47780 [01:27<01:05, 329.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26318/47780 [01:27<01:14, 286.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26396/47780 [01:27<01:30, 235.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26055/47780 [01:27<01:21, 265.65 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10385/47780 [01:27<02:08, 290.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26367/47780 [01:27<01:07, 317.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26421/47780 [01:27<01:30, 236.71 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26315/47780 [01:27<01:20, 266.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26138/47780 [01:27<01:07, 321.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26347/47780 [01:27<01:13, 291.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26347/47780 [01:27<01:18, 272.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10416/47780 [01:27<02:06, 295.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26082/47780 [01:27<01:29, 242.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26399/47780 [01:27<01:14, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26445/47780 [01:27<01:30, 235.58 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26345/47780 [01:27<01:18, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26382/47780 [01:27<01:12, 293.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26379/47780 [01:27<01:13, 291.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26171/47780 [01:27<01:10, 306.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10447/47780 [01:27<02:05, 296.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26113/47780 [01:27<01:24, 257.78 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26430/47780 [01:27<01:13, 289.11 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26469/47780 [01:27<01:35, 224.28 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26413/47780 [01:27<01:14, 288.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26204/47780 [01:27<01:10, 306.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26373/47780 [01:27<01:23, 254.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26410/47780 [01:27<01:14, 285.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10481/47780 [01:27<02:00, 308.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26140/47780 [01:27<01:28, 245.19 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26461/47780 [01:27<01:17, 276.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26493/47780 [01:27<01:33, 228.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26235/47780 [01:27<01:10, 303.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26443/47780 [01:27<01:12, 296.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26443/47780 [01:27<01:17, 276.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10513/47780 [01:27<02:02, 305.12 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26401/47780 [01:27<01:26, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26170/47780 [01:27<01:24, 257.22 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26520/47780 [01:27<01:31, 232.51 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26490/47780 [01:28<01:21, 260.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26476/47780 [01:28<01:10, 301.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26266/47780 [01:27<01:15, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26427/47780 [01:28<01:27, 244.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10544/47780 [01:28<02:09, 286.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26471/47780 [01:28<01:24, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26199/47780 [01:28<01:23, 257.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26544/47780 [01:28<01:33, 226.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26507/47780 [01:28<01:11, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26517/47780 [01:28<01:25, 249.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26296/47780 [01:28<01:14, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10573/47780 [01:28<02:10, 284.44 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26459/47780 [01:28<01:23, 253.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26501/47780 [01:28<01:21, 262.10 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26226/47780 [01:28<01:24, 255.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26568/47780 [01:28<01:32, 228.36 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26539/47780 [01:28<01:11, 297.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26544/47780 [01:28<01:23, 254.99 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26500/47780 [01:28<01:12, 292.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10603/47780 [01:28<02:13, 279.23 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26325/47780 [01:28<01:25, 251.15 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26253/47780 [01:28<01:27, 245.84 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26528/47780 [01:28<01:27, 243.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26595/47780 [01:28<01:28, 240.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26569/47780 [01:28<01:15, 282.14 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26536/47780 [01:28<01:08, 307.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26570/47780 [01:28<01:30, 235.47 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10642/47780 [01:28<02:00, 307.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26278/47780 [01:28<01:28, 243.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26558/47780 [01:28<01:22, 258.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26622/47780 [01:28<01:28, 240.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26351/47780 [01:28<01:32, 231.48 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26599/47780 [01:28<01:13, 286.82 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10681/47780 [01:28<01:52, 330.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26568/47780 [01:28<01:11, 297.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26594/47780 [01:28<01:35, 222.74 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26304/47780 [01:28<01:27, 246.07 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26591/47780 [01:28<01:17, 274.65 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26422/47780 [01:28<01:01, 349.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26648/47780 [01:28<01:27, 242.89 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26631/47780 [01:28<01:11, 293.97 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10716/47780 [01:28<01:50, 336.11 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26599/47780 [01:28<01:13, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26332/47780 [01:28<01:24, 252.87 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26620/47780 [01:28<01:17, 273.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26617/47780 [01:28<01:43, 203.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26678/47780 [01:28<01:23, 253.77 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26661/47780 [01:28<01:11, 294.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26460/47780 [01:28<01:04, 328.34 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10750/47780 [01:28<01:52, 329.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26629/47780 [01:28<01:13, 286.60 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26363/47780 [01:28<01:20, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26649/47780 [01:28<01:16, 277.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26706/47780 [01:28<01:20, 261.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26638/47780 [01:28<01:47, 197.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26691/47780 [01:28<01:11, 293.17 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10784/47780 [01:28<01:55, 321.49 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26495/47780 [01:28<01:10, 303.91 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26658/47780 [01:28<01:13, 286.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26393/47780 [01:28<01:17, 275.52 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26678/47780 [01:28<01:16, 274.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26675/47780 [01:28<01:27, 241.95 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26733/47780 [01:28<01:23, 251.77 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26721/47780 [01:28<01:13, 284.96 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26687/47780 [01:28<01:14, 284.15 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10822/47780 [01:28<01:54, 323.33 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26429/47780 [01:28<01:12, 293.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26706/47780 [01:28<01:19, 266.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26527/47780 [01:28<01:13, 288.83 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26759/47780 [01:28<01:23, 251.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26701/47780 [01:28<01:30, 231.96 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10856/47780 [01:28<01:53, 324.49 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26761/47780 [01:28<01:13, 285.38 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26735/47780 [01:29<01:18, 267.73 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26716/47780 [01:29<01:20, 261.87 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26557/47780 [01:29<01:15, 279.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26459/47780 [01:29<01:19, 269.54 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26789/47780 [01:29<01:19, 262.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26725/47780 [01:29<01:31, 228.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26798/47780 [01:29<01:08, 308.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26764/47780 [01:29<01:16, 273.78 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10889/47780 [01:29<02:02, 302.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26747/47780 [01:29<01:17, 271.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26586/47780 [01:29<01:15, 281.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26493/47780 [01:29<01:15, 283.61 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26817/47780 [01:29<01:21, 258.58 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26749/47780 [01:29<01:32, 227.15 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26831/47780 [01:29<01:08, 304.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26792/47780 [01:29<01:18, 266.43 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10920/47780 [01:29<02:06, 292.53 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26615/47780 [01:29<01:16, 275.18 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26775/47780 [01:29<01:20, 260.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26526/47780 [01:29<01:14, 286.89 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26843/47780 [01:29<01:22, 253.32 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26773/47780 [01:29<01:37, 216.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26862/47780 [01:29<01:09, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26823/47780 [01:29<01:17, 269.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10955/47780 [01:29<02:02, 301.13 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26556/47780 [01:29<01:14, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26651/47780 [01:29<01:16, 277.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26802/47780 [01:29<01:26, 241.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26873/47780 [01:29<01:22, 254.77 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26796/47780 [01:29<01:36, 217.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26893/47780 [01:29<01:13, 282.29 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26858/47780 [01:29<01:12, 289.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10987/47780 [01:29<02:03, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26828/47780 [01:29<01:26, 243.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26680/47780 [01:29<01:17, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26901/47780 [01:29<01:19, 261.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26585/47780 [01:29<01:20, 263.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26833/47780 [01:29<01:25, 246.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26924/47780 [01:29<01:16, 272.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26889/47780 [01:29<01:15, 275.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26860/47780 [01:29<01:20, 261.35 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11018/47780 [01:29<02:15, 271.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26708/47780 [01:29<01:20, 260.30 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26616/47780 [01:29<01:19, 266.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26865/47780 [01:29<01:18, 266.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26929/47780 [01:29<01:35, 217.59 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26924/47780 [01:29<01:12, 287.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26952/47780 [01:29<01:21, 254.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11052/47780 [01:29<02:07, 286.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26643/47780 [01:29<01:20, 261.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26887/47780 [01:29<01:26, 242.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26897/47780 [01:29<01:14, 281.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26735/47780 [01:29<01:31, 230.87 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26964/47780 [01:29<01:25, 243.84 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26954/47780 [01:29<01:12, 287.57 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26978/47780 [01:29<01:23, 248.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26914/47780 [01:29<01:24, 247.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11082/47780 [01:29<02:18, 264.66 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26672/47780 [01:29<01:25, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26926/47780 [01:29<01:20, 260.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26760/47780 [01:29<01:30, 233.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26990/47780 [01:29<01:25, 242.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26983/47780 [01:29<01:14, 279.02 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26942/47780 [01:29<01:21, 255.88 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27004/47780 [01:29<01:26, 239.19 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11117/47780 [01:29<02:07, 286.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26705/47780 [01:29<01:20, 261.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26956/47780 [01:29<01:18, 265.82 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26787/47780 [01:29<01:30, 233.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27016/47780 [01:29<01:29, 232.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27011/47780 [01:30<01:16, 269.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27029/47780 [01:30<01:25, 241.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26972/47780 [01:30<01:19, 262.59 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11150/47780 [01:30<02:03, 295.44 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26988/47780 [01:30<01:14, 280.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26734/47780 [01:30<01:20, 260.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26813/47780 [01:30<01:28, 237.18 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27040/47780 [01:30<01:16, 272.37 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27040/47780 [01:30<01:30, 228.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27056/47780 [01:30<01:23, 247.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11181/47780 [01:30<02:02, 299.32 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26999/47780 [01:30<01:25, 242.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27017/47780 [01:30<01:15, 273.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26837/47780 [01:30<01:33, 223.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26761/47780 [01:30<01:28, 237.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27070/47780 [01:30<01:24, 246.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27069/47780 [01:30<01:16, 271.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27081/47780 [01:30<01:24, 245.22 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11222/47780 [01:30<01:51, 327.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27035/47780 [01:30<01:17, 268.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27045/47780 [01:30<01:16, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26861/47780 [01:30<01:32, 225.72 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26786/47780 [01:30<01:29, 235.69 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27096/47780 [01:30<01:27, 236.85 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27102/47780 [01:30<01:15, 274.69 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11258/47780 [01:30<01:49, 333.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27106/47780 [01:30<01:26, 238.36 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27076/47780 [01:30<01:13, 280.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27063/47780 [01:30<01:19, 260.37 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26884/47780 [01:30<01:39, 210.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27131/47780 [01:30<01:25, 241.54 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26810/47780 [01:30<01:38, 213.16 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27123/47780 [01:30<01:28, 234.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27130/47780 [01:30<01:19, 259.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11292/47780 [01:30<01:57, 309.74 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27094/47780 [01:30<01:18, 265.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27105/47780 [01:30<01:21, 253.50 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26906/47780 [01:30<01:42, 204.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27157/47780 [01:30<01:25, 240.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26832/47780 [01:30<01:38, 213.74 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27147/47780 [01:30<01:32, 222.74 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27157/47780 [01:30<01:22, 248.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11324/47780 [01:30<02:00, 302.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27123/47780 [01:30<01:19, 260.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27131/47780 [01:30<01:23, 246.81 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26927/47780 [01:30<01:43, 201.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27182/47780 [01:30<01:26, 238.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26855/47780 [01:30<01:36, 215.82 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27170/47780 [01:30<01:31, 224.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11358/47780 [01:30<01:56, 312.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27190/47780 [01:30<01:16, 268.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27150/47780 [01:30<01:20, 257.64 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26882/47780 [01:30<01:31, 228.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27157/47780 [01:30<01:31, 226.36 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27206/47780 [01:30<01:29, 230.94 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26948/47780 [01:30<01:48, 191.96 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27195/47780 [01:30<01:28, 231.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27218/47780 [01:30<01:15, 271.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11390/47780 [01:30<01:55, 314.48 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27176/47780 [01:30<01:25, 242.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27181/47780 [01:30<01:31, 225.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27232/47780 [01:30<01:27, 234.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26906/47780 [01:30<01:34, 221.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26994/47780 [01:30<01:19, 260.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27219/47780 [01:30<01:30, 227.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11423/47780 [01:30<01:55, 314.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27246/47780 [01:30<01:17, 264.87 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27201/47780 [01:30<01:27, 235.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27256/47780 [01:30<01:28, 233.11 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27204/47780 [01:31<01:32, 221.75 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26931/47780 [01:31<01:33, 222.09 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11456/47780 [01:30<01:54, 316.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27242/47780 [01:30<01:32, 222.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27022/47780 [01:30<01:21, 254.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27277/47780 [01:31<01:17, 265.54 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27225/47780 [01:31<01:27, 234.14 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27281/47780 [01:31<01:27, 235.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27268/47780 [01:31<01:28, 230.48 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11488/47780 [01:31<01:59, 303.61 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27230/47780 [01:31<01:34, 217.99 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26956/47780 [01:31<01:35, 217.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27048/47780 [01:31<01:23, 247.96 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27304/47780 [01:31<01:19, 257.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27249/47780 [01:31<01:31, 224.52 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27305/47780 [01:31<01:31, 223.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27252/47780 [01:31<01:34, 218.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11521/47780 [01:31<01:58, 306.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27292/47780 [01:31<01:32, 220.40 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26984/47780 [01:31<01:31, 227.27 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27333/47780 [01:31<01:16, 266.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27074/47780 [01:31<01:28, 233.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27277/47780 [01:31<01:26, 237.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27282/47780 [01:31<01:25, 240.76 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11558/47780 [01:31<01:52, 322.16 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27337/47780 [01:31<01:23, 245.16 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27327/47780 [01:31<01:20, 254.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27020/47780 [01:31<01:20, 257.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27361/47780 [01:31<01:17, 262.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27098/47780 [01:31<01:33, 220.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27304/47780 [01:31<01:24, 243.53 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27358/47780 [01:31<01:15, 268.75 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11591/47780 [01:31<01:55, 313.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27362/47780 [01:31<01:26, 235.69 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27388/47780 [01:31<01:18, 258.40 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27046/47780 [01:31<01:23, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27307/47780 [01:31<01:35, 214.03 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27125/47780 [01:31<01:31, 226.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27329/47780 [01:31<01:29, 227.40 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11627/47780 [01:31<01:51, 325.49 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27387/47780 [01:31<01:27, 232.21 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27071/47780 [01:31<01:24, 245.52 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27414/47780 [01:31<01:21, 250.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27388/47780 [01:31<01:21, 249.61 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27150/47780 [01:31<01:29, 230.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27343/47780 [01:31<01:26, 235.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27352/47780 [01:31<01:33, 218.35 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11661/47780 [01:31<01:55, 312.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27443/47780 [01:31<01:18, 258.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27414/47780 [01:31<01:20, 251.86 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27411/47780 [01:31<01:32, 219.76 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27175/47780 [01:31<01:28, 233.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27096/47780 [01:31<01:33, 221.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27367/47780 [01:31<01:32, 220.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27375/47780 [01:31<01:38, 208.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27476/47780 [01:31<01:12, 278.92 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11693/47780 [01:31<02:02, 295.17 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27447/47780 [01:31<01:15, 268.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27441/47780 [01:31<01:25, 238.82 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27199/47780 [01:31<01:31, 224.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27124/47780 [01:31<01:29, 231.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27391/47780 [01:31<01:31, 223.07 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27505/47780 [01:31<01:12, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11724/47780 [01:31<02:01, 295.97 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27396/47780 [01:31<01:44, 195.58 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27475/47780 [01:31<01:18, 257.16 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27225/47780 [01:31<01:28, 232.24 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27466/47780 [01:31<01:32, 220.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27418/47780 [01:31<01:27, 232.91 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27148/47780 [01:31<01:36, 213.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27534/47780 [01:32<01:14, 272.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27434/47780 [01:32<01:23, 242.38 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11755/47780 [01:31<02:03, 290.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27502/47780 [01:31<01:19, 254.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27249/47780 [01:31<01:27, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27495/47780 [01:32<01:25, 237.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27442/47780 [01:32<01:29, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27170/47780 [01:32<01:35, 215.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27570/47780 [01:32<01:08, 294.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27459/47780 [01:32<01:24, 241.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11790/47780 [01:32<01:58, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27532/47780 [01:32<01:16, 264.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27273/47780 [01:32<01:27, 233.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27520/47780 [01:32<01:28, 228.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27467/47780 [01:32<01:27, 232.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27192/47780 [01:32<01:37, 211.89 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27484/47780 [01:32<01:25, 236.21 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11822/47780 [01:32<01:59, 301.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27560/47780 [01:32<01:16, 266.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27600/47780 [01:32<01:18, 257.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27297/47780 [01:32<01:33, 220.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27545/47780 [01:32<01:29, 225.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27492/47780 [01:32<01:28, 228.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27214/47780 [01:32<01:42, 200.96 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27508/47780 [01:32<01:28, 230.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27588/47780 [01:32<01:15, 268.84 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11853/47780 [01:32<02:03, 290.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27627/47780 [01:32<01:17, 260.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27324/47780 [01:32<01:29, 228.86 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27569/47780 [01:32<01:28, 229.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27515/47780 [01:32<01:31, 221.43 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27238/47780 [01:32<01:39, 207.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27615/47780 [01:32<01:15, 266.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11890/47780 [01:32<01:56, 308.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27654/47780 [01:32<01:18, 257.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27351/47780 [01:32<01:27, 232.46 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27532/47780 [01:32<01:38, 205.11 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27594/47780 [01:32<01:29, 225.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27538/47780 [01:32<01:36, 209.87 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27259/47780 [01:32<01:44, 196.81 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27642/47780 [01:32<01:17, 259.54 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11926/47780 [01:32<01:53, 316.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27684/47780 [01:32<01:15, 266.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27381/47780 [01:32<01:22, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27620/47780 [01:32<01:26, 232.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27561/47780 [01:32<01:30, 224.09 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27562/47780 [01:32<01:33, 215.94 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27287/47780 [01:32<01:36, 212.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27670/47780 [01:32<01:15, 264.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11959/47780 [01:32<01:54, 313.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27409/47780 [01:32<01:20, 254.61 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27711/47780 [01:32<01:19, 253.27 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27586/47780 [01:32<01:28, 229.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27647/47780 [01:32<01:25, 234.86 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27589/47780 [01:32<01:27, 230.92 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27314/47780 [01:32<01:30, 225.99 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27697/47780 [01:32<01:17, 260.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11991/47780 [01:32<01:58, 301.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27438/47780 [01:32<01:17, 261.81 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27739/47780 [01:32<01:17, 259.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27610/47780 [01:32<01:28, 227.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27672/47780 [01:32<01:26, 231.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27613/47780 [01:32<01:30, 223.03 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27345/47780 [01:32<01:21, 249.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27724/47780 [01:32<01:17, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27465/47780 [01:32<01:16, 264.13 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27767/47780 [01:32<01:16, 260.41 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12022/47780 [01:32<02:04, 286.79 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27634/47780 [01:32<01:28, 228.10 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27699/47780 [01:32<01:23, 239.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27638/47780 [01:32<01:28, 228.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27371/47780 [01:32<01:21, 250.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27751/47780 [01:32<01:18, 253.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27496/47780 [01:32<01:13, 274.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27796/47780 [01:33<01:15, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12051/47780 [01:32<02:06, 282.56 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27660/47780 [01:33<01:28, 226.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27724/47780 [01:33<01:24, 237.15 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27670/47780 [01:33<01:19, 254.14 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27399/47780 [01:33<01:19, 254.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27778/47780 [01:33<01:17, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27526/47780 [01:33<01:13, 277.30 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27829/47780 [01:33<01:11, 278.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27683/47780 [01:33<01:30, 222.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27748/47780 [01:33<01:25, 234.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27696/47780 [01:33<01:19, 254.03 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12080/47780 [01:33<02:19, 256.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27425/47780 [01:33<01:24, 239.84 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27804/47780 [01:33<01:23, 239.78 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27858/47780 [01:33<01:12, 275.28 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27554/47780 [01:33<01:20, 250.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27724/47780 [01:33<01:17, 259.56 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12114/47780 [01:33<02:08, 277.98 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27772/47780 [01:33<01:29, 222.96 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27706/47780 [01:33<01:36, 208.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27459/47780 [01:33<01:15, 267.62 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27829/47780 [01:33<01:26, 230.07 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27886/47780 [01:33<01:15, 264.46 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27582/47780 [01:33<01:19, 255.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27751/47780 [01:33<01:17, 257.63 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12143/47780 [01:33<02:08, 278.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27801/47780 [01:33<01:23, 240.01 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27729/47780 [01:33<01:35, 209.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27492/47780 [01:33<01:11, 285.08 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27862/47780 [01:33<01:18, 255.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27915/47780 [01:33<01:13, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27612/47780 [01:33<01:17, 261.78 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12172/47780 [01:33<02:10, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27785/47780 [01:33<01:14, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27757/47780 [01:33<01:28, 226.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27522/47780 [01:33<01:11, 282.81 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27826/47780 [01:33<01:34, 211.76 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27888/47780 [01:33<01:18, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27943/47780 [01:33<01:13, 271.61 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12203/47780 [01:33<02:05, 282.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27642/47780 [01:33<01:16, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27782/47780 [01:33<01:26, 230.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27812/47780 [01:33<01:19, 251.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27552/47780 [01:33<01:14, 272.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27852/47780 [01:33<01:28, 224.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27919/47780 [01:33<01:14, 266.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27972/47780 [01:33<01:13, 271.07 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12237/47780 [01:33<01:59, 298.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27669/47780 [01:33<01:16, 264.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27806/47780 [01:33<01:32, 216.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27838/47780 [01:33<01:21, 243.69 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27883/47780 [01:33<01:21, 244.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27580/47780 [01:33<01:18, 258.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28000/47780 [01:33<01:13, 270.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27946/47780 [01:33<01:17, 255.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12271/47780 [01:33<01:55, 307.12 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27705/47780 [01:33<01:11, 280.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27831/47780 [01:33<01:29, 222.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27864/47780 [01:33<01:21, 243.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27910/47780 [01:33<01:19, 251.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27607/47780 [01:33<01:23, 241.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28028/47780 [01:33<01:15, 261.27 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27976/47780 [01:33<01:17, 256.51 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12302/47780 [01:33<01:56, 304.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27735/47780 [01:33<01:12, 276.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27854/47780 [01:33<01:32, 215.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27940/47780 [01:33<01:17, 256.76 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27890/47780 [01:33<01:23, 236.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27632/47780 [01:33<01:23, 241.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28004/47780 [01:33<01:15, 262.37 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28058/47780 [01:33<01:14, 266.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12333/47780 [01:33<02:02, 289.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27763/47780 [01:33<01:12, 274.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27884/47780 [01:34<01:23, 238.53 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27967/47780 [01:33<01:16, 258.86 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27929/47780 [01:34<01:12, 274.04 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27658/47780 [01:34<01:22, 244.08 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28031/47780 [01:34<01:16, 259.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28085/47780 [01:34<01:16, 258.56 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12370/47780 [01:34<01:53, 312.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27791/47780 [01:34<01:14, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27909/47780 [01:34<01:23, 239.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27994/47780 [01:34<01:17, 254.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27957/47780 [01:34<01:14, 265.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27683/47780 [01:34<01:22, 242.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28059/47780 [01:34<01:14, 264.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28111/47780 [01:34<01:20, 245.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27818/47780 [01:34<01:16, 261.06 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27935/47780 [01:34<01:21, 242.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12402/47780 [01:34<02:09, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27990/47780 [01:34<01:11, 277.45 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27710/47780 [01:34<01:20, 247.89 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28020/47780 [01:34<01:25, 231.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28086/47780 [01:34<01:17, 254.74 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27846/47780 [01:34<01:18, 255.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28136/47780 [01:34<01:28, 222.75 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12435/47780 [01:34<02:03, 285.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28018/47780 [01:34<01:11, 277.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27960/47780 [01:34<01:28, 223.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28050/47780 [01:34<01:19, 249.40 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27740/47780 [01:34<01:21, 245.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28112/47780 [01:34<01:20, 245.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27886/47780 [01:34<01:07, 295.28 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12465/47780 [01:34<02:06, 279.95 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28159/47780 [01:34<01:31, 214.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27987/47780 [01:34<01:23, 236.47 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28082/47780 [01:34<01:14, 264.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28046/47780 [01:34<01:18, 252.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27783/47780 [01:34<01:08, 293.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28149/47780 [01:34<01:10, 279.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27917/47780 [01:34<01:09, 286.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28181/47780 [01:34<01:30, 215.54 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28013/47780 [01:34<01:22, 240.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12494/47780 [01:34<02:07, 276.81 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28112/47780 [01:34<01:13, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28073/47780 [01:34<01:17, 254.73 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28183/47780 [01:34<01:06, 294.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27813/47780 [01:34<01:12, 276.69 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27947/47780 [01:34<01:09, 287.16 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28047/47780 [01:34<01:13, 268.30 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12527/47780 [01:34<02:01, 290.37 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28205/47780 [01:34<01:31, 213.50 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28147/47780 [01:34<01:07, 289.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28099/47780 [01:34<01:20, 245.28 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28215/47780 [01:34<01:05, 298.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27842/47780 [01:34<01:12, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27977/47780 [01:34<01:08, 288.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28228/47780 [01:34<01:29, 217.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12558/47780 [01:34<02:11, 266.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28075/47780 [01:34<01:21, 241.44 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28177/47780 [01:34<01:12, 269.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28124/47780 [01:34<01:23, 236.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27870/47780 [01:34<01:15, 262.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28246/47780 [01:34<01:10, 276.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28007/47780 [01:34<01:10, 279.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28251/47780 [01:34<01:29, 219.17 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12586/47780 [01:34<02:11, 266.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28148/47780 [01:34<01:23, 236.10 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28205/47780 [01:34<01:13, 264.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28100/47780 [01:34<01:27, 224.52 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27900/47780 [01:34<01:13, 268.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28278/47780 [01:34<01:08, 285.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28284/47780 [01:34<01:17, 250.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12615/47780 [01:34<02:09, 271.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28036/47780 [01:34<01:21, 243.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28233/47780 [01:35<01:13, 266.27 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28172/47780 [01:35<01:24, 230.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28124/47780 [01:35<01:26, 227.86 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28307/47780 [01:34<01:09, 280.15 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27928/47780 [01:35<01:18, 252.09 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28313/47780 [01:35<01:16, 256.13 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28070/47780 [01:35<01:14, 265.13 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12643/47780 [01:35<02:17, 255.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28197/47780 [01:35<01:25, 228.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28260/47780 [01:35<01:17, 252.92 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28148/47780 [01:35<01:29, 219.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28336/47780 [01:35<01:11, 272.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28342/47780 [01:35<01:13, 265.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27955/47780 [01:35<01:21, 243.94 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28099/47780 [01:35<01:14, 263.48 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12669/47780 [01:35<02:18, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28223/47780 [01:35<01:23, 234.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28288/47780 [01:35<01:15, 259.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28173/47780 [01:35<01:28, 220.85 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28369/47780 [01:35<01:13, 264.11 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27985/47780 [01:35<01:17, 256.19 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28364/47780 [01:35<01:18, 247.70 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28126/47780 [01:35<01:15, 259.62 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12706/47780 [01:35<02:06, 277.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28247/47780 [01:35<01:24, 230.68 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28320/47780 [01:35<01:12, 268.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28197/47780 [01:35<01:28, 221.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28397/47780 [01:35<01:13, 264.86 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28014/47780 [01:35<01:14, 265.43 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28390/47780 [01:35<01:18, 246.15 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28153/47780 [01:35<01:15, 259.30 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12745/47780 [01:35<01:54, 305.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28275/47780 [01:35<01:20, 242.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28348/47780 [01:35<01:12, 269.61 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28224/47780 [01:35<01:24, 232.16 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28042/47780 [01:35<01:18, 252.15 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28415/47780 [01:35<01:20, 239.42 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28424/47780 [01:35<01:21, 238.87 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28180/47780 [01:35<01:15, 259.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12781/47780 [01:35<01:49, 320.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28376/47780 [01:35<01:11, 271.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28308/47780 [01:35<01:13, 263.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28248/47780 [01:35<01:28, 220.33 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28068/47780 [01:35<01:18, 251.49 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28440/47780 [01:35<01:20, 239.67 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28449/47780 [01:35<01:21, 236.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28207/47780 [01:35<01:15, 258.47 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28335/47780 [01:35<01:13, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28409/47780 [01:35<01:08, 282.17 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12814/47780 [01:35<01:56, 299.38 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28274/47780 [01:35<01:28, 221.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28095/47780 [01:35<01:18, 251.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28474/47780 [01:35<01:21, 235.62 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28467/47780 [01:35<01:24, 227.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28233/47780 [01:35<01:16, 256.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28364/47780 [01:35<01:12, 267.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28438/47780 [01:35<01:08, 280.99 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12845/47780 [01:35<01:58, 295.58 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28298/47780 [01:35<01:28, 220.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28121/47780 [01:35<01:22, 239.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28499/47780 [01:35<01:16, 251.58 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28498/47780 [01:35<01:25, 225.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28269/47780 [01:35<01:09, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28393/47780 [01:35<01:10, 273.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28468/47780 [01:35<01:10, 275.66 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12875/47780 [01:35<02:08, 272.38 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28326/47780 [01:35<01:22, 237.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28526/47780 [01:35<01:15, 255.55 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28146/47780 [01:35<01:23, 235.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28421/47780 [01:35<01:10, 274.96 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28521/47780 [01:35<01:27, 220.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28299/47780 [01:35<01:10, 276.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28496/47780 [01:35<01:14, 260.54 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12904/47780 [01:36<02:11, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28350/47780 [01:36<01:24, 230.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28554/47780 [01:36<01:13, 261.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28175/47780 [01:36<01:19, 248.00 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28330/47780 [01:36<01:08, 282.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28545/47780 [01:36<01:27, 218.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28449/47780 [01:36<01:15, 256.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28524/47780 [01:36<01:14, 260.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12931/47780 [01:36<02:10, 266.93 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28378/47780 [01:36<01:20, 241.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28581/47780 [01:36<01:12, 263.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28567/47780 [01:36<01:30, 212.28 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28200/47780 [01:36<01:25, 227.73 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28359/47780 [01:36<01:11, 270.49 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28475/47780 [01:36<01:16, 253.62 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12969/47780 [01:36<01:56, 298.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28551/47780 [01:36<01:18, 243.86 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28403/47780 [01:36<01:24, 229.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28608/47780 [01:36<01:13, 259.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28229/47780 [01:36<01:20, 243.86 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28598/47780 [01:36<01:21, 236.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28387/47780 [01:36<01:12, 266.12 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28501/47780 [01:36<01:17, 247.55 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13001/47780 [01:36<01:54, 304.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28580/47780 [01:36<01:15, 253.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28431/47780 [01:36<01:20, 239.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28636/47780 [01:36<01:13, 259.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28634/47780 [01:36<01:11, 268.30 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28415/47780 [01:36<01:12, 267.06 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28254/47780 [01:36<01:25, 228.75 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28526/47780 [01:36<01:20, 239.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13032/47780 [01:36<01:54, 302.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28663/47780 [01:36<01:13, 261.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28606/47780 [01:36<01:25, 225.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28456/47780 [01:36<01:27, 220.13 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28663/47780 [01:36<01:10, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28442/47780 [01:36<01:12, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28558/47780 [01:36<01:14, 257.78 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28283/47780 [01:36<01:21, 240.08 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13063/47780 [01:36<01:56, 298.18 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28633/47780 [01:36<01:20, 236.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28690/47780 [01:36<01:16, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28480/47780 [01:36<01:25, 225.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28695/47780 [01:36<01:07, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28469/47780 [01:36<01:15, 254.17 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28312/47780 [01:36<01:18, 248.29 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28584/47780 [01:36<01:17, 248.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13093/47780 [01:36<02:02, 282.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28506/47780 [01:36<01:22, 232.41 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28716/47780 [01:36<01:18, 242.37 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28497/47780 [01:36<01:14, 258.41 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28724/47780 [01:36<01:12, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28613/47780 [01:36<01:13, 259.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28338/47780 [01:36<01:20, 240.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28658/47780 [01:36<01:33, 205.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13122/47780 [01:36<02:05, 275.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28532/47780 [01:36<01:21, 237.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28741/47780 [01:36<01:18, 241.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28523/47780 [01:36<01:15, 254.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28758/47780 [01:36<01:07, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28640/47780 [01:36<01:13, 260.55 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28375/47780 [01:36<01:10, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28681/47780 [01:36<01:36, 197.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13150/47780 [01:36<02:12, 261.19 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28769/47780 [01:36<01:15, 250.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28556/47780 [01:36<01:28, 218.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28558/47780 [01:36<01:09, 276.91 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28787/47780 [01:36<01:07, 280.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28678/47780 [01:36<01:09, 275.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28728/47780 [01:36<01:13, 258.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13177/47780 [01:36<02:15, 256.00 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28799/47780 [01:36<01:12, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28404/47780 [01:37<01:22, 235.08 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28581/47780 [01:37<01:27, 219.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28586/47780 [01:37<01:10, 270.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28816/47780 [01:37<01:10, 270.25 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28718/47780 [01:37<01:02, 303.48 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28756/47780 [01:37<01:13, 257.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13207/47780 [01:37<02:10, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28826/47780 [01:37<01:12, 263.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28429/47780 [01:37<01:23, 231.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28620/47780 [01:37<01:07, 284.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28604/47780 [01:37<01:30, 211.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28750/47780 [01:37<01:03, 298.14 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28848/47780 [01:37<01:13, 255.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28792/47780 [01:37<01:06, 284.69 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13240/47780 [01:37<02:07, 271.43 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28853/47780 [01:37<01:13, 256.47 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28462/47780 [01:37<01:18, 247.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28653/47780 [01:37<01:04, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28628/47780 [01:37<01:29, 214.27 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28780/47780 [01:37<01:04, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28822/47780 [01:37<01:06, 285.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28874/47780 [01:37<01:16, 248.56 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13269/47780 [01:37<02:06, 273.46 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28885/47780 [01:37<01:09, 271.57 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28495/47780 [01:37<01:13, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28683/47780 [01:37<01:05, 293.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28659/47780 [01:37<01:21, 235.39 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28810/47780 [01:37<01:04, 293.36 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28900/47780 [01:37<01:15, 251.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28852/47780 [01:37<01:06, 283.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13306/47780 [01:37<01:55, 297.36 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28919/47780 [01:37<01:04, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28525/47780 [01:37<01:11, 267.45 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28718/47780 [01:37<01:01, 307.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28684/47780 [01:37<01:19, 239.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28927/47780 [01:37<01:14, 252.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28881/47780 [01:37<01:07, 280.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28841/47780 [01:37<01:09, 273.15 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13336/47780 [01:37<01:58, 291.72 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28950/47780 [01:37<01:05, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28553/47780 [01:37<01:11, 267.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28749/47780 [01:37<01:04, 294.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28709/47780 [01:37<01:22, 232.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28875/47780 [01:37<01:05, 288.81 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28954/47780 [01:37<01:18, 241.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13368/47780 [01:37<01:57, 292.90 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28910/47780 [01:37<01:12, 261.15 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28980/47780 [01:37<01:05, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28581/47780 [01:37<01:13, 259.75 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28789/47780 [01:37<00:59, 321.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28733/47780 [01:37<01:24, 224.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28905/47780 [01:37<01:08, 276.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28984/47780 [01:37<01:14, 251.59 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13405/47780 [01:37<01:51, 308.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28937/47780 [01:37<01:13, 258.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29009/47780 [01:37<01:09, 271.89 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28822/47780 [01:37<00:59, 316.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28613/47780 [01:37<01:12, 264.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28768/47780 [01:37<01:14, 254.95 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28939/47780 [01:37<01:04, 293.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29010/47780 [01:37<01:16, 245.84 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28964/47780 [01:37<01:12, 258.18 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13436/47780 [01:37<01:56, 294.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29040/47780 [01:37<01:07, 276.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28854/47780 [01:37<01:00, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28644/47780 [01:37<01:10, 270.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28795/47780 [01:37<01:13, 257.43 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28975/47780 [01:37<01:00, 311.67 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29035/47780 [01:37<01:15, 246.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28996/47780 [01:37<01:08, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13468/47780 [01:37<01:54, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29068/47780 [01:37<01:08, 271.69 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28676/47780 [01:38<01:07, 281.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28886/47780 [01:37<01:03, 298.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28825/47780 [01:38<01:11, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29071/47780 [01:38<01:07, 275.75 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29024/47780 [01:38<01:10, 267.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29007/47780 [01:38<01:03, 294.34 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13505/47780 [01:38<01:49, 311.79 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28708/47780 [01:38<01:06, 286.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29096/47780 [01:38<01:15, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28852/47780 [01:38<01:13, 255.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28917/47780 [01:38<01:08, 276.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29041/47780 [01:38<01:01, 306.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29099/47780 [01:38<01:09, 270.09 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29052/47780 [01:38<01:09, 269.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13537/47780 [01:38<01:53, 301.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28741/47780 [01:38<01:03, 298.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29122/47780 [01:38<01:16, 244.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28878/47780 [01:38<01:13, 256.95 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28947/47780 [01:38<01:09, 270.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29073/47780 [01:38<01:01, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29080/47780 [01:38<01:12, 256.27 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29127/47780 [01:38<01:13, 253.48 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13568/47780 [01:38<02:04, 274.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29154/47780 [01:38<01:10, 265.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28772/47780 [01:38<01:06, 285.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28911/47780 [01:38<01:07, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28977/47780 [01:38<01:08, 273.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29104/47780 [01:38<01:03, 295.47 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29106/47780 [01:38<01:15, 247.29 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29153/47780 [01:38<01:16, 241.96 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29182/47780 [01:38<01:09, 268.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13613/47780 [01:38<01:46, 320.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28941/47780 [01:38<01:06, 284.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28810/47780 [01:38<01:02, 301.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29005/47780 [01:38<01:11, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29134/47780 [01:38<01:02, 296.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29138/47780 [01:38<01:11, 261.89 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29180/47780 [01:38<01:14, 249.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29210/47780 [01:38<01:08, 271.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28970/47780 [01:38<01:06, 282.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28845/47780 [01:38<01:00, 311.89 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13647/47780 [01:38<01:54, 297.64 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29035/47780 [01:38<01:08, 273.20 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29164/47780 [01:38<01:06, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29206/47780 [01:38<01:13, 252.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29167/47780 [01:38<01:09, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29242/47780 [01:38<01:06, 276.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29006/47780 [01:38<01:02, 301.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28881/47780 [01:38<00:58, 325.31 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13679/47780 [01:38<01:52, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29063/47780 [01:38<01:12, 258.15 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29236/47780 [01:38<01:10, 263.28 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29193/47780 [01:38<01:08, 269.63 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29195/47780 [01:38<01:12, 256.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29273/47780 [01:38<01:06, 276.81 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28914/47780 [01:38<01:00, 312.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13717/47780 [01:38<01:46, 320.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29037/47780 [01:38<01:05, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29102/47780 [01:38<01:04, 287.87 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29263/47780 [01:38<01:12, 255.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29221/47780 [01:38<01:10, 264.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29224/47780 [01:38<01:10, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13757/47780 [01:38<01:39, 342.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28948/47780 [01:38<00:59, 316.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29301/47780 [01:38<01:11, 260.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29068/47780 [01:38<01:06, 282.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29133/47780 [01:38<01:04, 290.72 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29289/47780 [01:38<01:12, 255.31 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29255/47780 [01:38<01:07, 275.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29248/47780 [01:38<01:10, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29328/47780 [01:38<01:10, 262.82 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28981/47780 [01:38<01:00, 309.78 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13793/47780 [01:38<01:47, 316.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29163/47780 [01:39<01:06, 280.76 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29097/47780 [01:39<01:16, 242.67 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29315/47780 [01:39<01:13, 249.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29283/47780 [01:39<01:07, 273.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29279/47780 [01:39<01:07, 273.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29358/47780 [01:39<01:07, 273.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13834/47780 [01:39<01:39, 340.60 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29013/47780 [01:39<01:05, 286.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29140/47780 [01:39<01:04, 287.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29308/47780 [01:39<01:07, 274.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29317/47780 [01:39<01:05, 283.68 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29341/47780 [01:39<01:18, 234.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29386/47780 [01:39<01:07, 272.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29192/47780 [01:39<01:13, 252.19 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13869/47780 [01:39<01:39, 342.12 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29043/47780 [01:39<01:06, 282.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29171/47780 [01:39<01:03, 292.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29341/47780 [01:39<01:03, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29367/47780 [01:39<01:17, 238.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29346/47780 [01:39<01:07, 272.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29218/47780 [01:39<01:15, 244.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29414/47780 [01:39<01:12, 253.89 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13904/47780 [01:39<01:45, 320.05 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29073/47780 [01:39<01:06, 279.87 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29202/47780 [01:39<01:04, 287.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29371/47780 [01:39<01:03, 289.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29396/47780 [01:39<01:13, 250.21 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29247/47780 [01:39<01:12, 256.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29442/47780 [01:39<01:11, 258.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29374/47780 [01:39<01:16, 240.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29104/47780 [01:39<01:04, 288.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13939/47780 [01:39<01:44, 324.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29234/47780 [01:39<01:03, 294.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29401/47780 [01:39<01:05, 279.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29422/47780 [01:39<01:14, 247.30 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29279/47780 [01:39<01:09, 267.95 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29470/47780 [01:39<01:10, 261.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29399/47780 [01:39<01:18, 235.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29133/47780 [01:39<01:06, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13974/47780 [01:39<01:44, 324.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29264/47780 [01:39<01:03, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29453/47780 [01:39<01:09, 263.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29430/47780 [01:39<01:08, 267.14 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29308/47780 [01:39<01:08, 271.17 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29166/47780 [01:39<01:02, 295.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29497/47780 [01:39<01:14, 244.39 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14007/47780 [01:39<01:46, 315.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29424/47780 [01:39<01:20, 228.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29294/47780 [01:39<01:07, 273.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29480/47780 [01:39<01:11, 254.87 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29336/47780 [01:39<01:09, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29457/47780 [01:39<01:13, 249.03 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29522/47780 [01:39<01:15, 240.68 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14041/47780 [01:39<01:44, 322.38 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29196/47780 [01:39<01:05, 283.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29448/47780 [01:39<01:19, 229.28 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29322/47780 [01:39<01:07, 271.91 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29506/47780 [01:39<01:12, 253.70 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29367/47780 [01:39<01:06, 277.90 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29483/47780 [01:39<01:15, 241.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14075/47780 [01:39<01:43, 324.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29547/47780 [01:39<01:16, 238.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29473/47780 [01:39<01:19, 230.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29225/47780 [01:39<01:10, 264.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29352/47780 [01:39<01:06, 276.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29533/47780 [01:39<01:10, 258.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29405/47780 [01:39<01:00, 305.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29516/47780 [01:39<01:09, 262.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29573/47780 [01:39<01:14, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14115/47780 [01:39<01:38, 341.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29503/47780 [01:39<01:13, 249.41 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29560/47780 [01:40<01:10, 259.77 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29252/47780 [01:40<01:15, 245.01 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29386/47780 [01:40<01:04, 284.84 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29438/47780 [01:40<01:03, 289.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29543/47780 [01:40<01:11, 253.44 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29602/47780 [01:40<01:13, 248.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14150/47780 [01:40<01:40, 333.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29530/47780 [01:40<01:18, 233.96 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29588/47780 [01:40<01:09, 261.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29278/47780 [01:40<01:15, 246.41 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29415/47780 [01:40<01:07, 270.77 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29582/47780 [01:40<01:02, 290.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29468/47780 [01:40<01:04, 284.44 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29633/47780 [01:40<01:08, 263.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14184/47780 [01:40<01:41, 332.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29556/47780 [01:40<01:16, 238.43 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29623/47780 [01:40<01:03, 284.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29304/47780 [01:40<01:18, 236.42 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29443/47780 [01:40<01:09, 262.28 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29497/47780 [01:40<01:04, 283.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29613/47780 [01:40<01:04, 280.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14218/47780 [01:40<01:46, 314.18 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29660/47780 [01:40<01:16, 236.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29581/47780 [01:40<01:19, 228.80 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29652/47780 [01:40<01:07, 270.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29526/47780 [01:40<01:05, 278.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29470/47780 [01:40<01:14, 245.34 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29328/47780 [01:40<01:25, 214.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29644/47780 [01:40<01:04, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14258/47780 [01:40<01:42, 327.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29616/47780 [01:40<01:10, 259.13 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29686/47780 [01:40<01:17, 233.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29689/47780 [01:40<01:01, 295.00 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29559/47780 [01:40<01:03, 287.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29355/47780 [01:40<01:20, 228.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29510/47780 [01:40<01:04, 283.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29676/47780 [01:40<01:02, 290.62 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14294/47780 [01:40<01:40, 333.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29719/47780 [01:40<01:01, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29710/47780 [01:40<01:23, 215.74 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29643/47780 [01:40<01:17, 234.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29593/47780 [01:40<01:00, 302.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29539/47780 [01:40<01:04, 284.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29707/47780 [01:40<01:01, 295.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29379/47780 [01:40<01:22, 223.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14329/47780 [01:40<01:45, 317.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29749/47780 [01:40<01:01, 291.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29735/47780 [01:40<01:20, 223.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29672/47780 [01:40<01:12, 248.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29624/47780 [01:40<01:01, 294.38 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29407/47780 [01:40<01:16, 238.83 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29739/47780 [01:40<01:00, 296.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29568/47780 [01:40<01:05, 276.98 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14368/47780 [01:40<01:39, 336.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29779/47780 [01:40<01:03, 284.32 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29763/47780 [01:40<01:16, 234.83 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29698/47780 [01:40<01:13, 245.83 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29654/47780 [01:40<01:01, 293.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29596/47780 [01:40<01:06, 275.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29432/47780 [01:40<01:19, 230.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29769/47780 [01:40<01:10, 256.39 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14402/47780 [01:40<01:42, 325.96 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29814/47780 [01:40<00:59, 302.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29792/47780 [01:40<01:12, 249.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29728/47780 [01:40<01:10, 255.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29689/47780 [01:40<00:58, 309.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29468/47780 [01:40<01:09, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29624/47780 [01:40<01:10, 259.00 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29813/47780 [01:40<00:59, 304.01 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14435/47780 [01:40<01:45, 316.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29846/47780 [01:40<00:58, 304.57 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29818/47780 [01:40<01:12, 247.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29754/47780 [01:41<01:14, 240.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29503/47780 [01:41<01:03, 287.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29721/47780 [01:40<01:01, 292.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29651/47780 [01:41<01:09, 261.88 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29845/47780 [01:41<01:00, 298.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14477/47780 [01:41<01:37, 341.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29849/47780 [01:41<01:08, 261.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29878/47780 [01:41<01:01, 291.93 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29781/47780 [01:41<01:12, 248.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29764/47780 [01:41<00:55, 326.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29680/47780 [01:41<01:07, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29534/47780 [01:41<01:05, 280.64 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14512/47780 [01:41<01:39, 334.60 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29908/47780 [01:41<01:04, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29876/47780 [01:41<01:13, 244.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29807/47780 [01:41<01:12, 246.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29876/47780 [01:41<01:08, 261.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29797/47780 [01:41<00:56, 320.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29564/47780 [01:41<01:04, 282.91 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29712/47780 [01:41<01:07, 266.91 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14547/47780 [01:41<01:38, 337.19 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29943/47780 [01:41<01:00, 295.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29832/47780 [01:41<01:12, 247.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29901/47780 [01:41<01:15, 237.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29836/47780 [01:41<00:53, 332.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29593/47780 [01:41<01:04, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29744/47780 [01:41<01:04, 278.54 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29904/47780 [01:41<01:12, 245.12 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14581/47780 [01:41<01:43, 319.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29975/47780 [01:41<00:58, 302.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29865/47780 [01:41<01:06, 267.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29939/47780 [01:41<01:05, 274.15 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29623/47780 [01:41<01:04, 280.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29772/47780 [01:41<01:05, 275.89 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29938/47780 [01:41<01:06, 267.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29870/47780 [01:41<00:57, 312.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30008/47780 [01:41<00:58, 303.84 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14615/47780 [01:41<01:47, 307.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29892/47780 [01:41<01:07, 265.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29657/47780 [01:41<01:02, 291.22 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29970/47780 [01:41<01:03, 278.71 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29967/47780 [01:41<01:10, 253.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29813/47780 [01:41<00:59, 303.71 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29902/47780 [01:41<00:58, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30047/47780 [01:41<00:53, 328.45 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14646/47780 [01:41<01:50, 298.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29920/47780 [01:41<01:07, 266.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30002/47780 [01:41<01:01, 286.89 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29688/47780 [01:41<01:02, 289.90 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29848/47780 [01:41<00:57, 309.81 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29993/47780 [01:41<01:11, 247.39 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29933/47780 [01:41<01:00, 296.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30082/47780 [01:41<00:54, 323.28 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29951/47780 [01:41<01:04, 276.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14679/47780 [01:41<01:50, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30040/47780 [01:41<00:57, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29722/47780 [01:41<01:01, 294.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29967/47780 [01:41<00:57, 308.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30019/47780 [01:41<01:15, 235.22 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29879/47780 [01:41<01:01, 290.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29981/47780 [01:41<01:03, 279.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30120/47780 [01:41<00:53, 329.07 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30073/47780 [01:41<00:56, 311.54 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29752/47780 [01:41<01:02, 289.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14710/47780 [01:41<02:02, 270.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29999/47780 [01:41<00:57, 311.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30049/47780 [01:41<01:10, 249.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29910/47780 [01:41<01:02, 285.86 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30013/47780 [01:41<01:01, 290.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30164/47780 [01:41<00:48, 359.61 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14756/47780 [01:41<01:44, 316.97 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30035/47780 [01:41<00:55, 318.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29791/47780 [01:42<00:58, 307.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30075/47780 [01:41<01:10, 249.89 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30105/47780 [01:42<01:02, 281.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29940/47780 [01:42<01:02, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30201/47780 [01:42<00:51, 338.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30043/47780 [01:42<01:07, 262.81 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14789/47780 [01:42<01:43, 319.06 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30069/47780 [01:42<00:55, 321.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29823/47780 [01:42<00:59, 300.78 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30104/47780 [01:42<01:08, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30134/47780 [01:42<01:06, 266.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29970/47780 [01:42<01:06, 266.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30070/47780 [01:42<01:08, 259.64 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30236/47780 [01:42<00:54, 320.34 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30102/47780 [01:42<00:57, 306.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14823/47780 [01:42<01:48, 302.72 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30142/47780 [01:42<01:01, 286.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29855/47780 [01:42<01:02, 286.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29999/47780 [01:42<01:05, 272.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30162/47780 [01:42<01:07, 259.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30097/47780 [01:42<01:08, 256.99 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30269/47780 [01:42<00:55, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14865/47780 [01:42<01:38, 333.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30171/47780 [01:42<01:01, 285.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30134/47780 [01:42<00:59, 296.76 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29884/47780 [01:42<01:02, 284.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30189/47780 [01:42<01:07, 262.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30027/47780 [01:42<01:08, 259.12 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30127/47780 [01:42<01:07, 263.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30314/47780 [01:42<00:50, 346.65 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14900/47780 [01:42<01:39, 331.06 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30201/47780 [01:42<01:03, 278.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30169/47780 [01:42<00:57, 304.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29913/47780 [01:42<01:05, 273.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30216/47780 [01:42<01:08, 257.55 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30060/47780 [01:42<01:04, 276.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30154/47780 [01:42<01:06, 265.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30350/47780 [01:42<00:52, 334.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30200/47780 [01:42<00:58, 299.15 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30240/47780 [01:42<01:01, 287.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29941/47780 [01:42<01:07, 266.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14934/47780 [01:42<01:50, 297.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30094/47780 [01:42<01:00, 291.26 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30242/47780 [01:42<01:11, 245.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30181/47780 [01:42<01:07, 260.05 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30238/47780 [01:42<00:55, 318.70 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30384/47780 [01:42<00:55, 312.81 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29969/47780 [01:42<01:06, 268.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30274/47780 [01:42<00:58, 298.66 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14965/47780 [01:42<01:51, 294.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30127/47780 [01:42<00:59, 298.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30268/47780 [01:42<01:10, 249.17 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30208/47780 [01:42<01:09, 254.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30423/47780 [01:42<00:53, 323.27 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30271/47780 [01:42<00:58, 300.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29997/47780 [01:42<01:08, 257.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30294/47780 [01:42<01:10, 247.29 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30164/47780 [01:42<00:56, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14996/47780 [01:42<01:58, 275.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30304/47780 [01:42<01:05, 267.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30237/47780 [01:42<01:06, 264.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30461/47780 [01:42<00:51, 338.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30323/47780 [01:42<01:07, 259.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30026/47780 [01:42<01:06, 265.50 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30196/47780 [01:42<00:55, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30302/47780 [01:42<01:02, 281.68 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15028/47780 [01:42<01:54, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30332/47780 [01:42<01:04, 269.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30264/47780 [01:42<01:09, 251.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30497/47780 [01:43<00:53, 322.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30060/47780 [01:43<01:03, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30350/47780 [01:43<01:07, 256.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30228/47780 [01:43<00:57, 305.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30335/47780 [01:42<00:59, 294.45 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15074/47780 [01:43<01:39, 330.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30360/47780 [01:42<01:04, 268.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30290/47780 [01:43<01:09, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30376/47780 [01:43<01:07, 257.29 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30264/47780 [01:43<00:54, 319.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30089/47780 [01:43<01:03, 278.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30530/47780 [01:43<00:55, 312.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15109/47780 [01:43<01:38, 331.91 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30365/47780 [01:43<01:00, 286.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30389/47780 [01:43<01:06, 260.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30316/47780 [01:43<01:12, 241.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30405/47780 [01:43<01:05, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30117/47780 [01:43<01:03, 276.79 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30394/47780 [01:43<01:01, 284.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30562/47780 [01:43<01:00, 283.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30420/47780 [01:43<01:04, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30298/47780 [01:43<01:01, 285.02 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15143/47780 [01:43<01:48, 300.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30341/47780 [01:43<01:14, 234.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30436/47780 [01:43<01:02, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30145/47780 [01:43<01:05, 267.76 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30423/47780 [01:43<01:00, 285.85 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30592/47780 [01:43<01:00, 283.82 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30338/47780 [01:43<00:55, 314.53 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30456/47780 [01:43<01:00, 287.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15174/47780 [01:43<01:47, 302.76 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30365/47780 [01:43<01:20, 216.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30464/47780 [01:43<01:04, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30174/47780 [01:43<01:05, 268.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30452/47780 [01:43<01:05, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30623/47780 [01:43<00:59, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30487/47780 [01:43<00:59, 290.51 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15205/47780 [01:43<01:50, 293.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30372/47780 [01:43<00:59, 292.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30390/47780 [01:43<01:17, 225.72 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30491/47780 [01:43<01:05, 265.93 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30201/47780 [01:43<01:07, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30655/47780 [01:43<00:58, 293.07 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30479/47780 [01:43<01:07, 255.90 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30524/47780 [01:43<00:56, 306.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15237/47780 [01:43<01:51, 292.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30404/47780 [01:43<00:58, 296.72 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30415/47780 [01:43<01:14, 232.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30520/47780 [01:43<01:03, 269.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30228/47780 [01:43<01:07, 260.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30555/47780 [01:43<00:57, 300.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30505/47780 [01:43<01:07, 256.39 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30685/47780 [01:43<01:01, 276.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15278/47780 [01:43<01:40, 321.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30441/47780 [01:43<00:54, 316.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30549/47780 [01:43<01:03, 269.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30439/47780 [01:43<01:20, 215.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30255/47780 [01:43<01:09, 251.23 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30534/47780 [01:43<01:05, 263.50 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30586/47780 [01:43<00:56, 303.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30714/47780 [01:43<01:02, 274.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15311/47780 [01:43<01:42, 317.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30474/47780 [01:43<01:00, 288.20 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30577/47780 [01:43<01:03, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30463/47780 [01:43<01:19, 217.16 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30300/47780 [01:43<00:58, 297.11 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30621/47780 [01:43<00:54, 316.32 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30561/47780 [01:43<01:08, 250.58 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15343/47780 [01:43<01:42, 315.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30745/47780 [01:43<01:01, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30607/47780 [01:43<01:03, 271.92 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30504/47780 [01:43<01:02, 276.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30487/47780 [01:43<01:18, 220.78 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30591/47780 [01:43<01:05, 264.19 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30653/47780 [01:43<00:56, 302.32 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30773/47780 [01:44<01:01, 277.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30330/47780 [01:44<01:03, 272.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15378/47780 [01:44<01:45, 308.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30637/47780 [01:44<01:02, 273.62 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30535/47780 [01:44<01:01, 279.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30510/47780 [01:44<01:20, 213.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30620/47780 [01:44<01:03, 269.22 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30684/47780 [01:44<00:59, 289.14 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30358/47780 [01:44<01:04, 269.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30801/47780 [01:44<01:03, 267.08 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15409/47780 [01:44<01:48, 299.39 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30667/47780 [01:44<01:00, 281.05 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30565/47780 [01:44<01:02, 276.23 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30541/47780 [01:44<01:13, 235.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30648/47780 [01:44<01:04, 266.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30388/47780 [01:44<01:02, 277.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30715/47780 [01:44<01:01, 276.40 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15454/47780 [01:44<01:37, 332.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30828/47780 [01:44<01:08, 245.79 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30696/47780 [01:44<01:05, 262.20 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30595/47780 [01:44<01:03, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30573/47780 [01:44<01:07, 254.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30678/47780 [01:44<01:02, 272.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30419/47780 [01:44<01:01, 281.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30743/47780 [01:44<01:02, 271.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15488/47780 [01:44<01:37, 329.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30860/47780 [01:44<01:04, 262.93 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30726/47780 [01:44<01:03, 269.73 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30601/47780 [01:44<01:05, 260.38 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30630/47780 [01:44<01:00, 282.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30706/47780 [01:44<01:05, 262.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30448/47780 [01:44<01:03, 273.90 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15533/47780 [01:44<01:30, 356.47 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30772/47780 [01:44<01:03, 267.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30888/47780 [01:44<01:03, 264.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30761/47780 [01:44<00:58, 292.08 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30635/47780 [01:44<01:01, 279.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30663/47780 [01:44<00:57, 295.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30480/47780 [01:44<01:00, 283.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30733/47780 [01:44<01:08, 249.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30915/47780 [01:44<01:03, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30795/47780 [01:44<00:55, 305.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15569/47780 [01:44<01:40, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30666/47780 [01:44<00:59, 285.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30693/47780 [01:44<00:57, 296.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30799/47780 [01:44<01:13, 230.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30526/47780 [01:44<00:51, 333.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30763/47780 [01:44<01:05, 258.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30942/47780 [01:44<01:04, 261.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30830/47780 [01:44<00:53, 314.31 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15609/47780 [01:44<01:36, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30695/47780 [01:44<01:00, 284.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30832/47780 [01:44<01:06, 253.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30723/47780 [01:44<01:00, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30791/47780 [01:44<01:05, 259.93 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30971/47780 [01:44<01:02, 269.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30560/47780 [01:44<00:56, 307.09 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30863/47780 [01:44<00:54, 312.93 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15648/47780 [01:44<01:32, 346.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30724/47780 [01:44<01:01, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30859/47780 [01:44<01:07, 252.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30757/47780 [01:44<00:59, 287.60 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30818/47780 [01:44<01:05, 258.90 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31004/47780 [01:44<00:58, 286.88 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30592/47780 [01:44<00:57, 299.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15685/47780 [01:44<01:31, 352.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30896/47780 [01:44<00:54, 310.21 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30752/47780 [01:44<01:02, 272.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30885/47780 [01:44<01:07, 250.62 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31033/47780 [01:44<00:58, 285.29 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30847/47780 [01:44<01:04, 261.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30786/47780 [01:45<01:08, 247.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30623/47780 [01:45<00:59, 287.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15722/47780 [01:44<01:30, 353.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30928/47780 [01:45<00:56, 295.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30782/47780 [01:45<01:01, 274.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30911/47780 [01:45<01:10, 238.51 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31063/47780 [01:45<00:57, 288.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30881/47780 [01:45<01:00, 280.76 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30827/47780 [01:45<00:58, 288.41 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15763/47780 [01:45<01:26, 369.65 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30653/47780 [01:45<01:00, 284.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30962/47780 [01:45<00:56, 298.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30810/47780 [01:45<01:04, 263.34 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30940/47780 [01:45<01:06, 252.38 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31092/47780 [01:45<00:58, 286.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30917/47780 [01:45<00:56, 299.98 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15804/47780 [01:45<01:24, 377.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30859/47780 [01:45<00:59, 284.70 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30682/47780 [01:45<01:00, 283.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30840/47780 [01:45<01:02, 271.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30966/47780 [01:45<01:06, 251.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30993/47780 [01:45<01:00, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31125/47780 [01:45<00:55, 298.99 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30954/47780 [01:45<00:52, 319.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30899/47780 [01:45<00:54, 312.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15842/47780 [01:45<01:25, 373.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30711/47780 [01:45<01:02, 271.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30992/47780 [01:45<01:06, 253.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30868/47780 [01:45<01:06, 253.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30990/47780 [01:45<00:51, 328.08 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31022/47780 [01:45<01:03, 264.97 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31155/47780 [01:45<01:00, 276.24 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30932/47780 [01:45<00:54, 307.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15880/47780 [01:45<01:28, 358.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30744/47780 [01:45<01:00, 281.10 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31027/47780 [01:45<01:00, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30898/47780 [01:45<01:04, 263.32 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31024/47780 [01:45<00:51, 323.68 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31184/47780 [01:45<00:59, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31051/47780 [01:45<01:03, 261.76 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30966/47780 [01:45<00:55, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15918/47780 [01:45<01:30, 352.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30773/47780 [01:45<01:04, 264.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31056/47780 [01:45<00:59, 279.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30938/47780 [01:45<00:57, 291.69 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31063/47780 [01:45<00:49, 339.20 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31080/47780 [01:45<01:02, 269.22 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31212/47780 [01:45<01:01, 267.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15963/47780 [01:45<01:23, 380.24 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31092/47780 [01:45<00:56, 296.37 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30800/47780 [01:45<01:08, 249.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30972/47780 [01:45<00:55, 304.90 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31098/47780 [01:45<00:49, 337.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30998/47780 [01:45<01:04, 258.72 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31245/47780 [01:45<00:58, 283.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31108/47780 [01:45<01:03, 260.54 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16002/47780 [01:45<01:30, 350.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31122/47780 [01:45<00:57, 287.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30833/47780 [01:45<01:03, 268.64 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31003/47780 [01:45<00:55, 302.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31135/47780 [01:45<00:48, 343.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31040/47780 [01:45<00:56, 298.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31140/47780 [01:45<01:02, 268.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31274/47780 [01:45<01:00, 273.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16038/47780 [01:45<01:31, 345.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31152/47780 [01:45<00:57, 287.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30861/47780 [01:45<01:02, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31035/47780 [01:45<00:55, 301.04 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31171/47780 [01:45<00:51, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31167/47780 [01:45<01:03, 263.10 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31304/47780 [01:45<01:00, 271.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31072/47780 [01:45<01:01, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16073/47780 [01:45<01:35, 332.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30890/47780 [01:46<01:02, 271.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31181/47780 [01:45<00:59, 278.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31068/47780 [01:46<00:54, 305.82 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31200/47780 [01:46<00:58, 281.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31338/47780 [01:46<00:57, 287.04 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31204/47780 [01:46<00:54, 304.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31101/47780 [01:46<01:03, 263.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30918/47780 [01:46<01:02, 268.09 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31217/47780 [01:46<00:56, 295.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16107/47780 [01:46<01:43, 307.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31099/47780 [01:46<00:59, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31229/47780 [01:46<01:00, 274.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31367/47780 [01:46<00:58, 281.21 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31235/47780 [01:46<00:57, 289.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31133/47780 [01:46<00:59, 278.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30947/47780 [01:46<01:02, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31250/47780 [01:46<00:54, 301.62 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16142/47780 [01:46<01:39, 316.43 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31262/47780 [01:46<00:57, 287.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31406/47780 [01:46<00:53, 303.78 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31128/47780 [01:46<01:03, 261.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31265/47780 [01:46<00:57, 289.23 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31162/47780 [01:46<01:01, 271.63 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30978/47780 [01:46<01:00, 279.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31281/47780 [01:46<00:57, 287.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16175/47780 [01:46<01:40, 315.09 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31155/47780 [01:46<01:03, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31439/47780 [01:46<00:52, 309.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31291/47780 [01:46<01:01, 267.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31190/47780 [01:46<01:01, 268.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31011/47780 [01:46<00:57, 290.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31295/47780 [01:46<01:04, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31312/47780 [01:46<00:56, 293.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16208/47780 [01:46<01:39, 315.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31182/47780 [01:46<01:06, 250.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31319/47780 [01:46<01:02, 264.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31225/47780 [01:46<00:58, 285.32 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31471/47780 [01:46<00:59, 274.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31056/47780 [01:46<00:51, 325.21 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31342/47780 [01:46<00:56, 288.48 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16242/47780 [01:46<01:38, 321.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31323/47780 [01:46<01:08, 239.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31254/47780 [01:46<00:57, 286.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31346/47780 [01:46<01:03, 257.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31208/47780 [01:46<01:09, 237.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31092/47780 [01:46<00:49, 335.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31500/47780 [01:46<01:02, 262.23 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16277/47780 [01:46<01:36, 327.77 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31371/47780 [01:46<00:59, 276.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31348/47780 [01:46<01:09, 237.77 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31283/47780 [01:46<00:57, 287.51 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31232/47780 [01:46<01:09, 236.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31373/47780 [01:46<01:07, 244.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31529/47780 [01:46<01:00, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31126/47780 [01:46<00:51, 320.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31400/47780 [01:46<00:59, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31373/47780 [01:46<01:08, 240.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16310/47780 [01:46<01:43, 303.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31312/47780 [01:46<00:59, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31262/47780 [01:46<01:05, 253.70 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31404/47780 [01:46<01:05, 248.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31567/47780 [01:46<00:55, 291.08 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31159/47780 [01:46<00:54, 306.63 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31433/47780 [01:46<00:56, 287.67 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16344/47780 [01:46<01:41, 310.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31406/47780 [01:46<01:02, 262.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31343/47780 [01:46<00:57, 285.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31294/47780 [01:46<01:00, 271.73 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31430/47780 [01:46<01:04, 251.55 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31597/47780 [01:46<00:55, 293.24 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31435/47780 [01:46<01:00, 269.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31190/47780 [01:46<00:55, 297.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16379/47780 [01:46<01:39, 314.40 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31328/47780 [01:47<00:56, 289.02 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31372/47780 [01:47<00:58, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31633/47780 [01:47<00:51, 311.96 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31456/47780 [01:47<01:05, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31462/47780 [01:47<01:12, 226.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31221/47780 [01:47<00:55, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16415/47780 [01:47<01:36, 323.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31465/47780 [01:47<01:01, 266.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31364/47780 [01:47<00:53, 309.22 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31400/47780 [01:47<01:01, 264.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31482/47780 [01:47<01:06, 243.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31665/47780 [01:47<00:55, 291.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31258/47780 [01:47<00:53, 311.34 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16454/47780 [01:47<01:32, 339.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31492/47780 [01:47<01:00, 267.42 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31487/47780 [01:47<01:22, 197.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31396/47780 [01:47<00:56, 291.87 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31429/47780 [01:47<01:00, 270.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31509/47780 [01:47<01:06, 245.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31696/47780 [01:47<00:54, 296.19 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31290/47780 [01:47<00:53, 310.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31519/47780 [01:47<01:02, 259.08 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16489/47780 [01:47<01:39, 313.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31582/47780 [01:47<00:44, 365.33 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31457/47780 [01:47<01:00, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31437/47780 [01:47<00:51, 317.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31542/47780 [01:47<01:00, 268.99 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31727/47780 [01:47<00:57, 281.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31322/47780 [01:47<00:54, 302.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31550/47780 [01:47<00:59, 270.69 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16521/47780 [01:47<01:42, 305.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31486/47780 [01:47<00:59, 271.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31625/47780 [01:47<00:44, 359.73 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31470/47780 [01:47<00:52, 310.43 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31570/47780 [01:47<01:00, 266.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31356/47780 [01:47<00:53, 309.76 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31579/47780 [01:47<01:01, 264.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31756/47780 [01:47<01:00, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16563/47780 [01:47<01:33, 332.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31514/47780 [01:47<01:00, 270.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31506/47780 [01:47<00:50, 321.11 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31666/47780 [01:47<00:45, 354.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31597/47780 [01:47<01:01, 264.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31610/47780 [01:47<00:59, 273.90 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31388/47780 [01:47<00:57, 286.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16598/47780 [01:47<01:32, 337.06 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31785/47780 [01:47<01:00, 262.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31548/47780 [01:47<00:57, 281.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31539/47780 [01:47<00:53, 302.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31629/47780 [01:47<00:59, 271.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31705/47780 [01:47<00:47, 341.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31646/47780 [01:47<00:54, 298.32 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31417/47780 [01:47<00:58, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31812/47780 [01:47<01:03, 252.48 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16634/47780 [01:47<01:38, 314.89 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31577/47780 [01:47<00:58, 277.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31574/47780 [01:47<00:51, 315.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31661/47780 [01:47<00:56, 284.02 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31747/47780 [01:47<00:45, 348.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31677/47780 [01:47<00:53, 301.08 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31450/47780 [01:47<00:56, 289.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31846/47780 [01:47<01:00, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31611/47780 [01:47<00:55, 291.84 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16666/47780 [01:47<01:42, 303.56 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31606/47780 [01:47<00:52, 306.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31721/47780 [01:47<00:47, 338.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31784/47780 [01:47<00:46, 346.82 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31690/47780 [01:47<01:03, 251.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31483/47780 [01:47<00:54, 299.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31879/47780 [01:48<00:56, 281.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31653/47780 [01:48<00:49, 324.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16698/47780 [01:47<01:42, 304.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31637/47780 [01:48<00:54, 297.47 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31716/47780 [01:48<01:04, 251.00 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31755/47780 [01:48<00:50, 316.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31514/47780 [01:48<00:55, 291.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31820/47780 [01:48<00:51, 310.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31910/47780 [01:48<00:56, 280.46 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16732/47780 [01:48<01:40, 307.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31686/47780 [01:48<00:52, 306.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31667/47780 [01:48<00:54, 295.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31749/47780 [01:48<01:02, 256.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31545/47780 [01:48<00:56, 288.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31853/47780 [01:48<00:51, 309.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31939/47780 [01:48<00:55, 282.97 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31788/47780 [01:48<00:55, 290.74 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16763/47780 [01:48<01:41, 304.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31718/47780 [01:48<00:52, 308.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31697/47780 [01:48<00:54, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31775/47780 [01:48<01:02, 257.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31968/47780 [01:48<00:57, 276.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31818/47780 [01:48<00:55, 287.14 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16798/47780 [01:48<01:38, 314.39 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31885/47780 [01:48<00:54, 293.95 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31750/47780 [01:48<00:51, 311.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31574/47780 [01:48<01:02, 259.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31727/47780 [01:48<00:55, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31854/47780 [01:48<00:52, 301.24 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16830/47780 [01:48<01:38, 315.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31801/47780 [01:48<01:08, 232.36 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31996/47780 [01:48<00:58, 267.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31917/47780 [01:48<00:53, 294.47 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31783/47780 [01:48<00:52, 306.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31763/47780 [01:48<00:51, 311.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31606/47780 [01:48<00:59, 269.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31892/47780 [01:48<00:49, 321.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32026/47780 [01:48<00:58, 271.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31824/47780 [01:48<00:47, 332.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31830/47780 [01:48<01:07, 237.47 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31954/47780 [01:48<00:51, 308.16 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31795/47780 [01:48<00:51, 307.90 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16862/47780 [01:48<01:45, 293.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31634/47780 [01:48<01:01, 260.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32054/47780 [01:48<00:57, 273.47 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31989/47780 [01:48<00:49, 316.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31829/47780 [01:48<00:50, 316.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31925/47780 [01:48<00:52, 300.83 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31861/47780 [01:48<01:03, 251.31 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16903/47780 [01:48<01:34, 325.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31671/47780 [01:48<00:55, 287.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31858/47780 [01:48<00:52, 306.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32082/47780 [01:48<00:58, 269.25 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16940/47780 [01:48<01:33, 330.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31891/47780 [01:48<01:01, 256.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31963/47780 [01:48<00:50, 312.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31706/47780 [01:48<00:53, 302.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32022/47780 [01:48<00:52, 302.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31894/47780 [01:48<00:50, 317.52 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31861/47780 [01:48<00:55, 285.56 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32109/47780 [01:48<00:59, 263.13 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16980/47780 [01:48<01:28, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31740/47780 [01:48<00:51, 311.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31917/47780 [01:48<01:02, 252.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31995/47780 [01:48<00:51, 307.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31927/47780 [01:48<00:49, 320.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32053/47780 [01:48<00:54, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31900/47780 [01:48<00:50, 312.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32137/47780 [01:48<00:58, 265.20 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17016/47780 [01:48<01:27, 350.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31772/47780 [01:48<00:51, 310.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31943/47780 [01:48<01:04, 245.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32027/47780 [01:48<00:53, 291.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31960/47780 [01:49<00:52, 299.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31932/47780 [01:48<00:52, 300.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32083/47780 [01:48<00:58, 268.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17054/47780 [01:49<01:26, 354.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32164/47780 [01:49<01:02, 249.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31804/47780 [01:49<00:53, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32058/47780 [01:49<00:54, 290.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31963/47780 [01:49<00:53, 297.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31968/47780 [01:49<01:10, 224.53 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31992/47780 [01:49<00:54, 288.32 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32112/47780 [01:49<01:00, 260.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32203/47780 [01:49<00:54, 288.09 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17090/47780 [01:49<01:34, 326.09 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31841/47780 [01:49<00:51, 309.05 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31994/47780 [01:49<00:54, 287.89 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32090/47780 [01:49<00:56, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32027/47780 [01:49<00:52, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32002/47780 [01:49<01:04, 244.41 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32139/47780 [01:49<01:02, 249.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32235/47780 [01:49<00:54, 287.21 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17127/47780 [01:49<01:30, 338.00 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31873/47780 [01:49<00:51, 311.83 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32118/47780 [01:49<00:56, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32031/47780 [01:49<00:51, 307.03 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32035/47780 [01:49<00:59, 266.53 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32062/47780 [01:49<00:50, 310.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32170/47780 [01:49<00:59, 264.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31905/47780 [01:49<00:51, 310.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32265/47780 [01:49<00:56, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17162/47780 [01:49<01:37, 313.40 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32146/47780 [01:49<00:56, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32063/47780 [01:49<00:58, 266.65 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32063/47780 [01:49<00:51, 303.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32094/47780 [01:49<00:52, 296.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32201/47780 [01:49<00:56, 275.48 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31938/47780 [01:49<00:51, 309.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32294/47780 [01:49<00:56, 272.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32177/47780 [01:49<00:54, 284.30 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17203/47780 [01:49<01:31, 335.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32101/47780 [01:49<00:48, 325.33 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32091/47780 [01:49<01:01, 254.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32124/47780 [01:49<00:53, 290.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32230/47780 [01:49<00:56, 276.46 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31969/47780 [01:49<00:52, 302.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32330/47780 [01:49<00:52, 292.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32207/47780 [01:49<00:54, 285.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17238/47780 [01:49<01:34, 322.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32134/47780 [01:49<00:50, 308.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32120/47780 [01:49<00:59, 261.50 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32154/47780 [01:49<00:53, 290.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32258/47780 [01:49<00:58, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32008/47780 [01:49<00:48, 323.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32360/47780 [01:49<00:54, 282.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32236/47780 [01:49<00:54, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17272/47780 [01:49<01:34, 323.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32168/47780 [01:49<00:49, 314.31 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32162/47780 [01:49<00:51, 301.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32190/47780 [01:49<00:50, 306.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32290/47780 [01:49<00:55, 281.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32041/47780 [01:49<00:50, 314.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32392/47780 [01:49<00:53, 289.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17305/47780 [01:49<01:33, 324.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32200/47780 [01:49<00:50, 309.41 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32265/47780 [01:49<00:59, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32228/47780 [01:49<00:47, 325.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32193/47780 [01:49<00:52, 296.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32319/47780 [01:49<00:58, 264.47 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32073/47780 [01:49<00:50, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32422/47780 [01:49<00:54, 279.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32232/47780 [01:49<00:49, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32224/47780 [01:49<00:52, 298.36 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17338/47780 [01:49<01:39, 305.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32261/47780 [01:49<00:49, 315.24 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32292/47780 [01:49<01:01, 251.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32346/47780 [01:49<00:58, 263.12 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32105/47780 [01:50<00:51, 304.37 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32257/47780 [01:50<00:51, 303.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32451/47780 [01:50<00:59, 259.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32264/47780 [01:50<00:52, 293.57 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17369/47780 [01:50<01:44, 290.80 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32293/47780 [01:50<00:51, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32332/47780 [01:50<00:54, 281.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32376/47780 [01:50<00:56, 270.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32136/47780 [01:50<00:51, 302.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32289/47780 [01:50<00:51, 298.16 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32297/47780 [01:50<00:51, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17404/47780 [01:50<01:39, 306.68 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32482/47780 [01:50<00:58, 261.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32362/47780 [01:50<00:55, 280.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32404/47780 [01:50<00:56, 272.30 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32324/47780 [01:50<00:53, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32167/47780 [01:50<00:54, 285.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32319/47780 [01:50<00:51, 297.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32331/47780 [01:50<00:51, 300.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32509/47780 [01:50<00:58, 259.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17436/47780 [01:50<01:43, 294.38 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32391/47780 [01:50<00:56, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32432/47780 [01:50<00:59, 257.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32354/47780 [01:50<00:54, 283.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32201/47780 [01:50<00:51, 300.24 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32349/47780 [01:50<00:53, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17474/47780 [01:50<01:36, 314.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32362/47780 [01:50<00:52, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32396/47780 [01:50<00:47, 321.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32419/47780 [01:50<00:56, 270.29 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32536/47780 [01:50<01:01, 247.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32462/47780 [01:50<00:57, 266.25 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32234/47780 [01:50<00:50, 305.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32380/47780 [01:50<00:53, 289.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32403/47780 [01:50<00:47, 325.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32568/47780 [01:50<00:57, 264.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17506/47780 [01:50<01:40, 300.07 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32449/47780 [01:50<00:56, 269.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32489/47780 [01:50<00:58, 261.47 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32429/47780 [01:50<00:50, 303.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32265/47780 [01:50<00:52, 293.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32410/47780 [01:50<00:56, 273.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17537/47780 [01:50<01:41, 298.57 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32602/47780 [01:50<00:54, 279.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32482/47780 [01:50<00:54, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32460/47780 [01:50<00:51, 295.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32516/47780 [01:50<01:00, 252.12 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32437/47780 [01:50<00:53, 287.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32299/47780 [01:50<00:51, 299.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17568/47780 [01:50<01:41, 298.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32518/47780 [01:50<00:50, 302.25 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32633/47780 [01:50<00:55, 275.38 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32549/47780 [01:50<00:56, 271.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32438/47780 [01:50<00:59, 255.85 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32491/47780 [01:50<00:51, 299.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32467/47780 [01:50<00:54, 281.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32344/47780 [01:50<00:45, 340.69 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17598/47780 [01:50<01:42, 295.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32558/47780 [01:50<00:47, 323.20 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32471/47780 [01:50<00:55, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32661/47780 [01:50<00:55, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32522/47780 [01:50<00:52, 288.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32497/47780 [01:50<00:53, 286.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32578/47780 [01:50<01:01, 245.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32379/47780 [01:50<00:45, 335.51 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32592/47780 [01:50<00:46, 325.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32692/47780 [01:50<00:54, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17628/47780 [01:50<01:47, 280.80 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32499/47780 [01:50<00:56, 271.04 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32552/47780 [01:51<00:54, 279.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32527/47780 [01:50<00:55, 272.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32604/47780 [01:50<01:01, 248.66 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32413/47780 [01:51<00:50, 303.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32630/47780 [01:51<00:45, 332.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32528/47780 [01:51<00:55, 273.66 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17663/47780 [01:51<01:41, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32727/47780 [01:51<00:50, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32581/47780 [01:51<00:53, 282.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32558/47780 [01:51<00:53, 282.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32660/47780 [01:51<00:45, 331.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32449/47780 [01:51<00:48, 315.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32557/47780 [01:51<00:54, 277.94 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32757/47780 [01:51<00:51, 293.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17693/47780 [01:51<01:43, 291.15 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32587/47780 [01:51<00:53, 281.65 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32610/47780 [01:51<00:55, 271.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32664/47780 [01:51<00:52, 287.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32695/47780 [01:51<00:46, 321.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32482/47780 [01:51<00:49, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32592/47780 [01:51<00:51, 292.56 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17723/47780 [01:51<01:42, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32790/47780 [01:51<00:50, 297.16 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32616/47780 [01:51<00:53, 280.88 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32639/47780 [01:51<00:55, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32729/47780 [01:51<00:46, 326.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32712/47780 [01:51<00:45, 328.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32517/47780 [01:51<00:48, 316.74 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17756/47780 [01:51<01:38, 303.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32622/47780 [01:51<00:52, 291.18 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32820/47780 [01:51<00:53, 281.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32668/47780 [01:51<00:55, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32654/47780 [01:51<00:50, 302.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32763/47780 [01:51<00:46, 322.38 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32746/47780 [01:51<00:49, 304.93 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32550/47780 [01:51<00:48, 316.28 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17787/47780 [01:51<01:39, 302.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32655/47780 [01:51<00:52, 289.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32850/47780 [01:51<00:53, 280.25 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32699/47780 [01:51<00:53, 281.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32686/47780 [01:51<00:50, 300.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32796/47780 [01:51<00:48, 308.39 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32779/47780 [01:51<00:48, 308.29 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32582/47780 [01:51<00:49, 307.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17822/47780 [01:51<01:35, 312.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32687/47780 [01:51<00:52, 289.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32882/47780 [01:51<00:52, 284.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32735/47780 [01:51<00:50, 300.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32725/47780 [01:51<00:46, 322.08 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32828/47780 [01:51<00:49, 301.66 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32812/47780 [01:51<00:48, 309.47 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32618/47780 [01:51<00:47, 318.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32724/47780 [01:51<00:48, 310.62 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17854/47780 [01:51<01:41, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32917/47780 [01:51<00:49, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32767/47780 [01:51<00:50, 299.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32762/47780 [01:51<00:45, 328.38 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32859/47780 [01:51<00:50, 294.10 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32844/47780 [01:51<00:49, 300.98 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32661/47780 [01:51<00:44, 342.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32758/47780 [01:51<00:47, 315.26 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17884/47780 [01:51<01:43, 289.14 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32798/47780 [01:51<00:49, 299.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32948/47780 [01:51<00:51, 290.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32795/47780 [01:51<00:47, 318.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32892/47780 [01:51<00:49, 300.76 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32877/47780 [01:51<00:48, 305.76 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32696/47780 [01:51<00:45, 333.33 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32791/47780 [01:51<00:47, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17928/47780 [01:51<01:31, 324.62 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32832/47780 [01:51<00:48, 309.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32983/47780 [01:51<00:48, 303.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32832/47780 [01:51<00:45, 329.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32924/47780 [01:51<00:49, 299.56 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32909/47780 [01:51<00:52, 285.24 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32831/47780 [01:52<00:44, 337.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32730/47780 [01:52<00:48, 313.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33014/47780 [01:52<00:48, 304.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32865/47780 [01:52<00:48, 307.76 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32868/47780 [01:52<00:44, 337.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17961/47780 [01:52<01:40, 296.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32959/47780 [01:52<00:48, 303.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32866/47780 [01:52<00:45, 329.57 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32938/47780 [01:52<00:54, 270.75 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32903/47780 [01:52<00:46, 322.72 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32762/47780 [01:52<00:51, 293.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33046/47780 [01:52<00:50, 292.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32902/47780 [01:52<00:45, 327.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17992/47780 [01:52<01:41, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32994/47780 [01:52<00:47, 309.55 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32904/47780 [01:52<00:43, 342.50 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32792/47780 [01:52<00:51, 293.71 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32966/47780 [01:52<00:57, 259.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32945/47780 [01:52<00:41, 356.48 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32938/47780 [01:52<00:46, 315.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18028/47780 [01:52<01:36, 308.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33076/47780 [01:52<00:52, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33028/47780 [01:52<00:48, 301.14 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32943/47780 [01:52<00:42, 346.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32822/47780 [01:52<00:50, 293.73 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32994/47780 [01:52<00:56, 262.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18064/47780 [01:52<01:32, 322.40 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32983/47780 [01:52<00:42, 347.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33105/47780 [01:52<00:52, 280.83 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32970/47780 [01:52<00:48, 303.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33063/47780 [01:52<00:46, 314.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32978/47780 [01:52<00:43, 338.82 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32855/47780 [01:52<00:49, 300.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33021/47780 [01:52<00:56, 261.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18097/47780 [01:52<01:33, 317.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33021/47780 [01:52<00:41, 356.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33136/47780 [01:52<00:51, 286.23 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33001/47780 [01:52<00:51, 286.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33095/47780 [01:52<00:47, 310.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33012/47780 [01:52<00:44, 329.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32892/47780 [01:52<00:47, 313.08 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33050/47780 [01:52<00:55, 264.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18132/47780 [01:52<01:31, 323.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33168/47780 [01:52<00:49, 295.52 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33057/47780 [01:52<00:41, 351.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33030/47780 [01:52<00:53, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33128/47780 [01:52<00:46, 313.09 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33078/47780 [01:52<00:55, 264.89 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32927/47780 [01:52<00:47, 312.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33198/47780 [01:52<00:49, 296.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33046/47780 [01:52<00:50, 294.24 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33093/47780 [01:52<00:45, 322.25 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18165/47780 [01:52<01:42, 289.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33072/47780 [01:52<00:48, 306.04 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33160/47780 [01:52<00:47, 306.05 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33107/47780 [01:52<00:53, 271.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32959/47780 [01:52<00:48, 304.82 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33228/47780 [01:52<00:50, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18203/47780 [01:52<01:34, 312.79 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33128/47780 [01:52<00:46, 318.25 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33077/47780 [01:52<00:53, 275.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33103/47780 [01:52<00:48, 301.24 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33191/47780 [01:52<00:49, 293.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33139/47780 [01:52<00:51, 282.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33271/47780 [01:52<00:44, 327.98 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32991/47780 [01:52<00:49, 296.91 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18241/47780 [01:52<01:31, 324.15 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33116/47780 [01:52<00:48, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33161/47780 [01:52<00:47, 305.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33222/47780 [01:52<00:49, 295.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33134/47780 [01:53<00:53, 275.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33174/47780 [01:52<00:48, 302.02 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33310/47780 [01:53<00:42, 339.01 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33021/47780 [01:53<00:49, 296.39 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18274/47780 [01:53<01:31, 322.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33148/47780 [01:53<00:47, 306.47 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33192/47780 [01:53<00:49, 297.40 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33252/47780 [01:53<00:51, 283.14 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33175/47780 [01:53<00:47, 305.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33216/47780 [01:53<00:43, 332.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33345/47780 [01:53<00:42, 341.33 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33051/47780 [01:53<00:51, 284.59 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33181/47780 [01:53<00:47, 309.76 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18308/47780 [01:53<01:34, 313.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33288/47780 [01:53<00:48, 301.72 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33212/47780 [01:53<00:45, 319.71 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33251/47780 [01:53<00:43, 337.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33222/47780 [01:53<00:53, 270.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33385/47780 [01:53<00:40, 351.31 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33083/47780 [01:53<00:50, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33218/47780 [01:53<00:45, 323.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18348/47780 [01:53<01:28, 333.59 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33245/47780 [01:53<00:45, 316.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33285/47780 [01:53<00:44, 326.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33252/47780 [01:53<00:52, 276.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33319/47780 [01:53<00:50, 284.54 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33422/47780 [01:53<00:41, 347.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33120/47780 [01:53<00:47, 309.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33253/47780 [01:53<00:44, 327.23 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18382/47780 [01:53<01:31, 320.91 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33277/47780 [01:53<00:46, 313.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33318/47780 [01:53<00:44, 325.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33285/47780 [01:53<00:50, 284.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33348/47780 [01:53<00:51, 282.57 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33457/47780 [01:53<00:42, 337.46 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33152/47780 [01:53<00:49, 296.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33286/47780 [01:53<00:44, 324.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18418/47780 [01:53<01:29, 328.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33316/47780 [01:53<00:50, 288.60 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33377/47780 [01:53<00:52, 272.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33309/47780 [01:53<00:50, 288.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33491/47780 [01:53<00:42, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33351/47780 [01:53<00:50, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33325/47780 [01:53<00:42, 342.98 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33182/47780 [01:53<00:51, 284.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18453/47780 [01:53<01:27, 334.08 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33346/47780 [01:53<00:52, 276.23 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33344/47780 [01:53<00:47, 302.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33528/47780 [01:53<00:41, 340.84 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33406/47780 [01:53<00:54, 261.38 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33363/47780 [01:53<00:41, 349.40 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18491/47780 [01:53<01:24, 347.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33211/47780 [01:53<00:53, 273.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33382/47780 [01:53<01:00, 237.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33389/47780 [01:53<00:45, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33563/47780 [01:53<00:43, 330.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33440/47780 [01:53<00:51, 278.77 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33399/47780 [01:53<00:41, 344.85 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18527/47780 [01:53<01:25, 343.16 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33240/47780 [01:53<00:52, 275.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33375/47780 [01:53<00:54, 263.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33447/47780 [01:53<00:42, 333.74 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33421/47780 [01:53<00:45, 312.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33472/47780 [01:53<00:50, 284.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33601/47780 [01:53<00:42, 331.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18564/47780 [01:53<01:23, 350.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33280/47780 [01:53<00:46, 309.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33420/47780 [01:53<00:46, 308.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33434/47780 [01:53<00:45, 316.67 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33454/47780 [01:53<00:45, 314.38 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33508/47780 [01:53<00:46, 305.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33486/47780 [01:53<00:43, 325.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33638/47780 [01:54<00:43, 327.30 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18604/47780 [01:53<01:21, 358.22 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33453/47780 [01:54<00:45, 313.46 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33313/47780 [01:54<00:48, 298.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33467/47780 [01:54<00:47, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33487/47780 [01:54<00:44, 318.81 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33539/47780 [01:54<00:46, 303.09 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33672/47780 [01:54<00:43, 327.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33523/47780 [01:54<00:45, 315.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18640/47780 [01:54<01:23, 349.40 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33351/47780 [01:54<00:45, 314.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33498/47780 [01:54<00:47, 302.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33486/47780 [01:54<00:49, 289.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33528/47780 [01:54<00:41, 341.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33570/47780 [01:54<00:48, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33557/47780 [01:54<00:44, 316.57 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33705/47780 [01:54<00:44, 313.72 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18680/47780 [01:54<01:20, 359.76 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33384/47780 [01:54<00:46, 308.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33540/47780 [01:54<00:42, 333.26 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33523/47780 [01:54<00:46, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33564/47780 [01:54<00:41, 342.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33603/47780 [01:54<00:46, 302.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33592/47780 [01:54<00:44, 318.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33737/47780 [01:54<00:45, 308.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33575/47780 [01:54<00:43, 328.80 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18717/47780 [01:54<01:27, 331.89 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33558/47780 [01:54<00:45, 315.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33415/47780 [01:54<00:48, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33599/47780 [01:54<00:43, 326.90 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33639/47780 [01:54<00:45, 313.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33768/47780 [01:54<00:47, 292.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33625/47780 [01:54<00:47, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33610/47780 [01:54<00:42, 334.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18755/47780 [01:54<01:24, 344.88 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33591/47780 [01:54<00:45, 313.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33453/47780 [01:54<00:48, 295.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33634/47780 [01:54<00:42, 332.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33680/47780 [01:54<00:41, 338.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33665/47780 [01:54<00:43, 322.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33649/47780 [01:54<00:40, 346.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33626/47780 [01:54<00:44, 319.47 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33486/47780 [01:54<00:47, 301.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18790/47780 [01:54<01:34, 307.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33668/47780 [01:54<00:45, 309.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33798/47780 [01:54<00:58, 237.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33714/47780 [01:54<00:45, 309.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33701/47780 [01:54<00:42, 331.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33685/47780 [01:54<00:40, 350.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33659/47780 [01:54<00:45, 308.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18822/47780 [01:54<01:34, 305.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33854/47780 [01:54<00:45, 308.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33746/47780 [01:54<00:46, 299.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33735/47780 [01:54<00:42, 330.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33723/47780 [01:54<00:40, 350.84 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33700/47780 [01:54<00:51, 273.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33695/47780 [01:54<00:43, 320.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33517/47780 [01:54<01:00, 236.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18862/47780 [01:54<01:28, 327.16 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33888/47780 [01:54<00:46, 301.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33773/47780 [01:54<00:41, 337.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33777/47780 [01:54<00:48, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33760/47780 [01:54<00:40, 344.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33731/47780 [01:54<00:51, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33730/47780 [01:54<00:42, 327.68 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33567/47780 [01:54<00:47, 298.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18896/47780 [01:54<01:29, 323.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33920/47780 [01:54<00:45, 303.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33809/47780 [01:54<00:41, 340.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33809/47780 [01:54<00:47, 294.85 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33766/47780 [01:54<00:47, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33796/47780 [01:54<00:40, 343.13 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18935/47780 [01:54<01:24, 342.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33764/47780 [01:55<00:47, 296.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33601/47780 [01:55<00:52, 270.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33844/47780 [01:55<00:41, 334.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33840/47780 [01:55<00:47, 295.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33953/47780 [01:55<00:49, 277.71 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33831/47780 [01:55<00:43, 317.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33798/47780 [01:55<00:51, 274.11 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18970/47780 [01:55<01:25, 336.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33795/47780 [01:55<00:47, 294.14 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33878/47780 [01:55<00:43, 320.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33989/47780 [01:55<00:46, 298.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33829/47780 [01:55<00:49, 280.78 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33870/47780 [01:55<00:52, 265.40 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19009/47780 [01:55<01:22, 346.87 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33864/47780 [01:55<00:46, 301.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33826/47780 [01:55<00:47, 292.44 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33923/47780 [01:55<00:39, 355.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33631/47780 [01:55<01:09, 203.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34022/47780 [01:55<00:45, 300.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33915/47780 [01:55<00:45, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33858/47780 [01:55<00:50, 277.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19049/47780 [01:55<01:21, 352.35 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33898/47780 [01:55<00:45, 305.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33856/47780 [01:55<00:49, 279.17 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33670/47780 [01:55<00:58, 240.59 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33959/47780 [01:55<00:39, 350.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33887/47780 [01:55<00:51, 271.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19109/47780 [01:55<01:08, 420.31 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34053/47780 [01:55<00:48, 282.01 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33929/47780 [01:55<00:47, 293.26 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33890/47780 [01:55<00:47, 292.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33947/47780 [01:55<00:50, 273.62 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33699/47780 [01:55<00:57, 245.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33995/47780 [01:55<00:41, 329.60 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33915/47780 [01:55<00:51, 271.32 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34090/47780 [01:55<00:45, 303.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19152/47780 [01:55<01:14, 384.14 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33986/47780 [01:55<00:45, 300.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33921/47780 [01:55<00:49, 277.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33959/47780 [01:55<00:50, 271.78 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33727/47780 [01:55<00:55, 251.25 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34029/47780 [01:55<00:41, 330.78 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34122/47780 [01:55<00:47, 286.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33946/47780 [01:55<00:53, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33953/47780 [01:55<00:47, 288.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34018/47780 [01:55<00:46, 298.06 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33987/47780 [01:55<00:51, 268.39 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19192/47780 [01:55<01:21, 350.43 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33763/47780 [01:55<00:51, 270.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34063/47780 [01:55<00:44, 308.70 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33980/47780 [01:55<00:49, 280.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34152/47780 [01:55<00:49, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34022/47780 [01:55<00:47, 287.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33983/47780 [01:55<00:49, 277.81 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34049/47780 [01:55<00:49, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33792/47780 [01:55<00:50, 275.02 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19230/47780 [01:55<01:23, 340.49 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34095/47780 [01:55<00:46, 295.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34009/47780 [01:55<00:51, 265.17 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34016/47780 [01:55<00:47, 292.13 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34052/47780 [01:55<00:48, 280.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34081/47780 [01:55<00:47, 285.87 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34180/47780 [01:55<00:53, 253.92 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33821/47780 [01:55<00:50, 274.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19276/47780 [01:55<01:17, 367.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34125/47780 [01:55<00:46, 291.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34037/47780 [01:55<00:51, 266.30 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34046/47780 [01:56<00:48, 284.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34209/47780 [01:56<00:51, 263.19 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19314/47780 [01:56<01:17, 367.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33850/47780 [01:56<00:51, 268.71 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34111/47780 [01:55<00:51, 266.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34081/47780 [01:56<00:54, 253.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34155/47780 [01:56<00:48, 280.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34064/47780 [01:56<00:52, 261.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19359/47780 [01:56<01:13, 385.72 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34120/47780 [01:56<00:47, 288.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34236/47780 [01:56<00:56, 239.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34144/47780 [01:56<00:49, 272.93 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33878/47780 [01:56<00:54, 255.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34075/47780 [01:56<00:58, 234.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34188/47780 [01:56<00:46, 291.19 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34091/47780 [01:56<00:56, 242.13 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34150/47780 [01:56<00:47, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19399/47780 [01:56<01:16, 369.07 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33905/47780 [01:56<00:54, 253.74 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34261/47780 [01:56<00:58, 232.50 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34224/47780 [01:56<00:43, 310.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34172/47780 [01:56<00:54, 250.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34105/47780 [01:56<00:55, 245.01 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34116/47780 [01:56<00:57, 239.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19437/47780 [01:56<01:18, 360.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34294/47780 [01:56<00:52, 255.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34180/47780 [01:56<00:50, 270.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33931/47780 [01:56<00:58, 237.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34206/47780 [01:56<00:50, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34131/47780 [01:56<00:58, 232.20 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34257/47780 [01:56<00:47, 286.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34142/47780 [01:56<00:58, 232.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19476/47780 [01:56<01:17, 364.42 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34328/47780 [01:56<00:48, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34208/47780 [01:56<00:50, 270.44 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33956/47780 [01:56<00:58, 238.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34235/47780 [01:56<00:49, 272.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34156/47780 [01:56<00:58, 234.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34295/47780 [01:56<00:43, 308.53 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34167/47780 [01:56<00:58, 231.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34361/47780 [01:56<00:45, 292.07 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19513/47780 [01:56<01:21, 346.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33988/47780 [01:56<00:52, 260.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34236/47780 [01:56<00:54, 248.60 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34181/47780 [01:56<00:57, 235.88 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34329/47780 [01:56<00:44, 300.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34263/47780 [01:56<00:56, 239.09 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34194/47780 [01:56<00:57, 235.96 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19554/47780 [01:56<01:17, 363.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34015/47780 [01:56<00:54, 251.86 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34391/47780 [01:56<00:51, 259.41 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34262/47780 [01:56<00:57, 234.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34291/47780 [01:56<00:54, 249.38 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34206/47780 [01:56<01:02, 216.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34360/47780 [01:56<00:48, 278.64 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34219/47780 [01:56<00:58, 232.23 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19591/47780 [01:56<01:18, 357.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34052/47780 [01:56<00:48, 284.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34425/47780 [01:56<00:48, 277.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34286/47780 [01:56<00:58, 231.01 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34319/47780 [01:56<00:52, 254.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34241/47780 [01:56<00:53, 250.89 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19631/47780 [01:56<01:16, 365.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34244/47780 [01:56<00:59, 225.93 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34389/47780 [01:56<00:51, 259.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34081/47780 [01:56<00:48, 280.00 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34346/47780 [01:56<00:53, 253.43 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34310/47780 [01:57<01:00, 221.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34454/47780 [01:57<00:54, 243.50 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34267/47780 [01:57<00:55, 242.65 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19668/47780 [01:56<01:16, 366.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34269/47780 [01:57<00:58, 232.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34117/47780 [01:57<00:45, 302.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34416/47780 [01:57<00:53, 251.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34372/47780 [01:57<00:54, 247.28 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34333/47780 [01:57<01:01, 219.17 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34480/47780 [01:57<00:54, 245.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34299/47780 [01:57<00:54, 248.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19707/47780 [01:57<01:19, 353.17 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34292/47780 [01:57<01:01, 218.88 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34148/47780 [01:57<00:49, 276.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34444/47780 [01:57<00:55, 242.12 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34399/47780 [01:57<00:52, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34359/47780 [01:57<00:58, 230.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34506/47780 [01:57<00:57, 232.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19752/47780 [01:57<01:15, 371.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34325/47780 [01:57<00:55, 243.26 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34325/47780 [01:57<01:00, 221.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34470/47780 [01:57<00:54, 244.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34387/47780 [01:57<00:56, 238.78 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34425/47780 [01:57<00:54, 244.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34177/47780 [01:57<00:54, 250.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34530/47780 [01:57<00:58, 227.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34352/47780 [01:57<00:53, 249.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34355/47780 [01:57<00:55, 239.77 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34495/47780 [01:57<00:54, 244.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19790/47780 [01:57<01:22, 339.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34207/47780 [01:57<00:51, 262.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34450/47780 [01:57<00:55, 241.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34413/47780 [01:57<00:57, 234.14 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34554/47780 [01:57<01:02, 212.69 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34521/47780 [01:57<00:53, 247.28 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34380/47780 [01:57<00:56, 237.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34378/47780 [01:57<00:57, 231.71 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34477/47780 [01:57<00:53, 248.17 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34235/47780 [01:57<00:51, 261.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34440/47780 [01:57<00:54, 243.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19836/47780 [01:57<01:28, 315.63 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34576/47780 [01:57<01:01, 214.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34556/47780 [01:57<00:48, 273.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34408/47780 [01:57<00:54, 247.49 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34405/47780 [01:57<00:57, 230.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34262/47780 [01:57<00:52, 258.50 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34507/47780 [01:57<00:52, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34470/47780 [01:57<00:52, 251.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19883/47780 [01:57<01:19, 348.97 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34600/47780 [01:57<01:00, 218.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34586/47780 [01:57<00:47, 280.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34434/47780 [01:57<00:53, 248.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34432/47780 [01:57<00:56, 234.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34293/47780 [01:57<00:49, 272.58 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34498/47780 [01:57<00:51, 259.43 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34545/47780 [01:57<00:46, 286.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19920/47780 [01:57<01:19, 350.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34615/47780 [01:57<00:47, 277.17 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34624/47780 [01:57<01:01, 213.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34460/47780 [01:57<00:55, 238.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34460/47780 [01:57<00:56, 235.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34322/47780 [01:57<00:48, 277.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34525/47780 [01:57<00:50, 261.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34576/47780 [01:57<00:46, 286.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19961/47780 [01:57<01:16, 362.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34654/47780 [01:57<00:55, 235.57 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34643/47780 [01:57<00:49, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34486/47780 [01:57<00:55, 238.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34484/47780 [01:57<00:56, 236.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34351/47780 [01:57<00:49, 269.86 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34611/47780 [01:57<00:44, 298.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34552/47780 [01:57<00:53, 247.44 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19999/47780 [01:57<01:19, 348.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34673/47780 [01:57<00:48, 271.68 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34678/47780 [01:58<00:57, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34520/47780 [01:58<00:50, 264.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34515/47780 [01:58<00:52, 252.09 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34380/47780 [01:58<00:48, 275.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34641/47780 [01:58<00:45, 288.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20035/47780 [01:58<01:25, 323.46 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34705/47780 [01:58<00:55, 237.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34701/47780 [01:58<00:48, 270.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34577/47780 [01:58<01:05, 202.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34547/47780 [01:58<00:53, 248.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34542/47780 [01:58<00:54, 240.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34408/47780 [01:58<00:50, 266.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34670/47780 [01:58<00:46, 279.08 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20068/47780 [01:58<01:26, 321.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34733/47780 [01:58<00:55, 235.86 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34729/47780 [01:58<00:50, 256.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34617/47780 [01:58<00:53, 246.79 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34576/47780 [01:58<00:51, 254.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34446/47780 [01:58<00:45, 295.53 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34571/47780 [01:58<00:55, 238.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34699/47780 [01:58<00:48, 270.42 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20101/47780 [01:58<01:27, 316.81 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34761/47780 [01:58<00:47, 273.72 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34762/47780 [01:58<00:52, 248.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34645/47780 [01:58<00:52, 252.46 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34605/47780 [01:58<00:50, 261.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34477/47780 [01:58<00:45, 292.63 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34730/47780 [01:58<00:46, 278.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34595/47780 [01:58<00:59, 220.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20143/47780 [01:58<01:20, 341.73 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34794/47780 [01:58<00:44, 289.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34789/47780 [01:58<00:51, 251.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34672/47780 [01:58<00:54, 241.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34508/47780 [01:58<00:45, 294.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34632/47780 [01:58<00:53, 247.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34758/47780 [01:58<00:48, 266.37 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34623/47780 [01:58<00:58, 224.78 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20179/47780 [01:58<01:22, 335.68 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34830/47780 [01:58<00:41, 309.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34816/47780 [01:58<00:51, 253.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34698/47780 [01:58<00:53, 244.10 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34659/47780 [01:58<00:51, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34538/47780 [01:58<00:48, 271.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34785/47780 [01:58<00:52, 248.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34651/47780 [01:58<00:56, 233.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34862/47780 [01:58<00:42, 305.60 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20214/47780 [01:58<01:23, 331.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34842/47780 [01:58<00:51, 252.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34724/47780 [01:58<00:55, 233.27 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34567/47780 [01:58<00:48, 273.20 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34687/47780 [01:58<00:54, 239.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34811/47780 [01:58<00:52, 248.96 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34678/47780 [01:58<00:54, 240.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34895/47780 [01:58<00:41, 309.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20249/47780 [01:58<01:23, 329.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34868/47780 [01:58<00:51, 251.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34755/47780 [01:58<00:51, 251.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34717/47780 [01:58<00:51, 253.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34595/47780 [01:58<00:48, 269.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34837/47780 [01:58<00:51, 249.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34929/47780 [01:58<00:40, 314.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20292/47780 [01:58<01:16, 357.92 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34895/47780 [01:58<00:50, 254.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34703/47780 [01:58<00:56, 230.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34782/47780 [01:58<00:50, 256.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34623/47780 [01:58<00:48, 270.91 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34743/47780 [01:58<00:52, 249.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34864/47780 [01:58<00:52, 244.10 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34961/47780 [01:58<00:41, 305.29 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20329/47780 [01:58<01:19, 345.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34727/47780 [01:58<00:58, 223.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34921/47780 [01:59<00:55, 231.05 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34809/47780 [01:59<00:52, 248.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34651/47780 [01:59<00:50, 260.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34769/47780 [01:59<00:56, 231.89 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34891/47780 [01:59<00:51, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20364/47780 [01:59<01:19, 343.02 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34751/47780 [01:59<00:57, 226.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34992/47780 [01:59<00:44, 286.63 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34945/47780 [01:59<00:55, 231.66 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34835/47780 [01:59<00:52, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34678/47780 [01:59<00:52, 251.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34793/47780 [01:59<00:56, 231.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34917/47780 [01:59<00:52, 245.37 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20399/47780 [01:59<01:22, 333.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34775/47780 [01:59<00:57, 224.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34976/47780 [01:59<00:50, 253.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35021/47780 [01:59<00:46, 275.62 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34860/47780 [01:59<00:56, 230.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34704/47780 [01:59<00:53, 242.89 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34950/47780 [01:59<00:48, 267.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34802/47780 [01:59<00:55, 234.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20433/47780 [01:59<01:24, 324.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34817/47780 [01:59<01:04, 200.85 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35002/47780 [01:59<00:54, 236.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35049/47780 [01:59<00:48, 259.95 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34884/47780 [01:59<00:56, 227.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34730/47780 [01:59<00:53, 243.84 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34977/47780 [01:59<00:50, 255.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34831/47780 [01:59<00:52, 247.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20466/47780 [01:59<01:27, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35027/47780 [01:59<00:55, 230.13 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34838/47780 [01:59<01:07, 190.40 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34908/47780 [01:59<00:55, 230.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35076/47780 [01:59<00:53, 239.45 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34755/47780 [01:59<00:54, 238.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35003/47780 [01:59<00:50, 251.12 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20512/47780 [01:59<01:18, 349.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34856/47780 [01:59<00:59, 218.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34861/47780 [01:59<01:05, 197.71 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35051/47780 [01:59<00:57, 220.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34935/47780 [01:59<00:54, 237.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35101/47780 [01:59<00:53, 234.82 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34779/47780 [01:59<00:56, 231.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35034/47780 [01:59<00:48, 264.71 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20553/47780 [01:59<01:14, 366.32 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34895/47780 [01:59<00:50, 252.89 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34882/47780 [01:59<01:08, 189.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35132/47780 [01:59<00:50, 251.96 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34959/47780 [01:59<00:55, 229.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35074/47780 [01:59<01:03, 201.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34803/47780 [01:59<00:57, 226.29 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35061/47780 [01:59<00:49, 257.77 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20593/47780 [01:59<01:15, 359.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34927/47780 [01:59<00:47, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35160/47780 [01:59<00:49, 256.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34902/47780 [01:59<01:09, 186.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34986/47780 [01:59<00:54, 233.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35092/47780 [01:59<00:47, 269.08 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35095/47780 [01:59<01:05, 192.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34826/47780 [01:59<00:59, 217.69 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20633/47780 [01:59<01:13, 370.99 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35194/47780 [01:59<00:45, 276.52 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34957/47780 [01:59<00:50, 253.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35010/47780 [01:59<00:55, 229.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34921/47780 [01:59<01:12, 176.40 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34848/47780 [01:59<00:59, 216.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35115/47780 [01:59<01:06, 189.78 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20671/47780 [01:59<01:15, 357.13 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35120/47780 [01:59<00:53, 237.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35225/47780 [01:59<00:44, 280.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35034/47780 [02:00<00:54, 232.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34988/47780 [01:59<00:48, 263.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35008/47780 [02:00<00:36, 349.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34877/47780 [02:00<00:54, 236.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20714/47780 [02:00<01:13, 369.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35135/47780 [02:00<01:10, 179.37 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35146/47780 [02:00<00:52, 240.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35255/47780 [02:00<00:47, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35015/47780 [02:00<00:51, 248.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35058/47780 [02:00<00:59, 212.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34902/47780 [02:00<00:57, 224.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35155/47780 [02:00<01:08, 184.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20752/47780 [02:00<01:15, 360.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35046/47780 [02:00<00:40, 311.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35171/47780 [02:00<00:52, 238.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35083/47780 [02:00<00:58, 216.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35042/47780 [02:00<00:52, 244.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35282/47780 [02:00<00:50, 248.41 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34931/47780 [02:00<00:52, 242.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35174/47780 [02:00<01:08, 183.71 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20789/47780 [02:00<01:16, 351.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35196/47780 [02:00<00:52, 241.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35079/47780 [02:00<00:41, 307.08 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35067/47780 [02:00<00:51, 245.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35108/47780 [02:00<00:56, 225.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34964/47780 [02:00<00:48, 261.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35195/47780 [02:00<01:07, 187.34 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20828/47780 [02:00<01:14, 361.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35308/47780 [02:00<00:54, 229.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35222/47780 [02:00<00:53, 236.00 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35111/47780 [02:00<00:46, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35092/47780 [02:00<00:53, 238.59 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35131/47780 [02:00<00:57, 218.85 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34994/47780 [02:00<00:47, 269.51 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35217/47780 [02:00<01:03, 196.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35332/47780 [02:00<00:53, 231.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20871/47780 [02:00<01:12, 373.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35249/47780 [02:00<00:51, 244.27 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35239/47780 [02:00<01:02, 201.01 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35154/47780 [02:00<00:59, 213.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35140/47780 [02:00<00:50, 252.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35023/47780 [02:00<00:49, 259.73 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35361/47780 [02:00<00:50, 246.39 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20919/47780 [02:00<01:06, 401.21 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35117/47780 [02:00<00:58, 215.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35281/47780 [02:00<00:47, 261.10 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35260/47780 [02:00<01:01, 203.53 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35176/47780 [02:00<01:00, 207.91 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20961/47780 [02:00<01:06, 405.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35167/47780 [02:00<00:50, 249.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35391/47780 [02:00<00:48, 256.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35050/47780 [02:00<00:49, 254.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35140/47780 [02:00<00:58, 217.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35308/47780 [02:00<00:48, 257.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35282/47780 [02:00<01:00, 208.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21004/47780 [02:00<01:05, 406.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35195/47780 [02:00<00:49, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35419/47780 [02:00<00:47, 259.32 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35076/47780 [02:00<00:50, 250.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35163/47780 [02:00<00:59, 213.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35204/47780 [02:00<01:00, 209.37 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35334/47780 [02:00<00:52, 236.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35308/47780 [02:00<00:57, 215.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21057/47780 [02:00<01:01, 432.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35221/47780 [02:00<00:50, 246.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35446/47780 [02:00<00:50, 245.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35185/47780 [02:00<00:59, 210.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35226/47780 [02:00<01:00, 206.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35102/47780 [02:00<00:56, 223.81 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35359/47780 [02:00<00:56, 221.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35331/47780 [02:01<00:57, 217.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35246/47780 [02:01<00:50, 247.20 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35478/47780 [02:00<00:46, 263.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21101/47780 [02:01<01:08, 389.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35249/47780 [02:01<01:00, 205.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35207/47780 [02:01<01:01, 204.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35128/47780 [02:01<00:54, 230.24 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35383/47780 [02:01<00:54, 226.07 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35355/47780 [02:01<00:56, 218.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35272/47780 [02:01<00:52, 240.40 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35505/47780 [02:01<00:48, 253.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35238/47780 [02:01<00:54, 228.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35271/47780 [02:01<01:02, 198.62 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21141/47780 [02:01<01:12, 368.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35158/47780 [02:01<00:52, 240.01 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35407/47780 [02:01<00:54, 227.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35382/47780 [02:01<00:53, 233.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35299/47780 [02:01<00:50, 247.11 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35265/47780 [02:01<00:53, 234.64 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35292/47780 [02:01<01:01, 201.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35187/47780 [02:01<00:49, 252.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21179/47780 [02:01<01:13, 363.92 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35532/47780 [02:01<00:52, 234.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35430/47780 [02:01<00:56, 218.20 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35418/47780 [02:01<00:46, 267.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35324/47780 [02:01<00:51, 241.01 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21231/47780 [02:01<01:05, 406.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35313/47780 [02:01<01:03, 195.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35213/47780 [02:01<00:50, 248.59 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35289/47780 [02:01<00:57, 216.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35556/47780 [02:01<00:54, 224.10 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35453/47780 [02:01<00:55, 220.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35445/47780 [02:01<00:47, 261.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35349/47780 [02:01<00:55, 226.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35333/47780 [02:01<01:04, 193.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35311/47780 [02:01<00:57, 217.42 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21273/47780 [02:01<01:07, 391.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35239/47780 [02:01<00:52, 241.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35476/47780 [02:01<00:55, 221.67 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35579/47780 [02:01<00:56, 216.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35472/47780 [02:01<00:49, 247.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35374/47780 [02:01<00:53, 230.01 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35336/47780 [02:01<00:55, 222.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21313/47780 [02:01<01:08, 384.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35264/47780 [02:01<00:52, 238.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35353/47780 [02:01<01:08, 181.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35601/47780 [02:01<00:56, 217.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35499/47780 [02:01<01:01, 200.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35497/47780 [02:01<00:54, 225.44 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35398/47780 [02:01<00:57, 213.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35290/47780 [02:01<00:51, 244.00 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21353/47780 [02:01<01:09, 378.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35359/47780 [02:01<00:57, 216.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35372/47780 [02:01<01:07, 183.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35624/47780 [02:01<00:56, 216.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35525/47780 [02:01<00:56, 215.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35520/47780 [02:01<00:55, 221.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35429/47780 [02:01<00:52, 237.24 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35394/47780 [02:01<01:04, 191.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35389/47780 [02:01<00:52, 234.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35653/47780 [02:01<00:51, 234.36 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21395/47780 [02:01<01:12, 364.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35315/47780 [02:01<00:56, 218.73 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35547/47780 [02:01<01:02, 194.93 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35543/47780 [02:01<00:58, 208.40 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35418/47780 [02:01<01:00, 203.29 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35456/47780 [02:01<00:52, 233.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35413/47780 [02:01<00:53, 230.78 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21439/47780 [02:01<01:09, 377.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35340/47780 [02:01<00:55, 222.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35679/47780 [02:01<00:54, 224.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35572/47780 [02:01<00:58, 207.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35565/47780 [02:02<00:58, 209.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35451/47780 [02:02<00:52, 236.69 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21482/47780 [02:02<01:07, 391.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35480/47780 [02:02<00:56, 218.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35437/47780 [02:02<00:58, 211.66 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35366/47780 [02:02<00:55, 224.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35702/47780 [02:02<00:55, 215.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35599/47780 [02:02<00:54, 224.00 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35486/47780 [02:02<00:47, 260.40 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35588/47780 [02:02<01:02, 193.82 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21522/47780 [02:02<01:09, 376.53 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35398/47780 [02:02<00:49, 249.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35459/47780 [02:02<00:59, 207.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35503/47780 [02:02<01:00, 204.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35627/47780 [02:02<00:50, 239.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35724/47780 [02:02<01:00, 198.03 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35610/47780 [02:02<01:01, 199.42 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21560/47780 [02:02<01:10, 370.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35513/47780 [02:02<00:50, 242.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35524/47780 [02:02<00:59, 205.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35653/47780 [02:02<00:49, 242.55 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35480/47780 [02:02<01:06, 184.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35745/47780 [02:02<01:02, 192.60 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35424/47780 [02:02<00:58, 211.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35539/47780 [02:02<00:50, 243.01 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21601/47780 [02:02<01:09, 376.63 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35631/47780 [02:02<01:02, 192.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35547/47780 [02:02<00:58, 210.01 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35679/47780 [02:02<00:52, 231.33 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35506/47780 [02:02<01:00, 203.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35765/47780 [02:02<01:04, 187.38 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35449/47780 [02:02<00:56, 216.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35568/47780 [02:02<00:47, 255.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35655/47780 [02:02<01:00, 201.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35570/47780 [02:02<00:56, 215.36 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21639/47780 [02:02<01:19, 329.44 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35706/47780 [02:02<00:50, 237.20 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35531/47780 [02:02<00:57, 213.42 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35787/47780 [02:02<01:02, 191.63 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35472/47780 [02:02<00:57, 213.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35676/47780 [02:02<01:00, 201.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35594/47780 [02:02<00:50, 241.68 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35593/47780 [02:02<00:58, 207.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35730/47780 [02:02<00:52, 227.83 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21673/47780 [02:02<01:23, 312.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35553/47780 [02:02<01:00, 202.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35813/47780 [02:02<00:59, 201.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35495/47780 [02:02<00:58, 211.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35697/47780 [02:02<00:59, 201.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35627/47780 [02:02<00:46, 261.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35615/47780 [02:02<00:58, 206.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35754/47780 [02:02<00:52, 228.47 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21715/47780 [02:02<01:17, 336.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35578/47780 [02:02<00:58, 210.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35842/47780 [02:02<00:52, 225.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35523/47780 [02:02<00:55, 220.13 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35718/47780 [02:02<01:01, 194.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35658/47780 [02:02<00:44, 269.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35638/47780 [02:02<00:56, 213.15 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21750/47780 [02:02<01:18, 333.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35778/47780 [02:02<00:54, 219.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35601/47780 [02:02<00:57, 211.31 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35865/47780 [02:02<00:54, 219.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35550/47780 [02:02<00:53, 228.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35739/47780 [02:02<01:03, 190.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35661/47780 [02:02<00:56, 215.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21786/47780 [02:02<01:17, 336.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35687/47780 [02:02<00:51, 235.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35804/47780 [02:02<00:52, 227.18 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35625/47780 [02:02<00:59, 203.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35888/47780 [02:02<00:56, 210.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35576/47780 [02:03<00:52, 232.17 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35771/47780 [02:03<00:54, 221.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35688/47780 [02:03<00:54, 223.44 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21821/47780 [02:03<01:16, 340.33 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35728/47780 [02:03<00:44, 271.84 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35833/47780 [02:03<00:49, 240.40 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35646/47780 [02:03<00:59, 205.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35912/47780 [02:03<00:54, 216.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35600/47780 [02:03<00:54, 224.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35797/47780 [02:03<00:51, 232.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35713/47780 [02:03<00:52, 230.81 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21863/47780 [02:03<01:11, 362.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35757/47780 [02:03<00:44, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35667/47780 [02:03<00:59, 204.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35934/47780 [02:03<00:55, 214.65 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35858/47780 [02:03<00:54, 218.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35623/47780 [02:03<00:53, 225.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35737/47780 [02:03<00:53, 224.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21900/47780 [02:03<01:14, 349.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35821/47780 [02:03<00:59, 200.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35956/47780 [02:03<00:56, 209.30 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35689/47780 [02:03<01:00, 199.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35785/47780 [02:03<00:47, 252.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35884/47780 [02:03<00:52, 227.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35648/47780 [02:03<00:53, 227.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21936/47780 [02:03<01:15, 344.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35847/47780 [02:03<00:55, 213.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35760/47780 [02:03<00:59, 200.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35715/47780 [02:03<00:56, 214.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35978/47780 [02:03<00:56, 209.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35813/47780 [02:03<00:46, 256.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35671/47780 [02:03<00:53, 225.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35908/47780 [02:03<00:55, 215.81 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21976/47780 [02:03<01:11, 360.18 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35787/47780 [02:03<00:54, 218.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35874/47780 [02:03<00:53, 223.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36003/47780 [02:03<00:54, 216.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35846/47780 [02:03<00:44, 270.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35737/47780 [02:03<00:58, 206.52 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35695/47780 [02:03<00:54, 221.76 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35930/47780 [02:03<01:00, 196.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22014/47780 [02:03<01:11, 362.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35810/47780 [02:03<00:54, 219.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35900/47780 [02:03<00:51, 228.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35762/47780 [02:03<00:55, 218.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36033/47780 [02:03<00:51, 229.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35718/47780 [02:03<00:53, 223.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35874/47780 [02:03<00:45, 261.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35957/47780 [02:03<00:55, 213.21 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22052/47780 [02:03<01:10, 362.63 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35834/47780 [02:03<00:53, 222.30 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35928/47780 [02:03<00:48, 242.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35789/47780 [02:03<00:51, 230.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35902/47780 [02:03<00:45, 263.76 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36062/47780 [02:03<00:48, 239.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35741/47780 [02:03<00:58, 205.16 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35866/47780 [02:03<00:47, 249.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35955/47780 [02:03<00:47, 250.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35979/47780 [02:03<00:57, 205.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22089/47780 [02:03<01:14, 345.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35813/47780 [02:03<00:53, 223.17 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35929/47780 [02:03<00:46, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36086/47780 [02:03<00:51, 226.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35763/47780 [02:03<00:58, 206.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35893/47780 [02:03<00:46, 255.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36000/47780 [02:03<00:57, 205.19 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35981/47780 [02:03<00:48, 244.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22124/47780 [02:03<01:15, 337.82 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35836/47780 [02:03<00:54, 219.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35955/47780 [02:03<00:46, 252.33 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36115/47780 [02:03<00:47, 243.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35923/47780 [02:04<00:44, 265.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35784/47780 [02:04<01:03, 188.92 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36021/47780 [02:03<00:58, 201.88 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36006/47780 [02:04<00:48, 240.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22158/47780 [02:04<01:20, 317.42 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35981/47780 [02:04<00:46, 252.63 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35863/47780 [02:04<00:52, 226.50 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36142/47780 [02:04<00:47, 245.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35950/47780 [02:04<00:44, 265.39 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35809/47780 [02:04<00:58, 204.03 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36042/47780 [02:04<00:58, 201.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36031/47780 [02:04<00:52, 225.42 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22191/47780 [02:04<01:23, 307.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36167/47780 [02:04<00:47, 243.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35886/47780 [02:04<00:54, 217.77 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36007/47780 [02:04<00:48, 242.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35979/47780 [02:04<00:44, 264.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35830/47780 [02:04<00:59, 200.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36063/47780 [02:04<01:01, 191.31 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22222/47780 [02:04<01:23, 304.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36059/47780 [02:04<00:50, 232.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36192/47780 [02:04<00:47, 244.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35909/47780 [02:04<00:53, 220.32 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36040/47780 [02:04<00:44, 261.31 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36006/47780 [02:04<00:45, 257.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35858/47780 [02:04<00:55, 215.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36085/47780 [02:04<00:59, 198.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36219/47780 [02:04<00:46, 247.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36083/47780 [02:04<00:54, 215.98 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22253/47780 [02:04<01:31, 278.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36067/47780 [02:04<00:45, 257.92 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35933/47780 [02:04<00:58, 203.63 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35880/47780 [02:04<00:56, 211.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36106/47780 [02:04<00:58, 198.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36032/47780 [02:04<00:50, 233.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36244/47780 [02:04<00:46, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36108/47780 [02:04<00:51, 224.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22282/47780 [02:04<01:32, 275.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36094/47780 [02:04<00:46, 252.59 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35963/47780 [02:04<00:53, 219.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35902/47780 [02:04<00:55, 213.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36126/47780 [02:04<00:59, 196.16 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36057/47780 [02:04<00:50, 233.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22314/47780 [02:04<01:29, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36131/47780 [02:04<00:55, 210.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36269/47780 [02:04<00:51, 225.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35986/47780 [02:04<00:54, 216.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35924/47780 [02:04<00:57, 206.43 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36148/47780 [02:04<00:59, 194.58 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36122/47780 [02:04<00:52, 223.10 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22347/47780 [02:04<01:25, 297.25 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36081/47780 [02:04<00:55, 211.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36154/47780 [02:04<00:55, 210.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36292/47780 [02:04<00:52, 217.00 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36009/47780 [02:04<00:53, 219.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36169/47780 [02:04<00:58, 197.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36145/47780 [02:04<00:51, 224.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35945/47780 [02:04<01:03, 185.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22378/47780 [02:04<01:25, 297.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36103/47780 [02:04<00:55, 211.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36176/47780 [02:04<00:55, 208.85 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36322/47780 [02:04<00:49, 231.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36032/47780 [02:04<00:55, 212.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36192/47780 [02:04<00:56, 205.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36180/47780 [02:04<00:45, 254.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35964/47780 [02:04<01:05, 180.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22410/47780 [02:04<01:24, 300.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36125/47780 [02:04<00:57, 201.07 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36205/47780 [02:04<00:50, 229.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36346/47780 [02:04<00:49, 231.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36055/47780 [02:04<00:54, 215.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36217/47780 [02:04<00:52, 218.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36210/47780 [02:05<00:45, 256.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35987/47780 [02:05<01:01, 191.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36149/47780 [02:05<00:55, 209.92 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22442/47780 [02:05<01:28, 286.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36229/47780 [02:05<00:52, 221.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36371/47780 [02:05<00:50, 226.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36081/47780 [02:05<00:51, 227.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36241/47780 [02:05<00:52, 219.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36242/47780 [02:05<00:42, 268.40 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36007/47780 [02:05<01:00, 193.34 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36184/47780 [02:05<00:47, 244.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22480/47780 [02:05<01:22, 305.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36252/47780 [02:05<00:52, 219.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36396/47780 [02:05<00:49, 230.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36104/47780 [02:05<00:53, 216.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36270/47780 [02:05<00:42, 271.56 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36267/47780 [02:05<00:52, 217.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36040/47780 [02:05<00:51, 229.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36211/47780 [02:05<00:45, 251.59 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22511/47780 [02:05<01:24, 299.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36277/47780 [02:05<00:51, 222.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36126/47780 [02:05<00:54, 212.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36420/47780 [02:05<00:52, 215.65 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36294/47780 [02:05<00:50, 228.36 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36298/47780 [02:05<00:43, 264.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36066/47780 [02:05<00:50, 230.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36237/47780 [02:05<00:47, 245.57 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22547/47780 [02:05<01:20, 313.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36301/47780 [02:05<00:50, 227.28 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36155/47780 [02:05<00:50, 229.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36445/47780 [02:05<00:51, 218.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36321/47780 [02:05<00:48, 234.83 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36094/47780 [02:05<00:48, 238.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36325/47780 [02:05<00:48, 237.11 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22582/47780 [02:05<01:19, 316.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36262/47780 [02:05<00:48, 238.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36324/47780 [02:05<00:50, 227.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36183/47780 [02:05<00:48, 240.74 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36345/47780 [02:05<00:50, 226.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36468/47780 [02:05<00:53, 212.39 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36119/47780 [02:05<00:48, 239.39 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36351/47780 [02:05<00:48, 238.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22622/47780 [02:05<01:14, 339.11 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36293/47780 [02:05<00:45, 253.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36349/47780 [02:05<00:50, 226.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36209/47780 [02:05<00:48, 240.76 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36368/47780 [02:05<00:50, 226.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36493/47780 [02:05<00:51, 220.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36144/47780 [02:05<00:49, 235.93 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36383/47780 [02:05<00:44, 257.39 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22657/47780 [02:05<01:14, 339.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36327/47780 [02:05<00:42, 268.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36372/47780 [02:05<00:51, 222.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36234/47780 [02:05<00:49, 234.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36523/47780 [02:05<00:46, 239.76 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36391/47780 [02:05<00:51, 222.59 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36174/47780 [02:05<00:45, 253.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22692/47780 [02:05<01:13, 342.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36410/47780 [02:05<00:45, 249.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36354/47780 [02:05<00:43, 260.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36395/47780 [02:05<00:51, 219.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36549/47780 [02:05<00:46, 241.27 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36258/47780 [02:05<00:53, 215.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36200/47780 [02:05<00:48, 240.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22727/47780 [02:05<01:14, 337.11 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36414/47780 [02:05<00:56, 202.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36440/47780 [02:05<00:43, 263.53 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36381/47780 [02:05<00:43, 260.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36420/47780 [02:05<00:50, 223.49 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36574/47780 [02:05<00:48, 232.65 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36289/47780 [02:05<00:47, 240.24 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22763/47780 [02:05<01:12, 343.53 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36469/47780 [02:06<00:42, 268.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36438/47780 [02:05<00:54, 207.78 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36412/47780 [02:06<00:41, 271.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36226/47780 [02:06<00:51, 225.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36443/47780 [02:06<00:54, 206.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36470/47780 [02:06<00:47, 235.78 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22798/47780 [02:06<01:14, 333.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36314/47780 [02:06<00:50, 226.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36598/47780 [02:06<00:53, 208.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36440/47780 [02:06<00:42, 267.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36251/47780 [02:06<00:50, 229.63 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36497/47780 [02:06<00:44, 251.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36465/47780 [02:06<00:54, 205.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22832/47780 [02:06<01:15, 331.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36338/47780 [02:06<00:52, 217.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36478/47780 [02:06<00:38, 296.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36523/47780 [02:06<00:45, 246.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36620/47780 [02:06<00:55, 200.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36280/47780 [02:06<00:48, 238.57 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36495/47780 [02:06<00:53, 209.28 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36486/47780 [02:06<00:55, 202.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22866/47780 [02:06<01:15, 330.53 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36512/47780 [02:06<00:36, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36361/47780 [02:06<00:52, 216.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36641/47780 [02:06<00:56, 196.46 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36549/47780 [02:06<00:47, 236.92 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36525/47780 [02:06<00:48, 230.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36305/47780 [02:06<00:50, 227.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36522/47780 [02:06<00:46, 243.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22900/47780 [02:06<01:18, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36544/47780 [02:06<00:38, 292.02 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36576/47780 [02:06<00:45, 245.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36661/47780 [02:06<00:57, 193.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36329/47780 [02:06<00:50, 225.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36547/47780 [02:06<00:45, 244.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36383/47780 [02:06<00:58, 195.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36550/47780 [02:06<00:53, 210.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22932/47780 [02:06<01:18, 318.29 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36582/47780 [02:06<00:35, 312.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36681/47780 [02:06<00:57, 193.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36356/47780 [02:06<00:48, 237.39 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36576/47780 [02:06<00:43, 255.33 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36407/47780 [02:06<00:55, 205.40 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36601/47780 [02:06<00:48, 231.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36573/47780 [02:06<00:52, 213.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22971/47780 [02:06<01:13, 338.68 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36701/47780 [02:06<00:57, 193.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36428/47780 [02:06<00:54, 206.60 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36380/47780 [02:06<00:49, 230.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36616/47780 [02:06<00:37, 297.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36626/47780 [02:06<00:48, 231.03 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36603/47780 [02:06<00:45, 245.19 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36595/47780 [02:06<00:54, 204.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23006/47780 [02:06<01:13, 338.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36726/47780 [02:06<00:53, 204.74 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36450/47780 [02:06<00:54, 207.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36404/47780 [02:06<00:51, 220.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36647/47780 [02:06<00:40, 273.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36617/47780 [02:06<00:53, 208.48 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36650/47780 [02:06<00:52, 212.50 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23051/47780 [02:06<01:06, 370.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36628/47780 [02:06<00:50, 222.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36755/47780 [02:06<00:48, 226.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36474/47780 [02:06<00:52, 214.61 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36429/47780 [02:06<00:51, 221.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36639/47780 [02:06<00:54, 205.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36672/47780 [02:06<00:54, 203.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36675/47780 [02:06<00:43, 256.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36652/47780 [02:06<00:51, 216.37 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23089/47780 [02:06<01:10, 349.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36496/47780 [02:06<00:53, 209.10 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36779/47780 [02:06<00:52, 210.11 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36452/47780 [02:07<00:52, 214.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36664/47780 [02:06<00:51, 215.02 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36702/47780 [02:07<00:43, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36694/47780 [02:07<00:54, 203.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36680/47780 [02:07<00:48, 229.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23125/47780 [02:07<01:14, 332.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36524/47780 [02:07<00:49, 226.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36801/47780 [02:07<00:53, 204.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36692/47780 [02:07<00:47, 233.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36475/47780 [02:07<00:54, 209.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36729/47780 [02:07<00:42, 260.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36706/47780 [02:07<00:46, 237.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36715/47780 [02:07<00:56, 197.22 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23177/47780 [02:07<01:05, 377.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36547/47780 [02:07<00:50, 222.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36822/47780 [02:07<00:55, 197.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36500/47780 [02:07<00:53, 211.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36756/47780 [02:07<00:43, 252.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36735/47780 [02:07<00:56, 194.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36731/47780 [02:07<00:48, 227.17 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23220/47780 [02:07<01:04, 383.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36716/47780 [02:07<00:54, 204.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36570/47780 [02:07<00:51, 219.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36845/47780 [02:07<00:53, 204.44 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36523/47780 [02:07<00:53, 211.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36755/47780 [02:07<00:58, 188.87 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36755/47780 [02:07<00:49, 221.87 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23261/47780 [02:07<01:04, 378.17 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36738/47780 [02:07<00:54, 202.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36782/47780 [02:07<00:49, 222.64 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36593/47780 [02:07<00:51, 217.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36866/47780 [02:07<00:52, 205.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36545/47780 [02:07<00:55, 200.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36778/47780 [02:07<00:50, 217.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36766/47780 [02:07<00:49, 220.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23300/47780 [02:07<01:08, 357.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36778/47780 [02:07<01:00, 181.99 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36622/47780 [02:07<00:46, 237.94 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36805/47780 [02:07<00:51, 212.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36891/47780 [02:07<00:51, 210.98 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36571/47780 [02:07<00:52, 214.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36800/47780 [02:07<00:51, 213.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36651/47780 [02:07<00:44, 252.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36789/47780 [02:07<00:51, 211.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23337/47780 [02:07<01:10, 345.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36797/47780 [02:07<01:02, 176.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36919/47780 [02:07<00:47, 227.89 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36827/47780 [02:07<00:57, 191.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36597/47780 [02:07<00:49, 226.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36822/47780 [02:07<00:52, 210.64 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36678/47780 [02:07<00:43, 254.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36811/47780 [02:07<00:52, 209.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23373/47780 [02:07<01:10, 344.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36944/47780 [02:07<00:46, 231.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36815/47780 [02:07<01:05, 167.00 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36855/47780 [02:07<00:52, 209.72 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36624/47780 [02:07<00:48, 231.40 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36844/47780 [02:07<00:52, 208.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36712/47780 [02:07<00:40, 270.87 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23408/47780 [02:07<01:14, 329.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36976/47780 [02:07<00:42, 256.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36833/47780 [02:07<00:56, 195.19 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36832/47780 [02:07<01:08, 159.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36878/47780 [02:07<00:53, 202.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36648/47780 [02:07<00:49, 223.71 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36868/47780 [02:07<00:51, 213.59 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36741/47780 [02:07<00:40, 270.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23443/47780 [02:07<01:13, 331.41 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37011/47780 [02:07<00:38, 277.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36853/47780 [02:07<00:57, 188.49 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36850/47780 [02:08<01:08, 159.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36903/47780 [02:08<00:52, 208.08 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36891/47780 [02:08<00:50, 217.28 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36769/47780 [02:08<00:40, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36671/47780 [02:08<00:53, 207.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23479/47780 [02:08<01:11, 339.37 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37039/47780 [02:08<00:39, 271.25 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36874/47780 [02:08<00:57, 190.16 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36870/47780 [02:08<01:04, 170.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36927/47780 [02:08<00:50, 212.97 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36918/47780 [02:08<00:49, 219.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36797/47780 [02:08<00:41, 266.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36692/47780 [02:08<00:54, 203.53 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23527/47780 [02:08<01:06, 366.85 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36895/47780 [02:08<00:56, 193.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36897/47780 [02:08<00:56, 193.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37067/47780 [02:08<00:45, 236.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36949/47780 [02:08<00:53, 203.04 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36950/47780 [02:08<00:44, 242.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36828/47780 [02:08<00:41, 266.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23564/47780 [02:08<01:08, 351.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36919/47780 [02:08<00:52, 206.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36713/47780 [02:08<00:58, 188.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36917/47780 [02:08<00:56, 193.19 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36971/47780 [02:08<00:52, 205.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37092/47780 [02:08<00:47, 223.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36981/47780 [02:08<00:42, 255.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36863/47780 [02:08<00:38, 287.01 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23611/47780 [02:08<01:02, 384.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36944/47780 [02:08<00:52, 205.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36943/47780 [02:08<00:55, 195.95 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36733/47780 [02:08<01:03, 175.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36993/47780 [02:08<00:51, 209.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37115/47780 [02:08<00:49, 214.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37007/47780 [02:08<00:43, 245.38 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36893/47780 [02:08<00:40, 266.52 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23650/47780 [02:08<01:07, 359.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36967/47780 [02:08<00:50, 212.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36967/47780 [02:08<00:52, 205.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36751/47780 [02:08<01:03, 172.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37023/47780 [02:08<00:45, 234.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37142/47780 [02:08<00:46, 228.74 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37032/47780 [02:08<00:47, 227.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36920/47780 [02:08<00:41, 259.10 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36989/47780 [02:08<00:50, 212.35 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23688/47780 [02:08<01:08, 351.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36989/47780 [02:08<00:51, 209.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36771/47780 [02:08<01:02, 176.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37047/47780 [02:08<00:45, 236.04 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37176/47780 [02:08<00:42, 250.74 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36953/47780 [02:08<00:38, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37060/47780 [02:08<00:44, 238.34 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23724/47780 [02:08<01:08, 350.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36793/47780 [02:08<00:58, 187.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37011/47780 [02:08<00:52, 203.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37011/47780 [02:08<00:54, 196.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37072/47780 [02:08<00:46, 229.76 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37202/47780 [02:08<00:42, 247.89 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36986/47780 [02:08<00:36, 292.70 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37085/47780 [02:08<00:45, 237.31 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23761/47780 [02:08<01:08, 351.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36812/47780 [02:08<00:58, 186.71 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37032/47780 [02:08<00:55, 193.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37031/47780 [02:08<00:58, 185.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37235/47780 [02:08<00:39, 267.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37097/47780 [02:08<00:49, 215.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37109/47780 [02:08<00:46, 229.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37016/47780 [02:08<00:39, 275.94 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23797/47780 [02:08<01:10, 341.98 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36831/47780 [02:08<00:59, 182.65 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37053/47780 [02:08<00:56, 190.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37050/47780 [02:09<00:58, 184.14 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37128/47780 [02:09<00:44, 237.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37263/47780 [02:08<00:39, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37133/47780 [02:09<00:46, 229.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23839/47780 [02:09<01:06, 360.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37045/47780 [02:09<00:41, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37069/47780 [02:09<00:58, 182.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37073/47780 [02:09<00:56, 188.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36850/47780 [02:09<01:06, 163.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37154/47780 [02:09<00:44, 238.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37292/47780 [02:09<00:40, 260.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37164/47780 [02:09<00:43, 244.02 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23879/47780 [02:09<01:05, 367.44 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37072/47780 [02:09<00:41, 257.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37088/47780 [02:09<00:59, 180.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37097/47780 [02:09<00:54, 196.65 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36875/47780 [02:09<01:00, 180.46 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37325/47780 [02:09<00:37, 277.30 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37187/47780 [02:09<00:41, 256.96 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37190/47780 [02:09<00:44, 240.47 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23916/47780 [02:09<01:08, 348.01 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37100/47780 [02:09<00:40, 263.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37107/47780 [02:09<00:59, 178.77 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37117/47780 [02:09<00:56, 189.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36898/47780 [02:09<00:56, 191.63 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37353/47780 [02:09<00:37, 274.85 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37214/47780 [02:09<00:43, 241.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37218/47780 [02:09<00:42, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37129/47780 [02:09<00:39, 268.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23953/47780 [02:09<01:08, 350.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37129/47780 [02:09<00:57, 186.45 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36922/47780 [02:09<00:53, 202.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37136/47780 [02:09<00:59, 177.65 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37381/47780 [02:09<00:39, 264.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37239/47780 [02:09<00:44, 234.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37158/47780 [02:09<00:38, 274.62 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37248/47780 [02:09<00:41, 251.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23989/47780 [02:09<01:10, 337.00 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36946/47780 [02:09<00:51, 210.97 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37162/47780 [02:09<00:48, 219.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37156/47780 [02:09<00:59, 179.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37413/47780 [02:09<00:37, 276.59 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37263/47780 [02:09<00:45, 230.14 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37186/47780 [02:09<00:39, 267.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37281/47780 [02:09<00:39, 267.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24027/47780 [02:09<01:11, 331.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36972/47780 [02:09<00:48, 224.81 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37186/47780 [02:09<00:47, 224.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37177/47780 [02:09<00:58, 182.61 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37289/47780 [02:09<00:44, 235.99 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37441/47780 [02:09<00:41, 246.76 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37318/47780 [02:09<00:36, 285.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37214/47780 [02:09<00:40, 258.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24061/47780 [02:09<01:11, 333.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36996/47780 [02:09<00:47, 226.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37211/47780 [02:09<00:46, 227.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37196/47780 [02:09<00:59, 176.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37314/47780 [02:09<00:43, 239.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37472/47780 [02:09<00:39, 260.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37242/47780 [02:09<00:39, 263.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37347/47780 [02:09<00:36, 282.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24102/47780 [02:09<01:06, 355.15 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37023/47780 [02:09<00:46, 231.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37235/47780 [02:09<00:48, 218.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37217/47780 [02:09<00:58, 181.63 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37339/47780 [02:09<00:45, 227.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37376/47780 [02:09<00:36, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37271/47780 [02:09<00:39, 268.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24152/47780 [02:09<01:00, 392.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37499/47780 [02:09<00:42, 242.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37047/47780 [02:09<00:46, 228.47 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37259/47780 [02:09<00:47, 219.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37242/47780 [02:09<00:53, 198.33 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37369/47780 [02:10<00:42, 244.66 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37299/47780 [02:10<00:38, 268.83 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37413/47780 [02:10<00:34, 300.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24193/47780 [02:10<01:00, 392.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37529/47780 [02:10<00:39, 257.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37070/47780 [02:10<00:46, 228.89 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37282/47780 [02:10<00:51, 202.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37265/47780 [02:10<00:52, 200.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37397/47780 [02:10<00:41, 251.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37326/47780 [02:10<00:39, 263.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24233/47780 [02:10<01:01, 385.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37444/47780 [02:10<00:35, 291.00 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37096/47780 [02:10<00:44, 237.78 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37557/47780 [02:10<00:41, 244.03 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37295/47780 [02:10<00:47, 220.85 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37308/47780 [02:10<00:50, 206.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37432/47780 [02:10<00:37, 276.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24274/47780 [02:10<01:00, 388.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37475/47780 [02:10<00:35, 293.06 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37353/47780 [02:10<00:41, 249.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37588/47780 [02:10<00:40, 254.06 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37120/47780 [02:10<00:49, 215.80 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37320/47780 [02:10<00:46, 224.02 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37331/47780 [02:10<00:50, 208.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37461/47780 [02:10<00:38, 271.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24313/47780 [02:10<01:00, 388.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37505/47780 [02:10<00:36, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37379/47780 [02:10<00:42, 243.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37624/47780 [02:10<00:36, 279.74 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37142/47780 [02:10<00:50, 212.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37355/47780 [02:10<00:40, 256.52 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37353/47780 [02:10<00:49, 211.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37496/47780 [02:10<00:35, 292.68 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37535/47780 [02:10<00:35, 286.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37408/47780 [02:10<00:40, 253.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24353/47780 [02:10<01:06, 351.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37655/47780 [02:10<00:35, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37164/47780 [02:10<00:51, 207.55 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37384/47780 [02:10<00:39, 260.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37376/47780 [02:10<00:49, 209.70 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37526/47780 [02:10<00:37, 273.37 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37437/47780 [02:10<00:39, 262.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37564/47780 [02:10<00:37, 274.81 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37693/47780 [02:10<00:32, 307.37 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24389/47780 [02:10<01:12, 321.70 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37196/47780 [02:10<00:45, 233.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37412/47780 [02:10<00:39, 265.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37402/47780 [02:10<00:47, 218.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37464/47780 [02:10<00:39, 262.52 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37594/47780 [02:10<00:36, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37220/47780 [02:10<00:45, 230.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37427/47780 [02:10<00:45, 227.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37554/47780 [02:10<00:46, 218.24 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24422/47780 [02:10<01:20, 290.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37725/47780 [02:10<00:39, 256.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37439/47780 [02:10<00:42, 244.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37623/47780 [02:10<00:36, 278.76 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37491/47780 [02:10<00:43, 237.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37244/47780 [02:10<00:46, 227.70 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37451/47780 [02:10<00:45, 225.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37591/47780 [02:10<00:40, 253.48 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37770/47780 [02:10<00:33, 302.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24465/47780 [02:10<01:12, 319.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37465/47780 [02:10<00:43, 239.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37651/47780 [02:10<00:38, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37517/47780 [02:10<00:42, 242.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37274/47780 [02:10<00:42, 245.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37474/47780 [02:10<00:46, 221.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24499/47780 [02:10<01:13, 318.30 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37619/47780 [02:11<00:41, 243.06 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37490/47780 [02:10<00:44, 228.92 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37805/47780 [02:10<00:34, 286.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37678/47780 [02:11<00:38, 260.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37542/47780 [02:11<00:41, 244.03 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24537/47780 [02:11<01:09, 334.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37500/47780 [02:11<00:45, 224.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37299/47780 [02:11<00:47, 219.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37646/47780 [02:11<00:42, 240.16 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37514/47780 [02:11<00:44, 230.47 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37706/47780 [02:11<00:37, 265.66 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37836/47780 [02:11<00:35, 280.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37567/47780 [02:11<00:46, 219.70 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24572/47780 [02:11<01:08, 337.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37527/47780 [02:11<00:43, 235.43 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37324/47780 [02:11<00:46, 226.16 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37736/47780 [02:11<00:36, 273.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37672/47780 [02:11<00:42, 236.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37866/47780 [02:11<00:36, 271.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37538/47780 [02:11<00:48, 210.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37593/47780 [02:11<00:45, 225.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37554/47780 [02:11<00:42, 242.57 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24607/47780 [02:11<01:10, 328.00 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37348/47780 [02:11<00:48, 214.68 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37698/47780 [02:11<00:41, 241.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37895/47780 [02:11<00:36, 273.93 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37764/47780 [02:11<00:41, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37624/47780 [02:11<00:41, 247.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37566/47780 [02:11<00:47, 215.49 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37370/47780 [02:11<00:48, 213.86 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37726/47780 [02:11<00:39, 251.92 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37579/47780 [02:11<00:47, 214.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37931/47780 [02:11<00:33, 293.89 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24641/47780 [02:11<01:21, 283.32 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37791/47780 [02:11<00:40, 246.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37652/47780 [02:11<00:40, 252.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37592/47780 [02:11<00:45, 222.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37393/47780 [02:11<00:49, 209.33 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37752/47780 [02:11<00:40, 245.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37607/47780 [02:11<00:44, 230.77 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24697/47780 [02:11<01:05, 350.71 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37683/47780 [02:11<00:37, 268.46 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37961/47780 [02:11<00:35, 276.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37615/47780 [02:11<00:45, 224.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37817/47780 [02:11<00:41, 239.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37417/47780 [02:11<00:47, 217.42 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37782/47780 [02:11<00:38, 258.66 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37631/47780 [02:11<00:45, 224.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24734/47780 [02:11<01:06, 344.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37644/47780 [02:11<00:42, 240.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37714/47780 [02:11<00:36, 274.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37852/47780 [02:11<00:37, 266.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37990/47780 [02:11<00:36, 266.56 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37443/47780 [02:11<00:45, 226.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37657/47780 [02:11<00:43, 232.23 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37810/47780 [02:11<00:41, 242.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24770/47780 [02:11<01:08, 338.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37881/47780 [02:11<00:36, 270.21 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38020/47780 [02:11<00:35, 275.34 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37669/47780 [02:11<00:44, 226.56 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37742/47780 [02:11<00:39, 252.35 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37468/47780 [02:11<00:44, 233.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37681/47780 [02:11<00:43, 231.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37839/47780 [02:11<00:39, 252.62 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38049/47780 [02:11<00:34, 279.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37909/47780 [02:11<00:36, 269.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24805/47780 [02:11<01:10, 323.77 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37692/47780 [02:11<00:44, 225.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37770/47780 [02:11<00:38, 257.45 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37494/47780 [02:11<00:43, 238.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37708/47780 [02:11<00:41, 240.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37873/47780 [02:11<00:35, 276.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38082/47780 [02:11<00:33, 293.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37937/47780 [02:12<00:36, 272.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24839/47780 [02:12<01:13, 314.20 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37720/47780 [02:11<00:43, 233.46 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37797/47780 [02:12<00:39, 252.47 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37520/47780 [02:12<00:42, 239.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37733/47780 [02:12<00:43, 229.86 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37904/47780 [02:12<00:35, 280.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38114/47780 [02:12<00:32, 298.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37971/47780 [02:12<00:33, 290.24 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37745/47780 [02:12<00:42, 233.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37832/47780 [02:12<00:35, 276.44 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24871/47780 [02:12<01:15, 302.94 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37550/47780 [02:12<00:39, 256.59 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37763/47780 [02:12<00:40, 249.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37933/47780 [02:12<00:35, 280.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38145/47780 [02:12<00:32, 298.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38002/47780 [02:12<00:34, 280.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37771/47780 [02:12<00:41, 240.31 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37862/47780 [02:12<00:35, 279.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24906/47780 [02:12<01:14, 305.85 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37582/47780 [02:12<00:37, 268.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37790/47780 [02:12<00:39, 252.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37962/47780 [02:12<00:35, 279.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38176/47780 [02:12<00:34, 278.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37892/47780 [02:12<00:34, 284.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24950/47780 [02:12<01:06, 342.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38031/47780 [02:12<00:37, 261.38 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37796/47780 [02:12<00:43, 228.88 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37618/47780 [02:12<00:34, 294.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37992/47780 [02:12<00:35, 275.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37816/47780 [02:12<00:42, 235.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37923/47780 [02:12<00:34, 286.34 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24995/47780 [02:12<01:01, 369.73 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38059/47780 [02:12<00:36, 265.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38205/47780 [02:12<00:36, 264.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37821/47780 [02:12<00:42, 233.22 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37648/47780 [02:12<00:35, 281.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38020/47780 [02:12<00:37, 259.34 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37855/47780 [02:12<00:36, 269.06 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25033/47780 [02:12<01:02, 363.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38086/47780 [02:12<00:37, 258.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37953/47780 [02:12<00:35, 275.86 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37849/47780 [02:12<00:41, 238.36 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38232/47780 [02:12<00:37, 255.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37682/47780 [02:12<00:34, 296.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38047/47780 [02:12<00:37, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37883/47780 [02:12<00:38, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25073/47780 [02:12<01:01, 369.28 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38259/47780 [02:12<00:36, 258.96 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37873/47780 [02:12<00:41, 236.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37983/47780 [02:12<00:35, 276.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37712/47780 [02:12<00:34, 287.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38113/47780 [02:12<00:39, 245.28 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37909/47780 [02:12<00:39, 247.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38073/47780 [02:12<00:40, 237.36 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25114/47780 [02:12<01:00, 376.68 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38286/47780 [02:12<00:37, 253.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37743/47780 [02:12<00:34, 290.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37897/47780 [02:12<00:44, 222.21 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38138/47780 [02:12<00:42, 229.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38011/47780 [02:12<00:39, 245.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38100/47780 [02:12<00:39, 244.84 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37934/47780 [02:12<00:40, 243.21 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38318/47780 [02:12<00:35, 269.03 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37782/47780 [02:12<00:31, 315.66 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37923/47780 [02:12<00:42, 232.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38167/47780 [02:12<00:39, 245.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25152/47780 [02:12<01:10, 319.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38038/47780 [02:12<00:40, 238.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38133/47780 [02:12<00:36, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37959/47780 [02:12<00:40, 242.12 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38351/47780 [02:12<00:33, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37948/47780 [02:12<00:41, 235.62 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37827/47780 [02:13<00:28, 346.36 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38192/47780 [02:13<00:40, 238.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38068/47780 [02:13<00:38, 253.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25186/47780 [02:13<01:14, 305.07 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38172/47780 [02:13<00:33, 287.02 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38381/47780 [02:13<00:32, 285.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37977/47780 [02:13<00:39, 247.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37985/47780 [02:13<00:43, 223.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37862/47780 [02:13<00:30, 327.58 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38222/47780 [02:13<00:38, 250.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38104/47780 [02:13<00:34, 279.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25257/47780 [02:13<00:55, 405.51 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38207/47780 [02:13<00:31, 300.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38002/47780 [02:13<00:39, 247.73 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38410/47780 [02:13<00:33, 277.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37897/47780 [02:13<00:30, 323.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38008/47780 [02:13<00:46, 211.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38248/47780 [02:13<00:38, 249.39 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25300/47780 [02:13<00:56, 399.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38133/47780 [02:13<00:38, 248.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38443/47780 [02:13<00:32, 288.86 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38033/47780 [02:13<00:38, 256.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38274/47780 [02:13<00:38, 250.12 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38238/47780 [02:13<00:35, 266.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37930/47780 [02:13<00:31, 308.51 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38030/47780 [02:13<00:49, 196.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38167/47780 [02:13<00:35, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25342/47780 [02:13<01:01, 361.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38473/47780 [02:13<00:32, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38065/47780 [02:13<00:37, 261.83 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38272/47780 [02:13<00:33, 280.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38310/47780 [02:13<00:35, 269.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38066/47780 [02:13<00:40, 238.42 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37962/47780 [02:13<00:34, 285.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38195/47780 [02:13<00:35, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38511/47780 [02:13<00:30, 303.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25380/47780 [02:13<01:04, 346.50 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38092/47780 [02:13<00:37, 259.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38307/47780 [02:13<00:31, 297.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38337/47780 [02:13<00:36, 259.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38091/47780 [02:13<00:40, 239.00 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37992/47780 [02:13<00:34, 287.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38224/47780 [02:13<00:37, 256.41 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25420/47780 [02:13<01:02, 358.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38545/47780 [02:13<00:30, 306.62 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38123/47780 [02:13<00:35, 271.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38339/47780 [02:13<00:32, 294.29 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38371/47780 [02:13<00:33, 277.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38126/47780 [02:13<00:36, 266.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38023/47780 [02:13<00:34, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25457/47780 [02:13<01:02, 354.35 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38576/47780 [02:13<00:30, 299.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38253/47780 [02:13<00:37, 251.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38151/47780 [02:13<00:37, 258.84 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38399/47780 [02:13<00:34, 274.94 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38154/47780 [02:13<00:36, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38057/47780 [02:13<00:32, 299.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38369/47780 [02:13<00:36, 260.54 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25496/47780 [02:13<01:02, 356.26 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38281/47780 [02:13<00:37, 256.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38606/47780 [02:13<00:32, 281.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38177/47780 [02:13<00:37, 253.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38185/47780 [02:13<00:34, 276.34 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38427/47780 [02:13<00:36, 257.66 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38399/47780 [02:13<00:35, 267.86 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38095/47780 [02:13<00:32, 301.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38308/47780 [02:13<00:37, 254.66 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38206/47780 [02:13<00:36, 262.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38635/47780 [02:13<00:33, 277.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25533/47780 [02:13<01:08, 325.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38217/47780 [02:14<00:34, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38459/47780 [02:14<00:34, 272.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38430/47780 [02:14<00:33, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38132/47780 [02:14<00:31, 307.09 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38334/47780 [02:14<00:37, 250.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38234/47780 [02:14<00:35, 265.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25580/47780 [02:14<01:02, 354.41 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38663/47780 [02:14<00:35, 258.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38249/47780 [02:14<00:33, 284.38 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38489/47780 [02:14<00:34, 271.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38459/47780 [02:14<00:35, 262.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38169/47780 [02:14<00:29, 320.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38361/47780 [02:14<00:38, 242.58 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25621/47780 [02:14<01:00, 369.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38261/47780 [02:14<00:38, 244.56 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38690/47780 [02:14<00:35, 256.29 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38279/47780 [02:14<00:34, 273.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38517/47780 [02:14<00:35, 261.69 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38486/47780 [02:14<00:37, 248.30 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38202/47780 [02:14<00:33, 288.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38389/47780 [02:14<00:37, 247.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25661/47780 [02:14<00:59, 369.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38295/47780 [02:14<00:35, 267.62 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38717/47780 [02:14<00:35, 254.25 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38548/47780 [02:14<00:34, 271.10 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38307/47780 [02:14<00:35, 265.83 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38516/47780 [02:14<00:35, 259.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38232/47780 [02:14<00:33, 284.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38414/47780 [02:14<00:38, 242.79 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25699/47780 [02:14<01:01, 360.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38745/47780 [02:14<00:34, 260.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38576/47780 [02:14<00:34, 270.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38324/47780 [02:14<00:39, 241.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38334/47780 [02:14<00:38, 243.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38543/47780 [02:14<00:37, 246.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38444/47780 [02:14<00:36, 258.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25738/47780 [02:14<00:59, 368.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38261/47780 [02:14<00:36, 258.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38772/47780 [02:14<00:36, 244.77 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38604/47780 [02:14<00:34, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38363/47780 [02:14<00:36, 254.99 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38349/47780 [02:14<00:41, 227.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38471/47780 [02:14<00:35, 261.95 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38570/47780 [02:14<00:40, 228.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38289/47780 [02:14<00:36, 259.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25777/47780 [02:14<01:02, 351.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38635/47780 [02:14<00:33, 275.35 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38797/47780 [02:14<00:38, 236.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38389/47780 [02:14<00:38, 246.18 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38383/47780 [02:14<00:37, 248.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38500/47780 [02:14<00:34, 269.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38322/47780 [02:14<00:34, 277.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25813/47780 [02:14<01:02, 353.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38594/47780 [02:14<00:41, 223.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38667/47780 [02:14<00:32, 281.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38821/47780 [02:14<00:39, 224.61 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38421/47780 [02:14<00:35, 263.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38415/47780 [02:14<00:36, 253.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38528/47780 [02:14<00:37, 248.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38359/47780 [02:14<00:31, 299.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38617/47780 [02:14<00:40, 223.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25849/47780 [02:14<01:05, 332.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38853/47780 [02:14<00:36, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38453/47780 [02:14<00:33, 279.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38696/47780 [02:14<00:34, 262.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38455/47780 [02:14<00:32, 283.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38640/47780 [02:14<00:40, 223.90 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38393/47780 [02:14<00:30, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25883/47780 [02:14<01:05, 334.56 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38890/47780 [02:14<00:31, 281.37 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38554/47780 [02:14<00:42, 219.01 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38724/47780 [02:15<00:36, 246.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38482/47780 [02:15<00:36, 253.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38485/47780 [02:14<00:32, 281.69 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38426/47780 [02:15<00:31, 294.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25918/47780 [02:15<01:07, 324.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38664/47780 [02:15<00:44, 206.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38578/47780 [02:15<00:41, 223.38 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38919/47780 [02:15<00:32, 274.52 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38749/47780 [02:15<00:36, 247.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38512/47780 [02:15<00:34, 265.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38518/47780 [02:15<00:32, 287.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38456/47780 [02:15<00:31, 295.59 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25958/47780 [02:15<01:03, 342.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38602/47780 [02:15<00:40, 225.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38688/47780 [02:15<00:43, 208.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38948/47780 [02:15<00:32, 275.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38776/47780 [02:15<00:35, 250.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38552/47780 [02:15<00:31, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38540/47780 [02:15<00:36, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38715/47780 [02:15<00:40, 222.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38626/47780 [02:15<00:40, 225.54 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25993/47780 [02:15<01:06, 328.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38486/47780 [02:15<00:34, 266.55 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38802/47780 [02:15<00:36, 245.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38568/47780 [02:15<00:35, 256.62 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38976/47780 [02:15<00:37, 232.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38582/47780 [02:15<00:32, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38661/47780 [02:15<00:35, 260.03 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26027/47780 [02:15<01:06, 328.68 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38740/47780 [02:15<00:39, 228.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38514/47780 [02:15<00:37, 245.49 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38827/47780 [02:15<00:37, 238.33 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38595/47780 [02:15<00:35, 256.78 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39002/47780 [02:15<00:37, 233.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38611/47780 [02:15<00:35, 260.57 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26065/47780 [02:15<01:03, 339.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38764/47780 [02:15<00:39, 226.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38688/47780 [02:15<00:36, 246.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38543/47780 [02:15<00:36, 255.41 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38853/47780 [02:15<00:36, 241.90 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38622/47780 [02:15<00:37, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39027/47780 [02:15<00:39, 223.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38640/47780 [02:15<00:34, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38787/47780 [02:15<00:40, 222.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26100/47780 [02:15<01:08, 317.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38714/47780 [02:15<00:38, 234.52 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38885/47780 [02:15<00:33, 263.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38570/47780 [02:15<00:36, 253.63 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38647/47780 [02:15<00:37, 242.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39055/47780 [02:15<00:39, 222.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38811/47780 [02:15<00:41, 217.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26136/47780 [02:15<01:07, 321.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38747/47780 [02:15<00:35, 257.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38667/47780 [02:15<00:38, 236.58 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38597/47780 [02:15<00:36, 250.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38913/47780 [02:15<00:35, 249.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38673/47780 [02:15<00:38, 238.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39093/47780 [02:15<00:33, 261.59 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38836/47780 [02:15<00:41, 217.65 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26180/47780 [02:15<01:02, 346.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38774/47780 [02:15<00:35, 253.58 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38699/47780 [02:15<00:36, 247.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38630/47780 [02:15<00:34, 266.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38700/47780 [02:15<00:38, 234.57 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38939/47780 [02:15<00:40, 220.00 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39121/47780 [02:15<00:32, 262.68 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38859/47780 [02:15<00:40, 220.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26224/47780 [02:15<00:58, 367.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38728/47780 [02:15<00:35, 255.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38658/47780 [02:15<00:34, 267.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38800/47780 [02:15<00:37, 241.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38962/47780 [02:16<00:39, 221.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39149/47780 [02:16<00:32, 261.71 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38724/47780 [02:16<00:40, 223.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38889/47780 [02:16<00:37, 239.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26261/47780 [02:16<01:00, 353.13 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38825/47780 [02:16<00:37, 238.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38687/47780 [02:16<00:34, 264.62 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38755/47780 [02:16<00:36, 246.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39003/47780 [02:16<00:32, 267.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38750/47780 [02:16<00:41, 219.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39176/47780 [02:16<00:35, 244.81 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26301/47780 [02:16<00:59, 362.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38915/47780 [02:16<00:39, 224.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38860/47780 [02:16<00:33, 265.67 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38787/47780 [02:16<00:34, 260.74 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38715/47780 [02:16<00:35, 254.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39038/47780 [02:16<00:30, 288.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26345/47780 [02:16<00:56, 380.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39203/47780 [02:16<00:35, 243.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38773/47780 [02:16<00:42, 211.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38940/47780 [02:16<00:38, 229.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38814/47780 [02:16<00:34, 262.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38888/47780 [02:16<00:34, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38741/47780 [02:16<00:37, 242.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39068/47780 [02:16<00:30, 289.94 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26389/47780 [02:16<00:54, 392.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38969/47780 [02:16<00:35, 246.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38795/47780 [02:16<00:43, 206.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39230/47780 [02:16<00:35, 238.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38847/47780 [02:16<00:31, 279.99 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38925/47780 [02:16<00:33, 265.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38766/47780 [02:16<00:38, 232.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39102/47780 [02:16<00:29, 297.35 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39258/47780 [02:16<00:34, 249.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38876/47780 [02:16<00:32, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26432/47780 [02:16<00:58, 362.28 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38994/47780 [02:16<00:39, 219.68 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38816/47780 [02:16<00:48, 186.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38952/47780 [02:16<00:33, 264.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38790/47780 [02:16<00:38, 231.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39133/47780 [02:16<00:31, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26507/47780 [02:16<00:45, 466.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38908/47780 [02:16<00:31, 281.74 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39284/47780 [02:16<00:35, 236.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39021/47780 [02:16<00:38, 228.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38838/47780 [02:16<00:46, 194.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38814/47780 [02:16<00:39, 226.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38980/47780 [02:16<00:37, 232.53 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39162/47780 [02:16<00:32, 261.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38937/47780 [02:16<00:31, 280.91 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26556/47780 [02:16<00:45, 462.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39045/47780 [02:16<00:38, 229.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39308/47780 [02:16<00:38, 220.67 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38858/47780 [02:16<00:47, 188.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38838/47780 [02:16<00:39, 228.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39004/47780 [02:16<00:37, 232.87 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39191/47780 [02:16<00:31, 269.12 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38966/47780 [02:16<00:31, 279.98 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26605/47780 [02:16<00:46, 459.86 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39077/47780 [02:16<00:34, 254.26 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39335/47780 [02:16<00:36, 233.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38883/47780 [02:16<00:43, 204.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38865/47780 [02:16<00:38, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39221/47780 [02:16<00:31, 272.68 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39030/47780 [02:16<00:38, 225.86 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39105/47780 [02:16<00:33, 261.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38995/47780 [02:16<00:33, 262.07 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26653/47780 [02:16<00:48, 438.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38909/47780 [02:16<00:41, 214.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38889/47780 [02:17<00:39, 227.86 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39367/47780 [02:16<00:37, 226.27 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39250/47780 [02:17<00:31, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39056/47780 [02:17<00:37, 232.46 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39136/47780 [02:17<00:31, 273.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26698/47780 [02:17<00:48, 434.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39022/47780 [02:17<00:33, 258.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38933/47780 [02:17<00:39, 221.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38915/47780 [02:17<00:39, 226.96 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39392/47780 [02:17<00:37, 226.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39283/47780 [02:17<00:29, 287.78 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39080/47780 [02:17<00:37, 229.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39165/47780 [02:17<00:31, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39050/47780 [02:17<00:33, 264.48 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26751/47780 [02:17<00:46, 455.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38957/47780 [02:17<00:39, 222.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38946/47780 [02:17<00:35, 249.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39432/47780 [02:17<00:32, 254.81 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39314/47780 [02:17<00:30, 274.92 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39118/47780 [02:17<00:33, 262.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39193/47780 [02:17<00:32, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38980/47780 [02:17<00:41, 212.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39077/47780 [02:17<00:35, 243.57 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38981/47780 [02:17<00:31, 275.49 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26798/47780 [02:17<00:54, 385.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39458/47780 [02:17<00:33, 247.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39148/47780 [02:17<00:32, 266.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39342/47780 [02:17<00:32, 259.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39225/47780 [02:17<00:31, 274.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39013/47780 [02:17<00:35, 244.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39102/47780 [02:17<00:36, 238.05 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39010/47780 [02:17<00:32, 270.05 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26877/47780 [02:17<00:43, 483.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39177/47780 [02:17<00:31, 270.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39369/47780 [02:17<00:32, 259.47 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39255/47780 [02:17<00:30, 277.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39483/47780 [02:17<00:36, 224.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39128/47780 [02:17<00:35, 241.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39038/47780 [02:17<00:38, 228.30 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39039/47780 [02:17<00:33, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26929/47780 [02:17<00:42, 487.71 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39209/47780 [02:17<00:30, 277.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39397/47780 [02:17<00:31, 262.26 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39284/47780 [02:17<00:30, 279.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39507/47780 [02:17<00:36, 226.07 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39153/47780 [02:17<00:36, 238.19 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39065/47780 [02:17<00:37, 234.56 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39068/47780 [02:17<00:32, 269.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26980/47780 [02:17<00:42, 488.39 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39238/47780 [02:17<00:30, 281.13 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39424/47780 [02:17<00:31, 263.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39315/47780 [02:17<00:29, 284.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39544/47780 [02:17<00:31, 258.36 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39180/47780 [02:17<00:35, 244.68 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39089/47780 [02:17<00:37, 230.76 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27032/47780 [02:17<00:42, 491.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39096/47780 [02:17<00:36, 240.89 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39267/47780 [02:17<00:31, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39344/47780 [02:17<00:29, 281.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39452/47780 [02:17<00:32, 260.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39206/47780 [02:17<00:34, 248.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39572/47780 [02:17<00:32, 250.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39120/47780 [02:17<00:34, 250.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27083/47780 [02:17<00:42, 485.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39132/47780 [02:17<00:32, 269.56 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39479/47780 [02:17<00:31, 260.33 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39376/47780 [02:17<00:29, 286.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39294/47780 [02:17<00:32, 262.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39604/47780 [02:17<00:30, 266.87 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39232/47780 [02:17<00:35, 243.74 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39147/47780 [02:17<00:34, 250.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27133/47780 [02:17<00:44, 461.11 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39164/47780 [02:18<00:30, 280.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39509/47780 [02:18<00:31, 265.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39324/47780 [02:18<00:31, 267.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39405/47780 [02:18<00:29, 281.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39636/47780 [02:18<00:29, 280.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39262/47780 [02:17<00:32, 259.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39175/47780 [02:18<00:34, 252.90 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27180/47780 [02:18<00:45, 456.46 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39354/47780 [02:18<00:30, 273.84 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39536/47780 [02:18<00:31, 260.71 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39194/47780 [02:18<00:31, 273.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39434/47780 [02:18<00:29, 279.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39291/47780 [02:18<00:31, 265.45 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39666/47780 [02:18<00:30, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39201/47780 [02:18<00:34, 246.59 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39383/47780 [02:18<00:30, 278.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27227/47780 [02:18<00:47, 429.42 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39563/47780 [02:18<00:31, 261.73 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39463/47780 [02:18<00:30, 276.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39222/47780 [02:18<00:31, 269.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39322/47780 [02:18<00:30, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39235/47780 [02:18<00:32, 262.73 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39694/47780 [02:18<00:32, 250.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39411/47780 [02:18<00:30, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27272/47780 [02:18<00:47, 432.12 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39253/47780 [02:18<00:30, 279.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39497/47780 [02:18<00:28, 291.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39590/47780 [02:18<00:33, 243.12 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39350/47780 [02:18<00:32, 256.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39726/47780 [02:18<00:29, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39262/47780 [02:18<00:33, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39440/47780 [02:18<00:29, 278.40 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27316/47780 [02:18<00:47, 433.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39282/47780 [02:18<00:30, 278.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39527/47780 [02:18<00:29, 277.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39617/47780 [02:18<00:32, 248.01 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39383/47780 [02:18<00:30, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39754/47780 [02:18<00:30, 263.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39288/47780 [02:18<00:33, 250.63 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39472/47780 [02:18<00:28, 290.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27372/47780 [02:18<00:44, 459.93 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39311/47780 [02:18<00:30, 273.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39562/47780 [02:18<00:27, 298.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39652/47780 [02:18<00:30, 270.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39413/47780 [02:18<00:29, 281.39 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39781/47780 [02:18<00:30, 262.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39314/47780 [02:18<00:34, 242.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27419/47780 [02:18<00:45, 447.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39347/47780 [02:18<00:28, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39502/47780 [02:18<00:31, 262.37 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39593/47780 [02:18<00:28, 285.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39444/47780 [02:18<00:29, 286.96 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39680/47780 [02:18<00:31, 255.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39813/47780 [02:18<00:28, 275.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27465/47780 [02:18<00:45, 450.73 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39339/47780 [02:18<00:35, 239.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39379/47780 [02:18<00:28, 296.80 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39531/47780 [02:18<00:30, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39626/47780 [02:18<00:27, 294.54 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39713/47780 [02:18<00:29, 276.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39473/47780 [02:18<00:29, 281.48 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39845/47780 [02:18<00:27, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39366/47780 [02:18<00:34, 242.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27511/47780 [02:18<00:46, 433.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39559/47780 [02:18<00:30, 270.92 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39410/47780 [02:18<00:29, 284.29 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39657/47780 [02:18<00:27, 297.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39504/47780 [02:18<00:29, 280.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39741/47780 [02:18<00:30, 262.54 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39874/47780 [02:18<00:27, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39391/47780 [02:18<00:34, 244.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27561/47780 [02:18<00:44, 452.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39592/47780 [02:18<00:29, 281.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39693/47780 [02:19<00:26, 309.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39534/47780 [02:18<00:29, 282.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39439/47780 [02:19<00:32, 259.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39772/47780 [02:19<00:30, 266.71 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39416/47780 [02:19<00:35, 235.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39903/47780 [02:19<00:31, 253.08 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27607/47780 [02:19<00:46, 434.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39621/47780 [02:19<00:29, 277.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39734/47780 [02:19<00:24, 330.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39799/47780 [02:19<00:30, 264.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39567/47780 [02:19<00:28, 292.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39466/47780 [02:19<00:35, 237.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39937/47780 [02:19<00:28, 273.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27660/47780 [02:19<00:44, 456.46 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39441/47780 [02:19<00:36, 226.83 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39655/47780 [02:19<00:27, 292.00 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39768/47780 [02:19<00:24, 322.57 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39597/47780 [02:19<00:28, 291.46 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39832/47780 [02:19<00:29, 273.86 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39498/47780 [02:19<00:32, 256.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39985/47780 [02:19<00:23, 326.46 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39475/47780 [02:19<00:32, 252.31 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39694/47780 [02:19<00:25, 316.55 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27706/47780 [02:19<00:46, 428.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39811/47780 [02:19<00:22, 352.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39627/47780 [02:19<00:28, 290.56 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39528/47780 [02:19<00:30, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39860/47780 [02:19<00:30, 258.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40028/47780 [02:19<00:21, 355.33 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39733/47780 [02:19<00:23, 337.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39505/47780 [02:19<00:31, 262.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27754/47780 [02:19<00:45, 442.22 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39847/47780 [02:19<00:24, 327.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39657/47780 [02:19<00:30, 270.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39556/47780 [02:19<00:30, 267.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39890/47780 [02:19<00:29, 268.40 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40065/47780 [02:19<00:22, 338.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39532/47780 [02:19<00:31, 258.91 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39767/47780 [02:19<00:24, 322.78 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27799/47780 [02:19<00:47, 420.57 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39885/47780 [02:19<00:23, 339.33 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39691/47780 [02:19<00:28, 286.04 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39586/47780 [02:19<00:29, 273.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39918/47780 [02:19<00:30, 261.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40102/47780 [02:19<00:22, 345.22 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39800/47780 [02:19<00:24, 321.40 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39558/47780 [02:19<00:34, 239.89 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27842/47780 [02:19<00:49, 399.26 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39920/47780 [02:19<00:24, 327.03 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39725/47780 [02:19<00:26, 299.42 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39617/47780 [02:19<00:29, 274.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39945/47780 [02:19<00:31, 250.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40140/47780 [02:19<00:21, 354.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39838/47780 [02:19<00:23, 334.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39585/47780 [02:19<00:34, 240.53 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27893/47780 [02:19<00:46, 426.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39955/47780 [02:19<00:23, 326.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39756/47780 [02:19<00:27, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39645/47780 [02:19<00:31, 258.33 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39977/47780 [02:19<00:30, 257.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39876/47780 [02:19<00:23, 339.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40176/47780 [02:19<00:24, 313.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27939/47780 [02:19<00:45, 436.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39994/47780 [02:19<00:22, 344.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39610/47780 [02:19<00:36, 223.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39786/47780 [02:19<00:28, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39672/47780 [02:19<00:31, 256.33 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40005/47780 [02:19<00:30, 258.00 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39911/47780 [02:19<00:22, 342.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40029/47780 [02:19<00:22, 342.16 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40209/47780 [02:19<00:25, 298.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27984/47780 [02:19<00:48, 411.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39824/47780 [02:19<00:26, 300.15 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39633/47780 [02:20<00:40, 203.09 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40031/47780 [02:20<00:30, 255.78 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39952/47780 [02:20<00:21, 358.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39698/47780 [02:20<00:34, 231.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40064/47780 [02:20<00:22, 340.50 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28026/47780 [02:20<00:48, 405.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40240/47780 [02:20<00:26, 289.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39855/47780 [02:20<00:26, 302.74 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39663/47780 [02:20<00:36, 223.87 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40060/47780 [02:20<00:29, 262.41 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39988/47780 [02:20<00:22, 350.69 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40104/47780 [02:20<00:21, 353.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28067/47780 [02:20<00:48, 406.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40271/47780 [02:20<00:25, 294.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39723/47780 [02:20<00:39, 204.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39689/47780 [02:20<00:35, 230.96 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40087/47780 [02:20<00:30, 252.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39886/47780 [02:20<00:29, 267.90 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40024/47780 [02:20<00:24, 318.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40140/47780 [02:20<00:22, 343.48 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40305/47780 [02:20<00:24, 307.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28108/47780 [02:20<00:49, 398.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39745/47780 [02:20<00:40, 196.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39726/47780 [02:20<00:30, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40118/47780 [02:20<00:28, 266.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39914/47780 [02:20<00:29, 263.29 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40057/47780 [02:20<00:24, 313.72 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28150/47780 [02:20<00:49, 399.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40348/47780 [02:20<00:22, 330.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40175/47780 [02:20<00:24, 316.21 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39808/47780 [02:20<00:26, 304.22 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39757/47780 [02:20<00:29, 271.32 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40146/47780 [02:20<00:28, 267.00 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39941/47780 [02:20<00:30, 256.84 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40094/47780 [02:20<00:23, 328.21 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40383/47780 [02:20<00:22, 335.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28191/47780 [02:20<00:50, 389.85 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40208/47780 [02:20<00:24, 306.42 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39785/47780 [02:20<00:29, 267.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40173/47780 [02:20<00:29, 261.88 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39842/47780 [02:20<00:27, 291.68 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39970/47780 [02:20<00:30, 260.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40128/47780 [02:20<00:23, 327.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40425/47780 [02:20<00:20, 352.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28231/47780 [02:20<00:51, 379.45 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40247/47780 [02:20<00:23, 319.06 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39819/47780 [02:20<00:28, 283.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40201/47780 [02:20<00:28, 264.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39997/47780 [02:20<00:30, 256.92 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40164/47780 [02:20<00:22, 335.43 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39874/47780 [02:20<00:29, 271.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40465/47780 [02:20<00:20, 361.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28273/47780 [02:20<00:50, 386.92 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39848/47780 [02:20<00:27, 285.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40282/47780 [02:20<00:23, 316.96 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40228/47780 [02:20<00:28, 262.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40198/47780 [02:20<00:23, 328.04 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40023/47780 [02:20<00:32, 239.20 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40502/47780 [02:20<00:20, 351.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39903/47780 [02:20<00:30, 259.25 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28312/47780 [02:20<00:52, 370.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39877/47780 [02:20<00:27, 286.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40267/47780 [02:20<00:25, 297.93 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40314/47780 [02:20<00:24, 304.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40231/47780 [02:20<00:24, 309.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39943/47780 [02:20<00:27, 290.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40048/47780 [02:20<00:33, 227.76 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28358/47780 [02:20<00:49, 391.21 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40538/47780 [02:20<00:21, 331.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40349/47780 [02:21<00:24, 307.08 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39906/47780 [02:21<00:30, 257.41 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40297/47780 [02:21<00:27, 273.93 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40269/47780 [02:21<00:23, 326.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39974/47780 [02:21<00:26, 295.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28409/47780 [02:21<00:46, 413.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40074/47780 [02:21<00:34, 226.58 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40573/47780 [02:21<00:22, 322.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40389/47780 [02:21<00:22, 328.96 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40302/47780 [02:21<00:23, 321.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40005/47780 [02:21<00:26, 295.76 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39933/47780 [02:21<00:34, 227.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40325/47780 [02:21<00:30, 243.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40606/47780 [02:21<00:22, 324.63 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40098/47780 [02:21<00:34, 225.39 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28451/47780 [02:21<00:50, 386.43 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40429/47780 [02:21<00:21, 344.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40338/47780 [02:21<00:22, 330.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40046/47780 [02:21<00:23, 324.78 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39958/47780 [02:21<00:33, 231.42 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40351/47780 [02:21<00:30, 245.04 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40125/47780 [02:21<00:32, 236.58 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40643/47780 [02:21<00:21, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28495/47780 [02:21<00:48, 397.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40466/47780 [02:21<00:22, 324.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40080/47780 [02:21<00:24, 320.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40374/47780 [02:21<00:23, 320.35 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39984/47780 [02:21<00:33, 234.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40684/47780 [02:21<00:20, 351.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40377/47780 [02:21<00:31, 238.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40149/47780 [02:21<00:33, 228.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28536/47780 [02:21<00:48, 395.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40009/47780 [02:21<00:32, 238.98 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40499/47780 [02:21<00:24, 295.53 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40402/47780 [02:21<00:30, 239.88 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40721/47780 [02:21<00:20, 337.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40407/47780 [02:21<00:25, 293.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40113/47780 [02:21<00:26, 288.16 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28582/47780 [02:21<00:47, 405.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40172/47780 [02:21<00:35, 216.73 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40036/47780 [02:21<00:31, 244.95 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40432/47780 [02:21<00:28, 253.64 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40530/47780 [02:21<00:25, 285.93 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40765/47780 [02:21<00:19, 361.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40442/47780 [02:21<00:24, 305.70 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28625/47780 [02:21<00:46, 408.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40199/47780 [02:21<00:33, 228.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40144/47780 [02:21<00:28, 270.95 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40066/47780 [02:21<00:29, 257.52 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40458/47780 [02:21<00:28, 252.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28675/47780 [02:21<00:44, 428.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40223/47780 [02:21<00:32, 229.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40475/47780 [02:21<00:24, 299.20 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40559/47780 [02:21<00:27, 260.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40802/47780 [02:21<00:20, 337.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40172/47780 [02:21<00:28, 264.63 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40094/47780 [02:21<00:30, 252.45 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40487/47780 [02:21<00:28, 257.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28718/47780 [02:21<00:44, 428.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40249/47780 [02:21<00:31, 236.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40506/47780 [02:21<00:24, 297.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40837/47780 [02:21<00:20, 333.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40586/47780 [02:21<00:30, 234.29 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40121/47780 [02:21<00:30, 254.56 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28761/47780 [02:21<00:44, 424.47 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40513/47780 [02:21<00:30, 241.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40273/47780 [02:21<00:32, 233.39 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40199/47780 [02:21<00:34, 220.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40873/47780 [02:21<00:20, 339.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40536/47780 [02:21<00:26, 277.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40612/47780 [02:22<00:32, 223.47 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40147/47780 [02:22<00:30, 247.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40539/47780 [02:22<00:29, 244.09 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40300/47780 [02:21<00:30, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40255/47780 [02:22<00:25, 297.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28805/47780 [02:22<00:46, 408.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40565/47780 [02:22<00:25, 278.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40908/47780 [02:22<00:22, 309.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40638/47780 [02:22<00:30, 230.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40172/47780 [02:22<00:31, 240.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40329/47780 [02:22<00:29, 249.74 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28849/47780 [02:22<00:45, 414.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40564/47780 [02:22<00:31, 230.30 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40596/47780 [02:22<00:25, 283.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40288/47780 [02:22<00:26, 280.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40666/47780 [02:22<00:29, 242.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40940/47780 [02:22<00:24, 284.34 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40363/47780 [02:22<00:26, 275.60 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28896/47780 [02:22<00:44, 425.31 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40595/47780 [02:22<00:28, 249.32 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40627/47780 [02:22<00:24, 291.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40197/47780 [02:22<00:34, 218.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40319/47780 [02:22<00:28, 259.61 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40970/47780 [02:22<00:23, 284.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40691/47780 [02:22<00:29, 237.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28939/47780 [02:22<00:44, 423.57 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40242/47780 [02:22<00:27, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40623/47780 [02:22<00:28, 249.06 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40391/47780 [02:22<00:29, 249.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40660/47780 [02:22<00:24, 289.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40349/47780 [02:22<00:27, 266.79 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40722/47780 [02:22<00:27, 256.88 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28982/47780 [02:22<00:45, 417.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40999/47780 [02:22<00:26, 259.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40271/47780 [02:22<00:27, 277.70 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40660/47780 [02:22<00:25, 279.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40693/47780 [02:22<00:23, 297.42 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40417/47780 [02:22<00:32, 226.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40749/47780 [02:22<00:28, 250.98 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40377/47780 [02:22<00:29, 252.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29032/47780 [02:22<00:42, 437.76 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41027/47780 [02:22<00:25, 264.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40300/47780 [02:22<00:28, 266.66 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40689/47780 [02:22<00:27, 262.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40723/47780 [02:22<00:25, 279.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40444/47780 [02:22<00:31, 235.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40781/47780 [02:22<00:26, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40404/47780 [02:22<00:29, 251.21 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41054/47780 [02:22<00:25, 260.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40328/47780 [02:22<00:27, 270.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40723/47780 [02:22<00:25, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40469/47780 [02:22<00:31, 234.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40752/47780 [02:22<00:27, 259.33 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40811/47780 [02:22<00:25, 270.11 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29078/47780 [02:22<00:55, 335.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40430/47780 [02:22<00:30, 237.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41081/47780 [02:22<00:27, 241.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40760/47780 [02:22<00:23, 299.58 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40356/47780 [02:22<00:30, 245.84 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40495/47780 [02:22<00:30, 238.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40779/47780 [02:22<00:27, 251.49 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40845/47780 [02:22<00:23, 289.75 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29172/47780 [02:22<00:38, 479.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40459/47780 [02:22<00:29, 247.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41107/47780 [02:22<00:27, 239.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40529/47780 [02:22<00:27, 261.86 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40793/47780 [02:22<00:24, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40382/47780 [02:22<00:31, 234.22 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40875/47780 [02:22<00:23, 291.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40806/47780 [02:22<00:27, 250.86 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29227/47780 [02:22<00:39, 464.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40488/47780 [02:23<00:29, 245.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40824/47780 [02:23<00:23, 289.93 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41132/47780 [02:23<00:30, 220.92 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40907/47780 [02:23<00:23, 294.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40406/47780 [02:23<00:32, 228.88 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40834/47780 [02:23<00:27, 250.71 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40557/47780 [02:23<00:30, 233.02 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40514/47780 [02:23<00:29, 246.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29278/47780 [02:23<00:40, 454.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41155/47780 [02:23<00:30, 216.46 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40855/47780 [02:23<00:25, 276.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40937/47780 [02:23<00:25, 270.58 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40582/47780 [02:23<00:31, 229.13 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40430/47780 [02:23<00:35, 205.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40860/47780 [02:23<00:30, 225.92 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40539/47780 [02:23<00:30, 240.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29327/47780 [02:23<00:40, 452.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41177/47780 [02:23<00:31, 206.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40883/47780 [02:23<00:26, 260.62 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40965/47780 [02:23<00:25, 271.41 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29377/47780 [02:23<00:39, 464.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40564/47780 [02:23<00:30, 239.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40455/47780 [02:23<00:34, 210.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40884/47780 [02:23<00:30, 222.80 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40606/47780 [02:23<00:33, 215.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41207/47780 [02:23<00:28, 230.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40912/47780 [02:23<00:26, 261.79 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40993/47780 [02:23<00:25, 263.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29428/47780 [02:23<00:39, 466.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40913/47780 [02:23<00:29, 235.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40589/47780 [02:23<00:30, 234.32 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40628/47780 [02:23<00:33, 213.13 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40477/47780 [02:23<00:36, 202.44 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40945/47780 [02:23<00:25, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41020/47780 [02:23<00:26, 254.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41232/47780 [02:23<00:31, 210.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29479/47780 [02:23<00:38, 473.98 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40652/47780 [02:23<00:32, 219.90 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40617/47780 [02:23<00:29, 242.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40501/47780 [02:23<00:34, 210.01 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40938/47780 [02:23<00:29, 231.88 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40972/47780 [02:23<00:25, 264.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41046/47780 [02:23<00:26, 255.81 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41259/47780 [02:23<00:29, 221.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29529/47780 [02:23<00:38, 475.90 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40647/47780 [02:23<00:27, 258.13 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40523/47780 [02:23<00:35, 206.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40962/47780 [02:23<00:30, 226.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40675/47780 [02:23<00:33, 210.38 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40999/47780 [02:23<00:25, 265.80 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41286/47780 [02:23<00:27, 232.98 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41072/47780 [02:23<00:27, 248.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29578/47780 [02:23<00:38, 474.63 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40675/47780 [02:23<00:27, 261.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40985/47780 [02:23<00:29, 227.49 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40546/47780 [02:23<00:34, 210.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40697/47780 [02:23<00:34, 207.46 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29626/47780 [02:23<00:39, 465.42 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40703/47780 [02:23<00:27, 260.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41026/47780 [02:23<00:28, 240.58 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41311/47780 [02:23<00:29, 220.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41011/47780 [02:23<00:29, 231.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40570/47780 [02:23<00:33, 213.86 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41097/47780 [02:23<00:30, 221.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40722/47780 [02:23<00:33, 212.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29675/47780 [02:23<00:39, 463.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41334/47780 [02:23<00:29, 221.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41051/47780 [02:23<00:28, 240.07 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40594/47780 [02:23<00:32, 221.12 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41039/47780 [02:23<00:27, 242.72 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40730/47780 [02:23<00:28, 251.64 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41125/47780 [02:23<00:28, 232.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40752/47780 [02:23<00:30, 231.16 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29733/47780 [02:24<00:36, 495.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41078/47780 [02:24<00:27, 248.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41362/47780 [02:24<00:27, 233.91 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40617/47780 [02:24<00:32, 221.81 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40756/47780 [02:24<00:28, 245.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41150/47780 [02:24<00:28, 236.44 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41064/47780 [02:24<00:28, 233.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40786/47780 [02:24<00:27, 255.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29784/47780 [02:24<00:36, 498.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41386/47780 [02:24<00:27, 233.01 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41104/47780 [02:24<00:27, 243.64 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40641/47780 [02:24<00:32, 219.95 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41186/47780 [02:24<00:24, 265.07 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41088/47780 [02:24<00:29, 225.43 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40781/47780 [02:24<00:29, 234.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40812/47780 [02:24<00:27, 251.13 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29835/47780 [02:24<00:36, 491.47 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41413/47780 [02:24<00:26, 239.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40667/47780 [02:24<00:30, 230.78 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41214/47780 [02:24<00:24, 263.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41129/47780 [02:24<00:29, 225.22 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41114/47780 [02:24<00:28, 232.85 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40806/47780 [02:24<00:30, 230.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40838/47780 [02:24<00:28, 242.53 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29885/47780 [02:24<00:37, 483.55 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41446/47780 [02:24<00:24, 258.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41243/47780 [02:24<00:24, 267.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40692/47780 [02:24<00:31, 222.51 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41155/47780 [02:24<00:28, 233.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41139/47780 [02:24<00:28, 232.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40864/47780 [02:24<00:28, 239.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40830/47780 [02:24<00:32, 212.14 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29936/47780 [02:24<00:38, 463.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40716/47780 [02:24<00:31, 224.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41477/47780 [02:24<00:25, 250.02 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41270/47780 [02:24<00:25, 254.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41163/47780 [02:24<00:29, 221.87 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40889/47780 [02:24<00:28, 239.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41179/47780 [02:24<00:30, 217.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40864/47780 [02:24<00:28, 243.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29984/47780 [02:24<00:40, 443.17 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40739/47780 [02:24<00:31, 221.01 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41511/47780 [02:24<00:22, 273.96 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41299/47780 [02:24<00:24, 263.92 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40923/47780 [02:24<00:25, 265.17 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41198/47780 [02:24<00:26, 251.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40891/47780 [02:24<00:27, 250.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41208/47780 [02:24<00:28, 226.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30032/47780 [02:24<00:39, 448.34 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41333/47780 [02:24<00:23, 279.31 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40762/47780 [02:24<00:32, 214.37 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41224/47780 [02:24<00:26, 251.59 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41540/47780 [02:24<00:23, 261.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40950/47780 [02:24<00:26, 257.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41233/47780 [02:24<00:28, 227.19 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40918/47780 [02:24<00:28, 239.83 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30087/47780 [02:24<00:37, 466.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41363/47780 [02:24<00:22, 285.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40786/47780 [02:24<00:32, 216.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41251/47780 [02:24<00:26, 250.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40982/47780 [02:24<00:25, 263.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41567/47780 [02:24<00:25, 244.61 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41256/47780 [02:24<00:29, 221.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40951/47780 [02:24<00:26, 253.61 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30140/47780 [02:24<00:36, 484.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41400/47780 [02:24<00:20, 309.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40816/47780 [02:24<00:29, 233.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41282/47780 [02:24<00:24, 264.86 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41288/47780 [02:24<00:26, 246.04 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41009/47780 [02:24<00:26, 251.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41608/47780 [02:24<00:22, 274.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40986/47780 [02:24<00:24, 276.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30189/47780 [02:25<00:36, 480.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41432/47780 [02:25<00:21, 295.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41317/47780 [02:25<00:22, 288.91 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41315/47780 [02:25<00:25, 252.72 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40840/47780 [02:25<00:32, 215.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41040/47780 [02:25<00:25, 264.45 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41017/47780 [02:25<00:23, 282.93 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41637/47780 [02:25<00:24, 255.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30238/47780 [02:25<00:38, 456.91 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41470/47780 [02:25<00:20, 315.23 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41349/47780 [02:25<00:21, 294.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41350/47780 [02:25<00:22, 280.18 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41072/47780 [02:25<00:24, 276.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40862/47780 [02:25<00:33, 203.53 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41062/47780 [02:25<00:20, 322.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41674/47780 [02:25<00:21, 283.29 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30288/47780 [02:25<00:37, 463.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41379/47780 [02:25<00:22, 285.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41382/47780 [02:25<00:21, 291.59 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41502/47780 [02:25<00:21, 287.84 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41100/47780 [02:25<00:24, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40890/47780 [02:25<00:31, 218.88 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41095/47780 [02:25<00:21, 310.46 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41703/47780 [02:25<00:22, 274.00 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30339/47780 [02:25<00:37, 461.27 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41415/47780 [02:25<00:21, 300.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41409/47780 [02:25<00:22, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41534/47780 [02:25<00:21, 296.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41136/47780 [02:25<00:23, 286.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41128/47780 [02:25<00:21, 309.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41748/47780 [02:25<00:18, 320.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30388/47780 [02:25<00:37, 469.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40913/47780 [02:25<00:35, 195.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41458/47780 [02:25<00:18, 338.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41568/47780 [02:25<00:20, 305.34 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41441/47780 [02:25<00:22, 278.71 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41165/47780 [02:25<00:24, 266.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41160/47780 [02:25<00:23, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41781/47780 [02:25<00:19, 306.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40939/47780 [02:25<00:32, 210.93 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41608/47780 [02:25<00:18, 328.25 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30437/47780 [02:25<00:40, 425.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41494/47780 [02:25<00:19, 324.61 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41469/47780 [02:25<00:23, 269.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41192/47780 [02:25<00:25, 259.24 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40961/47780 [02:25<00:31, 213.15 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41815/47780 [02:25<00:19, 302.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41192/47780 [02:25<00:23, 280.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41527/47780 [02:25<00:20, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41497/47780 [02:25<00:23, 266.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41642/47780 [02:25<00:19, 307.17 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30482/47780 [02:25<00:43, 397.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41219/47780 [02:25<00:25, 253.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40983/47780 [02:25<00:31, 212.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41223/47780 [02:25<00:22, 288.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41846/47780 [02:25<00:20, 285.53 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41676/47780 [02:25<00:19, 312.73 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30544/47780 [02:25<00:38, 447.55 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41524/47780 [02:25<00:26, 238.59 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41246/47780 [02:25<00:25, 257.78 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41559/47780 [02:25<00:22, 271.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41005/47780 [02:25<00:31, 212.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41258/47780 [02:25<00:21, 302.15 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41875/47780 [02:25<00:21, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41708/47780 [02:25<00:19, 309.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30590/47780 [02:25<00:39, 439.73 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41551/47780 [02:25<00:25, 246.72 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41276/47780 [02:25<00:24, 267.22 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41591/47780 [02:25<00:22, 279.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41028/47780 [02:25<00:31, 212.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41291/47780 [02:25<00:20, 309.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41905/47780 [02:25<00:20, 280.78 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30642/47780 [02:26<00:37, 458.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41740/47780 [02:26<00:20, 294.23 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41586/47780 [02:26<00:23, 269.01 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41305/47780 [02:26<00:24, 267.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41057/47780 [02:26<00:28, 233.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41620/47780 [02:26<00:23, 262.46 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41323/47780 [02:26<00:22, 280.76 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41934/47780 [02:26<00:22, 260.15 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30689/47780 [02:26<00:37, 450.04 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41332/47780 [02:26<00:24, 262.47 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41081/47780 [02:26<00:28, 233.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41615/47780 [02:26<00:23, 257.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41771/47780 [02:26<00:24, 247.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41359/47780 [02:26<00:21, 295.01 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41647/47780 [02:26<00:25, 243.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41962/47780 [02:26<00:23, 244.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41360/47780 [02:26<00:24, 264.45 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41108/47780 [02:26<00:27, 241.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41642/47780 [02:26<00:23, 258.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30735/47780 [02:26<00:41, 408.51 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41815/47780 [02:26<00:20, 288.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41673/47780 [02:26<00:25, 240.11 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41391/47780 [02:26<00:22, 285.44 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41997/47780 [02:26<00:21, 266.61 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41143/47780 [02:26<00:24, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41672/47780 [02:26<00:22, 267.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30777/47780 [02:26<00:41, 407.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41387/47780 [02:26<00:25, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41850/47780 [02:26<00:19, 304.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41700/47780 [02:26<00:25, 243.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41420/47780 [02:26<00:23, 275.78 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41171/47780 [02:26<00:24, 269.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42025/47780 [02:26<00:22, 258.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41699/47780 [02:26<00:23, 256.27 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41416/47780 [02:26<00:25, 252.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41882/47780 [02:26<00:20, 292.88 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41732/47780 [02:26<00:23, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30822/47780 [02:26<00:51, 329.47 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41448/47780 [02:26<00:24, 255.39 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42053/47780 [02:26<00:21, 262.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41725/47780 [02:26<00:23, 257.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41200/47780 [02:26<00:26, 244.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41443/47780 [02:26<00:26, 243.38 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41913/47780 [02:26<00:19, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41760/47780 [02:26<00:22, 264.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30910/47780 [02:26<00:36, 458.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42091/47780 [02:26<00:19, 291.21 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41475/47780 [02:26<00:25, 247.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41752/47780 [02:26<00:23, 257.95 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41228/47780 [02:26<00:25, 252.79 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41468/47780 [02:26<00:26, 241.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41793/47780 [02:26<00:21, 282.30 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41946/47780 [02:26<00:20, 288.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41502/47780 [02:26<00:24, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41780/47780 [02:26<00:23, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41254/47780 [02:26<00:25, 254.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41497/47780 [02:26<00:24, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42121/47780 [02:26<00:21, 263.08 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41822/47780 [02:26<00:21, 280.66 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30962/47780 [02:26<00:42, 391.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41982/47780 [02:26<00:19, 297.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41530/47780 [02:26<00:24, 259.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41806/47780 [02:26<00:23, 252.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41285/47780 [02:26<00:24, 268.70 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42158/47780 [02:26<00:19, 286.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41530/47780 [02:26<00:23, 265.86 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41851/47780 [02:26<00:21, 280.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42013/47780 [02:27<00:20, 287.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41562/47780 [02:27<00:23, 270.17 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42193/47780 [02:27<00:18, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41832/47780 [02:27<00:24, 238.82 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41557/47780 [02:27<00:24, 258.34 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41313/47780 [02:27<00:25, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41880/47780 [02:27<00:21, 270.25 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31008/47780 [02:27<00:53, 314.46 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42049/47780 [02:27<00:19, 298.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41594/47780 [02:27<00:21, 284.13 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42227/47780 [02:27<00:18, 305.90 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41863/47780 [02:27<00:23, 249.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41585/47780 [02:27<00:23, 261.44 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41910/47780 [02:27<00:21, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41339/47780 [02:27<00:26, 239.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31114/47780 [02:27<00:36, 461.60 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42080/47780 [02:27<00:20, 275.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42260/47780 [02:27<00:18, 306.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41890/47780 [02:27<00:24, 245.03 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41623/47780 [02:27<00:25, 239.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41938/47780 [02:27<00:21, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41612/47780 [02:27<00:24, 246.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41364/47780 [02:27<00:27, 234.31 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42112/47780 [02:27<00:19, 286.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31171/47780 [02:27<00:38, 428.92 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41931/47780 [02:27<00:20, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41649/47780 [02:27<00:25, 244.48 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42291/47780 [02:27<00:19, 287.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41639/47780 [02:27<00:24, 250.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41967/47780 [02:27<00:21, 269.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41388/47780 [02:27<00:28, 222.66 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42142/47780 [02:27<00:20, 280.58 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41961/47780 [02:27<00:20, 285.46 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31222/47780 [02:27<00:39, 423.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41681/47780 [02:27<00:23, 259.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42321/47780 [02:27<00:19, 285.55 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41665/47780 [02:27<00:24, 250.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42016/47780 [02:27<00:18, 308.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41417/47780 [02:27<00:27, 234.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42171/47780 [02:27<00:20, 271.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42001/47780 [02:27<00:18, 317.62 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41691/47780 [02:27<00:24, 252.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41708/47780 [02:27<00:23, 254.60 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42351/47780 [02:27<00:19, 283.09 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42051/47780 [02:27<00:17, 318.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31270/47780 [02:27<00:41, 396.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41444/47780 [02:27<00:26, 241.51 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42209/47780 [02:27<00:18, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42043/47780 [02:27<00:16, 346.90 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41735/47780 [02:27<00:23, 255.22 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41721/47780 [02:27<00:23, 260.77 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42391/47780 [02:27<00:17, 311.38 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42083/47780 [02:27<00:18, 315.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41469/47780 [02:27<00:25, 243.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31314/47780 [02:27<00:41, 395.52 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42240/47780 [02:27<00:18, 301.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42090/47780 [02:27<00:15, 378.29 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41761/47780 [02:27<00:23, 255.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41748/47780 [02:27<00:23, 257.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42427/47780 [02:27<00:17, 312.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41495/47780 [02:27<00:26, 240.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31360/47780 [02:27<00:40, 407.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42115/47780 [02:27<00:19, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42282/47780 [02:27<00:16, 330.01 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42136/47780 [02:27<00:14, 401.81 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41781/47780 [02:27<00:21, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41787/47780 [02:27<00:24, 243.87 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42459/47780 [02:27<00:17, 301.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31406/47780 [02:27<00:39, 416.76 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42149/47780 [02:27<00:18, 303.87 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41520/47780 [02:27<00:27, 227.62 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42177/47780 [02:28<00:14, 390.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42316/47780 [02:28<00:17, 311.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41824/47780 [02:28<00:21, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41819/47780 [02:27<00:20, 291.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42503/47780 [02:28<00:16, 327.23 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41551/47780 [02:28<00:25, 247.56 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42180/47780 [02:28<00:19, 289.86 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31450/47780 [02:28<00:42, 382.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42348/47780 [02:28<00:17, 307.20 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42217/47780 [02:28<00:15, 368.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41861/47780 [02:28<00:20, 295.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42540/47780 [02:28<00:15, 336.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41849/47780 [02:28<00:22, 267.00 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41577/47780 [02:28<00:24, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31490/47780 [02:28<00:42, 386.51 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42210/47780 [02:28<00:19, 279.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42379/47780 [02:28<00:18, 298.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41891/47780 [02:28<00:20, 293.55 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42577/47780 [02:28<00:15, 338.03 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42255/47780 [02:28<00:16, 337.28 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41604/47780 [02:28<00:25, 237.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41877/47780 [02:28<00:23, 249.48 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42241/47780 [02:28<00:19, 284.95 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31530/47780 [02:28<00:45, 359.82 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41922/47780 [02:28<00:19, 297.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42409/47780 [02:28<00:19, 279.46 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42613/47780 [02:28<00:15, 340.61 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42298/47780 [02:28<00:15, 354.71 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41631/47780 [02:28<00:25, 241.71 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41903/47780 [02:28<00:23, 246.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42270/47780 [02:28<00:20, 274.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31567/47780 [02:28<00:47, 337.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41958/47780 [02:28<00:18, 309.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42438/47780 [02:28<00:19, 279.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42652/47780 [02:28<00:15, 335.17 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42338/47780 [02:28<00:15, 347.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41928/47780 [02:28<00:24, 235.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42298/47780 [02:28<00:20, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41657/47780 [02:28<00:27, 226.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42000/47780 [02:28<00:16, 340.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31611/47780 [02:28<00:44, 360.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42467/47780 [02:28<00:19, 276.06 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42686/47780 [02:28<00:15, 329.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42334/47780 [02:28<00:19, 286.44 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41683/47780 [02:28<00:26, 233.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41953/47780 [02:28<00:25, 231.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42374/47780 [02:28<00:17, 306.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42037/47780 [02:28<00:16, 342.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31657/47780 [02:28<00:42, 382.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42496/47780 [02:28<00:19, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42720/47780 [02:28<00:15, 332.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41713/47780 [02:28<00:24, 248.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42364/47780 [02:28<00:19, 283.86 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42408/47780 [02:28<00:17, 312.03 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41977/47780 [02:28<00:25, 224.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31697/47780 [02:28<00:42, 382.71 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42072/47780 [02:28<00:17, 324.82 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42524/47780 [02:28<00:20, 260.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42754/47780 [02:28<00:15, 330.30 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41742/47780 [02:28<00:23, 260.18 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42393/47780 [02:28<00:19, 282.42 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42440/47780 [02:28<00:17, 309.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42010/47780 [02:28<00:22, 251.10 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31739/47780 [02:28<00:41, 389.39 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42107/47780 [02:28<00:17, 328.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42555/47780 [02:28<00:19, 274.01 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42788/47780 [02:28<00:15, 331.27 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42422/47780 [02:28<00:19, 281.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42476/47780 [02:28<00:16, 319.64 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42036/47780 [02:28<00:24, 239.01 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41769/47780 [02:29<00:25, 238.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31780/47780 [02:28<00:43, 366.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42590/47780 [02:29<00:17, 292.08 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42142/47780 [02:29<00:18, 306.24 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42822/47780 [02:29<00:15, 317.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42451/47780 [02:29<00:19, 274.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42510/47780 [02:29<00:16, 312.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42621/47780 [02:29<00:17, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41798/47780 [02:29<00:24, 241.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31818/47780 [02:29<00:44, 357.95 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42061/47780 [02:29<00:25, 222.75 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42855/47780 [02:29<00:15, 317.71 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42174/47780 [02:29<00:18, 300.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42484/47780 [02:29<00:18, 286.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42542/47780 [02:29<00:17, 303.30 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41830/47780 [02:29<00:22, 260.81 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42653/47780 [02:29<00:17, 297.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31857/47780 [02:29<00:45, 351.68 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42091/47780 [02:29<00:24, 235.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42887/47780 [02:29<00:15, 311.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42216/47780 [02:29<00:16, 329.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42516/47780 [02:29<00:18, 288.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42573/47780 [02:29<00:17, 292.56 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41857/47780 [02:29<00:23, 257.06 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42116/47780 [02:29<00:23, 239.25 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42684/47780 [02:29<00:18, 275.99 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42919/47780 [02:29<00:15, 310.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42250/47780 [02:29<00:16, 325.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31893/47780 [02:29<00:48, 325.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42603/47780 [02:29<00:17, 291.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42545/47780 [02:29<00:20, 260.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41884/47780 [02:29<00:23, 252.24 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42721/47780 [02:29<00:16, 301.51 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42141/47780 [02:29<00:24, 234.67 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42288/47780 [02:29<00:16, 333.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42951/47780 [02:29<00:16, 286.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31928/47780 [02:29<00:52, 304.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42634/47780 [02:29<00:17, 296.28 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42602/47780 [02:29<00:15, 339.93 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41912/47780 [02:29<00:23, 246.38 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42758/47780 [02:29<00:15, 314.12 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42171/47780 [02:29<00:22, 247.16 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42322/47780 [02:29<00:16, 326.13 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42993/47780 [02:29<00:14, 320.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31961/47780 [02:29<00:50, 310.63 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42664/47780 [02:29<00:17, 286.43 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42791/47780 [02:29<00:15, 317.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41941/47780 [02:29<00:23, 252.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42638/47780 [02:29<00:16, 314.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42196/47780 [02:29<00:23, 237.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42356/47780 [02:29<00:17, 316.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43027/47780 [02:29<00:14, 318.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31993/47780 [02:29<00:52, 299.36 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42695/47780 [02:29<00:18, 278.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42825/47780 [02:29<00:15, 317.40 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42226/47780 [02:29<00:22, 249.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41967/47780 [02:29<00:24, 241.12 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42674/47780 [02:29<00:16, 309.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42388/47780 [02:29<00:17, 304.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43060/47780 [02:29<00:15, 304.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32024/47780 [02:29<00:52, 299.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42727/47780 [02:29<00:17, 290.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42857/47780 [02:29<00:15, 312.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42252/47780 [02:29<00:22, 244.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41995/47780 [02:29<00:23, 243.94 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42706/47780 [02:29<00:16, 303.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43091/47780 [02:29<00:15, 300.81 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42419/47780 [02:29<00:18, 290.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32059/47780 [02:29<00:50, 312.94 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42758/47780 [02:29<00:18, 276.61 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42889/47780 [02:30<00:16, 293.95 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42278/47780 [02:29<00:22, 248.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43122/47780 [02:29<00:15, 298.34 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42020/47780 [02:30<00:25, 223.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32109/47780 [02:30<00:44, 356.07 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42740/47780 [02:30<00:17, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42449/47780 [02:30<00:19, 266.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42305/47780 [02:30<00:21, 251.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42786/47780 [02:30<00:19, 251.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42043/47780 [02:30<00:25, 222.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32155/47780 [02:30<00:41, 375.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42919/47780 [02:30<00:19, 255.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43153/47780 [02:30<00:17, 270.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42769/47780 [02:30<00:19, 262.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42331/47780 [02:30<00:22, 240.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42812/47780 [02:30<00:20, 239.87 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42477/47780 [02:30<00:23, 223.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42067/47780 [02:30<00:25, 225.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42946/47780 [02:30<00:18, 258.89 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32193/47780 [02:30<00:42, 363.21 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43187/47780 [02:30<00:16, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42796/47780 [02:30<00:19, 257.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42360/47780 [02:30<00:21, 252.13 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42843/47780 [02:30<00:19, 255.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42502/47780 [02:30<00:23, 225.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42100/47780 [02:30<00:22, 251.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42979/47780 [02:30<00:17, 272.30 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43216/47780 [02:30<00:16, 279.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32230/47780 [02:30<00:45, 338.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42823/47780 [02:30<00:20, 240.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42390/47780 [02:30<00:21, 256.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42880/47780 [02:30<00:17, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42526/47780 [02:30<00:24, 218.31 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42126/47780 [02:30<00:23, 237.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43248/47780 [02:30<00:15, 290.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43007/47780 [02:30<00:18, 257.48 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32267/47780 [02:30<00:45, 343.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42851/47780 [02:30<00:19, 248.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42422/47780 [02:30<00:19, 273.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42910/47780 [02:30<00:17, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42157/47780 [02:30<00:22, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42554/47780 [02:30<00:22, 230.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43279/47780 [02:30<00:15, 289.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32314/47780 [02:30<00:41, 374.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43040/47780 [02:30<00:17, 271.08 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42877/47780 [02:30<00:19, 248.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42455/47780 [02:30<00:19, 277.67 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42939/47780 [02:30<00:17, 272.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42185/47780 [02:30<00:21, 259.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42578/47780 [02:30<00:23, 224.72 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43068/47780 [02:30<00:17, 267.53 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43309/47780 [02:30<00:16, 276.83 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32353/47780 [02:30<00:43, 353.17 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42905/47780 [02:30<00:18, 257.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42483/47780 [02:30<00:19, 272.27 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42967/47780 [02:30<00:17, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42216/47780 [02:30<00:20, 270.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42603/47780 [02:30<00:22, 229.23 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43097/47780 [02:30<00:17, 265.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43338/47780 [02:30<00:16, 275.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32394/47780 [02:30<00:42, 358.72 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42931/47780 [02:30<00:19, 254.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42511/47780 [02:30<00:19, 271.71 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42997/47780 [02:30<00:17, 276.98 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42627/47780 [02:30<00:22, 229.55 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42244/47780 [02:30<00:21, 255.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43366/47780 [02:30<00:16, 275.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43128/47780 [02:30<00:17, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42957/47780 [02:30<00:19, 250.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32431/47780 [02:30<00:45, 339.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42545/47780 [02:30<00:18, 287.51 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43025/47780 [02:30<00:17, 271.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43395/47780 [02:30<00:15, 276.42 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42651/47780 [02:31<00:24, 213.13 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43156/47780 [02:31<00:17, 270.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42270/47780 [02:31<00:22, 243.02 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42983/47780 [02:31<00:19, 246.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32476/47780 [02:31<00:41, 368.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42578/47780 [02:31<00:17, 296.36 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43055/47780 [02:31<00:17, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43424/47780 [02:31<00:15, 277.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42298/47780 [02:31<00:21, 250.66 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42675/47780 [02:31<00:23, 218.31 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43184/47780 [02:31<00:18, 250.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43009/47780 [02:31<00:19, 246.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42608/47780 [02:31<00:17, 293.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32514/47780 [02:31<00:46, 331.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43083/47780 [02:31<00:17, 266.33 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42698/47780 [02:31<00:23, 220.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42324/47780 [02:31<00:21, 251.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43455/47780 [02:31<00:16, 267.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42638/47780 [02:31<00:17, 289.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43210/47780 [02:31<00:19, 232.64 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43035/47780 [02:31<00:20, 227.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43116/47780 [02:31<00:16, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32549/47780 [02:31<00:47, 323.10 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42725/47780 [02:31<00:21, 233.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42351/47780 [02:31<00:21, 255.59 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43500/47780 [02:31<00:13, 315.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43237/47780 [02:31<00:18, 242.07 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43065/47780 [02:31<00:19, 244.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42667/47780 [02:31<00:18, 271.59 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32588/47780 [02:31<00:45, 337.10 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43146/47780 [02:31<00:16, 277.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42381/47780 [02:31<00:20, 262.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43533/47780 [02:31<00:13, 309.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42749/47780 [02:31<00:23, 210.69 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43262/47780 [02:31<00:18, 239.88 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43090/47780 [02:31<00:19, 240.15 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42695/47780 [02:31<00:19, 266.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43176/47780 [02:31<00:16, 283.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32623/47780 [02:31<00:45, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42409/47780 [02:31<00:20, 267.35 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42771/47780 [02:31<00:23, 211.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43565/47780 [02:31<00:14, 286.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43115/47780 [02:31<00:19, 242.78 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43294/47780 [02:31<00:17, 253.60 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43206/47780 [02:31<00:16, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32660/47780 [02:31<00:44, 343.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42445/47780 [02:31<00:18, 293.53 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42722/47780 [02:31<00:20, 245.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42797/47780 [02:31<00:22, 217.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43140/47780 [02:31<00:19, 239.50 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43320/47780 [02:31<00:18, 247.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43595/47780 [02:31<00:15, 264.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32695/47780 [02:31<00:44, 337.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43235/47780 [02:31<00:16, 279.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42751/47780 [02:31<00:19, 256.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42480/47780 [02:31<00:17, 300.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42828/47780 [02:31<00:20, 240.08 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43175/47780 [02:31<00:17, 267.83 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43347/47780 [02:31<00:17, 250.81 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43623/47780 [02:31<00:15, 264.07 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32732/47780 [02:31<00:44, 339.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43266/47780 [02:31<00:16, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42511/47780 [02:31<00:17, 302.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42792/47780 [02:31<00:16, 294.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42853/47780 [02:31<00:20, 234.95 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43208/47780 [02:31<00:16, 280.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43373/47780 [02:31<00:17, 248.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32770/47780 [02:31<00:42, 350.14 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43658/47780 [02:31<00:14, 280.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42823/47780 [02:31<00:16, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43294/47780 [02:31<00:16, 266.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42543/47780 [02:32<00:19, 270.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42877/47780 [02:32<00:21, 228.72 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43237/47780 [02:32<00:16, 273.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43400/47780 [02:32<00:17, 246.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43689/47780 [02:32<00:14, 287.97 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32809/47780 [02:32<00:42, 350.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42857/47780 [02:32<00:16, 307.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43321/47780 [02:32<00:17, 254.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42571/47780 [02:32<00:19, 264.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42901/47780 [02:32<00:21, 226.72 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43267/47780 [02:32<00:16, 273.58 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43429/47780 [02:32<00:17, 251.92 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32845/47780 [02:32<00:43, 341.28 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43719/47780 [02:32<00:14, 276.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42888/47780 [02:32<00:16, 300.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43347/47780 [02:32<00:17, 248.23 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42600/47780 [02:32<00:19, 262.88 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42924/47780 [02:32<00:22, 220.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43296/47780 [02:32<00:16, 275.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43462/47780 [02:32<00:15, 273.68 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32889/47780 [02:32<00:40, 365.09 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42919/47780 [02:32<00:16, 290.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43747/47780 [02:32<00:15, 262.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43380/47780 [02:32<00:16, 267.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42627/47780 [02:32<00:20, 256.16 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42947/47780 [02:32<00:22, 218.12 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32927/47780 [02:32<00:40, 365.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43324/47780 [02:32<00:17, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42954/47780 [02:32<00:15, 303.82 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43774/47780 [02:32<00:15, 263.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43408/47780 [02:32<00:16, 271.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43490/47780 [02:32<00:18, 238.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42658/47780 [02:32<00:19, 268.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42969/47780 [02:32<00:22, 211.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32974/47780 [02:32<00:37, 390.93 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42990/47780 [02:32<00:14, 319.71 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43350/47780 [02:32<00:18, 244.99 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43518/47780 [02:32<00:17, 248.46 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43442/47780 [02:32<00:15, 281.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43801/47780 [02:32<00:16, 240.31 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42689/47780 [02:32<00:18, 270.90 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42991/47780 [02:32<00:23, 206.81 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33026/47780 [02:32<00:34, 427.97 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43031/47780 [02:32<00:14, 337.92 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43381/47780 [02:32<00:16, 260.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43473/47780 [02:32<00:15, 284.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43545/47780 [02:32<00:17, 243.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43842/47780 [02:32<00:14, 280.06 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42721/47780 [02:32<00:18, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33076/47780 [02:32<00:33, 443.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43410/47780 [02:32<00:16, 268.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43067/47780 [02:32<00:14, 336.50 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43012/47780 [02:32<00:25, 187.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43505/47780 [02:32<00:14, 288.47 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43571/47780 [02:32<00:17, 244.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43872/47780 [02:32<00:13, 280.49 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42749/47780 [02:32<00:19, 256.70 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33121/47780 [02:32<00:34, 420.45 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43033/47780 [02:32<00:24, 192.88 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43438/47780 [02:32<00:16, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43597/47780 [02:32<00:16, 247.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43102/47780 [02:32<00:15, 310.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43534/47780 [02:32<00:15, 271.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43902/47780 [02:32<00:14, 262.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42778/47780 [02:32<00:18, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33184/47780 [02:32<00:30, 475.05 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43053/47780 [02:32<00:24, 192.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43472/47780 [02:32<00:15, 277.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43623/47780 [02:32<00:16, 247.94 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43562/47780 [02:32<00:15, 266.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43134/47780 [02:32<00:16, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43929/47780 [02:32<00:15, 253.67 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42807/47780 [02:33<00:18, 271.41 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43076/47780 [02:33<00:23, 196.68 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43503/47780 [02:33<00:15, 283.15 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33233/47780 [02:33<00:32, 447.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43660/47780 [02:33<00:14, 279.56 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43165/47780 [02:33<00:15, 291.83 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43592/47780 [02:33<00:15, 263.08 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43960/47780 [02:33<00:14, 263.98 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42843/47780 [02:33<00:16, 293.03 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43532/47780 [02:33<00:15, 278.85 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43100/47780 [02:33<00:22, 207.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43689/47780 [02:33<00:14, 276.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33279/47780 [02:33<00:35, 411.07 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43623/47780 [02:33<00:15, 270.86 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43199/47780 [02:33<00:15, 297.66 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42879/47780 [02:33<00:15, 308.45 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43987/47780 [02:33<00:15, 252.83 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43123/47780 [02:33<00:21, 212.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43561/47780 [02:33<00:15, 266.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43718/47780 [02:33<00:15, 266.61 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33321/47780 [02:33<00:37, 388.74 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43232/47780 [02:33<00:15, 294.99 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43651/47780 [02:33<00:15, 258.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44013/47780 [02:33<00:15, 250.71 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42911/47780 [02:33<00:16, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43148/47780 [02:33<00:20, 222.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43591/47780 [02:33<00:15, 269.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43757/47780 [02:33<00:13, 296.55 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43264/47780 [02:33<00:15, 291.59 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43677/47780 [02:33<00:16, 248.02 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33362/47780 [02:33<00:40, 360.40 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42948/47780 [02:33<00:15, 307.91 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43185/47780 [02:33<00:17, 262.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44039/47780 [02:33<00:15, 241.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43620/47780 [02:33<00:15, 270.18 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43787/47780 [02:33<00:13, 290.57 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33399/47780 [02:33<00:40, 352.08 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43707/47780 [02:33<00:16, 248.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43294/47780 [02:33<00:16, 271.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44071/47780 [02:33<00:14, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42980/47780 [02:33<00:16, 296.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43212/47780 [02:33<00:18, 245.36 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43648/47780 [02:33<00:15, 261.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43818/47780 [02:33<00:14, 271.76 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43322/47780 [02:33<00:16, 273.80 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43733/47780 [02:33<00:16, 246.16 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33435/47780 [02:33<00:41, 341.97 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43024/47780 [02:33<00:14, 334.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44098/47780 [02:33<00:14, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43683/47780 [02:33<00:14, 282.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43238/47780 [02:33<00:19, 231.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43847/47780 [02:33<00:14, 270.33 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43350/47780 [02:33<00:16, 273.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43762/47780 [02:33<00:15, 257.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33488/47780 [02:33<00:36, 389.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44128/47780 [02:33<00:13, 265.82 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43058/47780 [02:33<00:15, 304.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43262/47780 [02:33<00:20, 222.39 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43876/47780 [02:33<00:14, 274.48 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43712/47780 [02:33<00:15, 258.09 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43789/47780 [02:33<00:15, 256.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44159/47780 [02:33<00:13, 272.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33528/47780 [02:33<00:38, 371.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43378/47780 [02:33<00:18, 240.59 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43286/47780 [02:33<00:20, 221.90 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43090/47780 [02:33<00:16, 284.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43905/47780 [02:33<00:14, 271.02 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43815/47780 [02:33<00:15, 256.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44189/47780 [02:33<00:12, 279.84 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43739/47780 [02:33<00:17, 233.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33573/47780 [02:33<00:36, 384.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43407/47780 [02:33<00:17, 253.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43312/47780 [02:34<00:20, 222.55 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43120/47780 [02:34<00:16, 278.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43933/47780 [02:34<00:14, 264.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43841/47780 [02:34<00:15, 251.38 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44220/47780 [02:34<00:12, 280.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33613/47780 [02:34<00:36, 388.59 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43763/47780 [02:34<00:18, 216.46 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43442/47780 [02:34<00:16, 265.24 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43335/47780 [02:34<00:19, 222.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43149/47780 [02:34<00:16, 273.82 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43961/47780 [02:34<00:14, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43868/47780 [02:34<00:15, 254.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44251/47780 [02:34<00:12, 287.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33654/47780 [02:34<00:36, 390.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43802/47780 [02:34<00:15, 258.88 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43469/47780 [02:34<00:17, 253.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43358/47780 [02:34<00:19, 223.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43894/47780 [02:34<00:15, 253.40 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43989/47780 [02:34<00:15, 252.69 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44285/47780 [02:34<00:11, 302.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43177/47780 [02:34<00:18, 253.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33694/47780 [02:34<00:37, 372.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43830/47780 [02:34<00:15, 255.70 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43509/47780 [02:34<00:14, 290.28 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43384/47780 [02:34<00:18, 232.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44018/47780 [02:34<00:14, 262.92 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43205/47780 [02:34<00:17, 258.58 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43920/47780 [02:34<00:16, 238.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44317/47780 [02:34<00:11, 290.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33733/47780 [02:34<00:40, 342.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43857/47780 [02:34<00:16, 244.60 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43416/47780 [02:34<00:17, 253.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43539/47780 [02:34<00:15, 280.12 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44046/47780 [02:34<00:14, 253.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43952/47780 [02:34<00:14, 259.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44347/47780 [02:34<00:12, 284.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43233/47780 [02:34<00:18, 244.08 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33770/47780 [02:34<00:40, 346.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43446/47780 [02:34<00:16, 263.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43569/47780 [02:34<00:15, 278.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43883/47780 [02:34<00:17, 224.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43986/47780 [02:34<00:13, 281.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44080/47780 [02:34<00:13, 268.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44379/47780 [02:34<00:11, 287.62 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43258/47780 [02:34<00:19, 229.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33812/47780 [02:34<00:38, 358.50 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43474/47780 [02:34<00:16, 265.29 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43598/47780 [02:34<00:15, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44016/47780 [02:34<00:13, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44111/47780 [02:34<00:13, 279.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43907/47780 [02:34<00:18, 211.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44408/47780 [02:34<00:12, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43289/47780 [02:34<00:18, 245.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33849/47780 [02:34<00:39, 356.94 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43501/47780 [02:34<00:17, 249.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43625/47780 [02:34<00:16, 254.79 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43930/47780 [02:34<00:17, 213.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44045/47780 [02:34<00:14, 266.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44140/47780 [02:34<00:14, 258.77 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33886/47780 [02:34<00:38, 357.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44436/47780 [02:34<00:13, 256.58 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43314/47780 [02:34<00:19, 231.12 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43658/47780 [02:34<00:15, 268.63 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43527/47780 [02:34<00:18, 228.06 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43965/47780 [02:34<00:15, 247.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44078/47780 [02:34<00:13, 281.87 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33923/47780 [02:34<00:39, 354.28 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43345/47780 [02:34<00:17, 250.24 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44168/47780 [02:34<00:15, 238.20 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44462/47780 [02:34<00:13, 237.99 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43686/47780 [02:34<00:15, 271.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44000/47780 [02:35<00:13, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44107/47780 [02:35<00:13, 271.97 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43551/47780 [02:35<00:19, 212.60 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33959/47780 [02:35<00:40, 344.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43371/47780 [02:35<00:17, 247.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44195/47780 [02:35<00:14, 239.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44492/47780 [02:35<00:13, 248.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43719/47780 [02:35<00:14, 278.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44029/47780 [02:35<00:14, 266.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44135/47780 [02:35<00:13, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43586/47780 [02:35<00:17, 246.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33997/47780 [02:35<00:38, 353.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43398/47780 [02:35<00:18, 241.04 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44518/47780 [02:35<00:13, 246.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44221/47780 [02:35<00:15, 228.50 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44165/47780 [02:35<00:13, 273.49 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43612/47780 [02:35<00:16, 246.06 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43747/47780 [02:35<00:16, 250.96 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44059/47780 [02:35<00:14, 258.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34037/47780 [02:35<00:37, 366.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44245/47780 [02:35<00:15, 222.60 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44543/47780 [02:35<00:13, 232.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43423/47780 [02:35<00:19, 222.40 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44193/47780 [02:35<00:13, 275.04 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43773/47780 [02:35<00:15, 250.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43638/47780 [02:35<00:16, 244.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44087/47780 [02:35<00:14, 249.71 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34075/47780 [02:35<00:38, 357.76 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44268/47780 [02:35<00:15, 219.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44571/47780 [02:35<00:13, 240.24 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43446/47780 [02:35<00:20, 214.21 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44222/47780 [02:35<00:12, 274.00 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43663/47780 [02:35<00:17, 233.20 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43799/47780 [02:35<00:17, 233.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34112/47780 [02:35<00:39, 344.94 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44115/47780 [02:35<00:15, 235.14 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44604/47780 [02:35<00:12, 262.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44291/47780 [02:35<00:15, 219.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44250/47780 [02:35<00:13, 271.25 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43468/47780 [02:35<00:20, 207.09 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43830/47780 [02:35<00:15, 251.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43687/47780 [02:35<00:18, 225.23 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34153/47780 [02:35<00:37, 362.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44139/47780 [02:35<00:15, 235.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44318/47780 [02:35<00:15, 230.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44281/47780 [02:35<00:12, 280.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43491/47780 [02:35<00:20, 206.59 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44631/47780 [02:35<00:13, 239.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43856/47780 [02:35<00:15, 252.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34196/47780 [02:35<00:35, 378.65 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43728/47780 [02:35<00:15, 266.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44164/47780 [02:35<00:16, 221.55 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44343/47780 [02:35<00:15, 222.97 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43514/47780 [02:35<00:20, 206.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44310/47780 [02:35<00:13, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43890/47780 [02:35<00:14, 277.02 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44656/47780 [02:35<00:13, 227.77 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34235/47780 [02:35<00:35, 381.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43757/47780 [02:35<00:14, 270.21 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44370/47780 [02:35<00:14, 230.97 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44187/47780 [02:35<00:17, 207.66 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43539/47780 [02:35<00:19, 215.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44680/47780 [02:35<00:13, 228.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44337/47780 [02:35<00:13, 251.45 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43919/47780 [02:35<00:14, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34280/47780 [02:35<00:34, 394.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43790/47780 [02:35<00:13, 285.23 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44211/47780 [02:35<00:16, 215.95 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44403/47780 [02:36<00:13, 253.82 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43562/47780 [02:36<00:19, 219.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44704/47780 [02:35<00:13, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34329/47780 [02:36<00:32, 410.86 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43947/47780 [02:35<00:14, 260.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44364/47780 [02:36<00:14, 240.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43819/47780 [02:36<00:14, 266.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44233/47780 [02:36<00:16, 214.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43599/47780 [02:36<00:16, 259.44 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44429/47780 [02:36<00:14, 237.52 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34372/47780 [02:36<00:32, 411.58 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43982/47780 [02:36<00:13, 282.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44735/47780 [02:36<00:13, 233.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44391/47780 [02:36<00:13, 242.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43847/47780 [02:36<00:15, 259.21 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44258/47780 [02:36<00:16, 217.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43627/47780 [02:36<00:16, 259.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44457/47780 [02:36<00:13, 240.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34417/47780 [02:36<00:32, 413.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44012/47780 [02:36<00:13, 280.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44769/47780 [02:36<00:11, 256.47 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44418/47780 [02:36<00:13, 243.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43874/47780 [02:36<00:16, 243.58 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44282/47780 [02:36<00:15, 222.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43654/47780 [02:36<00:16, 256.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44482/47780 [02:36<00:13, 238.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34464/47780 [02:36<00:31, 429.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44043/47780 [02:36<00:13, 286.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44797/47780 [02:36<00:11, 259.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44443/47780 [02:36<00:13, 244.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44305/47780 [02:36<00:16, 215.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43682/47780 [02:36<00:15, 263.20 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43899/47780 [02:36<00:16, 228.31 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34510/47780 [02:36<00:30, 437.98 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44082/47780 [02:36<00:11, 314.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44507/47780 [02:36<00:14, 228.85 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44832/47780 [02:36<00:10, 281.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44474/47780 [02:36<00:12, 259.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43711/47780 [02:36<00:15, 268.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44329/47780 [02:36<00:15, 217.20 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43923/47780 [02:36<00:17, 225.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34561/47780 [02:36<00:29, 454.28 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44124/47780 [02:36<00:10, 341.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44534/47780 [02:36<00:13, 239.95 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44870/47780 [02:36<00:09, 305.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44506/47780 [02:36<00:11, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44354/47780 [02:36<00:15, 225.42 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43740/47780 [02:36<00:15, 268.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43946/47780 [02:36<00:17, 222.99 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34609/47780 [02:36<00:28, 461.68 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44166/47780 [02:36<00:09, 364.49 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44560/47780 [02:36<00:13, 243.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44902/47780 [02:36<00:09, 307.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44534/47780 [02:36<00:12, 269.57 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44382/47780 [02:36<00:14, 234.58 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34660/47780 [02:36<00:27, 475.40 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44211/47780 [02:36<00:09, 385.48 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43969/47780 [02:36<00:18, 211.59 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44587/47780 [02:36<00:12, 246.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44942/47780 [02:36<00:08, 333.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43767/47780 [02:36<00:16, 240.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44563/47780 [02:36<00:13, 244.23 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44411/47780 [02:36<00:13, 244.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34708/47780 [02:36<00:28, 460.93 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43995/47780 [02:36<00:17, 221.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44613/47780 [02:36<00:12, 245.80 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44976/47780 [02:36<00:08, 323.76 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44252/47780 [02:36<00:09, 357.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43793/47780 [02:36<00:17, 227.08 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44590/47780 [02:36<00:12, 247.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44440/47780 [02:36<00:13, 251.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34762/47780 [02:36<00:26, 483.57 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44024/47780 [02:36<00:15, 240.17 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44651/47780 [02:36<00:11, 282.71 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45010/47780 [02:36<00:08, 325.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43817/47780 [02:37<00:17, 226.34 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44616/47780 [02:37<00:12, 247.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44289/47780 [02:36<00:11, 308.86 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34811/47780 [02:37<00:27, 480.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44049/47780 [02:37<00:16, 232.18 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45043/47780 [02:37<00:08, 324.64 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44466/47780 [02:37<00:14, 225.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44680/47780 [02:37<00:11, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43840/47780 [02:37<00:18, 212.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44642/47780 [02:37<00:12, 244.97 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34867/47780 [02:37<00:25, 502.70 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44326/47780 [02:37<00:11, 307.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44497/47780 [02:37<00:13, 247.83 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44711/47780 [02:37<00:11, 275.42 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45076/47780 [02:37<00:08, 306.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44073/47780 [02:37<00:17, 215.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43863/47780 [02:37<00:18, 216.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44674/47780 [02:37<00:11, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34918/47780 [02:37<00:26, 493.78 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44359/47780 [02:37<00:11, 307.21 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44739/47780 [02:37<00:11, 269.32 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44523/47780 [02:37<00:13, 238.03 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44095/47780 [02:37<00:18, 203.50 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45107/47780 [02:37<00:09, 282.07 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43892/47780 [02:37<00:16, 230.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44701/47780 [02:37<00:12, 249.98 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34977/47780 [02:37<00:24, 518.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44395/47780 [02:37<00:10, 314.22 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44119/47780 [02:37<00:17, 210.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44548/47780 [02:37<00:14, 224.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45137/47780 [02:37<00:09, 284.37 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43919/47780 [02:37<00:16, 240.25 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44767/47780 [02:37<00:12, 246.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35039/47780 [02:37<00:23, 545.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44728/47780 [02:37<00:12, 249.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44432/47780 [02:37<00:10, 325.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44146/47780 [02:37<00:16, 224.43 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43947/47780 [02:37<00:15, 249.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44571/47780 [02:37<00:14, 218.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44793/47780 [02:37<00:12, 240.95 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44760/47780 [02:37<00:11, 267.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35094/47780 [02:37<00:24, 522.02 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45166/47780 [02:37<00:10, 249.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44466/47780 [02:37<00:10, 303.19 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44597/47780 [02:37<00:13, 228.22 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44177/47780 [02:37<00:14, 240.72 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43976/47780 [02:37<00:15, 245.96 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44788/47780 [02:37<00:11, 263.95 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35147/47780 [02:37<00:24, 524.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44818/47780 [02:37<00:13, 221.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45193/47780 [02:37<00:10, 252.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44497/47780 [02:37<00:10, 302.97 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44203/47780 [02:37<00:14, 243.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44011/47780 [02:37<00:13, 272.51 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44632/47780 [02:37<00:12, 244.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35200/47780 [02:37<00:24, 519.39 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45220/47780 [02:37<00:10, 252.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44815/47780 [02:37<00:12, 243.69 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44842/47780 [02:37<00:14, 206.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44529/47780 [02:37<00:10, 299.77 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44228/47780 [02:37<00:14, 241.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44049/47780 [02:37<00:12, 295.39 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44657/47780 [02:37<00:13, 240.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35254/47780 [02:37<00:24, 503.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45246/47780 [02:37<00:11, 229.16 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44840/47780 [02:37<00:13, 220.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44865/47780 [02:37<00:14, 195.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44254/47780 [02:37<00:14, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44560/47780 [02:37<00:11, 272.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44683/47780 [02:38<00:12, 241.72 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35307/47780 [02:38<00:24, 500.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44079/47780 [02:38<00:14, 261.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45271/47780 [02:38<00:11, 223.21 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44281/47780 [02:38<00:14, 249.34 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44863/47780 [02:38<00:13, 215.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44895/47780 [02:38<00:13, 218.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44588/47780 [02:38<00:12, 260.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44709/47780 [02:38<00:12, 245.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35358/47780 [02:38<00:25, 489.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44107/47780 [02:38<00:14, 261.52 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44923/47780 [02:38<00:12, 234.56 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45295/47780 [02:38<00:11, 222.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44307/47780 [02:38<00:14, 241.42 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44885/47780 [02:38<00:14, 206.35 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44615/47780 [02:38<00:12, 254.60 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44735/47780 [02:38<00:12, 235.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35410/47780 [02:38<00:25, 492.52 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44333/47780 [02:38<00:14, 244.73 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45319/47780 [02:38<00:11, 215.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44953/47780 [02:38<00:11, 238.20 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44134/47780 [02:38<00:16, 225.11 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44906/47780 [02:38<00:14, 203.44 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44644/47780 [02:38<00:12, 260.60 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44762/47780 [02:38<00:12, 243.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35476/47780 [02:38<00:23, 533.54 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44978/47780 [02:38<00:11, 241.35 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45341/47780 [02:38<00:11, 211.13 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44928/47780 [02:38<00:14, 202.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44672/47780 [02:38<00:11, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44358/47780 [02:38<00:15, 224.78 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44158/47780 [02:38<00:16, 213.14 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35536/47780 [02:38<00:22, 542.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44787/47780 [02:38<00:13, 226.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45004/47780 [02:38<00:11, 244.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44954/47780 [02:38<00:13, 215.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44383/47780 [02:38<00:14, 226.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44699/47780 [02:38<00:12, 246.82 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35596/47780 [02:38<00:22, 551.92 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44810/47780 [02:38<00:13, 222.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44181/47780 [02:38<00:17, 201.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45363/47780 [02:38<00:13, 180.57 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44406/47780 [02:38<00:15, 220.33 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44724/47780 [02:38<00:12, 243.36 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45029/47780 [02:38<00:12, 214.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35662/47780 [02:38<00:21, 563.77 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44976/47780 [02:38<00:14, 190.25 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44206/47780 [02:38<00:17, 209.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44834/47780 [02:38<00:13, 217.73 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45382/47780 [02:38<00:14, 169.39 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44429/47780 [02:38<00:15, 211.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45000/47780 [02:38<00:13, 202.78 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35719/47780 [02:38<00:21, 548.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44749/47780 [02:38<00:13, 229.03 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44234/47780 [02:38<00:16, 218.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44860/47780 [02:38<00:13, 222.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45052/47780 [02:38<00:14, 194.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45400/47780 [02:38<00:14, 158.70 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45021/47780 [02:38<00:13, 202.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44773/47780 [02:38<00:13, 230.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35774/47780 [02:38<00:22, 529.88 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44451/47780 [02:38<00:16, 204.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44266/47780 [02:38<00:14, 242.93 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44884/47780 [02:38<00:13, 221.92 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45074/47780 [02:38<00:13, 194.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45417/47780 [02:38<00:15, 156.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45052/47780 [02:38<00:11, 227.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35828/47780 [02:38<00:22, 530.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44797/47780 [02:38<00:13, 226.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44472/47780 [02:38<00:16, 199.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44907/47780 [02:39<00:13, 219.00 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44292/47780 [02:39<00:15, 229.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45098/47780 [02:39<00:13, 200.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45435/47780 [02:39<00:14, 160.84 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35883/47780 [02:39<00:22, 532.83 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45077/47780 [02:39<00:11, 225.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44506/47780 [02:39<00:13, 236.91 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44824/47780 [02:39<00:12, 234.11 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44929/47780 [02:39<00:13, 208.15 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44316/47780 [02:39<00:15, 226.71 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45124/47780 [02:39<00:12, 212.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45456/47780 [02:39<00:13, 172.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35940/47780 [02:39<00:22, 535.99 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44855/47780 [02:39<00:11, 254.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44537/47780 [02:39<00:12, 254.17 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45101/47780 [02:39<00:12, 211.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45147/47780 [02:39<00:12, 213.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44340/47780 [02:39<00:15, 226.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44950/47780 [02:39<00:14, 193.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45474/47780 [02:39<00:14, 160.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44881/47780 [02:39<00:11, 248.41 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35994/47780 [02:39<00:23, 501.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45123/47780 [02:39<00:12, 208.27 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44566/47780 [02:39<00:13, 243.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44365/47780 [02:39<00:15, 221.81 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45169/47780 [02:39<00:12, 205.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44973/47780 [02:39<00:14, 197.15 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44906/47780 [02:39<00:12, 238.16 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45145/47780 [02:39<00:12, 209.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44603/47780 [02:39<00:11, 269.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36045/47780 [02:39<00:25, 455.92 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45491/47780 [02:39<00:16, 138.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45190/47780 [02:39<00:12, 199.38 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44388/47780 [02:39<00:16, 207.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44993/47780 [02:39<00:14, 186.02 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45168/47780 [02:39<00:12, 214.24 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44931/47780 [02:39<00:12, 230.39 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44631/47780 [02:39<00:11, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36097/47780 [02:39<00:24, 472.11 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45507/47780 [02:39<00:15, 143.11 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45211/47780 [02:39<00:13, 197.22 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44411/47780 [02:39<00:16, 209.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45012/47780 [02:39<00:15, 181.28 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45192/47780 [02:39<00:11, 220.81 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44955/47780 [02:39<00:12, 223.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45524/47780 [02:39<00:15, 148.92 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44660/47780 [02:39<00:12, 252.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36146/47780 [02:39<00:26, 445.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45233/47780 [02:39<00:12, 202.20 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44438/47780 [02:39<00:14, 225.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45036/47780 [02:39<00:14, 190.79 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45218/47780 [02:39<00:11, 220.00 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45542/47780 [02:39<00:14, 156.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44686/47780 [02:39<00:12, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44978/47780 [02:39<00:13, 212.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36195/47780 [02:39<00:25, 453.73 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44461/47780 [02:39<00:15, 220.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45255/47780 [02:39<00:12, 200.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45056/47780 [02:39<00:14, 189.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45242/47780 [02:39<00:11, 222.56 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45566/47780 [02:39<00:12, 178.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45002/47780 [02:39<00:12, 215.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36241/47780 [02:39<00:25, 446.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45277/47780 [02:39<00:12, 202.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44713/47780 [02:39<00:13, 233.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45083/47780 [02:39<00:12, 209.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44484/47780 [02:39<00:15, 208.25 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45265/47780 [02:39<00:11, 224.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45587/47780 [02:39<00:11, 187.23 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45301/47780 [02:40<00:11, 213.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45028/47780 [02:39<00:12, 219.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36287/47780 [02:40<00:28, 408.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45107/47780 [02:40<00:13, 203.84 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44506/47780 [02:40<00:16, 198.25 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45609/47780 [02:40<00:11, 193.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44738/47780 [02:40<00:14, 206.04 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45051/47780 [02:40<00:12, 222.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45289/47780 [02:40<00:12, 205.34 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45325/47780 [02:40<00:11, 216.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36329/47780 [02:40<00:28, 407.05 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44531/47780 [02:40<00:15, 210.93 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45129/47780 [02:40<00:13, 199.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45629/47780 [02:40<00:11, 185.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44760/47780 [02:40<00:15, 198.32 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45075/47780 [02:40<00:12, 224.51 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45349/47780 [02:40<00:11, 220.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36372/47780 [02:40<00:28, 404.75 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44557/47780 [02:40<00:14, 220.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45311/47780 [02:40<00:13, 176.60 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45156/47780 [02:40<00:12, 215.68 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45373/47780 [02:40<00:10, 225.92 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45648/47780 [02:40<00:11, 178.49 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44782/47780 [02:40<00:15, 196.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45098/47780 [02:40<00:12, 206.51 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44586/47780 [02:40<00:13, 237.65 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45178/47780 [02:40<00:12, 215.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36414/47780 [02:40<00:30, 368.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45332/47780 [02:40<00:13, 181.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44803/47780 [02:40<00:15, 194.75 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45667/47780 [02:40<00:12, 170.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45396/47780 [02:40<00:11, 208.58 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45125/47780 [02:40<00:12, 216.95 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44611/47780 [02:40<00:13, 237.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36453/47780 [02:40<00:30, 373.81 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45359/47780 [02:40<00:11, 202.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45200/47780 [02:40<00:12, 204.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44825/47780 [02:40<00:14, 200.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45419/47780 [02:40<00:11, 213.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45685/47780 [02:40<00:13, 155.08 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45148/47780 [02:40<00:12, 204.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36491/47780 [02:40<00:30, 372.11 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44640/47780 [02:40<00:12, 242.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45381/47780 [02:40<00:12, 199.86 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45221/47780 [02:40<00:12, 197.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44847/47780 [02:40<00:14, 198.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45441/47780 [02:40<00:11, 205.86 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45169/47780 [02:40<00:12, 205.93 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45702/47780 [02:40<00:13, 155.87 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36529/47780 [02:40<00:30, 369.00 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44665/47780 [02:40<00:13, 231.77 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45403/47780 [02:40<00:12, 197.95 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45241/47780 [02:40<00:13, 184.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44868/47780 [02:40<00:14, 195.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45722/47780 [02:40<00:12, 167.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45195/47780 [02:40<00:11, 216.98 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45462/47780 [02:40<00:12, 189.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36567/47780 [02:40<00:30, 366.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44689/47780 [02:40<00:13, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45425/47780 [02:40<00:12, 189.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45267/47780 [02:40<00:12, 202.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44888/47780 [02:40<00:15, 189.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45741/47780 [02:40<00:11, 171.08 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45482/47780 [02:40<00:12, 190.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36604/47780 [02:40<00:30, 361.29 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45219/47780 [02:40<00:11, 213.99 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45445/47780 [02:40<00:12, 191.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45288/47780 [02:40<00:12, 204.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44712/47780 [02:40<00:14, 208.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44908/47780 [02:40<00:15, 188.35 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45765/47780 [02:40<00:10, 189.95 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36648/47780 [02:40<00:29, 377.99 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45247/47780 [02:40<00:11, 229.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45508/47780 [02:41<00:11, 197.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45467/47780 [02:41<00:11, 197.27 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45313/47780 [02:41<00:11, 214.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44738/47780 [02:41<00:14, 215.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44938/47780 [02:41<00:13, 208.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36688/47780 [02:41<00:28, 383.61 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45274/47780 [02:41<00:10, 233.09 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45532/47780 [02:41<00:11, 202.01 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45488/47780 [02:41<00:11, 197.53 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45785/47780 [02:41<00:12, 165.06 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45338/47780 [02:41<00:11, 217.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44764/47780 [02:41<00:13, 222.30 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44963/47780 [02:41<00:12, 218.59 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36728/47780 [02:41<00:28, 386.09 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45554/47780 [02:41<00:10, 206.58 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45298/47780 [02:41<00:11, 220.29 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45363/47780 [02:41<00:10, 226.48 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45508/47780 [02:41<00:11, 189.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45803/47780 [02:41<00:12, 162.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44799/47780 [02:41<00:11, 255.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44987/47780 [02:41<00:12, 222.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36768/47780 [02:41<00:29, 372.56 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45576/47780 [02:41<00:10, 209.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45528/47780 [02:41<00:11, 192.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45387/47780 [02:41<00:10, 224.86 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45321/47780 [02:41<00:11, 207.60 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45823/47780 [02:41<00:11, 168.93 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44825/47780 [02:41<00:11, 254.46 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45010/47780 [02:41<00:13, 209.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36809/47780 [02:41<00:29, 375.02 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45598/47780 [02:41<00:10, 200.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45346/47780 [02:41<00:11, 218.45 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45413/47780 [02:41<00:10, 229.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44861/47780 [02:41<00:10, 284.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45549/47780 [02:41<00:12, 185.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45846/47780 [02:41<00:11, 174.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45032/47780 [02:41<00:12, 212.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36853/47780 [02:41<00:27, 391.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45619/47780 [02:41<00:10, 198.64 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45374/47780 [02:41<00:10, 233.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45442/47780 [02:41<00:09, 246.39 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44890/47780 [02:41<00:10, 274.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45570/47780 [02:41<00:12, 178.07 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45864/47780 [02:41<00:11, 166.34 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45054/47780 [02:41<00:12, 210.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36897/47780 [02:41<00:27, 402.37 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45639/47780 [02:41<00:11, 193.19 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45400/47780 [02:41<00:09, 240.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45467/47780 [02:41<00:09, 240.58 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44925/47780 [02:41<00:09, 290.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45883/47780 [02:41<00:11, 169.03 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45600/47780 [02:41<00:10, 202.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36948/47780 [02:41<00:25, 431.08 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45080/47780 [02:41<00:12, 216.11 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45429/47780 [02:41<00:09, 251.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45659/47780 [02:41<00:11, 189.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45492/47780 [02:41<00:09, 236.42 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44959/47780 [02:41<00:09, 298.72 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45625/47780 [02:41<00:10, 215.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45901/47780 [02:41<00:11, 167.30 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36993/47780 [02:41<00:25, 427.52 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45108/47780 [02:41<00:11, 229.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45466/47780 [02:41<00:08, 279.23 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45684/47780 [02:41<00:10, 203.15 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45516/47780 [02:41<00:09, 227.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44991/47780 [02:41<00:09, 291.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45655/47780 [02:41<00:09, 235.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45926/47780 [02:41<00:09, 189.18 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37044/47780 [02:41<00:23, 449.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45141/47780 [02:41<00:10, 255.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45709/47780 [02:42<00:09, 214.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45497/47780 [02:41<00:08, 280.83 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45024/47780 [02:42<00:09, 301.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45540/47780 [02:42<00:09, 224.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45681/47780 [02:42<00:08, 237.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45171/47780 [02:42<00:09, 267.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45947/47780 [02:42<00:09, 184.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37091/47780 [02:42<00:24, 437.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45526/47780 [02:42<00:08, 280.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45563/47780 [02:42<00:09, 224.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45058/47780 [02:42<00:08, 304.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45731/47780 [02:42<00:10, 194.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45712/47780 [02:42<00:08, 246.80 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45975/47780 [02:42<00:08, 208.34 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37158/47780 [02:42<00:21, 494.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45198/47780 [02:42<00:10, 255.60 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45555/47780 [02:42<00:08, 274.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45091/47780 [02:42<00:08, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45599/47780 [02:42<00:08, 256.27 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45757/47780 [02:42<00:09, 209.61 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45741/47780 [02:42<00:07, 258.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37215/47780 [02:42<00:20, 514.61 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45997/47780 [02:42<00:08, 202.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45224/47780 [02:42<00:10, 241.53 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45588/47780 [02:42<00:07, 282.04 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45780/47780 [02:42<00:09, 213.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45627/47780 [02:42<00:08, 256.88 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45128/47780 [02:42<00:08, 317.11 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37274/47780 [02:42<00:19, 536.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45767/47780 [02:42<00:08, 242.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46019/47780 [02:42<00:09, 192.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45249/47780 [02:42<00:10, 234.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45808/47780 [02:42<00:08, 231.35 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45619/47780 [02:42<00:08, 266.92 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45167/47780 [02:42<00:07, 327.83 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45665/47780 [02:42<00:07, 274.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37328/47780 [02:42<00:19, 522.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45792/47780 [02:42<00:08, 239.78 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45285/47780 [02:42<00:09, 266.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46039/47780 [02:42<00:09, 185.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45832/47780 [02:42<00:08, 228.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45202/47780 [02:42<00:07, 330.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45647/47780 [02:42<00:08, 263.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45696/47780 [02:42<00:07, 283.35 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37388/47780 [02:42<00:19, 543.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45818/47780 [02:42<00:08, 241.23 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45313/47780 [02:42<00:09, 260.35 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46058/47780 [02:42<00:09, 183.92 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45857/47780 [02:42<00:08, 233.82 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45729/47780 [02:42<00:07, 292.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45682/47780 [02:42<00:07, 276.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45236/47780 [02:42<00:08, 314.19 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37444/47780 [02:42<00:19, 520.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45848/47780 [02:42<00:07, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45340/47780 [02:42<00:09, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46087/47780 [02:42<00:08, 207.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45884/47780 [02:42<00:07, 244.01 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45714/47780 [02:42<00:07, 284.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45268/47780 [02:42<00:08, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45759/47780 [02:42<00:07, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45876/47780 [02:42<00:07, 258.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37497/47780 [02:42<00:20, 500.31 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45912/47780 [02:42<00:07, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46109/47780 [02:42<00:08, 191.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45371/47780 [02:42<00:09, 242.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45743/47780 [02:42<00:07, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45301/47780 [02:42<00:08, 304.09 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37553/47780 [02:42<00:20, 509.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45787/47780 [02:42<00:07, 261.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45902/47780 [02:42<00:07, 239.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45938/47780 [02:42<00:07, 252.04 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45398/47780 [02:42<00:09, 240.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45771/47780 [02:42<00:07, 276.58 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45335/47780 [02:43<00:07, 307.65 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46133/47780 [02:42<00:08, 187.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37611/47780 [02:43<00:19, 528.97 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45933/47780 [02:43<00:07, 257.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45815/47780 [02:43<00:07, 249.86 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45964/47780 [02:43<00:08, 223.91 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45429/47780 [02:43<00:09, 249.96 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45368/47780 [02:43<00:07, 312.58 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46152/47780 [02:43<00:08, 186.43 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45800/47780 [02:43<00:07, 261.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37672/47780 [02:43<00:18, 550.59 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45960/47780 [02:43<00:07, 236.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45841/47780 [02:43<00:08, 221.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45990/47780 [02:43<00:07, 229.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45401/47780 [02:43<00:07, 314.56 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45457/47780 [02:43<00:09, 249.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46171/47780 [02:43<00:08, 182.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45827/47780 [02:43<00:07, 255.34 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37728/47780 [02:43<00:19, 527.73 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45990/47780 [02:43<00:07, 238.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46017/47780 [02:43<00:07, 238.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45864/47780 [02:43<00:08, 215.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45494/47780 [02:43<00:08, 281.64 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46194/47780 [02:43<00:08, 195.36 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45442/47780 [02:43<00:07, 330.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45855/47780 [02:43<00:07, 261.75 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37782/47780 [02:43<00:19, 503.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46015/47780 [02:43<00:07, 233.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46042/47780 [02:43<00:07, 233.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45890/47780 [02:43<00:08, 217.88 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45480/47780 [02:43<00:06, 343.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46215/47780 [02:43<00:08, 195.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45882/47780 [02:43<00:07, 259.73 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45523/47780 [02:43<00:08, 257.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37833/47780 [02:43<00:20, 489.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46039/47780 [02:43<00:07, 232.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46066/47780 [02:43<00:07, 226.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45913/47780 [02:43<00:08, 215.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46236/47780 [02:43<00:07, 195.82 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45515/47780 [02:43<00:06, 324.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37892/47780 [02:43<00:19, 517.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45909/47780 [02:43<00:07, 240.53 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45551/47780 [02:43<00:09, 235.49 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46065/47780 [02:43<00:07, 237.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46257/47780 [02:43<00:07, 197.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45551/47780 [02:43<00:06, 330.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45938/47780 [02:43<00:08, 214.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46090/47780 [02:43<00:07, 215.94 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45936/47780 [02:43<00:07, 247.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37957/47780 [02:43<00:17, 548.65 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45576/47780 [02:43<00:09, 236.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46096/47780 [02:43<00:06, 256.06 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46278/47780 [02:43<00:07, 199.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45965/47780 [02:43<00:07, 227.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45585/47780 [02:43<00:06, 326.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46112/47780 [02:43<00:07, 213.31 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45970/47780 [02:43<00:06, 270.68 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38017/47780 [02:43<00:17, 554.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45601/47780 [02:43<00:09, 233.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46298/47780 [02:43<00:07, 190.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45988/47780 [02:43<00:08, 223.18 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46122/47780 [02:43<00:07, 226.38 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45618/47780 [02:43<00:06, 316.71 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38088/47780 [02:43<00:16, 593.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46135/47780 [02:43<00:08, 203.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45999/47780 [02:43<00:07, 253.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45631/47780 [02:43<00:08, 251.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46318/47780 [02:43<00:07, 190.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46147/47780 [02:43<00:07, 229.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46018/47780 [02:43<00:07, 234.17 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38150/47780 [02:43<00:16, 595.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45657/47780 [02:44<00:06, 325.02 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46161/47780 [02:44<00:07, 213.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46026/47780 [02:43<00:06, 251.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45657/47780 [02:44<00:08, 237.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46346/47780 [02:44<00:06, 214.71 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38220/47780 [02:44<00:15, 621.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46172/47780 [02:44<00:07, 225.97 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46050/47780 [02:44<00:06, 251.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45690/47780 [02:44<00:06, 318.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46189/47780 [02:44<00:06, 229.01 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46055/47780 [02:44<00:06, 260.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45683/47780 [02:44<00:08, 239.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46368/47780 [02:44<00:06, 208.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46196/47780 [02:44<00:06, 229.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38284/47780 [02:44<00:15, 618.06 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46224/47780 [02:44<00:05, 261.64 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46076/47780 [02:44<00:07, 240.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46085/47780 [02:44<00:06, 267.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45722/47780 [02:44<00:07, 282.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45708/47780 [02:44<00:09, 218.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46394/47780 [02:44<00:06, 219.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38347/47780 [02:44<00:15, 614.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46220/47780 [02:44<00:07, 212.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46106/47780 [02:44<00:06, 248.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46119/47780 [02:44<00:05, 287.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46251/47780 [02:44<00:06, 252.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45751/47780 [02:44<00:07, 281.01 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45732/47780 [02:44<00:09, 217.47 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38409/47780 [02:44<00:15, 605.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46418/47780 [02:44<00:06, 212.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46242/47780 [02:44<00:07, 213.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46280/47780 [02:44<00:05, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46131/47780 [02:44<00:07, 232.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46149/47780 [02:44<00:06, 263.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45780/47780 [02:44<00:07, 256.50 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45760/47780 [02:44<00:08, 234.06 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38470/47780 [02:44<00:16, 563.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46264/47780 [02:44<00:07, 210.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46440/47780 [02:44<00:06, 197.08 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46155/47780 [02:44<00:07, 224.19 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46306/47780 [02:44<00:06, 232.39 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45807/47780 [02:44<00:07, 259.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46176/47780 [02:44<00:06, 244.67 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45784/47780 [02:44<00:08, 233.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38528/47780 [02:44<00:16, 562.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46286/47780 [02:44<00:07, 201.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46460/47780 [02:44<00:07, 187.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46180/47780 [02:44<00:07, 227.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46330/47780 [02:44<00:06, 222.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45834/47780 [02:44<00:07, 250.90 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45808/47780 [02:44<00:08, 231.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46205/47780 [02:44<00:06, 239.17 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38586/47780 [02:44<00:16, 566.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46315/47780 [02:44<00:06, 224.65 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46481/47780 [02:44<00:06, 190.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46206/47780 [02:44<00:06, 236.16 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45860/47780 [02:44<00:07, 252.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45832/47780 [02:44<00:08, 230.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46354/47780 [02:44<00:06, 216.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46234/47780 [02:44<00:06, 250.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38646/47780 [02:44<00:16, 560.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46338/47780 [02:44<00:06, 219.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46501/47780 [02:44<00:06, 187.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46230/47780 [02:44<00:07, 214.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45887/47780 [02:44<00:07, 253.46 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46379/47780 [02:44<00:06, 223.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46260/47780 [02:44<00:06, 252.07 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38716/47780 [02:44<00:15, 591.55 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45856/47780 [02:44<00:09, 210.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46363/47780 [02:44<00:06, 222.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46521/47780 [02:44<00:06, 185.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46407/47780 [02:45<00:05, 238.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45914/47780 [02:45<00:07, 250.75 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46288/47780 [02:44<00:05, 258.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46252/47780 [02:45<00:07, 195.24 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45880/47780 [02:45<00:09, 208.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46393/47780 [02:45<00:05, 237.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38776/47780 [02:45<00:16, 532.20 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46540/47780 [02:45<00:06, 180.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45941/47780 [02:45<00:07, 252.29 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46277/47780 [02:45<00:07, 202.71 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46435/47780 [02:45<00:06, 218.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46317/47780 [02:45<00:06, 235.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46418/47780 [02:45<00:05, 235.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38832/47780 [02:45<00:17, 513.70 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45903/47780 [02:45<00:09, 194.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46559/47780 [02:45<00:06, 178.17 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45967/47780 [02:45<00:07, 250.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46307/47780 [02:45<00:06, 218.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46442/47780 [02:45<00:05, 229.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38885/47780 [02:45<00:17, 517.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46342/47780 [02:45<00:06, 219.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46458/47780 [02:45<00:06, 200.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45923/47780 [02:45<00:10, 178.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46577/47780 [02:45<00:07, 163.08 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45994/47780 [02:45<00:07, 243.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46330/47780 [02:45<00:06, 215.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46466/47780 [02:45<00:05, 227.47 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38938/47780 [02:45<00:17, 506.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46365/47780 [02:45<00:06, 207.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45946/47780 [02:45<00:09, 190.74 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46022/47780 [02:45<00:06, 253.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46598/47780 [02:45<00:06, 170.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46479/47780 [02:45<00:07, 172.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46492/47780 [02:45<00:05, 235.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38992/47780 [02:45<00:17, 512.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46387/47780 [02:45<00:06, 206.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46353/47780 [02:45<00:07, 190.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45968/47780 [02:45<00:09, 194.57 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46050/47780 [02:45<00:06, 257.62 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46620/47780 [02:45<00:06, 174.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46499/47780 [02:45<00:07, 170.55 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39045/47780 [02:45<00:17, 505.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46516/47780 [02:45<00:05, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46380/47780 [02:45<00:06, 204.23 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45990/47780 [02:45<00:09, 194.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46409/47780 [02:45<00:06, 198.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46077/47780 [02:45<00:06, 251.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46639/47780 [02:45<00:06, 177.43 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46518/47780 [02:45<00:07, 173.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39096/47780 [02:45<00:17, 499.12 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46404/47780 [02:45<00:06, 209.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46539/47780 [02:45<00:06, 203.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46433/47780 [02:45<00:06, 200.64 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46012/47780 [02:45<00:09, 192.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46103/47780 [02:45<00:06, 242.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46657/47780 [02:45<00:06, 173.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46536/47780 [02:45<00:07, 173.84 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39147/47780 [02:45<00:17, 489.65 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46428/47780 [02:45<00:06, 215.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46035/47780 [02:45<00:08, 200.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46560/47780 [02:45<00:06, 196.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46675/47780 [02:45<00:06, 165.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46554/47780 [02:45<00:07, 170.43 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46128/47780 [02:45<00:07, 218.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46454/47780 [02:45<00:07, 176.51 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39211/47780 [02:45<00:16, 530.93 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46056/47780 [02:46<00:08, 195.87 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46580/47780 [02:45<00:06, 191.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46695/47780 [02:45<00:06, 173.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46450/47780 [02:46<00:07, 182.02 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46151/47780 [02:46<00:07, 209.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46573/47780 [02:46<00:07, 160.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46475/47780 [02:46<00:07, 176.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39266/47780 [02:46<00:17, 499.14 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46602/47780 [02:46<00:05, 198.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46077/47780 [02:46<00:08, 194.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46723/47780 [02:46<00:05, 200.17 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46178/47780 [02:46<00:07, 224.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46593/47780 [02:46<00:07, 166.51 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39324/47780 [02:46<00:16, 521.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46472/47780 [02:46<00:07, 178.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46622/47780 [02:46<00:05, 194.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46108/47780 [02:46<00:07, 222.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46495/47780 [02:46<00:08, 154.25 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46744/47780 [02:46<00:05, 181.83 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46211/47780 [02:46<00:06, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39381/47780 [02:46<00:15, 534.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46610/47780 [02:46<00:07, 164.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46493/47780 [02:46<00:06, 185.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46645/47780 [02:46<00:05, 202.05 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46514/47780 [02:46<00:08, 155.97 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46132/47780 [02:46<00:08, 201.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46237/47780 [02:46<00:06, 246.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46763/47780 [02:46<00:05, 179.85 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46517/47780 [02:46<00:06, 197.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46628/47780 [02:46<00:07, 163.12 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39435/47780 [02:46<00:16, 503.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46667/47780 [02:46<00:05, 204.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46532/47780 [02:46<00:08, 154.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46650/47780 [02:46<00:06, 178.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46153/47780 [02:46<00:08, 190.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39492/47780 [02:46<00:15, 521.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46264/47780 [02:46<00:06, 235.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46782/47780 [02:46<00:06, 164.09 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46538/47780 [02:46<00:06, 180.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46696/47780 [02:46<00:04, 228.43 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46552/47780 [02:46<00:07, 161.45 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46173/47780 [02:46<00:08, 188.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39545/47780 [02:46<00:16, 511.98 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46670/47780 [02:46<00:06, 172.08 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46802/47780 [02:46<00:05, 172.49 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46289/47780 [02:46<00:06, 221.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46557/47780 [02:46<00:07, 169.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46721/47780 [02:46<00:04, 215.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39600/47780 [02:46<00:15, 521.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46577/47780 [02:46<00:07, 171.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46197/47780 [02:46<00:08, 193.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46820/47780 [02:46<00:05, 170.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46690/47780 [02:46<00:06, 168.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46313/47780 [02:46<00:06, 211.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46575/47780 [02:46<00:07, 168.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46745/47780 [02:46<00:04, 219.39 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39664/47780 [02:46<00:14, 553.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46222/47780 [02:46<00:07, 205.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46841/47780 [02:46<00:05, 179.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46596/47780 [02:46<00:07, 164.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46712/47780 [02:46<00:06, 174.10 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46335/47780 [02:46<00:06, 211.98 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46595/47780 [02:46<00:06, 175.37 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46769/47780 [02:46<00:04, 209.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39734/47780 [02:46<00:13, 593.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46862/47780 [02:46<00:05, 177.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46243/47780 [02:46<00:08, 191.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46731/47780 [02:46<00:05, 175.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46613/47780 [02:46<00:06, 173.99 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46357/47780 [02:46<00:06, 205.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46613/47780 [02:46<00:07, 151.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46792/47780 [02:46<00:04, 212.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39795/47780 [02:47<00:14, 535.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46263/47780 [02:47<00:07, 190.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46760/47780 [02:47<00:05, 199.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46629/47780 [02:47<00:07, 148.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46631/47780 [02:47<00:06, 165.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46378/47780 [02:47<00:07, 192.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46815/47780 [02:47<00:04, 209.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46880/47780 [02:47<00:05, 153.81 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39857/47780 [02:47<00:14, 556.53 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46283/47780 [02:47<00:07, 189.24 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46782/47780 [02:47<00:05, 194.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46644/47780 [02:47<00:07, 146.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46406/47780 [02:47<00:06, 209.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46648/47780 [02:47<00:07, 148.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46896/47780 [02:47<00:06, 143.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46838/47780 [02:47<00:04, 191.93 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39914/47780 [02:47<00:14, 549.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46303/47780 [02:47<00:08, 183.36 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46803/47780 [02:47<00:05, 194.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46438/47780 [02:47<00:05, 229.61 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46659/47780 [02:47<00:08, 136.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46669/47780 [02:47<00:06, 162.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39970/47780 [02:47<00:14, 550.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46911/47780 [02:47<00:06, 129.81 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46858/47780 [02:47<00:05, 175.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46823/47780 [02:47<00:05, 190.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46322/47780 [02:47<00:08, 170.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46673/47780 [02:47<00:08, 133.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46463/47780 [02:47<00:05, 220.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46686/47780 [02:47<00:07, 150.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40026/47780 [02:47<00:15, 503.06 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46929/47780 [02:47<00:06, 134.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46844/47780 [02:47<00:04, 191.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46876/47780 [02:47<00:05, 161.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46344/47780 [02:47<00:08, 177.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46694/47780 [02:47<00:07, 149.18 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46706/47780 [02:47<00:06, 159.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46486/47780 [02:47<00:06, 203.35 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40088/47780 [02:47<00:14, 534.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46943/47780 [02:47<00:06, 133.80 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46864/47780 [02:47<00:04, 193.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46366/47780 [02:47<00:07, 183.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46894/47780 [02:47<00:05, 155.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46710/47780 [02:47<00:07, 143.91 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40143/47780 [02:47<00:14, 538.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46723/47780 [02:47<00:06, 156.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46509/47780 [02:47<00:06, 201.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46957/47780 [02:47<00:06, 128.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46886/47780 [02:47<00:04, 189.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46385/47780 [02:47<00:07, 183.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46725/47780 [02:47<00:07, 139.76 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40199/47780 [02:47<00:13, 544.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46911/47780 [02:47<00:06, 141.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46740/47780 [02:47<00:06, 155.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46532/47780 [02:47<00:06, 204.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46976/47780 [02:47<00:05, 143.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46906/47780 [02:47<00:04, 181.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46404/47780 [02:47<00:07, 173.51 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40254/47780 [02:47<00:13, 545.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46745/47780 [02:47<00:06, 152.55 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46932/47780 [02:47<00:05, 157.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46564/47780 [02:47<00:05, 233.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46756/47780 [02:47<00:06, 152.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46992/47780 [02:47<00:05, 142.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46925/47780 [02:47<00:04, 178.95 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46423/47780 [02:47<00:07, 172.82 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40324/47780 [02:47<00:12, 587.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46765/47780 [02:47<00:06, 159.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46949/47780 [02:48<00:05, 145.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46588/47780 [02:48<00:05, 217.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46780/47780 [02:48<00:06, 158.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47007/47780 [02:48<00:05, 138.37 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46442/47780 [02:48<00:07, 171.15 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40387/47780 [02:48<00:12, 593.94 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46943/47780 [02:48<00:05, 165.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46783/47780 [02:48<00:06, 157.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46801/47780 [02:48<00:05, 172.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47021/47780 [02:48<00:05, 138.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46611/47780 [02:48<00:05, 200.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46965/47780 [02:48<00:06, 135.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40467/47780 [02:48<00:11, 640.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46966/47780 [02:48<00:04, 182.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46467/47780 [02:48<00:07, 182.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46799/47780 [02:48<00:06, 152.51 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47036/47780 [02:48<00:05, 140.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46820/47780 [02:48<00:05, 164.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46981/47780 [02:48<00:05, 137.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46634/47780 [02:48<00:05, 200.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46985/47780 [02:48<00:04, 179.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40533/47780 [02:48<00:11, 623.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46487/47780 [02:48<00:07, 182.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46815/47780 [02:48<00:06, 153.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47052/47780 [02:48<00:05, 138.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46997/47780 [02:48<00:05, 136.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46655/47780 [02:48<00:05, 192.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46837/47780 [02:48<00:06, 151.84 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40596/47780 [02:48<00:11, 613.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46831/47780 [02:48<00:06, 153.82 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46506/47780 [02:48<00:07, 172.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47004/47780 [02:48<00:04, 165.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47066/47780 [02:48<00:05, 135.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46675/47780 [02:48<00:05, 193.65 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40667/47780 [02:48<00:11, 640.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47011/47780 [02:48<00:05, 134.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46856/47780 [02:48<00:06, 150.31 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46525/47780 [02:48<00:07, 170.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46849/47780 [02:48<00:06, 153.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47023/47780 [02:48<00:04, 163.51 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47080/47780 [02:48<00:05, 132.80 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46695/47780 [02:48<00:05, 190.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40732/47780 [02:48<00:11, 628.71 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47028/47780 [02:48<00:05, 140.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46881/47780 [02:48<00:05, 171.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46867/47780 [02:48<00:05, 159.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47044/47780 [02:48<00:04, 172.76 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46543/47780 [02:48<00:07, 165.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47094/47780 [02:48<00:05, 132.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46718/47780 [02:48<00:05, 199.82 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40796/47780 [02:48<00:11, 626.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47043/47780 [02:48<00:05, 138.46 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46905/47780 [02:48<00:04, 183.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46562/47780 [02:48<00:07, 169.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46885/47780 [02:48<00:05, 153.30 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47063/47780 [02:48<00:04, 164.06 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40860/47780 [02:48<00:11, 612.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46740/47780 [02:48<00:05, 198.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47057/47780 [02:48<00:05, 138.87 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47108/47780 [02:48<00:05, 122.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46924/47780 [02:48<00:04, 184.01 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46580/47780 [02:48<00:07, 166.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46902/47780 [02:48<00:05, 152.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47090/47780 [02:48<00:03, 187.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46760/47780 [02:48<00:05, 196.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47121/47780 [02:48<00:05, 124.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40922/47780 [02:48<00:11, 594.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47071/47780 [02:48<00:05, 131.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46598/47780 [02:48<00:06, 169.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46945/47780 [02:49<00:04, 179.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46918/47780 [02:48<00:06, 138.93 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47110/47780 [02:49<00:03, 174.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47136/47780 [02:49<00:04, 130.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46781/47780 [02:49<00:05, 195.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40996/47780 [02:49<00:10, 626.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47087/47780 [02:49<00:05, 138.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46615/47780 [02:49<00:06, 166.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46973/47780 [02:49<00:04, 187.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47151/47780 [02:49<00:04, 134.40 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41061/47780 [02:49<00:10, 633.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46935/47780 [02:49<00:06, 140.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46808/47780 [02:49<00:04, 212.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47128/47780 [02:49<00:03, 166.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47101/47780 [02:49<00:05, 135.31 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46637/47780 [02:49<00:06, 178.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46992/47780 [02:49<00:04, 183.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47168/47780 [02:49<00:04, 142.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41125/47780 [02:49<00:10, 615.29 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46951/47780 [02:49<00:05, 138.93 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46837/47780 [02:49<00:04, 221.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47146/47780 [02:49<00:03, 164.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47121/47780 [02:49<00:04, 149.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46655/47780 [02:49<00:06, 173.75 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41187/47780 [02:49<00:10, 612.19 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46967/47780 [02:49<00:05, 142.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47184/47780 [02:49<00:04, 137.37 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47011/47780 [02:49<00:04, 164.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47138/47780 [02:49<00:04, 151.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46864/47780 [02:49<00:04, 223.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47164/47780 [02:49<00:04, 153.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46674/47780 [02:49<00:06, 175.94 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41251/47780 [02:49<00:10, 614.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47155/47780 [02:49<00:04, 155.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46988/47780 [02:49<00:05, 155.46 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47028/47780 [02:49<00:04, 156.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47200/47780 [02:49<00:04, 133.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46693/47780 [02:49<00:06, 176.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47181/47780 [02:49<00:03, 151.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46887/47780 [02:49<00:04, 202.16 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41330/47780 [02:49<00:09, 664.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47005/47780 [02:49<00:04, 157.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47171/47780 [02:49<00:04, 150.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47214/47780 [02:49<00:04, 134.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47044/47780 [02:49<00:04, 152.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47198/47780 [02:49<00:03, 154.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46909/47780 [02:49<00:04, 204.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46712/47780 [02:49<00:06, 171.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41398/47780 [02:49<00:09, 651.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47022/47780 [02:49<00:05, 149.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47228/47780 [02:49<00:04, 129.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46733/47780 [02:49<00:05, 178.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46932/47780 [02:49<00:04, 206.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47187/47780 [02:49<00:04, 136.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47060/47780 [02:49<00:05, 141.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47214/47780 [02:49<00:03, 146.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41473/47780 [02:49<00:09, 674.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47041/47780 [02:49<00:04, 157.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47250/47780 [02:49<00:03, 148.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46751/47780 [02:49<00:05, 176.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47202/47780 [02:49<00:04, 129.15 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41543/47780 [02:49<00:09, 676.85 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46953/47780 [02:49<00:04, 184.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47076/47780 [02:49<00:05, 131.61 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47229/47780 [02:49<00:04, 129.60 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47057/47780 [02:49<00:04, 148.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46770/47780 [02:49<00:05, 173.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47265/47780 [02:49<00:03, 135.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47219/47780 [02:49<00:04, 139.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41611/47780 [02:49<00:09, 673.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46973/47780 [02:50<00:04, 181.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47092/47780 [02:50<00:05, 132.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47245/47780 [02:50<00:04, 133.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46793/47780 [02:50<00:05, 184.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47282/47780 [02:50<00:03, 143.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47075/47780 [02:50<00:04, 145.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47235/47780 [02:50<00:03, 144.56 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41680/47780 [02:50<00:09, 629.20 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47259/47780 [02:50<00:03, 134.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46993/47780 [02:50<00:04, 179.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47107/47780 [02:50<00:05, 124.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47250/47780 [02:50<00:03, 144.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47093/47780 [02:50<00:04, 147.53 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46812/47780 [02:50<00:05, 171.15 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41745/47780 [02:50<00:09, 632.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47297/47780 [02:50<00:03, 122.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47273/47780 [02:50<00:04, 125.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47120/47780 [02:50<00:05, 123.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47012/47780 [02:50<00:04, 159.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47268/47780 [02:50<00:03, 153.25 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41815/47780 [02:50<00:09, 645.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46830/47780 [02:50<00:05, 162.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47108/47780 [02:50<00:05, 129.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47286/47780 [02:50<00:04, 120.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47137/47780 [02:50<00:05, 127.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47311/47780 [02:50<00:04, 113.59 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41884/47780 [02:50<00:08, 657.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47284/47780 [02:50<00:03, 137.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47029/47780 [02:50<00:05, 138.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46847/47780 [02:50<00:06, 154.63 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47122/47780 [02:50<00:05, 123.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47299/47780 [02:50<00:04, 117.40 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47158/47780 [02:50<00:04, 143.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41954/47780 [02:50<00:08, 669.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47323/47780 [02:50<00:04, 107.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47300/47780 [02:50<00:03, 139.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47045/47780 [02:50<00:05, 141.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46867/47780 [02:50<00:05, 160.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47312/47780 [02:50<00:04, 115.05 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47135/47780 [02:50<00:05, 115.36 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42022/47780 [02:50<00:08, 650.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47173/47780 [02:50<00:04, 132.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47062/47780 [02:50<00:04, 148.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47315/47780 [02:50<00:03, 138.90 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46886/47780 [02:50<00:05, 161.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47335/47780 [02:50<00:04, 95.79 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47328/47780 [02:50<00:03, 126.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47147/47780 [02:50<00:05, 113.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47188/47780 [02:50<00:04, 134.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42092/47780 [02:50<00:09, 616.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47331/47780 [02:50<00:03, 142.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47078/47780 [02:50<00:05, 139.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46914/47780 [02:50<00:04, 185.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47346/47780 [02:50<00:04, 92.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47348/47780 [02:50<00:03, 140.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47202/47780 [02:50<00:04, 132.30 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42165/47780 [02:50<00:08, 641.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47159/47780 [02:50<00:06, 102.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47356/47780 [02:50<00:02, 164.86 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47094/47780 [02:50<00:04, 137.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47356/47780 [02:50<00:04, 91.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46933/47780 [02:50<00:04, 170.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47364/47780 [02:50<00:03, 135.52 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42232/47780 [02:50<00:08, 626.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47216/47780 [02:51<00:04, 125.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47170/47780 [02:50<00:05, 101.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47378/47780 [02:50<00:02, 174.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47110/47780 [02:51<00:05, 133.06 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46951/47780 [02:51<00:04, 167.83 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47366/47780 [02:51<00:04, 87.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47229/47780 [02:51<00:04, 126.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47398/47780 [02:51<00:02, 175.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47181/47780 [02:51<00:06, 99.49 examples/s] 
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42299/47780 [02:51<00:09, 583.54 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47379/47780 [02:51<00:03, 116.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47127/47780 [02:51<00:04, 138.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46969/47780 [02:51<00:04, 163.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47382/47780 [02:51<00:03, 103.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47244/47780 [02:51<00:04, 128.78 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42375/47780 [02:51<00:08, 624.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47195/47780 [02:51<00:05, 107.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47417/47780 [02:51<00:02, 170.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47392/47780 [02:51<00:03, 115.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47146/47780 [02:51<00:04, 138.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46986/47780 [02:51<00:05, 153.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47393/47780 [02:51<00:03, 98.05 examples/s] 
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42447/47780 [02:51<00:08, 646.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47257/47780 [02:51<00:04, 119.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47207/47780 [02:51<00:05, 105.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47436/47780 [02:51<00:02, 153.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47161/47780 [02:51<00:04, 135.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47405/47780 [02:51<00:03, 102.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42519/47780 [02:51<00:07, 665.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47002/47780 [02:51<00:05, 147.37 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47404/47780 [02:51<00:03, 96.03 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47271/47780 [02:51<00:04, 118.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47218/47780 [02:51<00:05, 98.63 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47453/47780 [02:51<00:02, 154.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47180/47780 [02:51<00:04, 145.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42591/47780 [02:51<00:07, 671.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47018/47780 [02:51<00:05, 149.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47417/47780 [02:51<00:03, 99.62 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47415/47780 [02:51<00:03, 93.09 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47287/47780 [02:51<00:03, 129.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47229/47780 [02:51<00:05, 95.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47469/47780 [02:51<00:02, 144.05 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42661/47780 [02:51<00:07, 672.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47033/47780 [02:51<00:05, 143.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47196/47780 [02:51<00:04, 138.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47432/47780 [02:51<00:03, 105.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47301/47780 [02:51<00:04, 118.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47239/47780 [02:51<00:05, 95.36 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42729/47780 [02:51<00:07, 673.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47426/47780 [02:51<00:04, 80.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47485/47780 [02:51<00:02, 139.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47048/47780 [02:51<00:05, 138.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47212/47780 [02:51<00:04, 137.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47443/47780 [02:51<00:03, 99.01 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47314/47780 [02:51<00:03, 116.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47249/47780 [02:51<00:05, 92.32 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42802/47780 [02:51<00:07, 673.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47436/47780 [02:51<00:04, 84.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47063/47780 [02:51<00:05, 136.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47227/47780 [02:51<00:04, 134.79 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47500/47780 [02:51<00:02, 120.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47329/47780 [02:51<00:03, 124.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47454/47780 [02:51<00:03, 97.59 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47259/47780 [02:51<00:06, 85.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47452/47780 [02:51<00:03, 97.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42870/47780 [02:51<00:07, 624.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47081/47780 [02:51<00:04, 146.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47241/47780 [02:52<00:03, 135.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47344/47780 [02:52<00:03, 128.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47465/47780 [02:52<00:03, 95.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47513/47780 [02:52<00:02, 111.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47464/47780 [02:52<00:03, 99.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47258/47780 [02:52<00:03, 143.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42934/47780 [02:52<00:08, 583.27 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47099/47780 [02:52<00:04, 149.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47269/47780 [02:52<00:06, 77.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47361/47780 [02:52<00:03, 132.74 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47481/47780 [02:52<00:02, 109.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47528/47780 [02:52<00:02, 117.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47480/47780 [02:52<00:02, 114.00 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42994/47780 [02:52<00:08, 571.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47118/47780 [02:52<00:04, 155.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47280/47780 [02:52<00:06, 81.66 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47274/47780 [02:52<00:03, 127.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47375/47780 [02:52<00:03, 132.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47493/47780 [02:52<00:02, 109.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47492/47780 [02:52<00:02, 113.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47541/47780 [02:52<00:02, 112.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47134/47780 [02:52<00:04, 154.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43059/47780 [02:52<00:08, 576.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47390/47780 [02:52<00:02, 136.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47288/47780 [02:52<00:03, 126.35 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47289/47780 [02:52<00:06, 77.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47506/47780 [02:52<00:02, 106.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43131/47780 [02:52<00:07, 611.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47558/47780 [02:52<00:01, 116.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47504/47780 [02:52<00:02, 101.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47150/47780 [02:52<00:04, 145.61 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47303/47780 [02:52<00:03, 132.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47297/47780 [02:52<00:06, 77.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47517/47780 [02:52<00:02, 104.91 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43193/47780 [02:52<00:07, 613.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47404/47780 [02:52<00:03, 115.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47168/47780 [02:52<00:03, 154.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47516/47780 [02:52<00:02, 105.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47570/47780 [02:52<00:01, 107.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47317/47780 [02:52<00:03, 129.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47305/47780 [02:52<00:06, 74.79 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43258/47780 [02:52<00:07, 622.35 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47418/47780 [02:52<00:02, 120.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47529/47780 [02:52<00:02, 97.45 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47186/47780 [02:52<00:03, 155.38 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47527/47780 [02:52<00:02, 100.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47582/47780 [02:52<00:01, 109.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47337/47780 [02:52<00:03, 146.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47315/47780 [02:52<00:05, 79.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47431/47780 [02:52<00:02, 121.73 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43322/47780 [02:52<00:07, 610.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47202/47780 [02:52<00:03, 149.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47539/47780 [02:52<00:02, 89.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47353/47780 [02:52<00:02, 149.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47538/47780 [02:52<00:02, 97.44 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47594/47780 [02:52<00:01, 103.25 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47328/47780 [02:52<00:05, 87.43 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47445/47780 [02:52<00:02, 123.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43385/47780 [02:52<00:07, 574.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47552/47780 [02:52<00:02, 94.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47549/47780 [02:52<00:02, 94.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47369/47780 [02:52<00:03, 135.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47218/47780 [02:52<00:04, 130.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47458/47780 [02:52<00:02, 123.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47340/47780 [02:52<00:04, 89.48 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43444/47780 [02:52<00:07, 573.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47605/47780 [02:52<00:01, 89.13 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47559/47780 [02:53<00:02, 91.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47232/47780 [02:53<00:04, 129.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47383/47780 [02:53<00:03, 127.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47350/47780 [02:53<00:04, 88.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43502/47780 [02:53<00:07, 561.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47471/47780 [02:53<00:02, 112.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47562/47780 [02:53<00:02, 77.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47569/47780 [02:53<00:02, 91.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47246/47780 [02:53<00:04, 131.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47398/47780 [02:53<00:02, 129.56 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43559/47780 [02:53<00:07, 553.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47359/47780 [02:53<00:05, 79.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47483/47780 [02:53<00:02, 106.69 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47261/47780 [02:53<00:03, 135.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47579/47780 [02:53<00:02, 90.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43624/47780 [02:53<00:07, 578.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47615/47780 [02:53<00:02, 61.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47571/47780 [02:53<00:03, 64.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47368/47780 [02:53<00:05, 79.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47498/47780 [02:53<00:02, 112.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47412/47780 [02:53<00:03, 110.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47590/47780 [02:53<00:02, 94.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47282/47780 [02:53<00:03, 145.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47580/47780 [02:53<00:02, 69.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43684/47780 [02:53<00:07, 521.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47601/47780 [02:53<00:01, 97.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47623/47780 [02:53<00:02, 56.29 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47510/47780 [02:53<00:02, 102.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47378/47780 [02:53<00:05, 74.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47298/47780 [02:53<00:03, 147.66 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47425/47780 [02:53<00:03, 100.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43742/47780 [02:53<00:07, 535.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47588/47780 [02:53<00:02, 65.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47613/47780 [02:53<00:01, 102.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47523/47780 [02:53<00:02, 108.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47386/47780 [02:53<00:05, 71.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47313/47780 [02:53<00:03, 132.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47436/47780 [02:53<00:03, 96.12 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43797/47780 [02:53<00:07, 515.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47597/47780 [02:53<00:02, 70.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47628/47780 [02:53<00:01, 114.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47630/47780 [02:53<00:03, 49.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47535/47780 [02:53<00:02, 102.04 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47398/47780 [02:53<00:04, 80.83 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43851/47780 [02:53<00:07, 521.77 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47328/47780 [02:53<00:03, 130.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47447/47780 [02:53<00:03, 94.90 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47605/47780 [02:53<00:02, 67.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47641/47780 [02:53<00:01, 105.65 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43910/47780 [02:53<00:07, 540.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47407/47780 [02:53<00:04, 78.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47546/47780 [02:53<00:02, 96.21 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47458/47780 [02:53<00:03, 97.27 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47342/47780 [02:53<00:03, 123.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47636/47780 [02:53<00:03, 40.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47613/47780 [02:53<00:02, 64.49 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43971/47780 [02:53<00:06, 553.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47416/47780 [02:53<00:04, 78.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47557/47780 [02:53<00:02, 95.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47653/47780 [02:53<00:01, 97.45 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47358/47780 [02:53<00:03, 124.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47468/47780 [02:54<00:03, 86.89 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47622/47780 [02:54<00:02, 69.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44031/47780 [02:54<00:06, 554.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47641/47780 [02:54<00:03, 38.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47425/47780 [02:54<00:04, 77.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47380/47780 [02:54<00:02, 144.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47567/47780 [02:54<00:02, 86.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47483/47780 [02:54<00:02, 101.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47664/47780 [02:54<00:01, 87.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44095/47780 [02:54<00:06, 572.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47631/47780 [02:54<00:02, 66.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47442/47780 [02:54<00:03, 98.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47646/47780 [02:54<00:03, 38.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47581/47780 [02:54<00:02, 96.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47395/47780 [02:54<00:02, 140.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47496/47780 [02:54<00:02, 104.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44161/47780 [02:54<00:06, 595.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47676/47780 [02:54<00:01, 86.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47454/47780 [02:54<00:03, 99.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47643/47780 [02:54<00:01, 74.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47414/47780 [02:54<00:02, 152.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47512/47780 [02:54<00:02, 113.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47653/47780 [02:54<00:03, 40.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44222/47780 [02:54<00:05, 596.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47600/47780 [02:54<00:01, 109.27 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47690/47780 [02:54<00:00, 96.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47471/47780 [02:54<00:02, 114.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47651/47780 [02:54<00:01, 73.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44292/47780 [02:54<00:05, 625.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47660/47780 [02:54<00:02, 45.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47431/47780 [02:54<00:02, 138.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47701/47780 [02:54<00:00, 99.16 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47619/47780 [02:54<00:01, 123.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47524/47780 [02:54<00:02, 103.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47486/47780 [02:54<00:02, 121.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47659/47780 [02:54<00:01, 74.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44377/47780 [02:54<00:04, 686.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47447/47780 [02:54<00:02, 141.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47665/47780 [02:54<00:02, 44.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47538/47780 [02:54<00:02, 111.16 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47632/47780 [02:54<00:01, 119.46 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47499/47780 [02:54<00:02, 113.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47712/47780 [02:54<00:00, 83.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44447/47780 [02:54<00:05, 649.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47463/47780 [02:54<00:02, 141.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47667/47780 [02:54<00:01, 62.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47670/47780 [02:54<00:02, 43.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47550/47780 [02:54<00:02, 102.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44514/47780 [02:54<00:05, 652.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47511/47780 [02:54<00:02, 103.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47478/47780 [02:54<00:02, 140.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47646/47780 [02:54<00:01, 93.80 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47721/47780 [02:54<00:00, 67.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44583/47780 [02:54<00:04, 655.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47680/47780 [02:54<00:02, 47.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47674/47780 [02:54<00:02, 51.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47561/47780 [02:54<00:02, 88.38 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47498/47780 [02:54<00:01, 149.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47522/47780 [02:54<00:02, 96.75 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47657/47780 [02:54<00:01, 90.98 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44658/47780 [02:54<00:04, 676.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47730/47780 [02:54<00:00, 69.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47571/47780 [02:55<00:02, 85.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47534/47780 [02:54<00:02, 101.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47680/47780 [02:55<00:02, 49.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47687/47780 [02:55<00:01, 47.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47514/47780 [02:55<00:02, 128.37 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44726/47780 [02:55<00:04, 671.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47668/47780 [02:55<00:01, 80.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47739/47780 [02:55<00:00, 66.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47693/47780 [02:55<00:01, 49.85 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47583/47780 [02:55<00:02, 88.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47545/47780 [02:55<00:02, 97.59 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47687/47780 [02:55<00:01, 48.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44796/47780 [02:55<00:04, 636.79 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47529/47780 [02:55<00:02, 124.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47556/47780 [02:55<00:02, 99.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47747/47780 [02:55<00:00, 64.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47596/47780 [02:55<00:01, 93.20 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44861/47780 [02:55<00:04, 625.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47677/47780 [02:55<00:01, 68.29 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47546/47780 [02:55<00:01, 128.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47701/47780 [02:55<00:01, 44.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47693/47780 [02:55<00:02, 43.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47608/47780 [02:55<00:01, 99.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47567/47780 [02:55<00:02, 88.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47567/47780 [02:55<00:01, 147.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44926/47780 [02:55<00:04, 589.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47685/47780 [02:55<00:01, 64.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47619/47780 [02:55<00:01, 96.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47698/47780 [02:55<00:01, 41.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47707/47780 [02:55<00:01, 42.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47578/47780 [02:55<00:02, 86.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44986/47780 [02:55<00:04, 570.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47584/47780 [02:55<00:01, 140.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47692/47780 [02:55<00:01, 64.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47703/47780 [02:55<00:01, 38.55 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47629/47780 [02:55<00:01, 83.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45044/47780 [02:55<00:04, 558.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47588/47780 [02:55<00:02, 80.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47599/47780 [02:55<00:01, 133.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47713/47780 [02:55<00:01, 38.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47700/47780 [02:55<00:01, 63.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47754/47780 [02:55<00:00, 35.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45103/47780 [02:55<00:04, 554.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47707/47780 [02:55<00:01, 37.32 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47709/47780 [02:55<00:01, 69.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47598/47780 [02:55<00:02, 79.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47638/47780 [02:55<00:01, 73.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47613/47780 [02:55<00:01, 121.48 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45162/47780 [02:55<00:04, 562.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47711/47780 [02:55<00:01, 36.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47719/47780 [02:55<00:01, 36.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47608/47780 [02:55<00:02, 82.14 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47626/47780 [02:55<00:01, 120.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47718/47780 [02:55<00:00, 67.85 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45219/47780 [02:55<00:04, 548.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47646/47780 [02:56<00:02, 65.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47724/47780 [02:56<00:01, 36.97 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47717/47780 [02:56<00:01, 39.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47617/47780 [02:56<00:02, 80.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47640/47780 [02:56<00:01, 115.55 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47726/47780 [02:56<00:00, 64.28 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45274/47780 [02:56<00:04, 516.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47760/47780 [02:56<00:00, 26.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47722/47780 [02:56<00:01, 38.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47730/47780 [02:56<00:01, 38.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47654/47780 [02:56<00:02, 58.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47627/47780 [02:56<00:01, 79.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45341/47780 [02:56<00:04, 550.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47653/47780 [02:56<00:01, 108.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47735/47780 [02:56<00:00, 62.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47734/47780 [02:56<00:01, 38.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47726/47780 [02:56<00:01, 36.77 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47661/47780 [02:56<00:02, 58.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45397/47780 [02:56<00:04, 532.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47639/47780 [02:56<00:01, 78.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47668/47780 [02:56<00:01, 107.95 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47742/47780 [02:56<00:00, 60.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47738/47780 [02:56<00:01, 35.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47732/47780 [02:56<00:01, 39.01 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45456/47780 [02:56<00:04, 545.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47669/47780 [02:56<00:01, 57.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47647/47780 [02:56<00:01, 74.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47680/47780 [02:56<00:00, 110.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47765/47780 [02:56<00:00, 22.43 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45511/47780 [02:56<00:04, 509.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47738/47780 [02:56<00:01, 40.00 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47744/47780 [02:56<00:01, 35.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47692/47780 [02:56<00:00, 108.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47657/47780 [02:56<00:01, 72.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47675/47780 [02:56<00:02, 46.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45566/47780 [02:56<00:04, 506.85 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47703/47780 [02:56<00:00, 101.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47745/47780 [02:56<00:00, 41.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47748/47780 [02:56<00:01, 30.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45633/47780 [02:56<00:03, 546.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [02:56<00:00, 20.33 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47750/47780 [02:56<00:00, 37.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47665/47780 [02:56<00:01, 62.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47716/47780 [02:56<00:00, 104.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47751/47780 [02:56<00:00, 42.30 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45692/47780 [02:56<00:03, 556.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47674/47780 [02:56<00:01, 63.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47682/47780 [02:56<00:02, 36.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47729/47780 [02:56<00:00, 107.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47752/47780 [02:56<00:01, 27.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47758/47780 [02:57<00:00, 45.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45751/47780 [02:56<00:03, 524.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47756/47780 [02:57<00:00, 33.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47682/47780 [02:56<00:01, 65.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47755/47780 [02:57<00:00, 25.40 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45805/47780 [02:57<00:03, 523.04 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47765/47780 [02:57<00:00, 48.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47689/47780 [02:57<00:01, 66.10 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47688/47780 [02:57<00:02, 32.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45864/47780 [02:57<00:03, 539.64 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47762/47780 [02:57<00:00, 32.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47740/47780 [02:57<00:00, 71.78 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47701/47780 [02:57<00:00, 79.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47770/47780 [02:57<00:00, 43.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47759/47780 [02:57<00:00, 24.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47693/47780 [02:57<00:02, 34.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45923/47780 [02:57<00:03, 527.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47766/47780 [02:57<00:00, 31.50 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47711/47780 [02:57<00:00, 75.87 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45977/47780 [02:57<00:03, 507.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47763/47780 [02:57<00:00, 24.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47699/47780 [02:57<00:02, 35.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47770/47780 [02:57<00:00, 30.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47719/47780 [02:57<00:00, 68.09 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47750/47780 [02:57<00:00, 53.84 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47767/47780 [02:57<00:00, 26.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46030/47780 [02:57<00:03, 454.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47705/47780 [02:57<00:01, 38.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47774/47780 [02:57<00:00, 30.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47727/47780 [02:57<00:00, 60.11 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47771/47780 [02:57<00:00, 26.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46077/47780 [02:57<00:04, 411.52 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47760/47780 [02:57<00:00, 52.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47711/47780 [02:57<00:02, 32.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47735/47780 [02:57<00:00, 61.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47775/47780 [02:57<00:00, 27.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46120/47780 [02:57<00:04, 394.03 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46161/47780 [02:57<00:04, 383.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47717/47780 [02:58<00:01, 34.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47743/47780 [02:57<00:00, 57.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47723/47780 [02:58<00:01, 38.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46201/47780 [02:58<00:04, 355.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47751/47780 [02:58<00:00, 57.17 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46246/47780 [02:58<00:04, 374.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47728/47780 [02:58<00:01, 38.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47759/47780 [02:58<00:00, 55.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46286/47780 [02:58<00:04, 362.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47733/47780 [02:58<00:01, 37.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46329/47780 [02:58<00:03, 376.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47765/47780 [02:58<00:00, 48.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47737/47780 [02:58<00:01, 34.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46376/47780 [02:58<00:03, 399.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47771/47780 [02:58<00:00, 42.20 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46418/47780 [02:58<00:03, 369.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47741/47780 [02:58<00:01, 31.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46459/47780 [02:58<00:03, 366.61 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47748/47780 [02:58<00:00, 34.59 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46497/47780 [02:58<00:03, 354.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47778/47780 [02:58<00:00,  8.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47753/47780 [02:58<00:00, 37.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46538/47780 [02:58<00:03, 366.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47757/47780 [02:59<00:00, 36.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47772/47780 [02:59<00:01,  5.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46576/47780 [02:59<00:03, 328.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47761/47780 [02:59<00:00, 34.18 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46611/47780 [02:59<00:03, 331.51 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47765/47780 [02:59<00:00, 34.01 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46652/47780 [02:59<00:03, 341.76 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [02:59<00:00, 32.94 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46695/47780 [02:59<00:02, 361.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46750/47780 [02:59<00:02, 410.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47773/47780 [02:59<00:00, 32.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46800/47780 [02:59<00:02, 429.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46844/47780 [02:59<00:02, 432.27 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46889/47780 [02:59<00:02, 395.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46956/47780 [03:00<00:01, 448.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47003/47780 [03:00<00:01, 399.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47775/47780 [03:00<00:00,  5.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47046/47780 [03:00<00:02, 338.81 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47082/47780 [03:00<00:02, 303.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47117/47780 [03:00<00:02, 305.90 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47775/47780 [03:00<00:01,  4.03 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47150/47780 [03:00<00:02, 291.26 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47180/47780 [03:00<00:02, 254.80 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47207/47780 [03:01<00:02, 243.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47241/47780 [03:01<00:02, 258.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47270/47780 [03:01<00:02, 244.97 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47295/47780 [03:01<00:02, 213.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47318/47780 [03:01<00:02, 190.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47340/47780 [03:01<00:02, 169.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47359/47780 [03:01<00:02, 168.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47378/47780 [03:02<00:02, 147.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47396/47780 [03:02<00:02, 150.15 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47427/47780 [03:02<00:02, 171.79 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47445/47780 [03:02<00:02, 162.72 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47462/47780 [03:02<00:02, 154.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47478/47780 [03:02<00:02, 128.16 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47493/47780 [03:02<00:02, 109.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47777/47780 [03:02<00:01,  2.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47506/47780 [03:03<00:02, 98.25 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47519/47780 [03:03<00:02, 91.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47529/47780 [03:03<00:02, 90.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47539/47780 [03:03<00:02, 91.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47552/47780 [03:03<00:02, 91.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47565/47780 [03:03<00:02, 94.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [03:03<00:02,  5.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47575/47780 [03:03<00:02, 93.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47585/47780 [03:04<00:02, 94.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47597/47780 [03:04<00:01, 93.04 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47612/47780 [03:04<00:01, 95.66 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47623/47780 [03:04<00:01, 84.25 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47633/47780 [03:04<00:01, 82.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47778/47780 [03:04<00:00,  2.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47778/47780 [03:04<00:00,  2.12 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47645/47780 [03:04<00:01, 87.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47656/47780 [03:04<00:01, 81.68 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47670/47780 [03:04<00:01, 91.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47681/47780 [03:05<00:01, 95.20 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47774/47780 [03:05<00:01,  5.02 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47691/47780 [03:05<00:01, 69.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47700/47780 [03:05<00:01, 49.22 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47708/47780 [03:05<00:01, 45.36 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47715/47780 [03:06<00:01, 46.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47777/47780 [03:06<00:01,  2.84 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47721/47780 [03:06<00:01, 43.33 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47778/47780 [03:06<00:00,  4.63 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47727/47780 [03:06<00:01, 39.64 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47732/47780 [03:06<00:01, 38.41 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47738/47780 [03:06<00:01, 34.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:06<00:00, 255.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47742/47780 [03:06<00:01, 33.72 examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47747/47780 [03:07<00:00, 34.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47754/47780 [03:07<00:00, 41.88 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47759/47780 [03:07<00:00, 40.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:00<00:28, 1639.91 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10000/47780 [00:00<00:02, 18123.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47764/47780 [03:07<00:00, 20.57 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25988/47780 [00:00<00:00, 47639.08 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:07<00:00, 254.31 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43343/47780 [00:00<00:00, 76171.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:08<00:00, 253.58 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:08<00:00,  1.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:00<00:32, 1449.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [03:08<00:01, 10.01 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:09<00:00, 252.71 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8000/47780 [00:00<00:03, 9947.16 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31960/47780 [00:01<00:00, 45577.37 examples/s]
Truncating train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46301/47780 [00:01<00:00, 62328.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<00:47, 979.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:09<00:00, 251.90 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  10%|â–ˆ         | 5000/47780 [00:01<00:07, 5754.36 examples/s]
Truncating train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28480/47780 [00:01<00:00, 39034.44 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43343/47780 [00:01<00:00, 57825.76 examples/s]
Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:00<00:45, 1029.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:10<00:00,  1.47 examples/s]
Truncating train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10000/47780 [00:01<00:03, 12398.65 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:10<00:00,  8.70 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19987/47780 [00:01<00:01, 25671.96 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29440/47780 [00:01<00:00, 36360.75 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36905/47780 [00:01<00:00, 41957.45 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:00<00:46, 1016.63 examples/s]
Truncating train dataset (num_proc=32):  10%|â–ˆ         | 5000/47780 [00:01<00:07, 5915.07 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:11<00:00, 250.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Truncating train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43821/47780 [00:01<00:00, 37050.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:11<00:00, 250.07 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13494/47780 [00:01<00:01, 17813.92 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37917/47780 [00:01<00:00, 57685.09 examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:00<00:29, 1602.69 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8000/47780 [00:00<00:02, 13808.66 examples/s]
Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:00<00:36, 1292.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13494/47780 [00:00<00:01, 22112.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   4%|â–         | 2000/47780 [00:00<00:17, 2544.14 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18468/47780 [00:00<00:01, 27070.08 examples/s]
Truncating train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8000/47780 [00:01<00:03, 11290.28 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25427/47780 [00:01<00:00, 35545.06 examples/s]
Truncating train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24481/47780 [00:01<00:00, 38711.48 examples/s]
Truncating train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32399/47780 [00:01<00:00, 41904.89 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47772/47780 [03:12<00:02,  3.21 examples/s]
Truncating train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36933/47780 [00:01<00:00, 55513.46 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43836/47780 [00:01<00:00, 54826.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45808/47780 [00:03<00:00, 9292.60 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47775/47780 [03:16<00:02,  1.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:12<00:00, 76171.99 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:11<00:00, 62328.98 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:11<00:00, 57825.76 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:12<00:00, 57685.09 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:12<00:00, 37050.67 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:18<00:00, 54826.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:19<00:00, 9292.60 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47776/47780 [03:31<00:02,  1.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:35<00:00,  1.61s/ examples]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:29<00:00, 973.00 examples/s]  
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:29<00:00, 709.73 examples/s]  
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:38<00:00, 218.67 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:27<00:00, 779.83 examples/s]  
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:28<00:00, 808.36 examples/s] 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:31<00:00, 911.17 examples/s]  
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:33<00:00, 798.62 examples/s]  
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):   9%|â–‰         | 4479/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:37<00:00, 901.01 examples/s]  
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:42<00:00, 973.00 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:38<00:00, 779.83 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:42<00:00, 1113.83 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:39<00:00, 1220.39 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:41<00:00, 911.17 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:39<00:00, 1216.73 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:42<00:00, 1122.82 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:42<00:00, 1135.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:41<00:00, 1154.43 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:40<00:00, 1169.34 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:19,345] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:19,590] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:19,901] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:19,918] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:19,935] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:19,970] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:20,045] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:21,943] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  11%|â–ˆâ–        | 5479/47780 [00:17<12:07, 58.13 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Truncating train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16479/47780 [00:17<00:32, 963.33 examples/s]
Truncating train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23889/47780 [00:21<00:26, 914.29 examples/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:33,950] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 18:56:35,163] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m  10%|â–ˆ         | 1/10 [00:45<06:50, 45.61s/it]
[36m(head, rank=0, pid=3451)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:25<05:38, 42.35s/it]
[36m(head, rank=0, pid=3451)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [02:05<04:46, 40.98s/it]
[36m(head, rank=0, pid=3451)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:44<04:02, 40.35s/it]
[36m(head, rank=0, pid=3451)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:24<03:20, 40.16s/it]
[36m(head, rank=0, pid=3451)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [04:02<02:38, 39.55s/it]
[36m(head, rank=0, pid=3451)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:42<01:58, 39.59s/it]
[36m(head, rank=0, pid=3451)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [05:22<01:19, 39.65s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [06:00<00:39, 39.30s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:37<00:00, 38.55s/it]Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:37<00:00, 38.55s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 177.96 secondsCompleted Save checkpoint in 177.96 seconds
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 177.96 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 177.96 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 177.96 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 177.96 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 177.96 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 177.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 177.96s (Total: 177.96s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1108.42 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1108.55 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96sCompleted Training in 1108.54 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 358.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 358.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 358.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1108.54 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1108.42 secondsCheckpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.35sCompleted run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 358.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.jsonTraining completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1Completed Training in 1108.42 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:Completed Training in 1108.60 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 357.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.47s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 358.50s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1087.13 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 358.64s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 10.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 356.62s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.jsonCompleted run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 315.26 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 315.26s (Total: 315.26s)
[36m(head, rank=0, pid=3451)[0m 
                                               
{'train_runtime': 712.7353, 'train_samples_per_second': 1.796, 'train_steps_per_second': 0.014, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [11:52<00:00, 38.55s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [11:52<00:00, 71.27s/it]
[36m(head, rank=0, pid=3451)[0m Completed Training in 1088.78 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 315.26s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 315.26s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 315.26s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 315.26s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 356.78s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 8.15s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1109.05 seconds
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 357.88s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.47s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 10.03s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1109.24 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 1108.92 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:  - Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1  - Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:  - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10  - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Min save time: 177.96s  - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Max save time: 177.96s  - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:  - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10  - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:  - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 358.79s  - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.07s  - Average training step time: 4.48s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:  - Min training step time: 3.67s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80  - Max training step time: 10.03s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 358.85sTraining completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.49s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 10.04s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1109.21 seconds
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 357.79s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.47s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 10.04s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1109.14 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 1109.20 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 358.28s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.48s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 10.03s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 358.17s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.48s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 10.03s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1109.21 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 357.46s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.47s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 10.03s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 23.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 23.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 23.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 23.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1087.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1087.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1087.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1087.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 356.62s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1112.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1112.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1112.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1112.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "timestamp": "2025-08-03T18:50:25.302651",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_load_time": 2.1264991760253906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_load_time": 23.31706166267395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_time": 1087.127856016159,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_time": 1112.5714168548584,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     177.9581913948059
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_batch_sample_time": 0.34697508811950684,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_batch_sample_time": 0.03469750881195068,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_batch_sample_time": 0.02711343765258789,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_batch_sample_time": 0.08063077926635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.08063077926635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.028328418731689453,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.02950143814086914,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.029354333877563477,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.03003215789794922,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.03322291374206543,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.03133726119995117,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.02858710289001465,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.028867244720458984,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.02711343765258789
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_training_step_time": 356.6178615093231,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_training_step_time": 4.457723268866539,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_training_step_time": 3.661790609359741,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_training_step_time": 8.121156215667725,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     8.121156215667725,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.3891942501068115,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.244091033935547,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.2746076583862305,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.326843738555908,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.013859033584595,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.25951075553894,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.131998300552368,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.33840012550354,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.1137776374816895,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.2530677318573,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.165959358215332,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.027961254119873,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.422185659408569,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.152146100997925,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.338744878768921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.850304841995239,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.332788705825806,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.097769737243652,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.137021780014038,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.742053508758545,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.145638942718506,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.057859897613525,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.159024477005005,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.382771253585815,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.50091028213501,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.278455972671509,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.132014751434326,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.890078067779541,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.146533250808716,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.283844470977783,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.790019750595093,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.36405086517334,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.23826789855957,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.555585145950317,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.510538101196289,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.718138217926025,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.552482604980469,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.661790609359741,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.147614479064941,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.854797601699829,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.139758586883545,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.498570442199707,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.390687704086304,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.372338771820068,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.115068674087524,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.083237648010254,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.206840753555298,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.142786979675293,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.067607402801514,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.976757526397705,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.102085113525391,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.402057886123657,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.294412612915039,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.610182523727417,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.9004814624786377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.373180866241455,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.488592863082886,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.312891244888306,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.562612771987915,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.100078344345093,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.10719108581543,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.873852252960205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.680653810501099,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.987004041671753,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.87021541595459,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.123366594314575,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.010411024093628,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.598409414291382,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.441286325454712,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.302518606185913,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.32189416885376,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.000012159347534,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.506608724594116,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.004967927932739,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.1436381340026855,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.277036666870117,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.0987818241119385,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.894702434539795,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.131221771240234
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "timestamp": "2025-08-03T18:50:25.302651",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_time": 2.1264991760253906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_time": 23.31706166267395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_time": 1087.127856016159,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_time": 1112.5714168548584,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       177.9581913948059
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 0.34697508811950684,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_batch_sample_time": 0.03469750881195068,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_batch_sample_time": 0.02711343765258789,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_batch_sample_time": 0.08063077926635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.08063077926635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.028328418731689453,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.02950143814086914,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.029354333877563477,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.03003215789794922,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.03322291374206543,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.03133726119995117,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.02858710289001465,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.028867244720458984,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.02711343765258789
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 356.6178615093231,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_training_step_time": 4.457723268866539,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_training_step_time": 3.661790609359741,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_training_step_time": 8.121156215667725,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       8.121156215667725,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.3891942501068115,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.244091033935547,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.2746076583862305,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.326843738555908,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.013859033584595,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.25951075553894,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.131998300552368,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.33840012550354,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.1137776374816895,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.2530677318573,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.165959358215332,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.027961254119873,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.422185659408569,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.152146100997925,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.338744878768921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.850304841995239,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.332788705825806,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.097769737243652,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.137021780014038,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.742053508758545,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.145638942718506,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.057859897613525,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.159024477005005,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.382771253585815,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.50091028213501,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.278455972671509,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.132014751434326,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.890078067779541,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.146533250808716,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.283844470977783,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.790019750595093,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.36405086517334,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.23826789855957,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.555585145950317,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.510538101196289,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.718138217926025,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.552482604980469,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.661790609359741,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.147614479064941,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.854797601699829,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.139758586883545,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.498570442199707,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.390687704086304,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.372338771820068,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.115068674087524,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.083237648010254,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.206840753555298,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.142786979675293,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.067607402801514,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.976757526397705,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.102085113525391,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.402057886123657,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.294412612915039,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.610182523727417,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.9004814624786377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.373180866241455,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.488592863082886,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.312891244888306,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.562612771987915,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.100078344345093,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.10719108581543,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.873852252960205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.680653810501099,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.987004041671753,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.87021541595459,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.123366594314575,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.010411024093628,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.598409414291382,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.441286325454712,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.302518606185913,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.32189416885376,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.000012159347534,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.506608724594116,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.004967927932739,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.1436381340026855,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.277036666870117,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.0987818241119385,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.894702434539795,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.131221771240234
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_average": 2.1264991760253906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_min": 2.1264991760253906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_max": 2.1264991760253906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_total": 2.1264991760253906
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_average": 23.31706166267395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_min": 23.31706166267395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_max": 23.31706166267395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_total": 23.31706166267395
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_average": 1087.127856016159,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_min": 1087.127856016159,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_max": 1087.127856016159,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_total": 1087.127856016159
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_average": 1112.5714168548584,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_min": 1112.5714168548584,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_max": 1112.5714168548584,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_total": 1112.5714168548584
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_save_time_per_checkpoint": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_min": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_max": 177.9581913948059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_average": 177.9581913948059
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 0.34697508811950684,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_sample_time_per_batch": 0.03469750881195068,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_min": 0.02711343765258789,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_max": 0.08063077926635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_average": 0.03469750881195068
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 356.6178615093231,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_step_time_per_step": 4.457723268866539,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_min": 3.661790609359741,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_max": 8.121156215667725,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_average": 4.457723268866539
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.13s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 21.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 21.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 21.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 21.67s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1088.78s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1088.78s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1088.78s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1088.78s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.46s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 8.15s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 356.78s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.36s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 315.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 315.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 315.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 315.26s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.59s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "run_id": 1,
[36m(head, rank=0, pid=3451)[0m   "timestamp": "2025-08-03T18:50:25.304615",
[36m(head, rank=0, pid=3451)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3451)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m   "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3451)[0m   "dataset_load_time": 2.1332175731658936,
[36m(head, rank=0, pid=3451)[0m   "model_load_time": 21.66869854927063,
[36m(head, rank=0, pid=3451)[0m   "training_time": 1088.7835998535156,
[36m(head, rank=0, pid=3451)[0m   "total_time": 1112.5855159759521,
[36m(head, rank=0, pid=3451)[0m   "error": null,
[36m(head, rank=0, pid=3451)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m   "total_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m   "average_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m   "min_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m   "max_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m     315.26026368141174
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m   "total_batch_sample_time": 0.36168718338012695,
[36m(head, rank=0, pid=3451)[0m   "average_batch_sample_time": 0.0361687183380127,
[36m(head, rank=0, pid=3451)[0m   "min_batch_sample_time": 0.027540922164916992,
[36m(head, rank=0, pid=3451)[0m   "max_batch_sample_time": 0.07986950874328613,
[36m(head, rank=0, pid=3451)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m     0.07986950874328613,
[36m(head, rank=0, pid=3451)[0m     0.032659053802490234,
[36m(head, rank=0, pid=3451)[0m     0.03299736976623535,
[36m(head, rank=0, pid=3451)[0m     0.030316591262817383,
[36m(head, rank=0, pid=3451)[0m     0.032385826110839844,
[36m(head, rank=0, pid=3451)[0m     0.029065370559692383,
[36m(head, rank=0, pid=3451)[0m     0.03265380859375,
[36m(head, rank=0, pid=3451)[0m     0.03216290473937988,
[36m(head, rank=0, pid=3451)[0m     0.027540922164916992,
[36m(head, rank=0, pid=3451)[0m     0.03203582763671875
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m   "total_training_step_time": 356.78466963768005,
[36m(head, rank=0, pid=3451)[0m   "average_training_step_time": 4.459808370471,
[36m(head, rank=0, pid=3451)[0m   "min_training_step_time": 3.6644134521484375,
[36m(head, rank=0, pid=3451)[0m   "max_training_step_time": 8.148733854293823,
[36m(head, rank=0, pid=3451)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m     8.148733854293823,
[36m(head, rank=0, pid=3451)[0m     4.783166408538818,
[36m(head, rank=0, pid=3451)[0m     5.241788387298584,
[36m(head, rank=0, pid=3451)[0m     4.2806127071380615,
[36m(head, rank=0, pid=3451)[0m     5.2950520515441895,
[36m(head, rank=0, pid=3451)[0m     4.018121242523193,
[36m(head, rank=0, pid=3451)[0m     4.118767499923706,
[36m(head, rank=0, pid=3451)[0m     4.136389970779419,
[36m(head, rank=0, pid=3451)[0m     4.276655435562134,
[36m(head, rank=0, pid=3451)[0m     5.14495325088501,
[36m(head, rank=0, pid=3451)[0m     4.253464937210083,
[36m(head, rank=0, pid=3451)[0m     4.16551661491394,
[36m(head, rank=0, pid=3451)[0m     4.0201802253723145,
[36m(head, rank=0, pid=3451)[0m     5.4205896854400635,
[36m(head, rank=0, pid=3451)[0m     4.150380849838257,
[36m(head, rank=0, pid=3451)[0m     4.838983774185181,
[36m(head, rank=0, pid=3451)[0m     4.886526823043823,
[36m(head, rank=0, pid=3451)[0m     4.33314847946167,
[36m(head, rank=0, pid=3451)[0m     4.023960828781128,
[36m(head, rank=0, pid=3451)[0m     4.1384828090667725,
[36m(head, rank=0, pid=3451)[0m     4.717159986495972,
[36m(head, rank=0, pid=3451)[0m     4.142578125,
[36m(head, rank=0, pid=3451)[0m     5.055387020111084,
[36m(head, rank=0, pid=3451)[0m     4.159034252166748,
[36m(head, rank=0, pid=3451)[0m     5.375937461853027,
[36m(head, rank=0, pid=3451)[0m     4.406747341156006,
[36m(head, rank=0, pid=3451)[0m     4.28113317489624,
[36m(head, rank=0, pid=3451)[0m     4.134499549865723,
[36m(head, rank=0, pid=3451)[0m     4.037315845489502,
[36m(head, rank=0, pid=3451)[0m     4.1421473026275635,
[36m(head, rank=0, pid=3451)[0m     4.299402475357056,
[36m(head, rank=0, pid=3451)[0m     4.787665605545044,
[36m(head, rank=0, pid=3451)[0m     5.309727430343628,
[36m(head, rank=0, pid=3451)[0m     4.238477945327759,
[36m(head, rank=0, pid=3451)[0m     4.5566325187683105,
[36m(head, rank=0, pid=3451)[0m     4.510152578353882,
[36m(head, rank=0, pid=3451)[0m     4.717361211776733,
[36m(head, rank=0, pid=3451)[0m     4.594281196594238,
[36m(head, rank=0, pid=3451)[0m     3.6644134521484375,
[36m(head, rank=0, pid=3451)[0m     4.150561571121216,
[36m(head, rank=0, pid=3451)[0m     3.941936731338501,
[36m(head, rank=0, pid=3451)[0m     3.989302158355713,
[36m(head, rank=0, pid=3451)[0m     5.497509479522705,
[36m(head, rank=0, pid=3451)[0m     4.3856284618377686,
[36m(head, rank=0, pid=3451)[0m     4.348859786987305,
[36m(head, rank=0, pid=3451)[0m     4.111646413803101,
[36m(head, rank=0, pid=3451)[0m     4.0851829051971436,
[36m(head, rank=0, pid=3451)[0m     4.206927537918091,
[36m(head, rank=0, pid=3451)[0m     5.140683889389038,
[36m(head, rank=0, pid=3451)[0m     5.0655434131622314,
[36m(head, rank=0, pid=3451)[0m     4.1029372215271,
[36m(head, rank=0, pid=3451)[0m     4.1002655029296875,
[36m(head, rank=0, pid=3451)[0m     4.404061555862427,
[36m(head, rank=0, pid=3451)[0m     4.381673574447632,
[36m(head, rank=0, pid=3451)[0m     4.630964517593384,
[36m(head, rank=0, pid=3451)[0m     3.899503469467163,
[36m(head, rank=0, pid=3451)[0m     5.3703272342681885,
[36m(head, rank=0, pid=3451)[0m     4.4900195598602295,
[36m(head, rank=0, pid=3451)[0m     4.315261125564575,
[36m(head, rank=0, pid=3451)[0m     4.586534738540649,
[36m(head, rank=0, pid=3451)[0m     4.248098373413086,
[36m(head, rank=0, pid=3451)[0m     4.103786468505859,
[36m(head, rank=0, pid=3451)[0m     3.871948003768921,
[36m(head, rank=0, pid=3451)[0m     4.779367685317993,
[36m(head, rank=0, pid=3451)[0m     3.9847588539123535,
[36m(head, rank=0, pid=3451)[0m     3.95863676071167,
[36m(head, rank=0, pid=3451)[0m     4.121338844299316,
[36m(head, rank=0, pid=3451)[0m     3.9254167079925537,
[36m(head, rank=0, pid=3451)[0m     4.596295356750488,
[36m(head, rank=0, pid=3451)[0m     5.4415295124053955,
[36m(head, rank=0, pid=3451)[0m     4.303666353225708,
[36m(head, rank=0, pid=3451)[0m     4.322439908981323,
[36m(head, rank=0, pid=3451)[0m     3.853355646133423,
[36m(head, rank=0, pid=3451)[0m     4.466620922088623,
[36m(head, rank=0, pid=3451)[0m     4.14479923248291,
[36m(head, rank=0, pid=3451)[0m     4.144121885299683,
[36m(head, rank=0, pid=3451)[0m     4.36201024055481,
[36m(head, rank=0, pid=3451)[0m     4.123190641403198,
[36m(head, rank=0, pid=3451)[0m     3.8917899131774902,
[36m(head, rank=0, pid=3451)[0m     4.130637168884277
[36m(head, rank=0, pid=3451)[0m   ]
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3451)[0m [
[36m(head, rank=0, pid=3451)[0m   {
[36m(head, rank=0, pid=3451)[0m     "run_id": 1,
[36m(head, rank=0, pid=3451)[0m     "timestamp": "2025-08-03T18:50:25.304615",
[36m(head, rank=0, pid=3451)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3451)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m     "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3451)[0m     "dataset_load_time": 2.1332175731658936,
[36m(head, rank=0, pid=3451)[0m     "model_load_time": 21.66869854927063,
[36m(head, rank=0, pid=3451)[0m     "training_time": 1088.7835998535156,
[36m(head, rank=0, pid=3451)[0m     "total_time": 1112.5855159759521,
[36m(head, rank=0, pid=3451)[0m     "error": null,
[36m(head, rank=0, pid=3451)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "average_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "min_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "max_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m       315.26026368141174
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 0.36168718338012695,
[36m(head, rank=0, pid=3451)[0m     "average_batch_sample_time": 0.0361687183380127,
[36m(head, rank=0, pid=3451)[0m     "min_batch_sample_time": 0.027540922164916992,
[36m(head, rank=0, pid=3451)[0m     "max_batch_sample_time": 0.07986950874328613,
[36m(head, rank=0, pid=3451)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m       0.07986950874328613,
[36m(head, rank=0, pid=3451)[0m       0.032659053802490234,
[36m(head, rank=0, pid=3451)[0m       0.03299736976623535,
[36m(head, rank=0, pid=3451)[0m       0.030316591262817383,
[36m(head, rank=0, pid=3451)[0m       0.032385826110839844,
[36m(head, rank=0, pid=3451)[0m       0.029065370559692383,
[36m(head, rank=0, pid=3451)[0m       0.03265380859375,
[36m(head, rank=0, pid=3451)[0m       0.03216290473937988,
[36m(head, rank=0, pid=3451)[0m       0.027540922164916992,
[36m(head, rank=0, pid=3451)[0m       0.03203582763671875
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 356.78466963768005,
[36m(head, rank=0, pid=3451)[0m     "average_training_step_time": 4.459808370471,
[36m(head, rank=0, pid=3451)[0m     "min_training_step_time": 3.6644134521484375,
[36m(head, rank=0, pid=3451)[0m     "max_training_step_time": 8.148733854293823,
[36m(head, rank=0, pid=3451)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m       8.148733854293823,
[36m(head, rank=0, pid=3451)[0m       4.783166408538818,
[36m(head, rank=0, pid=3451)[0m       5.241788387298584,
[36m(head, rank=0, pid=3451)[0m       4.2806127071380615,
[36m(head, rank=0, pid=3451)[0m       5.2950520515441895,
[36m(head, rank=0, pid=3451)[0m       4.018121242523193,
[36m(head, rank=0, pid=3451)[0m       4.118767499923706,
[36m(head, rank=0, pid=3451)[0m       4.136389970779419,
[36m(head, rank=0, pid=3451)[0m       4.276655435562134,
[36m(head, rank=0, pid=3451)[0m       5.14495325088501,
[36m(head, rank=0, pid=3451)[0m       4.253464937210083,
[36m(head, rank=0, pid=3451)[0m       4.16551661491394,
[36m(head, rank=0, pid=3451)[0m       4.0201802253723145,
[36m(head, rank=0, pid=3451)[0m       5.4205896854400635,
[36m(head, rank=0, pid=3451)[0m       4.150380849838257,
[36m(head, rank=0, pid=3451)[0m       4.838983774185181,
[36m(head, rank=0, pid=3451)[0m       4.886526823043823,
[36m(head, rank=0, pid=3451)[0m       4.33314847946167,
[36m(head, rank=0, pid=3451)[0m       4.023960828781128,
[36m(head, rank=0, pid=3451)[0m       4.1384828090667725,
[36m(head, rank=0, pid=3451)[0m       4.717159986495972,
[36m(head, rank=0, pid=3451)[0m       4.142578125,
[36m(head, rank=0, pid=3451)[0m       5.055387020111084,
[36m(head, rank=0, pid=3451)[0m       4.159034252166748,
[36m(head, rank=0, pid=3451)[0m       5.375937461853027,
[36m(head, rank=0, pid=3451)[0m       4.406747341156006,
[36m(head, rank=0, pid=3451)[0m       4.28113317489624,
[36m(head, rank=0, pid=3451)[0m       4.134499549865723,
[36m(head, rank=0, pid=3451)[0m       4.037315845489502,
[36m(head, rank=0, pid=3451)[0m       4.1421473026275635,
[36m(head, rank=0, pid=3451)[0m       4.299402475357056,
[36m(head, rank=0, pid=3451)[0m       4.787665605545044,
[36m(head, rank=0, pid=3451)[0m       5.309727430343628,
[36m(head, rank=0, pid=3451)[0m       4.238477945327759,
[36m(head, rank=0, pid=3451)[0m       4.5566325187683105,
[36m(head, rank=0, pid=3451)[0m       4.510152578353882,
[36m(head, rank=0, pid=3451)[0m       4.717361211776733,
[36m(head, rank=0, pid=3451)[0m       4.594281196594238,
[36m(head, rank=0, pid=3451)[0m       3.6644134521484375,
[36m(head, rank=0, pid=3451)[0m       4.150561571121216,
[36m(head, rank=0, pid=3451)[0m       3.941936731338501,
[36m(head, rank=0, pid=3451)[0m       3.989302158355713,
[36m(head, rank=0, pid=3451)[0m       5.497509479522705,
[36m(head, rank=0, pid=3451)[0m       4.3856284618377686,
[36m(head, rank=0, pid=3451)[0m       4.348859786987305,
[36m(head, rank=0, pid=3451)[0m       4.111646413803101,
[36m(head, rank=0, pid=3451)[0m       4.0851829051971436,
[36m(head, rank=0, pid=3451)[0m       4.206927537918091,
[36m(head, rank=0, pid=3451)[0m       5.140683889389038,
[36m(head, rank=0, pid=3451)[0m       5.0655434131622314,
[36m(head, rank=0, pid=3451)[0m       4.1029372215271,
[36m(head, rank=0, pid=3451)[0m       4.1002655029296875,
[36m(head, rank=0, pid=3451)[0m       4.404061555862427,
[36m(head, rank=0, pid=3451)[0m       4.381673574447632,
[36m(head, rank=0, pid=3451)[0m       4.630964517593384,
[36m(head, rank=0, pid=3451)[0m       3.899503469467163,
[36m(head, rank=0, pid=3451)[0m       5.3703272342681885,
[36m(head, rank=0, pid=3451)[0m       4.4900195598602295,
[36m(head, rank=0, pid=3451)[0m       4.315261125564575,
[36m(head, rank=0, pid=3451)[0m       4.586534738540649,
[36m(head, rank=0, pid=3451)[0m       4.248098373413086,
[36m(head, rank=0, pid=3451)[0m       4.103786468505859,
[36m(head, rank=0, pid=3451)[0m       3.871948003768921,
[36m(head, rank=0, pid=3451)[0m       4.779367685317993,
[36m(head, rank=0, pid=3451)[0m       3.9847588539123535,
[36m(head, rank=0, pid=3451)[0m       3.95863676071167,
[36m(head, rank=0, pid=3451)[0m       4.121338844299316,
[36m(head, rank=0, pid=3451)[0m       3.9254167079925537,
[36m(head, rank=0, pid=3451)[0m       4.596295356750488,
[36m(head, rank=0, pid=3451)[0m       5.4415295124053955,
[36m(head, rank=0, pid=3451)[0m       4.303666353225708,
[36m(head, rank=0, pid=3451)[0m       4.322439908981323,
[36m(head, rank=0, pid=3451)[0m       3.853355646133423,
[36m(head, rank=0, pid=3451)[0m       4.466620922088623,
[36m(head, rank=0, pid=3451)[0m       4.14479923248291,
[36m(head, rank=0, pid=3451)[0m       4.144121885299683,
[36m(head, rank=0, pid=3451)[0m       4.36201024055481,
[36m(head, rank=0, pid=3451)[0m       4.123190641403198,
[36m(head, rank=0, pid=3451)[0m       3.8917899131774902,
[36m(head, rank=0, pid=3451)[0m       4.130637168884277
[36m(head, rank=0, pid=3451)[0m     ]
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m ]
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3451)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3451)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_average": 2.1332175731658936,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_min": 2.1332175731658936,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_max": 2.1332175731658936,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_total": 2.1332175731658936
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "model_loading": {
[36m(head, rank=0, pid=3451)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "model_load_average": 21.66869854927063,
[36m(head, rank=0, pid=3451)[0m     "model_load_min": 21.66869854927063,
[36m(head, rank=0, pid=3451)[0m     "model_load_max": 21.66869854927063,
[36m(head, rank=0, pid=3451)[0m     "model_load_total": 21.66869854927063
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training": {
[36m(head, rank=0, pid=3451)[0m     "training_count": 1,
[36m(head, rank=0, pid=3451)[0m     "training_average": 1088.7835998535156,
[36m(head, rank=0, pid=3451)[0m     "training_min": 1088.7835998535156,
[36m(head, rank=0, pid=3451)[0m     "training_max": 1088.7835998535156,
[36m(head, rank=0, pid=3451)[0m     "training_total": 1088.7835998535156
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "total_run_time": {
[36m(head, rank=0, pid=3451)[0m     "total_count": 1,
[36m(head, rank=0, pid=3451)[0m     "total_average": 1112.5855159759521,
[36m(head, rank=0, pid=3451)[0m     "total_min": 1112.5855159759521,
[36m(head, rank=0, pid=3451)[0m     "total_max": 1112.5855159759521,
[36m(head, rank=0, pid=3451)[0m     "total_total": 1112.5855159759521
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3451)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "average_save_time_per_checkpoint": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_min": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_max": 315.26026368141174,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_average": 315.26026368141174
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3451)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 0.36168718338012695,
[36m(head, rank=0, pid=3451)[0m     "average_sample_time_per_batch": 0.0361687183380127,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_min": 0.027540922164916992,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_max": 0.07986950874328613,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_average": 0.0361687183380127
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training_steps": {
[36m(head, rank=0, pid=3451)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 356.78466963768005,
[36m(head, rank=0, pid=3451)[0m     "average_step_time_per_step": 4.459808370471,
[36m(head, rank=0, pid=3451)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3451)[0m     "training_step_min": 3.6644134521484375,
[36m(head, rank=0, pid=3451)[0m     "training_step_max": 8.148733854293823,
[36m(head, rank=0, pid=3451)[0m     "training_step_average": 4.459808370471
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.14s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.01s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1109.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1109.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1109.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1109.14s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 358.28s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.29s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.67s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.00s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1108.92s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1108.92s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1108.92s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1108.92s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.49s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 358.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.35s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96sSaved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.59s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.57s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.57s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.57s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.57s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 0.93s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1109.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1109.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1109.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1109.05s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.47s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 357.88s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.33s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.54s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.20s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 0.93s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1109.21s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1109.21s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1109.21s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1109.21s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.47s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 357.46s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.33s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.34s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.34s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.34s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.34s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.20s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 0.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 0.93s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1109.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1109.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1109.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1109.20s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 358.17s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.33s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.14s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 0.94s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 0.94s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 0.94s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 0.94s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1109.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1109.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1109.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1109.24s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 358.79s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.31s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.31s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.31s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.31s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.13s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.04s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1109.21s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1109.21s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1109.21s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1109.21s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.47s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 10.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 357.79s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.34s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 177.96s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1112.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1112.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1112.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1112.37s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 358.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.32s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.11s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 358.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1111.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1111.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1111.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1111.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 358.50s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1111.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1111.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1111.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1111.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 358.64s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1112.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1112.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1112.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1112.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.62s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.62s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.62s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.62s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 358.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1111.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1111.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1111.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1111.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.47s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 357.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1111.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1111.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1111.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1111.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1108.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 10.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 358.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 177.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1111.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(head, rank=0, pid=3451)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3451)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: 'pytorch_model-00001-of-00012.bin'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.22 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.24 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.24 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.25 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.25 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.28 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.28 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.30 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.30 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.34 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.31 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.33 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.39 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.37 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.68 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 61.27it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 75.15it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 71.30it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.27it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 65.91it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 61.48it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 65.34it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.00 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 63.08it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 63.45it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.10it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 65.50it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 66.48it/s]
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 0.98 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.02 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.00 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.13it/s]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.14 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.02 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.01 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.16 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.16 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 65.10it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.41 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  5.93s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  6.40s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:16,  5.58s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:12<00:18,  6.18s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:10,  5.35s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:18<00:11,  5.95s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:21<00:05,  5.20s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  4.97s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.17s/it]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 26.87 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:05,  5.82s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  5.70s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  5.84s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 30.10 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:10,387] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,694] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,695] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,695] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,698] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,700] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,702] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,702] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:11,725] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,094] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,096] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,121] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,122] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,122] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,123] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,126] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:12,126] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,922] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,949] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,951] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,960] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,967] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,970] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:10:12,972] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,199] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,213] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,367] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,369] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,370] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,371] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,375] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:10:13,379] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m  10%|â–ˆ         | 1/10 [00:39<05:53, 39.30s/it]
[36m(head, rank=0, pid=3451)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:15<04:59, 37.44s/it]
[36m(head, rank=0, pid=3451)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:50<04:15, 36.52s/it]
[36m(head, rank=0, pid=3451)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:26<03:36, 36.11s/it]
[36m(head, rank=0, pid=3451)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:03<03:01, 36.33s/it]
[36m(head, rank=0, pid=3451)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:37<02:23, 35.81s/it]
[36m(head, rank=0, pid=3451)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:14<01:47, 35.98s/it]
[36m(head, rank=0, pid=3451)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [04:50<01:12, 36.23s/it]
[36m(head, rank=0, pid=3451)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:26<00:35, 35.86s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:00<00:00, 35.32s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:00<00:00, 35.32s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.69 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.69s (Total: 381.69s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.69 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.69s (Total: 381.69s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.69 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.69s (Total: 381.69s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.70 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.70 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.70 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 381.71 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 381.71s (Total: 381.71s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.69 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.69s (Total: 381.69s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.69 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.69s (Total: 381.69s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.70 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.70 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.70 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.70 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.70s (Total: 381.70s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.71 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.71s (Total: 381.71s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 381.71 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 381.71s (Total: 381.71s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 683.36 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 683.36s (Total: 683.36s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1069.39 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1097.90 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1097.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 318.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 3.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 5.14s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1  - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.69s  - Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.70s  - Min save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.70s  - Max save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.70sBatch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10  - Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.05s  - Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.05s  - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s  - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:  - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.54s  - Total training step time: 320.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s  - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.38s  - Max training step time: 7.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1097.93 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1097.94 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.80s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1097.86 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1097.90 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.56s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 321.20s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1098.02 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 321.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m 
                                               
{'train_runtime': 1043.509, 'train_samples_per_second': 1.227, 'train_steps_per_second': 0.01, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [17:23<00:00, 35.32s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [17:23<00:00, 104.35s/it]
[36m(head, rank=0, pid=3451)[0m Completed Training in 1072.59 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 683.36s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 683.36s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 683.36s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 683.36s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.48s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.09s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 319.45s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 3.99s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 5.81s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.80 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 381.69s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 381.69s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.51s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.13s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 320.37s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.41s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.93 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 381.70s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.47s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.12s
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.85 secondsTraining Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 320.57s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.01s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.42s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 381.69s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 381.69s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.55s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.06s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.17s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.00s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.01s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.37s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.89 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 381.71s  - Total checkpoint save time: 381.69s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 381.69s  - Average save time per checkpoint: 381.71s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Min save time: 381.69s  - Min save time: 381.71s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Max save time: 381.69s  - Max save time: 381.71s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10  - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.52s  - Total batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.05s  - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s  - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.16s  - Max batch sample time: 0.15s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:Training Step Performance:
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80  - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 320.75s  - Total training step time: 320.50s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.01s  - Average training step time: 4.01s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.51s  - Min training step time: 3.55s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.38s  - Max training step time: 7.39s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 381.70s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.17s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 319.94s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.37s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1097.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 381.70s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.15s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.29s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.02s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.54s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.38s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1097.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1097.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1097.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1097.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.23s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.23s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.23s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.23s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 0.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 0.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 0.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 0.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1097.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1097.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1097.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1097.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.21s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.21s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.21s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.21s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 30.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 30.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 30.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 30.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1069.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1069.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1069.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1069.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 3.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 5.14s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 318.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "timestamp": "2025-08-03T19:09:36.184200",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_load_time": 2.295118570327759,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_load_time": 30.0997052192688,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_time": 1069.3914158344269,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_time": 1101.7862396240234,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     381.6986219882965
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_batch_sample_time": 0.42879724502563477,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_batch_sample_time": 0.04287972450256348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_batch_sample_time": 0.02793431282043457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_batch_sample_time": 0.06251001358032227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.06251001358032227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.05457735061645508,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.04015803337097168,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.05535769462585449,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.04385519027709961,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.03310060501098633,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.0333554744720459,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.035102128982543945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.0428464412689209,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.02793431282043457
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_training_step_time": 318.90199065208435,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_training_step_time": 3.9862748831510544,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_training_step_time": 3.5242607593536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_training_step_time": 5.1403868198394775,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.1403868198394775,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7195165157318115,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.3574464321136475,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6678531169891357,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.732527494430542,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8509531021118164,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.752487897872925,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.684100866317749,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.286592960357666,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.602537393569946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6748416423797607,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6624464988708496,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6605043411254883,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.995357990264893,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.674098253250122,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.534235954284668,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.074588775634766,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6996002197265625,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.923311233520508,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6661994457244873,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.279083967208862,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6650733947753906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.5684614181518555,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.706155300140381,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.956269979476929,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6817643642425537,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8053324222564697,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.734182834625244,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5242607593536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.682375907897949,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.800859212875366,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.321122884750366,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.707128286361694,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.839775562286377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.66620135307312,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.035324335098267,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.500259160995483,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.372689247131348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.662790298461914,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.834207773208618,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6038544178009033,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6723217964172363,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.757027864456177,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6764659881591797,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.9338643550872803,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8915388584136963,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6806797981262207,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8730320930480957,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.751429080963135,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.761165380477905,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5352413654327393,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6715712547302246,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.924669027328491,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.579911470413208,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.248375654220581,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6755564212799072,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.00471830368042,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.2827136516571045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8263957500457764,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.096125364303589,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5271904468536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7220113277435303,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.667250871658325,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.3593339920043945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.659165143966675,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5768821239471436,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6825668811798096,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6638126373291016,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.2608137130737305,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.8091161251068115,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.672485828399658,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8515825271606445,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7183480262756348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.169976472854614,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5523977279663086,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.033508062362671,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.820122718811035,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6545369625091553,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.670941114425659,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.680384635925293
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "timestamp": "2025-08-03T19:09:36.184200",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_time": 2.295118570327759,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_time": 30.0997052192688,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_time": 1069.3914158344269,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_time": 1101.7862396240234,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       381.6986219882965
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 0.42879724502563477,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_batch_sample_time": 0.04287972450256348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_batch_sample_time": 0.02793431282043457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_batch_sample_time": 0.06251001358032227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.06251001358032227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.05457735061645508,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.04015803337097168,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.05535769462585449,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.04385519027709961,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.03310060501098633,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.0333554744720459,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.035102128982543945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.0428464412689209,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.02793431282043457
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 318.90199065208435,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_training_step_time": 3.9862748831510544,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_training_step_time": 3.5242607593536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_training_step_time": 5.1403868198394775,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.1403868198394775,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7195165157318115,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.3574464321136475,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6678531169891357,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.732527494430542,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8509531021118164,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.752487897872925,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.684100866317749,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.286592960357666,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.602537393569946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6748416423797607,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6624464988708496,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6605043411254883,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.995357990264893,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.674098253250122,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.534235954284668,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.074588775634766,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6996002197265625,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.923311233520508,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6661994457244873,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.279083967208862,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6650733947753906,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.5684614181518555,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.706155300140381,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.956269979476929,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6817643642425537,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8053324222564697,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.734182834625244,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5242607593536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.682375907897949,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.800859212875366,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.321122884750366,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.707128286361694,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.839775562286377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.66620135307312,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.035324335098267,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.500259160995483,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.372689247131348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.662790298461914,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.834207773208618,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6038544178009033,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6723217964172363,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.757027864456177,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6764659881591797,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.9338643550872803,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8915388584136963,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6806797981262207,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8730320930480957,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.751429080963135,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.761165380477905,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5352413654327393,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6715712547302246,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.924669027328491,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.579911470413208,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.248375654220581,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6755564212799072,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.00471830368042,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.2827136516571045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8263957500457764,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.096125364303589,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5271904468536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7220113277435303,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.667250871658325,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.3593339920043945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.659165143966675,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5768821239471436,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6825668811798096,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6638126373291016,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.2608137130737305,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.8091161251068115,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.672485828399658,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8515825271606445,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7183480262756348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.169976472854614,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5523977279663086,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.033508062362671,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.820122718811035,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6545369625091553,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.670941114425659,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.680384635925293
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_average": 2.295118570327759,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_min": 2.295118570327759,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_max": 2.295118570327759,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_total": 2.295118570327759
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_average": 30.0997052192688,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_min": 30.0997052192688,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_max": 30.0997052192688,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_total": 30.0997052192688
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_average": 1069.3914158344269,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_min": 1069.3914158344269,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_max": 1069.3914158344269,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_total": 1069.3914158344269
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_average": 1101.7862396240234,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_min": 1101.7862396240234,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_max": 1101.7862396240234,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_total": 1101.7862396240234
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_save_time_per_checkpoint": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_min": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_max": 381.6986219882965,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_average": 381.6986219882965
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 0.42879724502563477,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_sample_time_per_batch": 0.04287972450256348,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_min": 0.02793431282043457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_max": 0.06251001358032227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_average": 0.04287972450256348
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 318.90199065208435,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_step_time_per_step": 3.9862748831510544,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_min": 3.5242607593536377,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_max": 5.1403868198394775,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_average": 3.9862748831510544
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.68s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.68s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.68s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.68s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 0.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1097.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1097.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1097.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1097.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.48s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.27s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.27s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.27s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.27s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1097.94s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1097.94s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1097.94s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1097.94s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.80s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.71s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.34s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.34s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.34s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.34s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1097.90s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 321.20s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.56s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.26s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.26s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.26s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.26s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.24s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.41s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.80s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.80s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.80s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.80s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 320.37s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.51s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.69s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.45s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.25s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.16s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.00s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.06s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.17s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.55s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.69s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.26s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.31s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.31s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.31s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.31s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 26.87s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 26.87s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 26.87s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 26.87s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1072.59s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_6.json  â€¢ Min time: 1072.59s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1072.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1072.59s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 3.99s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 5.81s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 319.45s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.09s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.48s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 683.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 683.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 683.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 683.36s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.77s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.77s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.77s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================  â€¢ Total time across all runs: 1101.77s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.24s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.24s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.14s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.55s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 320.50s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.15s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.69s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.22s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.22s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.22s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.22s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.36s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.02s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.89s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.89s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.89s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.89s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.38s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 320.75s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.71s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.71s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.71s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.71s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.27s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.27s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.27s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.27s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.33s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.16s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 319.94s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.17s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.33s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "run_id": 1,
[36m(head, rank=0, pid=3451)[0m   "timestamp": "2025-08-03T19:09:36.184200",
[36m(head, rank=0, pid=3451)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m   "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3451)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m   "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3451)[0m   "dataset_load_time": 2.295118570327759,
[36m(head, rank=0, pid=3451)[0m   "model_load_time": 30.0997052192688,
[36m(head, rank=0, pid=3451)[0m   "training_time": 1069.3914158344269,
[36m(head, rank=0, pid=3451)[0m   "total_time": 1101.7862396240234,
[36m(head, rank=0, pid=3451)[0m   "error": null,
[36m(head, rank=0, pid=3451)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m   "total_checkpoint_save_time": 381.6986219882965,
[36m(head, rank=0, pid=3451)[0m   "average_checkpoint_save_time": 381.6986219882965,
[36m(head, rank=0, pid=3451)[0m   "min_checkpoint_save_time": 381.6986219882965,
[36m(head, rank=0, pid=3451)[0m   "max_checkpoint_save_time": 381.6986219882965,
[36m(head, rank=0, pid=3451)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m     381.6986219882965
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m   "total_batch_sample_time": 0.42879724502563477,
[36m(head, rank=0, pid=3451)[0m   "average_batch_sample_time": 0.04287972450256348,
[36m(head, rank=0, pid=3451)[0m   "min_batch_sample_time": 0.02793431282043457,
[36m(head, rank=0, pid=3451)[0m   "max_batch_sample_time": 0.06251001358032227,
[36m(head, rank=0, pid=3451)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m     0.06251001358032227,
[36m(head, rank=0, pid=3451)[0m     0.05457735061645508,
[36m(head, rank=0, pid=3451)[0m     0.04015803337097168,
[36m(head, rank=0, pid=3451)[0m     0.05535769462585449,
[36m(head, rank=0, pid=3451)[0m     0.04385519027709961,
[36m(head, rank=0, pid=3451)[0m     0.03310060501098633,
[36m(head, rank=0, pid=3451)[0m     0.0333554744720459,
[36m(head, rank=0, pid=3451)[0m     0.035102128982543945,
[36m(head, rank=0, pid=3451)[0m     0.0428464412689209,
[36m(head, rank=0, pid=3451)[0m     0.02793431282043457
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m   "total_training_step_time": 318.90199065208435,
[36m(head, rank=0, pid=3451)[0m   "average_training_step_time": 3.9862748831510544,
[36m(head, rank=0, pid=3451)[0m   "min_training_step_time": 3.5242607593536377,
[36m(head, rank=0, pid=3451)[0m   "max_training_step_time": 5.1403868198394775,
[36m(head, rank=0, pid=3451)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m     5.1403868198394775,
[36m(head, rank=0, pid=3451)[0m     3.7195165157318115,
[36m(head, rank=0, pid=3451)[0m     4.3574464321136475,
[36m(head, rank=0, pid=3451)[0m     3.6678531169891357,
[36m(head, rank=0, pid=3451)[0m     4.732527494430542,
[36m(head, rank=0, pid=3451)[0m     3.8509531021118164,
[36m(head, rank=0, pid=3451)[0m     3.752487897872925,
[36m(head, rank=0, pid=3451)[0m     3.684100866317749,
[36m(head, rank=0, pid=3451)[0m     4.286592960357666,
[36m(head, rank=0, pid=3451)[0m     4.602537393569946,
[36m(head, rank=0, pid=3451)[0m     3.6748416423797607,
[36m(head, rank=0, pid=3451)[0m     3.6624464988708496,
[36m(head, rank=0, pid=3451)[0m     3.6605043411254883,
[36m(head, rank=0, pid=3451)[0m     4.995357990264893,
[36m(head, rank=0, pid=3451)[0m     3.674098253250122,
[36m(head, rank=0, pid=3451)[0m     4.534235954284668,
[36m(head, rank=0, pid=3451)[0m     4.074588775634766,
[36m(head, rank=0, pid=3451)[0m     3.6996002197265625,
[36m(head, rank=0, pid=3451)[0m     3.923311233520508,
[36m(head, rank=0, pid=3451)[0m     3.6661994457244873,
[36m(head, rank=0, pid=3451)[0m     4.279083967208862,
[36m(head, rank=0, pid=3451)[0m     3.6650733947753906,
[36m(head, rank=0, pid=3451)[0m     4.5684614181518555,
[36m(head, rank=0, pid=3451)[0m     3.706155300140381,
[36m(head, rank=0, pid=3451)[0m     4.956269979476929,
[36m(head, rank=0, pid=3451)[0m     3.6817643642425537,
[36m(head, rank=0, pid=3451)[0m     3.8053324222564697,
[36m(head, rank=0, pid=3451)[0m     3.734182834625244,
[36m(head, rank=0, pid=3451)[0m     3.5242607593536377,
[36m(head, rank=0, pid=3451)[0m     3.682375907897949,
[36m(head, rank=0, pid=3451)[0m     3.800859212875366,
[36m(head, rank=0, pid=3451)[0m     4.321122884750366,
[36m(head, rank=0, pid=3451)[0m     4.707128286361694,
[36m(head, rank=0, pid=3451)[0m     3.839775562286377,
[36m(head, rank=0, pid=3451)[0m     3.66620135307312,
[36m(head, rank=0, pid=3451)[0m     4.035324335098267,
[36m(head, rank=0, pid=3451)[0m     4.500259160995483,
[36m(head, rank=0, pid=3451)[0m     4.372689247131348,
[36m(head, rank=0, pid=3451)[0m     3.662790298461914,
[36m(head, rank=0, pid=3451)[0m     3.834207773208618,
[36m(head, rank=0, pid=3451)[0m     3.6038544178009033,
[36m(head, rank=0, pid=3451)[0m     3.6723217964172363,
[36m(head, rank=0, pid=3451)[0m     4.757027864456177,
[36m(head, rank=0, pid=3451)[0m     3.6764659881591797,
[36m(head, rank=0, pid=3451)[0m     3.9338643550872803,
[36m(head, rank=0, pid=3451)[0m     3.8915388584136963,
[36m(head, rank=0, pid=3451)[0m     3.6806797981262207,
[36m(head, rank=0, pid=3451)[0m     3.8730320930480957,
[36m(head, rank=0, pid=3451)[0m     4.751429080963135,
[36m(head, rank=0, pid=3451)[0m     4.761165380477905,
[36m(head, rank=0, pid=3451)[0m     3.5352413654327393,
[36m(head, rank=0, pid=3451)[0m     3.6715712547302246,
[36m(head, rank=0, pid=3451)[0m     3.924669027328491,
[36m(head, rank=0, pid=3451)[0m     3.579911470413208,
[36m(head, rank=0, pid=3451)[0m     4.248375654220581,
[36m(head, rank=0, pid=3451)[0m     3.6755564212799072,
[36m(head, rank=0, pid=3451)[0m     5.00471830368042,
[36m(head, rank=0, pid=3451)[0m     4.2827136516571045,
[36m(head, rank=0, pid=3451)[0m     3.8263957500457764,
[36m(head, rank=0, pid=3451)[0m     4.096125364303589,
[36m(head, rank=0, pid=3451)[0m     3.5271904468536377,
[36m(head, rank=0, pid=3451)[0m     3.7220113277435303,
[36m(head, rank=0, pid=3451)[0m     3.667250871658325,
[36m(head, rank=0, pid=3451)[0m     4.3593339920043945,
[36m(head, rank=0, pid=3451)[0m     3.659165143966675,
[36m(head, rank=0, pid=3451)[0m     3.5768821239471436,
[36m(head, rank=0, pid=3451)[0m     3.6825668811798096,
[36m(head, rank=0, pid=3451)[0m     3.6638126373291016,
[36m(head, rank=0, pid=3451)[0m     4.2608137130737305,
[36m(head, rank=0, pid=3451)[0m     4.8091161251068115,
[36m(head, rank=0, pid=3451)[0m     3.672485828399658,
[36m(head, rank=0, pid=3451)[0m     3.8515825271606445,
[36m(head, rank=0, pid=3451)[0m     3.7183480262756348,
[36m(head, rank=0, pid=3451)[0m     4.169976472854614,
[36m(head, rank=0, pid=3451)[0m     3.5523977279663086,
[36m(head, rank=0, pid=3451)[0m     4.033508062362671,
[36m(head, rank=0, pid=3451)[0m     3.820122718811035,
[36m(head, rank=0, pid=3451)[0m     3.6545369625091553,
[36m(head, rank=0, pid=3451)[0m     3.670941114425659,
[36m(head, rank=0, pid=3451)[0m     3.680384635925293
[36m(head, rank=0, pid=3451)[0m   ]
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3451)[0m [
[36m(head, rank=0, pid=3451)[0m   {
[36m(head, rank=0, pid=3451)[0m     "run_id": 1,
[36m(head, rank=0, pid=3451)[0m     "timestamp": "2025-08-03T19:09:36.186072",
[36m(head, rank=0, pid=3451)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m     "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3451)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m     "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3451)[0m     "dataset_load_time": 2.313937187194824,
[36m(head, rank=0, pid=3451)[0m     "model_load_time": 26.86936664581299,
[36m(head, rank=0, pid=3451)[0m     "training_time": 1072.5871214866638,
[36m(head, rank=0, pid=3451)[0m     "total_time": 1101.7704253196716,
[36m(head, rank=0, pid=3451)[0m     "error": null,
[36m(head, rank=0, pid=3451)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "average_checkpoint_save_time": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "min_checkpoint_save_time": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "max_checkpoint_save_time": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m       683.3612413406372
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 0.47702527046203613,
[36m(head, rank=0, pid=3451)[0m     "average_batch_sample_time": 0.04770252704620361,
[36m(head, rank=0, pid=3451)[0m     "min_batch_sample_time": 0.0318598747253418,
[36m(head, rank=0, pid=3451)[0m     "max_batch_sample_time": 0.08749675750732422,
[36m(head, rank=0, pid=3451)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m       0.08749675750732422,
[36m(head, rank=0, pid=3451)[0m       0.054045677185058594,
[36m(head, rank=0, pid=3451)[0m       0.06954574584960938,
[36m(head, rank=0, pid=3451)[0m       0.03729581832885742,
[36m(head, rank=0, pid=3451)[0m       0.053000450134277344,
[36m(head, rank=0, pid=3451)[0m       0.03487443923950195,
[36m(head, rank=0, pid=3451)[0m       0.0378725528717041,
[36m(head, rank=0, pid=3451)[0m       0.0379033088684082,
[36m(head, rank=0, pid=3451)[0m       0.033130645751953125,
[36m(head, rank=0, pid=3451)[0m       0.0318598747253418
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 319.4514744281769,
[36m(head, rank=0, pid=3451)[0m     "average_training_step_time": 3.993143430352211,
[36m(head, rank=0, pid=3451)[0m     "min_training_step_time": 3.5256762504577637,
[36m(head, rank=0, pid=3451)[0m     "max_training_step_time": 5.8099260330200195,
[36m(head, rank=0, pid=3451)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m       5.8099260330200195,
[36m(head, rank=0, pid=3451)[0m       4.108726263046265,
[36m(head, rank=0, pid=3451)[0m       4.357924938201904,
[36m(head, rank=0, pid=3451)[0m       3.667630910873413,
[36m(head, rank=0, pid=3451)[0m       4.69987416267395,
[36m(head, rank=0, pid=3451)[0m       3.847781181335449,
[36m(head, rank=0, pid=3451)[0m       3.6027166843414307,
[36m(head, rank=0, pid=3451)[0m       3.682533025741577,
[36m(head, rank=0, pid=3451)[0m       3.9873695373535156,
[36m(head, rank=0, pid=3451)[0m       4.631767988204956,
[36m(head, rank=0, pid=3451)[0m       3.675257682800293,
[36m(head, rank=0, pid=3451)[0m       3.6624155044555664,
[36m(head, rank=0, pid=3451)[0m       3.6597414016723633,
[36m(head, rank=0, pid=3451)[0m       4.991540908813477,
[36m(head, rank=0, pid=3451)[0m       3.669142484664917,
[36m(head, rank=0, pid=3451)[0m       4.031129598617554,
[36m(head, rank=0, pid=3451)[0m       4.088664293289185,
[36m(head, rank=0, pid=3451)[0m       3.696944236755371,
[36m(head, rank=0, pid=3451)[0m       3.847750186920166,
[36m(head, rank=0, pid=3451)[0m       3.6663310527801514,
[36m(head, rank=0, pid=3451)[0m       4.257611989974976,
[36m(head, rank=0, pid=3451)[0m       3.6650843620300293,
[36m(head, rank=0, pid=3451)[0m       4.566280364990234,
[36m(head, rank=0, pid=3451)[0m       3.704268217086792,
[36m(head, rank=0, pid=3451)[0m       4.969536066055298,
[36m(head, rank=0, pid=3451)[0m       3.586887836456299,
[36m(head, rank=0, pid=3451)[0m       3.804813861846924,
[36m(head, rank=0, pid=3451)[0m       3.73220157623291,
[36m(head, rank=0, pid=3451)[0m       3.672332286834717,
[36m(head, rank=0, pid=3451)[0m       3.6804258823394775,
[36m(head, rank=0, pid=3451)[0m       3.8201844692230225,
[36m(head, rank=0, pid=3451)[0m       4.318351984024048,
[36m(head, rank=0, pid=3451)[0m       4.647432565689087,
[36m(head, rank=0, pid=3451)[0m       3.8444621562957764,
[36m(head, rank=0, pid=3451)[0m       3.666762351989746,
[36m(head, rank=0, pid=3451)[0m       4.038097143173218,
[36m(head, rank=0, pid=3451)[0m       4.502989768981934,
[36m(head, rank=0, pid=3451)[0m       4.416157007217407,
[36m(head, rank=0, pid=3451)[0m       3.6631460189819336,
[36m(head, rank=0, pid=3451)[0m       3.836022138595581,
[36m(head, rank=0, pid=3451)[0m       3.6877901554107666,
[36m(head, rank=0, pid=3451)[0m       3.5256762504577637,
[36m(head, rank=0, pid=3451)[0m       4.757354021072388,
[36m(head, rank=0, pid=3451)[0m       3.6765623092651367,
[36m(head, rank=0, pid=3451)[0m       3.908273220062256,
[36m(head, rank=0, pid=3451)[0m       3.8900177478790283,
[36m(head, rank=0, pid=3451)[0m       3.6796445846557617,
[36m(head, rank=0, pid=3451)[0m       3.875492811203003,
[36m(head, rank=0, pid=3451)[0m       4.7419726848602295,
[36m(head, rank=0, pid=3451)[0m       4.761436700820923,
[36m(head, rank=0, pid=3451)[0m       3.660914421081543,
[36m(head, rank=0, pid=3451)[0m       3.670520067214966,
[36m(head, rank=0, pid=3451)[0m       3.9234514236450195,
[36m(head, rank=0, pid=3451)[0m       3.6661453247070312,
[36m(head, rank=0, pid=3451)[0m       4.268409252166748,
[36m(head, rank=0, pid=3451)[0m       3.6767537593841553,
[36m(head, rank=0, pid=3451)[0m       5.004920721054077,
[36m(head, rank=0, pid=3451)[0m       4.282747745513916,
[36m(head, rank=0, pid=3451)[0m       3.8280904293060303,
[36m(head, rank=0, pid=3451)[0m       4.1164374351501465,
[36m(head, rank=0, pid=3451)[0m       3.6721138954162598,
[36m(head, rank=0, pid=3451)[0m       3.7203121185302734,
[36m(head, rank=0, pid=3451)[0m       3.6658525466918945,
[36m(head, rank=0, pid=3451)[0m       4.453337669372559,
[36m(head, rank=0, pid=3451)[0m       3.6693363189697266,
[36m(head, rank=0, pid=3451)[0m       3.669553756713867,
[36m(head, rank=0, pid=3451)[0m       3.68213152885437,
[36m(head, rank=0, pid=3451)[0m       3.5786545276641846,
[36m(head, rank=0, pid=3451)[0m       4.26041841506958,
[36m(head, rank=0, pid=3451)[0m       4.807774305343628,
[36m(head, rank=0, pid=3451)[0m       3.67021107673645,
[36m(head, rank=0, pid=3451)[0m       3.8514795303344727,
[36m(head, rank=0, pid=3451)[0m       3.5794529914855957,
[36m(head, rank=0, pid=3451)[0m       4.131450653076172,
[36m(head, rank=0, pid=3451)[0m       3.6879940032958984,
[36m(head, rank=0, pid=3451)[0m       4.033569574356079,
[36m(head, rank=0, pid=3451)[0m       3.9053988456726074,
[36m(head, rank=0, pid=3451)[0m       3.6790361404418945,
[36m(head, rank=0, pid=3451)[0m       3.6713953018188477,
[36m(head, rank=0, pid=3451)[0m       3.6811740398406982
[36m(head, rank=0, pid=3451)[0m     ]
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m ]
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3451)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3451)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_average": 2.313937187194824,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_min": 2.313937187194824,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_max": 2.313937187194824,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_total": 2.313937187194824
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "model_loading": {
[36m(head, rank=0, pid=3451)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "model_load_average": 26.86936664581299,
[36m(head, rank=0, pid=3451)[0m     "model_load_min": 26.86936664581299,
[36m(head, rank=0, pid=3451)[0m     "model_load_max": 26.86936664581299,
[36m(head, rank=0, pid=3451)[0m     "model_load_total": 26.86936664581299
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training": {
[36m(head, rank=0, pid=3451)[0m     "training_count": 1,
[36m(head, rank=0, pid=3451)[0m     "training_average": 1072.5871214866638,
[36m(head, rank=0, pid=3451)[0m     "training_min": 1072.5871214866638,
[36m(head, rank=0, pid=3451)[0m     "training_max": 1072.5871214866638,
[36m(head, rank=0, pid=3451)[0m     "training_total": 1072.5871214866638
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "total_run_time": {
[36m(head, rank=0, pid=3451)[0m     "total_count": 1,
[36m(head, rank=0, pid=3451)[0m     "total_average": 1101.7704253196716,
[36m(head, rank=0, pid=3451)[0m     "total_min": 1101.7704253196716,
[36m(head, rank=0, pid=3451)[0m     "total_max": 1101.7704253196716,
[36m(head, rank=0, pid=3451)[0m     "total_total": 1101.7704253196716
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3451)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "average_save_time_per_checkpoint": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_min": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_max": 683.3612413406372,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_average": 683.3612413406372
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3451)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 0.47702527046203613,
[36m(head, rank=0, pid=3451)[0m     "average_sample_time_per_batch": 0.04770252704620361,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_min": 0.0318598747253418,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_max": 0.08749675750732422,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_average": 0.04770252704620361
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training_steps": {
[36m(head, rank=0, pid=3451)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 319.4514744281769,
[36m(head, rank=0, pid=3451)[0m     "average_step_time_per_step": 3.993143430352211,
[36m(head, rank=0, pid=3451)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3451)[0m     "training_step_min": 3.5256762504577637,
[36m(head, rank=0, pid=3451)[0m     "training_step_max": 5.8099260330200195,
[36m(head, rank=0, pid=3451)[0m     "training_step_average": 3.993143430352211
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.25s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.08s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.93s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.93s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 320.57s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.47s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.26s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.22s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.22s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.22s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.22s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1098.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1098.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1098.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1098.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.39s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 321.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1101.24s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.39s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.01s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1097.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1097.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.38s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.29s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.15s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 381.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 381.70s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1101.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1101.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1101.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1101.25s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(head, rank=0, pid=3451)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3451)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.41 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.45 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.50 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.95 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.93 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.95 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.93 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.92 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.96 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.98 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.99 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  6.78it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  6.30it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  7.94it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  7.71it/s]Completed Load dataset in 3.54 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 3.55 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 3.56 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  7.54it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  7.65it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.39it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.33it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.12it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.00it/s]
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.56 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.64 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  5.30it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 14.12it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 20.04it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 12.65it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 12.64it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 14.87it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00, 10.59it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 15.03it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 15.82it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 13.78it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 14.53it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 15.03it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 14.53it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  5.22it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 13.41it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 13.53it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.77it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.36 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.37 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.37 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.41 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.36 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.62it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 122.32it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 123.08it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 122.58it/s]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.57 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.59 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.07 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 4.98 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 5.03 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 121.57it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 120.51it/s]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.01 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.02 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:09<00:39,  9.76s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:40, 10.15s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:20<00:30, 10.02s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19<00:29,  9.77s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29<00:19,  9.93s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29<00:19,  9.91s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:39<00:09,  9.76s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48<00:00,  9.57s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48<00:00,  9.68s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 49.65 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:40<00:10, 10.04s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49<00:00,  9.84s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:49<00:00,  9.91s/it]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 50.63 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:40,971] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,820] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,820] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,834] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,836] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,855] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,863] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:41,870] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:42,354] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,069] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,114] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,124] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,149] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,160] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,164] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:29:43,187] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,643] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,643] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,644] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,645] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,646] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,650] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,653] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:06,657] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,853] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,855] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,859] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,861] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,870] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,880] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,890] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:30:07,895] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m  10%|â–ˆ         | 1/10 [00:39<05:54, 39.40s/it]
[36m(head, rank=0, pid=3451)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:16<05:03, 37.91s/it]
[36m(head, rank=0, pid=3451)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:52<04:20, 37.14s/it]
[36m(head, rank=0, pid=3451)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:28<03:40, 36.77s/it]
[36m(head, rank=0, pid=3451)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:06<03:05, 37.06s/it]
[36m(head, rank=0, pid=3451)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:41<02:26, 36.55s/it]
[36m(head, rank=0, pid=3451)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:19<01:50, 36.75s/it]
[36m(head, rank=0, pid=3451)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [04:56<01:13, 36.99s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:32<00:36, 36.59s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:07<00:00, 36.06s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:07<00:00, 36.06s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.42 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.42s (Total: 247.42s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.42 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.42s (Total: 247.42s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.43 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.43s (Total: 247.43s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.43 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.43s (Total: 247.43s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.44 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.44 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 247.44 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.43 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.43s (Total: 247.43s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.44 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.44 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.44 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.44 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.44 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.44s (Total: 247.44s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.45 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.45s (Total: 247.45s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 247.45 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 247.45s (Total: 247.45s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 436.39 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 436.39s (Total: 436.39s)
[36m(head, rank=0, pid=3451)[0m 
                                               
{'train_runtime': 803.479, 'train_samples_per_second': 1.593, 'train_steps_per_second': 0.012, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [13:23<00:00, 36.06s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [13:23<00:00, 80.35s/it]
[36m(head, rank=0, pid=3451)[0m Completed Training in 907.37 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 436.39s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 436.39s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 436.39s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 436.39s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.31s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.73s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.58s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.95s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 319.69s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 5.20s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 955.72 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.43s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.43s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.26s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.73s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.59s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.88s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 320.85s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.01s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.25s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 955.63 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 954.33 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.42s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.42s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.52s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.75s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.58s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 1.32s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.07s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.01s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.81s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.44s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.87s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.79s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.45s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 1.48s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.50s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.02s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.66s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 956.30 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.43s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.43s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.32s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.73s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.46sCompleted Training in 955.67 seconds
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 1.33s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.43s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.02s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.81s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.42s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.42s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.78s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.78s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.61s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 1.29s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.46s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.02s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.84s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 956.30 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.44s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 6.79s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.68s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.49s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.86s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.63s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.02s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.30s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 954.36 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 247.44s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 7.90s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.79s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 1.23s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 320.06s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.90s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_1_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_0_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_6_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_3_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_4_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_5_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_7_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3/training_run_2_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.38 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.35 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.40 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1  - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 247.45s  - Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.44s  - Min save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.44s  - Max save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:  - Total checkpoint save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10  - Average save time per checkpoint: 247.45s  - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 7.79s  - Total batch sample time: 7.31s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.78s  - Max save time: 247.45s  - Average batch sample time: 0.73s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.46s  - Min batch sample time: 0.56sBatch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 1.28s  - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 1.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 7.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:  - Average batch sample time: 0.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80  - Min batch sample time: 0.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 321.16s  - Total training step time: 320.64s  - Max batch sample time: 1.31s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01sTraining Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80  - Min training step time: 3.53s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.45 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.86s  - Max training step time: 7.02s  - Total training step time: 321.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1Training completed successfully for run 1  - Average training step time: 4.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.83s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 7.74s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 1.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 321.20s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.78s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.41 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 8.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.82s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.56s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 1.74s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 907.83 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 7.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.74s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.29s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.53s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.41 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 955.49 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 6.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 1.14s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 322.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 7.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 7.61s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 1.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 321.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 3.55s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 3.55s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 3.55s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 3.55s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.01s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 955.72s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 955.72s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 955.72s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 955.72s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.55s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 320.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.73s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.59s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.88s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.26s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.43s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.43s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.28s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.28s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.28s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.28s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 4.98s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 4.98s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 4.98s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 4.98s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.02s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 954.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 954.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 954.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 954.33s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.50s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.79s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 1.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.87s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.33s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 3.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 3.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 3.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 3.56s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.07s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.07s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.07s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.07s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 955.63s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 955.63s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 955.63s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 955.63s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.81s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.07s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.75s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.58s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 1.32s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.42s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.26s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.26s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.41s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.41s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.64s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.64s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.64s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.64s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 956.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 956.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 956.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 956.30s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.81s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.43s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.73s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.46s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 1.33s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.32s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.43s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.43s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.43s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.35s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.35s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.35s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.35s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 3.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 3.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 3.54s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 3.54s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.08s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 955.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 955.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 955.67s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 955.67s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.46s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.78s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.61s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 1.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.78s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.42s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.42s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.29s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.29s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.50s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.50s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.50s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.50s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.56s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 956.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 956.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 956.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 956.30s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.30s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.63s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.68s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.49s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.86s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 6.79s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.36s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.45s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 50.63s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 50.63s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 50.63s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 50.63s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 907.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 907.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 907.37s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 907.37s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 5.20s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 319.69s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.73s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.58s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.95s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.31s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 436.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 436.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 436.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 436.39s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.46s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.46s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.46s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.46s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Training Run 1 Info (Directory: /checkpoints_s3) ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "run_id": 1,
[36m(head, rank=0, pid=3451)[0m   "timestamp": "2025-08-03T19:28:28.119191",
[36m(head, rank=0, pid=3451)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m   "checkpoint_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3451)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m   "output_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3451)[0m   "dataset_load_time": 2.9800193309783936,
[36m(head, rank=0, pid=3451)[0m   "model_load_time": 49.65049910545349,
[36m(head, rank=0, pid=3451)[0m   "training_time": 907.8299987316132,
[36m(head, rank=0, pid=3451)[0m   "total_time": 960.460517168045,
[36m(head, rank=0, pid=3451)[0m   "error": null,
[36m(head, rank=0, pid=3451)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m   "total_checkpoint_save_time": 247.42986702919006,
[36m(head, rank=0, pid=3451)[0m   "average_checkpoint_save_time": 247.42986702919006,
[36m(head, rank=0, pid=3451)[0m   "min_checkpoint_save_time": 247.42986702919006,
[36m(head, rank=0, pid=3451)[0m   "max_checkpoint_save_time": 247.42986702919006,
[36m(head, rank=0, pid=3451)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m     247.42986702919006
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m   "total_batch_sample_time": 7.4038941860198975,
[36m(head, rank=0, pid=3451)[0m   "average_batch_sample_time": 0.7403894186019897,
[36m(head, rank=0, pid=3451)[0m   "min_batch_sample_time": 0.40069079399108887,
[36m(head, rank=0, pid=3451)[0m   "max_batch_sample_time": 0.9576940536499023,
[36m(head, rank=0, pid=3451)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m     0.40069079399108887,
[36m(head, rank=0, pid=3451)[0m     0.9576940536499023,
[36m(head, rank=0, pid=3451)[0m     0.6848945617675781,
[36m(head, rank=0, pid=3451)[0m     0.7790617942810059,
[36m(head, rank=0, pid=3451)[0m     0.9317760467529297,
[36m(head, rank=0, pid=3451)[0m     0.7422840595245361,
[36m(head, rank=0, pid=3451)[0m     0.7353520393371582,
[36m(head, rank=0, pid=3451)[0m     0.7966005802154541,
[36m(head, rank=0, pid=3451)[0m     0.7522807121276855,
[36m(head, rank=0, pid=3451)[0m     0.6232595443725586
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m   "total_training_step_time": 320.28878450393677,
[36m(head, rank=0, pid=3451)[0m   "average_training_step_time": 4.00360980629921,
[36m(head, rank=0, pid=3451)[0m   "min_training_step_time": 3.525031328201294,
[36m(head, rank=0, pid=3451)[0m   "max_training_step_time": 6.1329004764556885,
[36m(head, rank=0, pid=3451)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m     6.1329004764556885,
[36m(head, rank=0, pid=3451)[0m     3.7903690338134766,
[36m(head, rank=0, pid=3451)[0m     4.361799955368042,
[36m(head, rank=0, pid=3451)[0m     3.6638312339782715,
[36m(head, rank=0, pid=3451)[0m     4.744275331497192,
[36m(head, rank=0, pid=3451)[0m     3.873499631881714,
[36m(head, rank=0, pid=3451)[0m     3.6821627616882324,
[36m(head, rank=0, pid=3451)[0m     3.6799919605255127,
[36m(head, rank=0, pid=3451)[0m     4.221408128738403,
[36m(head, rank=0, pid=3451)[0m     4.612486362457275,
[36m(head, rank=0, pid=3451)[0m     3.6630241870880127,
[36m(head, rank=0, pid=3451)[0m     3.70587420463562,
[36m(head, rank=0, pid=3451)[0m     3.695085048675537,
[36m(head, rank=0, pid=3451)[0m     4.901811838150024,
[36m(head, rank=0, pid=3451)[0m     3.6640982627868652,
[36m(head, rank=0, pid=3451)[0m     4.539960145950317,
[36m(head, rank=0, pid=3451)[0m     4.259422063827515,
[36m(head, rank=0, pid=3451)[0m     3.6990411281585693,
[36m(head, rank=0, pid=3451)[0m     3.8309009075164795,
[36m(head, rank=0, pid=3451)[0m     3.6686007976531982,
[36m(head, rank=0, pid=3451)[0m     4.2936320304870605,
[36m(head, rank=0, pid=3451)[0m     3.6668171882629395,
[36m(head, rank=0, pid=3451)[0m     4.609968185424805,
[36m(head, rank=0, pid=3451)[0m     3.7339630126953125,
[36m(head, rank=0, pid=3451)[0m     5.007274627685547,
[36m(head, rank=0, pid=3451)[0m     3.6693379878997803,
[36m(head, rank=0, pid=3451)[0m     3.794774055480957,
[36m(head, rank=0, pid=3451)[0m     3.6913163661956787,
[36m(head, rank=0, pid=3451)[0m     3.525031328201294,
[36m(head, rank=0, pid=3451)[0m     3.6888251304626465,
[36m(head, rank=0, pid=3451)[0m     3.783266305923462,
[36m(head, rank=0, pid=3451)[0m     4.3346266746521,
[36m(head, rank=0, pid=3451)[0m     4.694365501403809,
[36m(head, rank=0, pid=3451)[0m     3.8479297161102295,
[36m(head, rank=0, pid=3451)[0m     3.703676462173462,
[36m(head, rank=0, pid=3451)[0m     4.048393964767456,
[36m(head, rank=0, pid=3451)[0m     4.4764814376831055,
[36m(head, rank=0, pid=3451)[0m     4.339013576507568,
[36m(head, rank=0, pid=3451)[0m     3.6669681072235107,
[36m(head, rank=0, pid=3451)[0m     3.833444356918335,
[36m(head, rank=0, pid=3451)[0m     3.6946938037872314,
[36m(head, rank=0, pid=3451)[0m     3.6733298301696777,
[36m(head, rank=0, pid=3451)[0m     4.7467546463012695,
[36m(head, rank=0, pid=3451)[0m     3.6998050212860107,
[36m(head, rank=0, pid=3451)[0m     3.9102485179901123,
[36m(head, rank=0, pid=3451)[0m     3.8770551681518555,
[36m(head, rank=0, pid=3451)[0m     3.6790812015533447,
[36m(head, rank=0, pid=3451)[0m     3.85892653465271,
[36m(head, rank=0, pid=3451)[0m     4.816167116165161,
[36m(head, rank=0, pid=3451)[0m     4.777299880981445,
[36m(head, rank=0, pid=3451)[0m     3.536317825317383,
[36m(head, rank=0, pid=3451)[0m     3.6991031169891357,
[36m(head, rank=0, pid=3451)[0m     3.9255154132843018,
[36m(head, rank=0, pid=3451)[0m     3.5815179347991943,
[36m(head, rank=0, pid=3451)[0m     4.25351881980896,
[36m(head, rank=0, pid=3451)[0m     3.7015621662139893,
[36m(head, rank=0, pid=3451)[0m     4.9850547313690186,
[36m(head, rank=0, pid=3451)[0m     4.287268877029419,
[36m(head, rank=0, pid=3451)[0m     3.825587749481201,
[36m(head, rank=0, pid=3451)[0m     4.079952716827393,
[36m(head, rank=0, pid=3451)[0m     3.525944948196411,
[36m(head, rank=0, pid=3451)[0m     3.7074079513549805,
[36m(head, rank=0, pid=3451)[0m     3.7196218967437744,
[36m(head, rank=0, pid=3451)[0m     4.363668918609619,
[36m(head, rank=0, pid=3451)[0m     3.659177303314209,
[36m(head, rank=0, pid=3451)[0m     3.577116012573242,
[36m(head, rank=0, pid=3451)[0m     3.667093515396118,
[36m(head, rank=0, pid=3451)[0m     3.628472328186035,
[36m(head, rank=0, pid=3451)[0m     4.265937089920044,
[36m(head, rank=0, pid=3451)[0m     4.794704914093018,
[36m(head, rank=0, pid=3451)[0m     3.670358419418335,
[36m(head, rank=0, pid=3451)[0m     3.8442583084106445,
[36m(head, rank=0, pid=3451)[0m     3.893232822418213,
[36m(head, rank=0, pid=3451)[0m     4.188976049423218,
[36m(head, rank=0, pid=3451)[0m     3.5340466499328613,
[36m(head, rank=0, pid=3451)[0m     4.006010293960571,
[36m(head, rank=0, pid=3451)[0m     3.8212459087371826,
[36m(head, rank=0, pid=3451)[0m     3.6559877395629883,
[36m(head, rank=0, pid=3451)[0m     3.6697776317596436,
[36m(head, rank=0, pid=3451)[0m     3.687335252761841
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3451)[0m [
[36m(head, rank=0, pid=3451)[0m   {
[36m(head, rank=0, pid=3451)[0m     "run_id": 1,
[36m(head, rank=0, pid=3451)[0m     "timestamp": "2025-08-03T19:28:28.120809",
[36m(head, rank=0, pid=3451)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m     "checkpoint_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3451)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m     "output_dir": "/checkpoints_s3",
[36m(head, rank=0, pid=3451)[0m     "dataset_load_time": 2.4531116485595703,
[36m(head, rank=0, pid=3451)[0m     "model_load_time": 50.62792229652405,
[36m(head, rank=0, pid=3451)[0m     "training_time": 907.374758720398,
[36m(head, rank=0, pid=3451)[0m     "total_time": 960.4557926654816,
[36m(head, rank=0, pid=3451)[0m     "error": null,
[36m(head, rank=0, pid=3451)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "average_checkpoint_save_time": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "min_checkpoint_save_time": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "max_checkpoint_save_time": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m       436.38636803627014
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 7.305380344390869,
[36m(head, rank=0, pid=3451)[0m     "average_batch_sample_time": 0.7305380344390869,
[36m(head, rank=0, pid=3451)[0m     "min_batch_sample_time": 0.578312873840332,
[36m(head, rank=0, pid=3451)[0m     "max_batch_sample_time": 0.9484901428222656,
[36m(head, rank=0, pid=3451)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m       0.9484901428222656,
[36m(head, rank=0, pid=3451)[0m       0.6460020542144775,
[36m(head, rank=0, pid=3451)[0m       0.7749214172363281,
[36m(head, rank=0, pid=3451)[0m       0.7706828117370605,
[36m(head, rank=0, pid=3451)[0m       0.5845754146575928,
[36m(head, rank=0, pid=3451)[0m       0.8180310726165771,
[36m(head, rank=0, pid=3451)[0m       0.6807773113250732,
[36m(head, rank=0, pid=3451)[0m       0.578312873840332,
[36m(head, rank=0, pid=3451)[0m       0.7202551364898682,
[36m(head, rank=0, pid=3451)[0m       0.783332109451294
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 319.6939871311188,
[36m(head, rank=0, pid=3451)[0m     "average_training_step_time": 3.996174839138985,
[36m(head, rank=0, pid=3451)[0m     "min_training_step_time": 3.5269691944122314,
[36m(head, rank=0, pid=3451)[0m     "max_training_step_time": 5.204550743103027,
[36m(head, rank=0, pid=3451)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m       5.127914190292358,
[36m(head, rank=0, pid=3451)[0m       4.181765079498291,
[36m(head, rank=0, pid=3451)[0m       4.3594701290130615,
[36m(head, rank=0, pid=3451)[0m       3.6658623218536377,
[36m(head, rank=0, pid=3451)[0m       4.707970142364502,
[36m(head, rank=0, pid=3451)[0m       3.871642827987671,
[36m(head, rank=0, pid=3451)[0m       3.5291860103607178,
[36m(head, rank=0, pid=3451)[0m       3.681730270385742,
[36m(head, rank=0, pid=3451)[0m       4.14243745803833,
[36m(head, rank=0, pid=3451)[0m       4.6423540115356445,
[36m(head, rank=0, pid=3451)[0m       3.6648242473602295,
[36m(head, rank=0, pid=3451)[0m       3.7038793563842773,
[36m(head, rank=0, pid=3451)[0m       3.6892123222351074,
[36m(head, rank=0, pid=3451)[0m       4.898568153381348,
[36m(head, rank=0, pid=3451)[0m       3.6601364612579346,
[36m(head, rank=0, pid=3451)[0m       4.0358726978302,
[36m(head, rank=0, pid=3451)[0m       4.209705114364624,
[36m(head, rank=0, pid=3451)[0m       3.7014479637145996,
[36m(head, rank=0, pid=3451)[0m       3.7563602924346924,
[36m(head, rank=0, pid=3451)[0m       3.667698383331299,
[36m(head, rank=0, pid=3451)[0m       4.271538734436035,
[36m(head, rank=0, pid=3451)[0m       3.6684699058532715,
[36m(head, rank=0, pid=3451)[0m       4.607828617095947,
[36m(head, rank=0, pid=3451)[0m       3.734553813934326,
[36m(head, rank=0, pid=3451)[0m       5.013027191162109,
[36m(head, rank=0, pid=3451)[0m       3.5690524578094482,
[36m(head, rank=0, pid=3451)[0m       3.794731616973877,
[36m(head, rank=0, pid=3451)[0m       3.690032482147217,
[36m(head, rank=0, pid=3451)[0m       3.6759214401245117,
[36m(head, rank=0, pid=3451)[0m       3.6846423149108887,
[36m(head, rank=0, pid=3451)[0m       3.802191972732544,
[36m(head, rank=0, pid=3451)[0m       4.333096742630005,
[36m(head, rank=0, pid=3451)[0m       4.9957122802734375,
[36m(head, rank=0, pid=3451)[0m       3.8488407135009766,
[36m(head, rank=0, pid=3451)[0m       3.70249080657959,
[36m(head, rank=0, pid=3451)[0m       4.049834966659546,
[36m(head, rank=0, pid=3451)[0m       4.477298259735107,
[36m(head, rank=0, pid=3451)[0m       4.380860805511475,
[36m(head, rank=0, pid=3451)[0m       3.66864013671875,
[36m(head, rank=0, pid=3451)[0m       3.8297855854034424,
[36m(head, rank=0, pid=3451)[0m       3.706468343734741,
[36m(head, rank=0, pid=3451)[0m       3.5269691944122314,
[36m(head, rank=0, pid=3451)[0m       4.745503664016724,
[36m(head, rank=0, pid=3451)[0m       3.6981379985809326,
[36m(head, rank=0, pid=3451)[0m       3.8854482173919678,
[36m(head, rank=0, pid=3451)[0m       3.875972032546997,
[36m(head, rank=0, pid=3451)[0m       3.677586555480957,
[36m(head, rank=0, pid=3451)[0m       3.8552067279815674,
[36m(head, rank=0, pid=3451)[0m       4.867959976196289,
[36m(head, rank=0, pid=3451)[0m       4.7782323360443115,
[36m(head, rank=0, pid=3451)[0m       3.663140296936035,
[36m(head, rank=0, pid=3451)[0m       3.695112705230713,
[36m(head, rank=0, pid=3451)[0m       3.925400733947754,
[36m(head, rank=0, pid=3451)[0m       3.6681833267211914,
[36m(head, rank=0, pid=3451)[0m       4.275540351867676,
[36m(head, rank=0, pid=3451)[0m       3.6999847888946533,
[36m(head, rank=0, pid=3451)[0m       5.204550743103027,
[36m(head, rank=0, pid=3451)[0m       4.28628396987915,
[36m(head, rank=0, pid=3451)[0m       3.8229870796203613,
[36m(head, rank=0, pid=3451)[0m       4.097162485122681,
[36m(head, rank=0, pid=3451)[0m       3.6709117889404297,
[36m(head, rank=0, pid=3451)[0m       3.7058849334716797,
[36m(head, rank=0, pid=3451)[0m       3.7155508995056152,
[36m(head, rank=0, pid=3451)[0m       4.459172964096069,
[36m(head, rank=0, pid=3451)[0m       3.6837387084960938,
[36m(head, rank=0, pid=3451)[0m       3.6631953716278076,
[36m(head, rank=0, pid=3451)[0m       3.663594961166382,
[36m(head, rank=0, pid=3451)[0m       3.5422592163085938,
[36m(head, rank=0, pid=3451)[0m       4.264320611953735,
[36m(head, rank=0, pid=3451)[0m       4.7922680377960205,
[36m(head, rank=0, pid=3451)[0m       3.6715588569641113,
[36m(head, rank=0, pid=3451)[0m       3.8447017669677734,
[36m(head, rank=0, pid=3451)[0m       3.5948374271392822,
[36m(head, rank=0, pid=3451)[0m       4.148868799209595,
[36m(head, rank=0, pid=3451)[0m       3.6712265014648438,
[36m(head, rank=0, pid=3451)[0m       4.0082502365112305,
[36m(head, rank=0, pid=3451)[0m       3.905245780944824,
[36m(head, rank=0, pid=3451)[0m       3.6808719635009766,
[36m(head, rank=0, pid=3451)[0m       3.6689560413360596,
[36m(head, rank=0, pid=3451)[0m       3.686152458190918
[36m(head, rank=0, pid=3451)[0m     ]
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m ]
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3451)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3451)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_average": 2.4531116485595703,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_min": 2.4531116485595703,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_max": 2.4531116485595703,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_total": 2.4531116485595703
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "model_loading": {
[36m(head, rank=0, pid=3451)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "model_load_average": 50.62792229652405,
[36m(head, rank=0, pid=3451)[0m     "model_load_min": 50.62792229652405,
[36m(head, rank=0, pid=3451)[0m     "model_load_max": 50.62792229652405,
[36m(head, rank=0, pid=3451)[0m     "model_load_total": 50.62792229652405
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training": {
[36m(head, rank=0, pid=3451)[0m     "training_count": 1,
[36m(head, rank=0, pid=3451)[0m     "training_average": 907.374758720398,
[36m(head, rank=0, pid=3451)[0m     "training_min": 907.374758720398,
[36m(head, rank=0, pid=3451)[0m     "training_max": 907.374758720398,
[36m(head, rank=0, pid=3451)[0m     "training_total": 907.374758720398
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "total_run_time": {
[36m(head, rank=0, pid=3451)[0m     "total_count": 1,
[36m(head, rank=0, pid=3451)[0m     "total_average": 960.4557926654816,
[36m(head, rank=0, pid=3451)[0m     "total_min": 960.4557926654816,
[36m(head, rank=0, pid=3451)[0m     "total_max": 960.4557926654816,
[36m(head, rank=0, pid=3451)[0m     "total_total": 960.4557926654816
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3451)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "average_save_time_per_checkpoint": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_min": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_max": 436.38636803627014,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_average": 436.38636803627014
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3451)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 7.305380344390869,
[36m(head, rank=0, pid=3451)[0m     "average_sample_time_per_batch": 0.7305380344390869,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_min": 0.578312873840332,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_max": 0.9484901428222656,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_average": 0.7305380344390869
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training_steps": {
[36m(head, rank=0, pid=3451)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 319.6939871311188,
[36m(head, rank=0, pid=3451)[0m     "average_step_time_per_step": 3.996174839138985,
[36m(head, rank=0, pid=3451)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3451)[0m     "training_step_min": 3.5269691944122314,
[36m(head, rank=0, pid=3451)[0m     "training_step_max": 5.204550743103027,
[36m(head, rank=0, pid=3451)[0m     "training_step_average": 3.996174839138985
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.99s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.83s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 321.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.31s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 7.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.75s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.75s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.75s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.75s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.98s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 49.65s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 49.65s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 49.65s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 49.65s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 907.83s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 907.83s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 907.83s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 907.83s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.53s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.29s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.74s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 7.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 960.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 960.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 960.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 960.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Training Run 1 Info (Directory: /checkpoints_s3) ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.78s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 321.20s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 7.74s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.92s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.92s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.92s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.92s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.57s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 321.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.78s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.46s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 7.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.84s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.84s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.84s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.84s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "timestamp": "2025-08-03T19:28:28.119191",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "output_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_load_time": 2.9800193309783936,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_load_time": 49.65049910545349,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_time": 907.8299987316132,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_time": 960.460517168045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     247.42986702919006
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_batch_sample_time": 7.4038941860198975,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_batch_sample_time": 0.7403894186019897,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_batch_sample_time": 0.40069079399108887,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_batch_sample_time": 0.9576940536499023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.40069079399108887,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.9576940536499023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.6848945617675781,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.7790617942810059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.9317760467529297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.7422840595245361,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.7353520393371582,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.7966005802154541,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.7522807121276855,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.6232595443725586
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_training_step_time": 320.28878450393677,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_training_step_time": 4.00360980629921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_training_step_time": 3.525031328201294,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_training_step_time": 6.1329004764556885,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     6.1329004764556885,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7903690338134766,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.361799955368042,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6638312339782715,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.744275331497192,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.873499631881714,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6821627616882324,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6799919605255127,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.221408128738403,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.612486362457275,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6630241870880127,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.70587420463562,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.695085048675537,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.901811838150024,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6640982627868652,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.539960145950317,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.259422063827515,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6990411281585693,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8309009075164795,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6686007976531982,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.2936320304870605,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6668171882629395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.609968185424805,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7339630126953125,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.007274627685547,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6693379878997803,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.794774055480957,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6913163661956787,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.525031328201294,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6888251304626465,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.783266305923462,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.3346266746521,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.694365501403809,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8479297161102295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.703676462173462,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.048393964767456,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.4764814376831055,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.339013576507568,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6669681072235107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.833444356918335,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6946938037872314,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6733298301696777,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.7467546463012695,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6998050212860107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.9102485179901123,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8770551681518555,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6790812015533447,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.85892653465271,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.816167116165161,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.777299880981445,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.536317825317383,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6991031169891357,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.9255154132843018,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5815179347991943,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.25351881980896,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7015621662139893,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.9850547313690186,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.287268877029419,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.825587749481201,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.079952716827393,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.525944948196411,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7074079513549805,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7196218967437744,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.363668918609619,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.659177303314209,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.577116012573242,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.667093515396118,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.628472328186035,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.265937089920044,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.794704914093018,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.670358419418335,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8442583084106445,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.893232822418213,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.188976049423218,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5340466499328613,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.006010293960571,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8212459087371826,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6559877395629883,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6697776317596436,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.687335252761841
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "timestamp": "2025-08-03T19:28:28.119191",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "output_dir": "/checkpoints_s3",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_time": 2.9800193309783936,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_time": 49.65049910545349,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_time": 907.8299987316132,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_time": 960.460517168045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       247.42986702919006
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 7.4038941860198975,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_batch_sample_time": 0.7403894186019897,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_batch_sample_time": 0.40069079399108887,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_batch_sample_time": 0.9576940536499023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.40069079399108887,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.9576940536499023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.6848945617675781,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.7790617942810059,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.9317760467529297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.7422840595245361,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.7353520393371582,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.7966005802154541,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.7522807121276855,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.6232595443725586
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 320.28878450393677,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_training_step_time": 4.00360980629921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_training_step_time": 3.525031328201294,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_training_step_time": 6.1329004764556885,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       6.1329004764556885,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7903690338134766,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.361799955368042,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6638312339782715,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.744275331497192,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.873499631881714,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6821627616882324,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6799919605255127,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.221408128738403,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.612486362457275,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6630241870880127,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.70587420463562,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.695085048675537,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.901811838150024,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6640982627868652,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.539960145950317,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.259422063827515,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6990411281585693,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8309009075164795,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6686007976531982,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.2936320304870605,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6668171882629395,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.609968185424805,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7339630126953125,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.007274627685547,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6693379878997803,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.794774055480957,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6913163661956787,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.525031328201294,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6888251304626465,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.783266305923462,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.3346266746521,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.694365501403809,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8479297161102295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.703676462173462,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.048393964767456,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.4764814376831055,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.339013576507568,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6669681072235107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.833444356918335,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6946938037872314,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6733298301696777,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.7467546463012695,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6998050212860107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.9102485179901123,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8770551681518555,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6790812015533447,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.85892653465271,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.816167116165161,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.777299880981445,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.536317825317383,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6991031169891357,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.9255154132843018,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5815179347991943,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.25351881980896,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7015621662139893,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.9850547313690186,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.287268877029419,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.825587749481201,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.079952716827393,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.525944948196411,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7074079513549805,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7196218967437744,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.363668918609619,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.659177303314209,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.577116012573242,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.667093515396118,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.628472328186035,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.265937089920044,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.794704914093018,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.670358419418335,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8442583084106445,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.893232822418213,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.188976049423218,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5340466499328613,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.006010293960571,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8212459087371826,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6559877395629883,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6697776317596436,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.687335252761841
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_average": 2.9800193309783936,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_min": 2.9800193309783936,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_max": 2.9800193309783936,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_total": 2.9800193309783936
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_average": 49.65049910545349,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_min": 49.65049910545349,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_max": 49.65049910545349,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_total": 49.65049910545349
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_average": 907.8299987316132,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_min": 907.8299987316132,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_max": 907.8299987316132,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_total": 907.8299987316132
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_average": 960.460517168045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_min": 960.460517168045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_max": 960.460517168045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_total": 960.460517168045
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_save_time_per_checkpoint": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_min": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_max": 247.42986702919006,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_average": 247.42986702919006
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 7.4038941860198975,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_sample_time_per_batch": 0.7403894186019897,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_min": 0.40069079399108887,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_max": 0.9576940536499023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_average": 0.7403894186019897
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 320.28878450393677,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_step_time_per_step": 4.00360980629921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_min": 3.525031328201294,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_max": 6.1329004764556885,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_average": 4.00360980629921
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.53s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.64s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.73s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.56s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 7.31s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.72s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.72s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.72s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.72s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.40s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.82s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.56s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.74s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 8.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 5.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 5.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 5.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 5.03s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.01s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 954.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 954.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 954.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 954.36s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.00s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.90s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 320.06s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.79s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 1.23s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 7.90s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 247.44s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 960.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 960.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 960.39s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 960.39s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.37s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 7.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 322.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.14s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 6.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.73s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.73s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.73s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.73s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.36s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 955.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 955.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 955.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 955.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.02s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.58s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.69s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 321.67s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.76s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 1.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 7.61s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 247.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 959.81s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 959.81s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 959.81s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 959.81s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(head, rank=0, pid=3451)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3451)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3451)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3451)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3451)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load dataset...
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.51 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.51 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.52 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.52 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.52 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.52 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.52 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3451)[0m Completed Load dataset in 2.58 seconds
[36m(head, rank=0, pid=3451)[0m Starting Load model...
[36m(head, rank=0, pid=3451)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.60 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load dataset in 2.59 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Load model...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 46.67it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 46.60it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 46.55it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 46.48it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 52.39it/s]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 35.37it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 35.38it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 37.47it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 37.41it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 47.19it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 56.37it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 47.11it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 86.44it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 113.39it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 105.97it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 100.49it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 107.41it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.03 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.04 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.04 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.06 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.12 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.12 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3451)[0m Completed Load model in 1.19 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.16 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 1.17 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  9.51it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 41.99it/s]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 3.16 seconds
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  6.01it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 27.78it/s]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 3.79 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:15<01:00, 15.08s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:20<01:23, 20.80s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:35<00:55, 18.41s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:36<00:52, 17.54s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:57<00:39, 19.87s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:57<00:38, 19.40s/it]
[36m(head, rank=0, pid=3451)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:22<00:21, 21.58s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 21.08s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 20.56s/it]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:22<00:21, 21.87s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 21.26s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 20.51s/it]
[36m(head, rank=0, pid=3451)[0m Completed Load model in 103.77 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Load model in 103.66 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m Starting Training...
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:54,338] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,390] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,391] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,396] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,398] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,398] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,473] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,474] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:55,736] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,706] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,715] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,740] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,746] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,773] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,781] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m [2025-08-03 19:46:56,783] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,207] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,212] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,215] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,219] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,224] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,225] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,239] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:00,251] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,429] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,443] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,484] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,486] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,528] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,531] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,645] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [2025-08-03 19:47:01,666] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3451)[0m  10%|â–ˆ         | 1/10 [00:40<06:00, 40.02s/it]
[36m(head, rank=0, pid=3451)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:16<05:01, 37.74s/it]
[36m(head, rank=0, pid=3451)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:51<04:17, 36.75s/it]
[36m(head, rank=0, pid=3451)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:27<03:37, 36.26s/it]
[36m(head, rank=0, pid=3451)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:04<03:03, 36.78s/it]
[36m(head, rank=0, pid=3451)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:39<02:24, 36.10s/it]
[36m(head, rank=0, pid=3451)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:16<01:49, 36.33s/it]
[36m(head, rank=0, pid=3451)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [04:53<01:12, 36.48s/it]
[36m(head, rank=0, pid=3451)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:28<00:36, 36.02s/it]
[36m(head, rank=0, pid=3451)[0m 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:02<00:00, 35.45s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3451)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:02<00:00, 35.45s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.84s (Total: 327.84s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.84s (Total: 327.84s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.84s (Total: 327.84s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.84s (Total: 327.84s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.84s (Total: 327.84s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.85 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 327.85 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.85 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.85 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.85 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.85 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.85 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.85s (Total: 327.85s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.86 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.86s (Total: 327.86s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.86 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.86s (Total: 327.86s)
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Save checkpoint in 327.86 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint save time: 327.86s (Total: 327.86s)
[36m(head, rank=0, pid=3451)[0m Completed Save checkpoint in 585.36 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint save time: 585.36s (Total: 585.36s)
[36m(head, rank=0, pid=3451)[0m 
                                               
{'train_runtime': 947.9146, 'train_samples_per_second': 1.35, 'train_steps_per_second': 0.011, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3451)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [15:47<00:00, 35.45s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [15:47<00:00, 94.79s/it]
[36m(head, rank=0, pid=3451)[0m Completed Training in 1000.05 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 585.36s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 585.36s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 585.36s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 585.36s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 0.96s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.40s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 321.25s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.02s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.19s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1000.15 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1102.30 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1102.33 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.78sCompleted Training in 1102.33 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:  - Total training step time: 322.22s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.03s  - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 6.92s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 327.85sTraining completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1100.04 secondsCompleted Training in 1102.33 seconds  - Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 1.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 322.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 1.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 323.23s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 1.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.14sCheckpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1  - Max batch sample time: 0.58s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:Training Step Performance:  - Total checkpoint save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1  - Number of training steps: 80  - Average save time per checkpoint: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 323.44s  - Total checkpoint save time: 327.85s  - Min save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.86s  - Average training step time: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.56s  - Number of batch samples: 10  - Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.09sBatch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1  - Number of batch samples: 10  - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 1.28s  - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.13s  - Max batch sample time: 0.50s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:  - Min batch sample time: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80  - Max batch sample time: 0.50s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 323.45sTraining Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.04s  - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.53s  - Total training step time: 323.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.17s  - Average training step time: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1  - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1102.38 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 1.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 0.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 322.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 8.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed Training in 1102.30 seconds
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total batch sample time: 4.29s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average batch sample time: 0.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max batch sample time: 3.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Total training step time: 320.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Average training step time: 4.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   - Max training step time: 5.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1101.98 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 1100.70 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 1.16s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.12s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.76s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 322.73s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.03s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 7.91s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 1.16s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.12s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.56s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 322.85s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.04s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 8.11s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1101.85 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 1101.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 1.05s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 322.27s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.03s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 8.14s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.85s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.85s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 1.04s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.61s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 323.19s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.04s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 8.06s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1101.81 seconds
[36m(head, rank=0, pid=3451)[0m Completed Training in 1101.80 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.85s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.85s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 2.52s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.25s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 1.97s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 322.23s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.03s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 6.69s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 1.82s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.18s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.58s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 322.12s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.03s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 8.09s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Completed Training in 1101.84 seconds
[36m(head, rank=0, pid=3451)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3451)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   - Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   - Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3451)[0m   - Total batch sample time: 1.22s
[36m(head, rank=0, pid=3451)[0m   - Average batch sample time: 0.12s
[36m(head, rank=0, pid=3451)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   - Max batch sample time: 0.66s
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3451)[0m   - Total training step time: 323.32s
[36m(head, rank=0, pid=3451)[0m   - Average training step time: 4.04s
[36m(head, rank=0, pid=3451)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   - Max training step time: 8.01s
[36m(head, rank=0, pid=3451)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(head, rank=0, pid=3451)[0m Completed run 1/1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 103.77s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 103.77s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 103.77s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 103.77s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1000.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1000.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1000.05s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1000.05s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.02s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.19s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 321.25s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.40s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 0.96s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 585.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 585.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 585.36s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 585.36s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1106.34s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1106.34s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1106.34s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1106.34s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "run_id": 1,
[36m(head, rank=0, pid=3451)[0m   "timestamp": "2025-08-03T19:44:58.186508",
[36m(head, rank=0, pid=3451)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3451)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3451)[0m   "dataset_load_time": 2.521544933319092,
[36m(head, rank=0, pid=3451)[0m   "model_load_time": 103.76775240898132,
[36m(head, rank=0, pid=3451)[0m   "training_time": 1000.0469038486481,
[36m(head, rank=0, pid=3451)[0m   "total_time": 1106.3362011909485,
[36m(head, rank=0, pid=3451)[0m   "error": null,
[36m(head, rank=0, pid=3451)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m   "total_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m   "average_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m   "min_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m   "max_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m     585.3604807853699
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m   "total_batch_sample_time": 0.9558145999908447,
[36m(head, rank=0, pid=3451)[0m   "average_batch_sample_time": 0.09558145999908448,
[36m(head, rank=0, pid=3451)[0m   "min_batch_sample_time": 0.03196525573730469,
[36m(head, rank=0, pid=3451)[0m   "max_batch_sample_time": 0.3990142345428467,
[36m(head, rank=0, pid=3451)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m     0.3990142345428467,
[36m(head, rank=0, pid=3451)[0m     0.10390162467956543,
[36m(head, rank=0, pid=3451)[0m     0.14999127388000488,
[36m(head, rank=0, pid=3451)[0m     0.06863832473754883,
[36m(head, rank=0, pid=3451)[0m     0.0572047233581543,
[36m(head, rank=0, pid=3451)[0m     0.03196525573730469,
[36m(head, rank=0, pid=3451)[0m     0.034960031509399414,
[36m(head, rank=0, pid=3451)[0m     0.04124116897583008,
[36m(head, rank=0, pid=3451)[0m     0.032351016998291016,
[36m(head, rank=0, pid=3451)[0m     0.036546945571899414
[36m(head, rank=0, pid=3451)[0m   ],
[36m(head, rank=0, pid=3451)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m   "total_training_step_time": 321.2468225955963,
[36m(head, rank=0, pid=3451)[0m   "average_training_step_time": 4.015585282444954,
[36m(head, rank=0, pid=3451)[0m   "min_training_step_time": 3.521800994873047,
[36m(head, rank=0, pid=3451)[0m   "max_training_step_time": 6.189626693725586,
[36m(head, rank=0, pid=3451)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m     6.189626693725586,
[36m(head, rank=0, pid=3451)[0m     4.064239025115967,
[36m(head, rank=0, pid=3451)[0m     4.367373704910278,
[36m(head, rank=0, pid=3451)[0m     3.6908624172210693,
[36m(head, rank=0, pid=3451)[0m     4.755096673965454,
[36m(head, rank=0, pid=3451)[0m     3.8570265769958496,
[36m(head, rank=0, pid=3451)[0m     3.521800994873047,
[36m(head, rank=0, pid=3451)[0m     3.6890902519226074,
[36m(head, rank=0, pid=3451)[0m     3.9206178188323975,
[36m(head, rank=0, pid=3451)[0m     4.684338092803955,
[36m(head, rank=0, pid=3451)[0m     3.662104845046997,
[36m(head, rank=0, pid=3451)[0m     3.6675994396209717,
[36m(head, rank=0, pid=3451)[0m     3.6739299297332764,
[36m(head, rank=0, pid=3451)[0m     4.945501089096069,
[36m(head, rank=0, pid=3451)[0m     3.6789464950561523,
[36m(head, rank=0, pid=3451)[0m     4.0326902866363525,
[36m(head, rank=0, pid=3451)[0m     4.195798397064209,
[36m(head, rank=0, pid=3451)[0m     3.7137434482574463,
[36m(head, rank=0, pid=3451)[0m     3.7776453495025635,
[36m(head, rank=0, pid=3451)[0m     3.6738574504852295,
[36m(head, rank=0, pid=3451)[0m     4.25466775894165,
[36m(head, rank=0, pid=3451)[0m     3.669321298599243,
[36m(head, rank=0, pid=3451)[0m     4.587184429168701,
[36m(head, rank=0, pid=3451)[0m     3.691619396209717,
[36m(head, rank=0, pid=3451)[0m     4.995250225067139,
[36m(head, rank=0, pid=3451)[0m     3.5773890018463135,
[36m(head, rank=0, pid=3451)[0m     3.7909202575683594,
[36m(head, rank=0, pid=3451)[0m     3.6936957836151123,
[36m(head, rank=0, pid=3451)[0m     3.669384479522705,
[36m(head, rank=0, pid=3451)[0m     3.688037395477295,
[36m(head, rank=0, pid=3451)[0m     3.8207502365112305,
[36m(head, rank=0, pid=3451)[0m     4.3179028034210205,
[36m(head, rank=0, pid=3451)[0m     4.757098913192749,
[36m(head, rank=0, pid=3451)[0m     4.724949836730957,
[36m(head, rank=0, pid=3451)[0m     3.6658971309661865,
[36m(head, rank=0, pid=3451)[0m     4.046098232269287,
[36m(head, rank=0, pid=3451)[0m     4.495440721511841,
[36m(head, rank=0, pid=3451)[0m     4.416604518890381,
[36m(head, rank=0, pid=3451)[0m     3.663623809814453,
[36m(head, rank=0, pid=3451)[0m     3.828447103500366,
[36m(head, rank=0, pid=3451)[0m     3.720529556274414,
[36m(head, rank=0, pid=3451)[0m     3.5238049030303955,
[36m(head, rank=0, pid=3451)[0m     4.754109859466553,
[36m(head, rank=0, pid=3451)[0m     3.6822493076324463,
[36m(head, rank=0, pid=3451)[0m     3.872391700744629,
[36m(head, rank=0, pid=3451)[0m     3.87117075920105,
[36m(head, rank=0, pid=3451)[0m     3.7321979999542236,
[36m(head, rank=0, pid=3451)[0m     3.8086633682250977,
[36m(head, rank=0, pid=3451)[0m     5.238526821136475,
[36m(head, rank=0, pid=3451)[0m     4.759556293487549,
[36m(head, rank=0, pid=3451)[0m     3.658936023712158,
[36m(head, rank=0, pid=3451)[0m     3.6676080226898193,
[36m(head, rank=0, pid=3451)[0m     3.9375948905944824,
[36m(head, rank=0, pid=3451)[0m     3.666733741760254,
[36m(head, rank=0, pid=3451)[0m     4.265244960784912,
[36m(head, rank=0, pid=3451)[0m     3.6668407917022705,
[36m(head, rank=0, pid=3451)[0m     5.003926753997803,
[36m(head, rank=0, pid=3451)[0m     4.305850267410278,
[36m(head, rank=0, pid=3451)[0m     3.819777250289917,
[36m(head, rank=0, pid=3451)[0m     4.11783766746521,
[36m(head, rank=0, pid=3451)[0m     3.6713438034057617,
[36m(head, rank=0, pid=3451)[0m     3.713165760040283,
[36m(head, rank=0, pid=3451)[0m     3.663409471511841,
[36m(head, rank=0, pid=3451)[0m     4.460571527481079,
[36m(head, rank=0, pid=3451)[0m     3.7187156677246094,
[36m(head, rank=0, pid=3451)[0m     3.6616697311401367,
[36m(head, rank=0, pid=3451)[0m     3.6663079261779785,
[36m(head, rank=0, pid=3451)[0m     3.5414888858795166,
[36m(head, rank=0, pid=3451)[0m     4.237628221511841,
[36m(head, rank=0, pid=3451)[0m     4.801765441894531,
[36m(head, rank=0, pid=3451)[0m     3.66922926902771,
[36m(head, rank=0, pid=3451)[0m     3.8383312225341797,
[36m(head, rank=0, pid=3451)[0m     3.6241397857666016,
[36m(head, rank=0, pid=3451)[0m     4.124359369277954,
[36m(head, rank=0, pid=3451)[0m     3.67769455909729,
[36m(head, rank=0, pid=3451)[0m     4.070509672164917,
[36m(head, rank=0, pid=3451)[0m     3.8970696926116943,
[36m(head, rank=0, pid=3451)[0m     3.675187110900879,
[36m(head, rank=0, pid=3451)[0m     3.66920804977417,
[36m(head, rank=0, pid=3451)[0m     3.6753041744232178
[36m(head, rank=0, pid=3451)[0m   ]
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3451)[0m [
[36m(head, rank=0, pid=3451)[0m   {
[36m(head, rank=0, pid=3451)[0m     "run_id": 1,
[36m(head, rank=0, pid=3451)[0m     "timestamp": "2025-08-03T19:44:58.186508",
[36m(head, rank=0, pid=3451)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3451)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3451)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3451)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3451)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3451)[0m     "dataset_load_time": 2.521544933319092,
[36m(head, rank=0, pid=3451)[0m     "model_load_time": 103.76775240898132,
[36m(head, rank=0, pid=3451)[0m     "training_time": 1000.0469038486481,
[36m(head, rank=0, pid=3451)[0m     "total_time": 1106.3362011909485,
[36m(head, rank=0, pid=3451)[0m     "error": null,
[36m(head, rank=0, pid=3451)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "average_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "min_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "max_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3451)[0m       585.3604807853699
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 0.9558145999908447,
[36m(head, rank=0, pid=3451)[0m     "average_batch_sample_time": 0.09558145999908448,
[36m(head, rank=0, pid=3451)[0m     "min_batch_sample_time": 0.03196525573730469,
[36m(head, rank=0, pid=3451)[0m     "max_batch_sample_time": 0.3990142345428467,
[36m(head, rank=0, pid=3451)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3451)[0m       0.3990142345428467,
[36m(head, rank=0, pid=3451)[0m       0.10390162467956543,
[36m(head, rank=0, pid=3451)[0m       0.14999127388000488,
[36m(head, rank=0, pid=3451)[0m       0.06863832473754883,
[36m(head, rank=0, pid=3451)[0m       0.0572047233581543,
[36m(head, rank=0, pid=3451)[0m       0.03196525573730469,
[36m(head, rank=0, pid=3451)[0m       0.034960031509399414,
[36m(head, rank=0, pid=3451)[0m       0.04124116897583008,
[36m(head, rank=0, pid=3451)[0m       0.032351016998291016,
[36m(head, rank=0, pid=3451)[0m       0.036546945571899414
[36m(head, rank=0, pid=3451)[0m     ],
[36m(head, rank=0, pid=3451)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 321.2468225955963,
[36m(head, rank=0, pid=3451)[0m     "average_training_step_time": 4.015585282444954,
[36m(head, rank=0, pid=3451)[0m     "min_training_step_time": 3.521800994873047,
[36m(head, rank=0, pid=3451)[0m     "max_training_step_time": 6.189626693725586,
[36m(head, rank=0, pid=3451)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3451)[0m       6.189626693725586,
[36m(head, rank=0, pid=3451)[0m       4.064239025115967,
[36m(head, rank=0, pid=3451)[0m       4.367373704910278,
[36m(head, rank=0, pid=3451)[0m       3.6908624172210693,
[36m(head, rank=0, pid=3451)[0m       4.755096673965454,
[36m(head, rank=0, pid=3451)[0m       3.8570265769958496,
[36m(head, rank=0, pid=3451)[0m       3.521800994873047,
[36m(head, rank=0, pid=3451)[0m       3.6890902519226074,
[36m(head, rank=0, pid=3451)[0m       3.9206178188323975,
[36m(head, rank=0, pid=3451)[0m       4.684338092803955,
[36m(head, rank=0, pid=3451)[0m       3.662104845046997,
[36m(head, rank=0, pid=3451)[0m       3.6675994396209717,
[36m(head, rank=0, pid=3451)[0m       3.6739299297332764,
[36m(head, rank=0, pid=3451)[0m       4.945501089096069,
[36m(head, rank=0, pid=3451)[0m       3.6789464950561523,
[36m(head, rank=0, pid=3451)[0m       4.0326902866363525,
[36m(head, rank=0, pid=3451)[0m       4.195798397064209,
[36m(head, rank=0, pid=3451)[0m       3.7137434482574463,
[36m(head, rank=0, pid=3451)[0m       3.7776453495025635,
[36m(head, rank=0, pid=3451)[0m       3.6738574504852295,
[36m(head, rank=0, pid=3451)[0m       4.25466775894165,
[36m(head, rank=0, pid=3451)[0m       3.669321298599243,
[36m(head, rank=0, pid=3451)[0m       4.587184429168701,
[36m(head, rank=0, pid=3451)[0m       3.691619396209717,
[36m(head, rank=0, pid=3451)[0m       4.995250225067139,
[36m(head, rank=0, pid=3451)[0m       3.5773890018463135,
[36m(head, rank=0, pid=3451)[0m       3.7909202575683594,
[36m(head, rank=0, pid=3451)[0m       3.6936957836151123,
[36m(head, rank=0, pid=3451)[0m       3.669384479522705,
[36m(head, rank=0, pid=3451)[0m       3.688037395477295,
[36m(head, rank=0, pid=3451)[0m       3.8207502365112305,
[36m(head, rank=0, pid=3451)[0m       4.3179028034210205,
[36m(head, rank=0, pid=3451)[0m       4.757098913192749,
[36m(head, rank=0, pid=3451)[0m       4.724949836730957,
[36m(head, rank=0, pid=3451)[0m       3.6658971309661865,
[36m(head, rank=0, pid=3451)[0m       4.046098232269287,
[36m(head, rank=0, pid=3451)[0m       4.495440721511841,
[36m(head, rank=0, pid=3451)[0m       4.416604518890381,
[36m(head, rank=0, pid=3451)[0m       3.663623809814453,
[36m(head, rank=0, pid=3451)[0m       3.828447103500366,
[36m(head, rank=0, pid=3451)[0m       3.720529556274414,
[36m(head, rank=0, pid=3451)[0m       3.5238049030303955,
[36m(head, rank=0, pid=3451)[0m       4.754109859466553,
[36m(head, rank=0, pid=3451)[0m       3.6822493076324463,
[36m(head, rank=0, pid=3451)[0m       3.872391700744629,
[36m(head, rank=0, pid=3451)[0m       3.87117075920105,
[36m(head, rank=0, pid=3451)[0m       3.7321979999542236,
[36m(head, rank=0, pid=3451)[0m       3.8086633682250977,
[36m(head, rank=0, pid=3451)[0m       5.238526821136475,
[36m(head, rank=0, pid=3451)[0m       4.759556293487549,
[36m(head, rank=0, pid=3451)[0m       3.658936023712158,
[36m(head, rank=0, pid=3451)[0m       3.6676080226898193,
[36m(head, rank=0, pid=3451)[0m       3.9375948905944824,
[36m(head, rank=0, pid=3451)[0m       3.666733741760254,
[36m(head, rank=0, pid=3451)[0m       4.265244960784912,
[36m(head, rank=0, pid=3451)[0m       3.6668407917022705,
[36m(head, rank=0, pid=3451)[0m       5.003926753997803,
[36m(head, rank=0, pid=3451)[0m       4.305850267410278,
[36m(head, rank=0, pid=3451)[0m       3.819777250289917,
[36m(head, rank=0, pid=3451)[0m       4.11783766746521,
[36m(head, rank=0, pid=3451)[0m       3.6713438034057617,
[36m(head, rank=0, pid=3451)[0m       3.713165760040283,
[36m(head, rank=0, pid=3451)[0m       3.663409471511841,
[36m(head, rank=0, pid=3451)[0m       4.460571527481079,
[36m(head, rank=0, pid=3451)[0m       3.7187156677246094,
[36m(head, rank=0, pid=3451)[0m       3.6616697311401367,
[36m(head, rank=0, pid=3451)[0m       3.6663079261779785,
[36m(head, rank=0, pid=3451)[0m       3.5414888858795166,
[36m(head, rank=0, pid=3451)[0m       4.237628221511841,
[36m(head, rank=0, pid=3451)[0m       4.801765441894531,
[36m(head, rank=0, pid=3451)[0m       3.66922926902771,
[36m(head, rank=0, pid=3451)[0m       3.8383312225341797,
[36m(head, rank=0, pid=3451)[0m       3.6241397857666016,
[36m(head, rank=0, pid=3451)[0m       4.124359369277954,
[36m(head, rank=0, pid=3451)[0m       3.67769455909729,
[36m(head, rank=0, pid=3451)[0m       4.070509672164917,
[36m(head, rank=0, pid=3451)[0m       3.8970696926116943,
[36m(head, rank=0, pid=3451)[0m       3.675187110900879,
[36m(head, rank=0, pid=3451)[0m       3.66920804977417,
[36m(head, rank=0, pid=3451)[0m       3.6753041744232178
[36m(head, rank=0, pid=3451)[0m     ]
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m ]
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3451)[0m {
[36m(head, rank=0, pid=3451)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3451)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3451)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_average": 2.521544933319092,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_min": 2.521544933319092,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_max": 2.521544933319092,
[36m(head, rank=0, pid=3451)[0m     "dataset_load_total": 2.521544933319092
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "model_loading": {
[36m(head, rank=0, pid=3451)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3451)[0m     "model_load_average": 103.76775240898132,
[36m(head, rank=0, pid=3451)[0m     "model_load_min": 103.76775240898132,
[36m(head, rank=0, pid=3451)[0m     "model_load_max": 103.76775240898132,
[36m(head, rank=0, pid=3451)[0m     "model_load_total": 103.76775240898132
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training": {
[36m(head, rank=0, pid=3451)[0m     "training_count": 1,
[36m(head, rank=0, pid=3451)[0m     "training_average": 1000.0469038486481,
[36m(head, rank=0, pid=3451)[0m     "training_min": 1000.0469038486481,
[36m(head, rank=0, pid=3451)[0m     "training_max": 1000.0469038486481,
[36m(head, rank=0, pid=3451)[0m     "training_total": 1000.0469038486481
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "total_run_time": {
[36m(head, rank=0, pid=3451)[0m     "total_count": 1,
[36m(head, rank=0, pid=3451)[0m     "total_average": 1106.3362011909485,
[36m(head, rank=0, pid=3451)[0m     "total_min": 1106.3362011909485,
[36m(head, rank=0, pid=3451)[0m     "total_max": 1106.3362011909485,
[36m(head, rank=0, pid=3451)[0m     "total_total": 1106.3362011909485
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3451)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3451)[0m     "total_checkpoint_save_time": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "average_save_time_per_checkpoint": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_min": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_max": 585.3604807853699,
[36m(head, rank=0, pid=3451)[0m     "checkpoint_save_average": 585.3604807853699
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3451)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3451)[0m     "total_batch_sample_time": 0.9558145999908447,
[36m(head, rank=0, pid=3451)[0m     "average_sample_time_per_batch": 0.09558145999908448,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_min": 0.03196525573730469,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_max": 0.3990142345428467,
[36m(head, rank=0, pid=3451)[0m     "batch_sample_average": 0.09558145999908448
[36m(head, rank=0, pid=3451)[0m   },
[36m(head, rank=0, pid=3451)[0m   "training_steps": {
[36m(head, rank=0, pid=3451)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3451)[0m     "total_training_step_time": 321.2468225955963,
[36m(head, rank=0, pid=3451)[0m     "average_step_time_per_step": 4.015585282444954,
[36m(head, rank=0, pid=3451)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3451)[0m     "training_step_min": 3.521800994873047,
[36m(head, rank=0, pid=3451)[0m     "training_step_max": 6.189626693725586,
[36m(head, rank=0, pid=3451)[0m     "training_step_average": 4.015585282444954
[36m(head, rank=0, pid=3451)[0m   }
[36m(head, rank=0, pid=3451)[0m }
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.13s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1101.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1101.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1101.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1101.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 8.14s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 322.27s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.53s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 1.05s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1105.50s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1105.50s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1105.50s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1105.50s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.12s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1101.98s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1101.98s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1101.98s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1101.98s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 7.91s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 322.73s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.76s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 1.16s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1105.61s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1105.61s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1105.61s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1105.61s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 322.93s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.12s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.55s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 1.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1106.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1106.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1106.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1106.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.60s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 103.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 103.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 103.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 103.66s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1000.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1000.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1000.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1000.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 6.92s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 322.22s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.08s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.15s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.78s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1106.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1106.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1106.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1106.41s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "timestamp": "2025-08-03T19:44:58.185251",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_load_time": 2.59515118598938,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_load_time": 103.65957880020142,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_time": 1000.1529998779297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_time": 1106.4077298641205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     327.85447549819946
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_batch_sample_time": 0.7771289348602295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_batch_sample_time": 0.07771289348602295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_batch_sample_time": 0.03226780891418457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_batch_sample_time": 0.1508772373199463,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.1041102409362793,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.1508772373199463,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.04391288757324219,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.14923620223999023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.07898879051208496,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.08521318435668945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.032982826232910156,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.06415176391601562,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.03538799285888672,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     0.03226780891418457
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_training_step_time": 322.221488237381,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "average_training_step_time": 4.027768602967262,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "min_training_step_time": 3.5224249362945557,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "max_training_step_time": 6.92305326461792,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     6.92305326461792,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6930394172668457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.362616062164307,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6960997581481934,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.783129692077637,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8601534366607666,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6716103553771973,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6889758110046387,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.384709596633911,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.654513597488403,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6597979068756104,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6698355674743652,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.675586700439453,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.946117639541626,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6812524795532227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.534721612930298,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.258641004562378,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7146413326263428,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8552606105804443,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.675227165222168,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.278099060058594,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6697580814361572,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.587138414382935,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.693384885787964,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.9199395179748535,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6759719848632812,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7936313152313232,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.694715738296509,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5224249362945557,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6865501403808594,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.798985719680786,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.318939685821533,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.783239841461182,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.724112510681152,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6651735305786133,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.042554140090942,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.492839336395264,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.373925685882568,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6627326011657715,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.828683614730835,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5862948894500732,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6721584796905518,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.752338647842407,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6817800998687744,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.894714593887329,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.872436285018921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.733142375946045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8113772869110107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     5.246322870254517,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.761903285980225,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.53527569770813,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6716935634613037,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.93986439704895,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.580656051635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.2448625564575195,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.666890859603882,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.9844560623168945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.305425643920898,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.825706720352173,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.094642877578735,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.525275230407715,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.7147269248962402,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.662959575653076,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.364704608917236,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.719312906265259,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.5767927169799805,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6674952507019043,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6255862712860107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.239252805709839,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.800826787948608,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.670083999633789,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.837310552597046,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.768460273742676,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.168846607208252,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.540126085281372,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     4.069596767425537,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.8137340545654297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.647899627685547,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.66961932182312,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     3.6751508712768555
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "timestamp": "2025-08-03T19:44:58.185251",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_time": 2.59515118598938,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_time": 103.65957880020142,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_time": 1000.1529998779297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_time": 1106.4077298641205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "error": null,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       327.85447549819946
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 0.7771289348602295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_batch_sample_time": 0.07771289348602295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_batch_sample_time": 0.03226780891418457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_batch_sample_time": 0.1508772373199463,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.1041102409362793,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.1508772373199463,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.04391288757324219,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.14923620223999023,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.07898879051208496,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.08521318435668945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.032982826232910156,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.06415176391601562,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.03538799285888672,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       0.03226780891418457
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ],
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 322.221488237381,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_training_step_time": 4.027768602967262,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "min_training_step_time": 3.5224249362945557,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "max_training_step_time": 6.92305326461792,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       6.92305326461792,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6930394172668457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.362616062164307,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6960997581481934,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.783129692077637,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8601534366607666,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6716103553771973,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6889758110046387,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.384709596633911,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.654513597488403,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6597979068756104,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6698355674743652,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.675586700439453,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.946117639541626,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6812524795532227,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.534721612930298,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.258641004562378,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7146413326263428,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8552606105804443,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.675227165222168,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.278099060058594,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6697580814361572,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.587138414382935,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.693384885787964,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.9199395179748535,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6759719848632812,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7936313152313232,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.694715738296509,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5224249362945557,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6865501403808594,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.798985719680786,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.318939685821533,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.783239841461182,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.724112510681152,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6651735305786133,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.042554140090942,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.492839336395264,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.373925685882568,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6627326011657715,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.828683614730835,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5862948894500732,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6721584796905518,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.752338647842407,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6817800998687744,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.894714593887329,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.872436285018921,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.733142375946045,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8113772869110107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       5.246322870254517,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.761903285980225,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.53527569770813,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6716935634613037,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.93986439704895,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.580656051635742,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.2448625564575195,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.666890859603882,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.9844560623168945,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.305425643920898,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.825706720352173,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.094642877578735,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.525275230407715,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.7147269248962402,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.662959575653076,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.364704608917236,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.719312906265259,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.5767927169799805,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6674952507019043,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6255862712860107,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.239252805709839,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.800826787948608,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.670083999633789,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.837310552597046,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.768460273742676,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.168846607208252,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.540126085281372,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       4.069596767425537,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.8137340545654297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.647899627685547,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.66961932182312,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m       3.6751508712768555
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ]
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_average": 2.59515118598938,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_min": 2.59515118598938,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_max": 2.59515118598938,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "dataset_load_total": 2.59515118598938
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_average": 103.65957880020142,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_min": 103.65957880020142,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_max": 103.65957880020142,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "model_load_total": 103.65957880020142
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_average": 1000.1529998779297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_min": 1000.1529998779297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_max": 1000.1529998779297,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_total": 1000.1529998779297
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_average": 1106.4077298641205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_min": 1106.4077298641205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_max": 1106.4077298641205,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_total": 1106.4077298641205
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_checkpoint_save_time": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_save_time_per_checkpoint": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_min": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_max": 327.85447549819946,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "checkpoint_save_average": 327.85447549819946
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_batch_sample_time": 0.7771289348602295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_sample_time_per_batch": 0.07771289348602295,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_min": 0.03226780891418457,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_max": 0.1508772373199463,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "batch_sample_average": 0.07771289348602295
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   },
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "total_training_step_time": 322.221488237381,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "average_step_time_per_step": 4.027768602967262,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_min": 3.5224249362945557,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_max": 6.92305326461792,
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m     "training_step_average": 4.027768602967262
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m }
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.06s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.56s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.09s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 323.44s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.14s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.58s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 1.35s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1105.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1105.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1105.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1105.97s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 323.23s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.51s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 1.01s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1102.33s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.53s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 323.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.50s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 0.96s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1105.95s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 3.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 3.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 3.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 3.79s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1100.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1100.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1100.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1100.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 323.17s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.13s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.50s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 1.28s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1106.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1106.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1106.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1106.42s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1102.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1102.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1102.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1102.38s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 8.18s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 322.77s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 0.49s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 1.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.86s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1106.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1106.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1106.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1106.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.51s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.13s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.13s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1101.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1101.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1101.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1101.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 8.06s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 323.19s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.61s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 1.04s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1105.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1105.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1105.48s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1105.48s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.19s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.19s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.19s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.19s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1101.81s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1101.81s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1101.81s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1101.81s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 6.69s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 322.23s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.25s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 1.97s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 2.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.85s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1105.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1105.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1105.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1105.51s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.58s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.58s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.58s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.58s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.08s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.08s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1101.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1101.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1101.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1101.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 8.01s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 323.32s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.66s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 1.22s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1105.49s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1105.49s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1105.49s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1105.49s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.52s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1.12s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1101.80s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1101.80s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1101.80s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1101.80s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.55s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 8.09s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 322.12s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.18s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.58s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 1.82s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1105.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1105.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1105.45s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1105.45s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 2.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 2.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 2.51s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 2.51s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Model Loading Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 3.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 3.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 3.16s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 3.16s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average time: 1100.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min time: 1100.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max time: 1100.70s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time: 1100.70s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Training Step Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3451)[0m   â€¢ Average step time per step: 4.04s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min step time: 3.52s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max step time: 8.11s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total training step time: 322.85s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3451)[0m   â€¢ Average sample time per batch: 0.12s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max sample time: 0.56s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total batch sample time: 1.16s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3451)[0m   â€¢ Average save time per checkpoint: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max save time: 327.84s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total checkpoint save time: 327.84s
[36m(head, rank=0, pid=3451)[0m 
[36m(head, rank=0, pid=3451)[0m Overall Run Performance:
[36m(head, rank=0, pid=3451)[0m   â€¢ Average total time per run: 1106.38s
[36m(head, rank=0, pid=3451)[0m   â€¢ Min total time: 1106.38s
[36m(head, rank=0, pid=3451)[0m   â€¢ Max total time: 1106.38s
[36m(head, rank=0, pid=3451)[0m   â€¢ Total time across all runs: 1106.38s
[36m(head, rank=0, pid=3451)[0m ================================================================================
[36m(head, rank=0, pid=3451)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 2.59s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1.16s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time: 1102.30s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min step time: 3.52s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max step time: 5.25s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total training step time: 320.04s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average sample time per batch: 0.43s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max sample time: 3.45s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total batch sample time: 4.29s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average save time per checkpoint: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total checkpoint save time: 327.85s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m 
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Average total time per run: 1106.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Min total time: 1106.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Max total time: 1106.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m   â€¢ Total time across all runs: 1106.05s
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m ================================================================================
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(head, rank=0, pid=3451)[0m cp: cannot stat '/tmp/trace_*': No such file or directory
[36m(worker1, rank=1, pid=2564, ip=10.102.30.211)[0m skypilot: cached mount uploaded complete
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3451)[0m skypilot: cached mount uploaded complete
[0m[32mâœ“ Job finished (status: SUCCEEDED).[0m[0m
