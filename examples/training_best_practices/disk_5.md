[33mTailing logs of job 1 on cluster 'dd'...[0m
[2mâ”œâ”€â”€ [0m[2mWaiting for task resources on 2 nodes.[0m
[2mâ””â”€â”€ [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3864)[0m Channels:
[36m(setup pid=3864)[0m  - nvidia
[36m(setup pid=3864)[0m  - defaults
[36m(setup pid=3864)[0m Platform: linux-64
[36m(setup pid=2703, ip=10.102.30.141)[0m Channels:
[36m(setup pid=2703, ip=10.102.30.141)[0m  - nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m  - defaults
[36m(setup pid=2703, ip=10.102.30.141)[0m Platform: linux-64
[36m(setup pid=3864)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3864)[0m Solving environment: ...working... done
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m ## Package Plan ##
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m   environment location: /root/miniconda3
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m   added / updated specs:
[36m(setup pid=3864)[0m     - cuda
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m The following packages will be downloaded:
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m     package                    |            build
[36m(setup pid=3864)[0m     ---------------------------|-----------------
[36m(setup pid=3864)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3864)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3864)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3864)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3864)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3864)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3864)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3864)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3864)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3864)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3864)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3864)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3864)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3864)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3864)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3864)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3864)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3864)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3864)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3864)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3864)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3864)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3864)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3864)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3864)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3864)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3864)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3864)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3864)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3864)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3864)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3864)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3864)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3864)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3864)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3864)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3864)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3864)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3864)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3864)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3864)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3864)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3864)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3864)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3864)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3864)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3864)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3864)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3864)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3864)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3864)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3864)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3864)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3864)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3864)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3864)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3864)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3864)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3864)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3864)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3864)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3864)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3864)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3864)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3864)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3864)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3864)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3864)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3864)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3864)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3864)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3864)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3864)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3864)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3864)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3864)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3864)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3864)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3864)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3864)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3864)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3864)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3864)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3864)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3864)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3864)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3864)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3864)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3864)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3864)[0m     ------------------------------------------------------------
[36m(setup pid=3864)[0m                                            Total:        2.06 GB
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3864)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3864)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3864)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3864)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3864)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3864)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3864)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3864)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3864)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3864)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3864)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3864)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3864)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3864)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3864)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3864)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3864)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3864)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3864)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3864)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3864)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3864)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3864)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3864)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3864)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3864)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3864)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3864)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3864)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3864)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3864)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3864)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3864)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3864)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3864)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3864)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3864)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3864)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3864)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3864)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3864)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3864)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3864)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3864)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3864)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3864)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3864)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3864)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3864)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3864)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3864)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3864)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3864)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3864)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3864)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3864)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3864)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3864)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3864)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3864)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3864)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3864)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3864)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3864)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3864)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3864)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3864)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3864)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3864)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3864)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3864)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3864)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3864)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3864)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3864)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m The following packages will be UPDATED:
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3864)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3864)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3864)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3864)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3864)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3864)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3864)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3864)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3864)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3864)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m Proceed ([y]/n)? 
[36m(setup pid=3864)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2703, ip=10.102.30.141)[0m Solving environment: ...working... done
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m ## Package Plan ##
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m   environment location: /root/miniconda3
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m   added / updated specs:
[36m(setup pid=2703, ip=10.102.30.141)[0m     - cuda
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m The following packages will be downloaded:
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m     package                    |            build
[36m(setup pid=2703, ip=10.102.30.141)[0m     ---------------------------|-----------------
[36m(setup pid=2703, ip=10.102.30.141)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2703, ip=10.102.30.141)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2703, ip=10.102.30.141)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2703, ip=10.102.30.141)[0m     ------------------------------------------------------------
[36m(setup pid=2703, ip=10.102.30.141)[0m                                            Total:        2.06 GB
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2703, ip=10.102.30.141)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2703, ip=10.102.30.141)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2703, ip=10.102.30.141)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2703, ip=10.102.30.141)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2703, ip=10.102.30.141)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m The following packages will be UPDATED:
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2703, ip=10.102.30.141)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m Proceed ([y]/n)? 
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=3864)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3864)[0m Preparing transaction: ...working... done
[36m(setup pid=3864)[0m Verifying transaction: ...working... done
[36m(setup pid=3864)[0m Executing transaction: ...working... done
[36m(setup pid=3864)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3864)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3864)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3864)[0m  + pip==25.2
[36m(setup pid=3864)[0m  + setuptools==80.9.0
[36m(setup pid=3864)[0m  + wheel==0.45.1
[36m(setup pid=3864)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3864)[0m Resolved 29 packages in 115ms
[36m(setup pid=3864)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3864)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3864)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3864)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3864)[0m Downloading triton (148.4MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3864)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=3864)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=3864)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3864)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3864)[0m Downloading torch (783.1MiB)
[36m(setup pid=3864)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=3864)[0m  Downloading torchaudio
[36m(setup pid=3864)[0m  Downloading torchvision
[36m(setup pid=3864)[0m  Downloading pillow
[36m(setup pid=3864)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=3864)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3864)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing transaction: ...working... done
[36m(setup pid=2703, ip=10.102.30.141)[0m Verifying transaction: ...working... done
[36m(setup pid=3864)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m Executing transaction: ...working... done
[36m(setup pid=2703, ip=10.102.30.141)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2703, ip=10.102.30.141)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2703, ip=10.102.30.141)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pip==25.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + setuptools==80.9.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + wheel==0.45.1
[36m(setup pid=2703, ip=10.102.30.141)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2703, ip=10.102.30.141)[0m Resolved 29 packages in 173ms
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading triton (148.4MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading torch (783.1MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading torchaudio
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading torchvision
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading pillow
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=3864)[0m  Downloading sympy
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=3864)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3864)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=3864)[0m  Downloading triton
[36m(setup pid=3864)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3864)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3864)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading sympy
[36m(setup pid=3864)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3864)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading triton
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3864)[0m  Downloading torch
[36m(setup pid=3864)[0m Prepared 22 packages in 22.68s
[36m(setup pid=3864)[0m Installed 28 packages in 177ms
[36m(setup pid=3864)[0m  + filelock==3.18.0
[36m(setup pid=3864)[0m  + fsspec==2025.7.0
[36m(setup pid=3864)[0m  + jinja2==3.1.6
[36m(setup pid=3864)[0m  + markupsafe==3.0.2
[36m(setup pid=3864)[0m  + mpmath==1.3.0
[36m(setup pid=3864)[0m  + networkx==3.4.2
[36m(setup pid=3864)[0m  + numpy==2.2.6
[36m(setup pid=3864)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3864)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3864)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3864)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3864)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3864)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3864)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3864)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3864)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3864)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3864)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3864)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3864)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3864)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3864)[0m  + pillow==11.3.0
[36m(setup pid=3864)[0m  + sympy==1.14.0
[36m(setup pid=3864)[0m  + torch==2.7.1
[36m(setup pid=3864)[0m  + torchaudio==2.7.1
[36m(setup pid=3864)[0m  + torchvision==0.22.1
[36m(setup pid=3864)[0m  + triton==3.3.1
[36m(setup pid=3864)[0m  + typing-extensions==4.14.1
[36m(setup pid=3864)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3864)[0m Resolved 73 packages in 277ms
[36m(setup pid=3864)[0m    Building deepspeed==0.17.4
[36m(setup pid=3864)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3864)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=3864)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3864)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3864)[0m  Downloading tokenizers
[36m(setup pid=3864)[0m  Downloading hf-xet
[36m(setup pid=3864)[0m  Downloading pyarrow
[36m(setup pid=3864)[0m  Downloading transformers
[36m(setup pid=3864)[0m       Built deepspeed==0.17.4
[36m(setup pid=3864)[0m Prepared 21 packages in 1.43s
[36m(setup pid=3864)[0m Uninstalled 1 package in 1ms
[36m(setup pid=3864)[0m Installed 48 packages in 154ms
[36m(setup pid=3864)[0m  + accelerate==1.9.0
[36m(setup pid=3864)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3864)[0m  + aiohttp==3.12.15
[36m(setup pid=3864)[0m  + aiosignal==1.4.0
[36m(setup pid=3864)[0m  + annotated-types==0.7.0
[36m(setup pid=3864)[0m  + async-timeout==5.0.1
[36m(setup pid=3864)[0m  + attrs==25.3.0
[36m(setup pid=3864)[0m  + certifi==2025.8.3
[36m(setup pid=3864)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3864)[0m  + datasets==4.0.0
[36m(setup pid=3864)[0m  + deepspeed==0.17.4
[36m(setup pid=3864)[0m  + dill==0.3.8
[36m(setup pid=3864)[0m  + einops==0.8.1
[36m(setup pid=3864)[0m  + frozenlist==1.7.0
[36m(setup pid=3864)[0m  - fsspec==2025.7.0
[36m(setup pid=3864)[0m  + fsspec==2025.3.0
[36m(setup pid=3864)[0m  + hf-xet==1.1.5
[36m(setup pid=3864)[0m  + hjson==3.1.0
[36m(setup pid=3864)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3864)[0m  + idna==3.10
[36m(setup pid=3864)[0m  + liger-kernel==0.6.1
[36m(setup pid=3864)[0m  + msgpack==1.1.1
[36m(setup pid=3864)[0m  + multidict==6.6.3
[36m(setup pid=3864)[0m  + multiprocess==0.70.16
[36m(setup pid=3864)[0m  + ninja==1.11.1.4
[36m(setup pid=3864)[0m  + packaging==25.0
[36m(setup pid=3864)[0m  + pandas==2.3.1
[36m(setup pid=3864)[0m  + propcache==0.3.2
[36m(setup pid=3864)[0m  + psutil==7.0.0
[36m(setup pid=3864)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3864)[0m  + pyarrow==21.0.0
[36m(setup pid=3864)[0m  + pydantic==2.11.7
[36m(setup pid=3864)[0m  + pydantic-core==2.33.2
[36m(setup pid=3864)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3864)[0m  + pytz==2025.2
[36m(setup pid=3864)[0m  + pyyaml==6.0.2
[36m(setup pid=3864)[0m  + regex==2025.7.34
[36m(setup pid=3864)[0m  + requests==2.32.4
[36m(setup pid=3864)[0m  + safetensors==0.5.3
[36m(setup pid=3864)[0m  + six==1.17.0
[36m(setup pid=3864)[0m  + tokenizers==0.21.4
[36m(setup pid=3864)[0m  + tqdm==4.67.1
[36m(setup pid=3864)[0m  + transformers==4.54.1
[36m(setup pid=3864)[0m  + trl==0.20.0
[36m(setup pid=3864)[0m  + typing-inspection==0.4.1
[36m(setup pid=3864)[0m  + tzdata==2025.2
[36m(setup pid=3864)[0m  + urllib3==2.5.0
[36m(setup pid=3864)[0m  + xxhash==3.5.0
[36m(setup pid=3864)[0m  + yarl==1.20.1
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m Reading package lists...
[36m(setup pid=3864)[0m Building dependency tree...
[36m(setup pid=3864)[0m Reading state information...
[36m(setup pid=3864)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3864)[0m   libfuse2
[36m(setup pid=3864)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3864)[0m The following additional packages will be installed:
[36m(setup pid=3864)[0m   vim-common vim-runtime
[36m(setup pid=3864)[0m Suggested packages:
[36m(setup pid=3864)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3864)[0m The following NEW packages will be installed:
[36m(setup pid=3864)[0m   vmtouch
[36m(setup pid=3864)[0m The following packages will be upgraded:
[36m(setup pid=3864)[0m   vim vim-common vim-runtime
[36m(setup pid=3864)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=3864)[0m Need to get 8664 kB of archives.
[36m(setup pid=3864)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3864)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=3864)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=3864)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3864)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=3864)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3864)[0m Fetched 8664 kB in 1s (16.4 MB/s)
[36m(setup pid=3864)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3864)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=3864)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3864)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3864)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3864)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading torch
[36m(setup pid=2703, ip=10.102.30.141)[0m Prepared 22 packages in 22.50s
[36m(setup pid=2703, ip=10.102.30.141)[0m Installed 28 packages in 202ms
[36m(setup pid=2703, ip=10.102.30.141)[0m  + filelock==3.18.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + fsspec==2025.7.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + jinja2==3.1.6
[36m(setup pid=2703, ip=10.102.30.141)[0m  + markupsafe==3.0.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + mpmath==1.3.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + networkx==3.4.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + numpy==2.2.6
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pillow==11.3.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + sympy==1.14.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + torch==2.7.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + torchaudio==2.7.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + torchvision==0.22.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + triton==3.3.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + typing-extensions==4.14.1
[36m(setup pid=2703, ip=10.102.30.141)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2703, ip=10.102.30.141)[0m Resolved 73 packages in 317ms
[36m(setup pid=2703, ip=10.102.30.141)[0m    Building deepspeed==0.17.4
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading transformers (10.7MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading tokenizers
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading hf-xet
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading pyarrow
[36m(setup pid=2703, ip=10.102.30.141)[0m  Downloading transformers
[36m(setup pid=3864)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3864)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3864)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3864)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=3864)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3864)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3864)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3864)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3864)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m       Built deepspeed==0.17.4
[36m(setup pid=2703, ip=10.102.30.141)[0m Prepared 21 packages in 1.41s
[36m(setup pid=2703, ip=10.102.30.141)[0m Uninstalled 1 package in 0.85ms
[36m(setup pid=2703, ip=10.102.30.141)[0m Installed 48 packages in 70ms
[36m(setup pid=2703, ip=10.102.30.141)[0m  + accelerate==1.9.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + aiohttp==3.12.15
[36m(setup pid=2703, ip=10.102.30.141)[0m  + aiosignal==1.4.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + annotated-types==0.7.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + async-timeout==5.0.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + attrs==25.3.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + certifi==2025.8.3
[36m(setup pid=2703, ip=10.102.30.141)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + datasets==4.0.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + deepspeed==0.17.4
[36m(setup pid=2703, ip=10.102.30.141)[0m  + dill==0.3.8
[36m(setup pid=2703, ip=10.102.30.141)[0m  + einops==0.8.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + frozenlist==1.7.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  - fsspec==2025.7.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + fsspec==2025.3.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + hf-xet==1.1.5
[36m(setup pid=2703, ip=10.102.30.141)[0m  + hjson==3.1.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2703, ip=10.102.30.141)[0m  + idna==3.10
[36m(setup pid=2703, ip=10.102.30.141)[0m  + liger-kernel==0.6.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + msgpack==1.1.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + multidict==6.6.3
[36m(setup pid=2703, ip=10.102.30.141)[0m  + multiprocess==0.70.16
[36m(setup pid=2703, ip=10.102.30.141)[0m  + ninja==1.11.1.4
[36m(setup pid=2703, ip=10.102.30.141)[0m  + packaging==25.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pandas==2.3.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + propcache==0.3.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + psutil==7.0.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pyarrow==21.0.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pydantic==2.11.7
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pydantic-core==2.33.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pytz==2025.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + pyyaml==6.0.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + regex==2025.7.34
[36m(setup pid=2703, ip=10.102.30.141)[0m  + requests==2.32.4
[36m(setup pid=2703, ip=10.102.30.141)[0m  + safetensors==0.5.3
[36m(setup pid=2703, ip=10.102.30.141)[0m  + six==1.17.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + tokenizers==0.21.4
[36m(setup pid=2703, ip=10.102.30.141)[0m  + tqdm==4.67.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + transformers==4.54.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + trl==0.20.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + typing-inspection==0.4.1
[36m(setup pid=2703, ip=10.102.30.141)[0m  + tzdata==2025.2
[36m(setup pid=2703, ip=10.102.30.141)[0m  + urllib3==2.5.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + xxhash==3.5.0
[36m(setup pid=2703, ip=10.102.30.141)[0m  + yarl==1.20.1
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=3864)[0m Reading package lists...
[36m(setup pid=3864)[0m Building dependency tree...
[36m(setup pid=3864)[0m Reading state information...
[36m(setup pid=2703, ip=10.102.30.141)[0m Reading package lists...
[36m(setup pid=3864)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3864)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3864)[0m   libfuse2
[36m(setup pid=3864)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3864)[0m The following additional packages will be installed:
[36m(setup pid=3864)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3864)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3864)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3864)[0m   python3.10 python3.10-minimal
[36m(setup pid=3864)[0m Suggested packages:
[36m(setup pid=3864)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2703, ip=10.102.30.141)[0m Building dependency tree...
[36m(setup pid=2703, ip=10.102.30.141)[0m Reading state information...
[36m(setup pid=3864)[0m The following NEW packages will be installed:
[36m(setup pid=3864)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3864)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3864)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3864)[0m The following packages will be upgraded:
[36m(setup pid=3864)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3864)[0m   python3.10 python3.10-minimal
[36m(setup pid=2703, ip=10.102.30.141)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2703, ip=10.102.30.141)[0m   libfuse2
[36m(setup pid=2703, ip=10.102.30.141)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2703, ip=10.102.30.141)[0m The following additional packages will be installed:
[36m(setup pid=2703, ip=10.102.30.141)[0m   vim-common vim-runtime
[36m(setup pid=2703, ip=10.102.30.141)[0m Suggested packages:
[36m(setup pid=2703, ip=10.102.30.141)[0m   ctags vim-doc vim-scripts
[36m(setup pid=2703, ip=10.102.30.141)[0m The following NEW packages will be installed:
[36m(setup pid=2703, ip=10.102.30.141)[0m   vmtouch
[36m(setup pid=2703, ip=10.102.30.141)[0m The following packages will be upgraded:
[36m(setup pid=2703, ip=10.102.30.141)[0m   vim vim-common vim-runtime
[36m(setup pid=3864)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=3864)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3864)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3864)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=2703, ip=10.102.30.141)[0m Need to get 8664 kB of archives.
[36m(setup pid=2703, ip=10.102.30.141)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=3864)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=3864)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3864)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=3864)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=3864)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=3864)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3864)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3864)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3864)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=3864)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3864)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3864)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3864)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3864)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3864)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3864)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Fetched 8664 kB in 1s (6605 kB/s)
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2703, ip=10.102.30.141)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3864)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3864)[0m Fetched 13.7 MB in 2s (9012 kB/s)
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3864)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=3864)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3864)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3864)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3864)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3864)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=3864)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3864)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3864)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3864)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3864)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3864)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3864)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3864)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3864)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3864)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3864)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3864)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3864)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3864)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3864)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3864)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3864)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3864)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3864)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3864)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3864)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3864)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3864)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3864)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3864)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2703, ip=10.102.30.141)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=3864)[0m Reading package lists...
[36m(setup pid=3864)[0m Building dependency tree...
[36m(setup pid=3864)[0m Reading state information...
[36m(setup pid=2703, ip=10.102.30.141)[0m Reading package lists...
[36m(setup pid=3864)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3864)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3864)[0m   libfuse2
[36m(setup pid=3864)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3864)[0m The following additional packages will be installed:
[36m(setup pid=3864)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3864)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3864)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3864)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3864)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3864)[0m   xdg-user-dirs
[36m(setup pid=3864)[0m Suggested packages:
[36m(setup pid=3864)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3864)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3864)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=3864)[0m The following NEW packages will be installed:
[36m(setup pid=3864)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3864)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3864)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3864)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3864)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3864)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3864)[0m The following packages will be upgraded:
[36m(setup pid=3864)[0m   libsystemd0 net-tools
[36m(setup pid=2703, ip=10.102.30.141)[0m Building dependency tree...
[36m(setup pid=2703, ip=10.102.30.141)[0m Reading state information...
[36m(setup pid=2703, ip=10.102.30.141)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2703, ip=10.102.30.141)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2703, ip=10.102.30.141)[0m   libfuse2
[36m(setup pid=2703, ip=10.102.30.141)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2703, ip=10.102.30.141)[0m The following additional packages will be installed:
[36m(setup pid=2703, ip=10.102.30.141)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2703, ip=10.102.30.141)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2703, ip=10.102.30.141)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2703, ip=10.102.30.141)[0m   python3.10 python3.10-minimal
[36m(setup pid=2703, ip=10.102.30.141)[0m Suggested packages:
[36m(setup pid=2703, ip=10.102.30.141)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2703, ip=10.102.30.141)[0m The following NEW packages will be installed:
[36m(setup pid=2703, ip=10.102.30.141)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2703, ip=10.102.30.141)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2703, ip=10.102.30.141)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2703, ip=10.102.30.141)[0m The following packages will be upgraded:
[36m(setup pid=2703, ip=10.102.30.141)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2703, ip=10.102.30.141)[0m   python3.10 python3.10-minimal
[36m(setup pid=3864)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3864)[0m Need to get 10.6 MB of archives.
[36m(setup pid=3864)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3864)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=2703, ip=10.102.30.141)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2703, ip=10.102.30.141)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=3864)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3864)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3864)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3864)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=3864)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2703, ip=10.102.30.141)[0m Fetched 13.7 MB in 1s (25.2 MB/s)
[36m(setup pid=2703, ip=10.102.30.141)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3864)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3864)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3864)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3864)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3864)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3864)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3864)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3864)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3864)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=3864)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=3864)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3864)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3864)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3864)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3864)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3864)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3864)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3864)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3864)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3864)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3864)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3864)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3864)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3864)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3864)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3864)[0m Fetched 10.6 MB in 2s (6252 kB/s)
[36m(setup pid=3864)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3864)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3864)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3864)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3864)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package systemd.
[36m(setup pid=3864)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3864)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package dbus.
[36m(setup pid=3864)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3864)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3864)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3864)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3864)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3864)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3864)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3864)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3864)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3864)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3864)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3864)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=3864)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3864)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package htop.
[36m(setup pid=3864)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3864)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3864)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3864)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3864)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3864)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=3864)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3864)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3864)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3864)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3864)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3864)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3864)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3864)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3864)[0m No schema files found: doing nothing.
[36m(setup pid=3864)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3864)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3864)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3864)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3864)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3864)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3864)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=3864)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3864)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3864)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3864)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3864)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3864)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3864)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3864)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3864)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3864)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3864)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3864)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=3864)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer â†’ /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=3864)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer â†’ /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=3864)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service â†’ /lib/systemd/system/sysstat.service.
[36m(setup pid=3864)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Reading package lists...
[36m(setup pid=3864)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3864)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3864)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3864)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3864)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Building dependency tree...
[36m(setup pid=2703, ip=10.102.30.141)[0m Reading state information...
[36m(setup pid=3864)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3864)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3864)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3864)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3864)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3864)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3864)[0m       D     : show the differences between the versions
[36m(setup pid=3864)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3864)[0m  The default action is to keep your current version.
[36m(setup pid=3864)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3864)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3864)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3864)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3864)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3864)[0m   Package systemd is not configured yet.
[36m(setup pid=3864)[0m 
[36m(setup pid=3864)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3864)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3864)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2703, ip=10.102.30.141)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2703, ip=10.102.30.141)[0m   libfuse2
[36m(setup pid=2703, ip=10.102.30.141)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2703, ip=10.102.30.141)[0m The following additional packages will be installed:
[36m(setup pid=2703, ip=10.102.30.141)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2703, ip=10.102.30.141)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2703, ip=10.102.30.141)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2703, ip=10.102.30.141)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2703, ip=10.102.30.141)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2703, ip=10.102.30.141)[0m   xdg-user-dirs
[36m(setup pid=2703, ip=10.102.30.141)[0m Suggested packages:
[36m(setup pid=2703, ip=10.102.30.141)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2703, ip=10.102.30.141)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2703, ip=10.102.30.141)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=3864)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service â†’ /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3864)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m The following NEW packages will be installed:
[36m(setup pid=2703, ip=10.102.30.141)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2703, ip=10.102.30.141)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2703, ip=10.102.30.141)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2703, ip=10.102.30.141)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2703, ip=10.102.30.141)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2703, ip=10.102.30.141)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2703, ip=10.102.30.141)[0m The following packages will be upgraded:
[36m(setup pid=2703, ip=10.102.30.141)[0m   libsystemd0 net-tools
[36m(setup pid=3864)[0m Errors were encountered while processing:
[36m(setup pid=3864)[0m  systemd
[36m(setup pid=3864)[0m  systemd-timesyncd
[36m(setup pid=3864)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3864)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3864)[0m Resolved 3 packages in 48ms
[36m(setup pid=3864)[0m Prepared 1 package in 10ms
[36m(setup pid=3864)[0m Installed 2 packages in 16ms
[36m(setup pid=3864)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3864)[0m  + nvitop==1.5.2
[36m(setup pid=2703, ip=10.102.30.141)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2703, ip=10.102.30.141)[0m Need to get 10.6 MB of archives.
[36m(setup pid=2703, ip=10.102.30.141)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=2703, ip=10.102.30.141)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2703, ip=10.102.30.141)[0m Fetched 10.6 MB in 2s (4495 kB/s)
[36m(setup pid=2703, ip=10.102.30.141)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m (Reading database ... 
(Reading database ... 5%
(Reading database ... 10%
(Reading database ... 15%
(Reading database ... 20%
(Reading database ... 25%
(Reading database ... 30%
(Reading database ... 35%
(Reading database ... 40%
(Reading database ... 45%
(Reading database ... 50%
(Reading database ... 55%
(Reading database ... 60%
(Reading database ... 65%
(Reading database ... 70%
(Reading database ... 75%
(Reading database ... 80%
(Reading database ... 85%
(Reading database ... 90%
(Reading database ... 95%
(Reading database ... 100%
(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package systemd.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package dbus.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package htop.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2703, ip=10.102.30.141)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m No schema files found: doing nothing.
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=2703, ip=10.102.30.141)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2703, ip=10.102.30.141)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2703, ip=10.102.30.141)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer â†’ /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2703, ip=10.102.30.141)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer â†’ /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2703, ip=10.102.30.141)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service â†’ /lib/systemd/system/sysstat.service.
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2703, ip=10.102.30.141)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2703, ip=10.102.30.141)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2703, ip=10.102.30.141)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2703, ip=10.102.30.141)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2703, ip=10.102.30.141)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2703, ip=10.102.30.141)[0m       D     : show the differences between the versions
[36m(setup pid=2703, ip=10.102.30.141)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2703, ip=10.102.30.141)[0m  The default action is to keep your current version.
[36m(setup pid=2703, ip=10.102.30.141)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2703, ip=10.102.30.141)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2703, ip=10.102.30.141)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2703, ip=10.102.30.141)[0m   Package systemd is not configured yet.
[36m(setup pid=2703, ip=10.102.30.141)[0m 
[36m(setup pid=2703, ip=10.102.30.141)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2703, ip=10.102.30.141)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2703, ip=10.102.30.141)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service â†’ /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2703, ip=10.102.30.141)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2703, ip=10.102.30.141)[0m Errors were encountered while processing:
[36m(setup pid=2703, ip=10.102.30.141)[0m  systemd
[36m(setup pid=2703, ip=10.102.30.141)[0m  systemd-timesyncd
[36m(setup pid=2703, ip=10.102.30.141)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2703, ip=10.102.30.141)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2703, ip=10.102.30.141)[0m Resolved 3 packages in 25ms
[36m(setup pid=2703, ip=10.102.30.141)[0m Prepared 1 package in 10ms
[36m(setup pid=2703, ip=10.102.30.141)[0m Installed 2 packages in 17ms
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2703, ip=10.102.30.141)[0m  + nvitop==1.5.2
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(head, rank=0, pid=3864)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3864)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:   2%|â–         | 1000/47780 [00:00<00:25, 1820.46 examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:  19%|â–ˆâ–‰        | 9000/47780 [00:00<00:02, 17691.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:  29%|â–ˆâ–ˆâ–‰       | 14000/47780 [00:00<00:01, 21959.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21000/47780 [00:00<00:00, 30224.01 examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28000/47780 [00:01<00:00, 37524.34 examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35556/47780 [00:01<00:00, 46358.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Generating train split:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43668/47780 [00:01<00:00, 53181.47 examples/s]
Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:01<00:00, 32914.82 examples/s]
[36m(head, rank=0, pid=3864)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3864)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3864)[0m vmtouch output: Files: 14
[36m(head, rank=0, pid=3864)[0m      Directories: 5
[36m(head, rank=0, pid=3864)[0m    Evicted Pages: 1212952 (4G)
[36m(head, rank=0, pid=3864)[0m          Elapsed: 3.7141 seconds
[36m(head, rank=0, pid=3864)[0m Downloading and caching model...
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:   2%|â–         | 1000/47780 [00:00<00:24, 1926.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:  13%|â–ˆâ–Ž        | 6000/47780 [00:00<00:03, 12179.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:  23%|â–ˆâ–ˆâ–Ž       | 11000/47780 [00:00<00:01, 20176.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18000/47780 [00:00<00:00, 30437.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23000/47780 [00:01<00:00, 31168.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31000/47780 [00:01<00:00, 41383.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41112/47780 [00:01<00:00, 55908.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:01<00:00, 54920.61 examples/s]
Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:01<00:00, 33175.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m vmtouch output: Files: 14
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m      Directories: 5
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m    Evicted Pages: 1212952 (4G)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m          Elapsed: 3.7253 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Fetching 5 files:  20%|â–ˆâ–ˆ        | 1/5 [00:21<01:25, 21.49s/it]
[36m(head, rank=0, pid=3864)[0m Fetching 5 files:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:21<00:11,  5.66s/it]
Fetching 5 files:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:04,  4.20s/it]
Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:23<00:00,  4.63s/it]
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Fetching 5 files:  20%|â–ˆâ–ˆ        | 1/5 [00:17<01:10, 17.75s/it]
Fetching 5 files:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:18<00:03,  3.65s/it]
Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.77s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:17,  4.50s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:08<00:13,  4.34s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:16,  4.06s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:12<00:08,  4.26s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:07<00:11,  3.97s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:04,  4.26s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.28s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.30s/it]
[36m(head, rank=0, pid=3864)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:11<00:07,  3.93s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:15<00:03,  3.93s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.84s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.89s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3864)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3864)[0m      Directories: 10
[36m(head, rank=0, pid=3864)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3864)[0m          Elapsed: 21.702 seconds
[36m(head, rank=0, pid=3864)[0m Completed processing directory 1/2
[36m(head, rank=0, pid=3864)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3864)[0m vmtouch output: Files: 32
[36m(head, rank=0, pid=3864)[0m      Directories: 15
[36m(head, rank=0, pid=3864)[0m    Evicted Pages: 7163861 (27G)
[36m(head, rank=0, pid=3864)[0m          Elapsed: 0.003187 seconds
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Processing directory 2/2: /mnt/data ===
[36m(head, rank=0, pid=3864)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3864)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3864)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3864)[0m vmtouch output: Files: 78
[36m(head, rank=0, pid=3864)[0m      Directories: 5
[36m(head, rank=0, pid=3864)[0m    Evicted Pages: 4617819 (17G)
[36m(head, rank=0, pid=3864)[0m          Elapsed: 0.24552 seconds
[36m(head, rank=0, pid=3864)[0m Downloading and caching model...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m      Directories: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m          Elapsed: 25.193 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed processing directory 1/2
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m vmtouch output: Files: 32
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m      Directories: 15
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m    Evicted Pages: 7163861 (27G)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m          Elapsed: 0.001283 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Processing directory 2/2: /mnt/data ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m vmtouch output: Files: 78
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m      Directories: 5
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m    Evicted Pages: 4617819 (17G)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m          Elapsed: 0.3488 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  5.76s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  5.77s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:25,  6.32s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  5.67s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:17,  5.94s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  5.65s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.48s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.58s/it]
[36m(head, rank=0, pid=3864)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  5.60s/it]
[36m(head, rank=0, pid=3864)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3864)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3864)[0m      Directories: 10
[36m(head, rank=0, pid=3864)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3864)[0m          Elapsed: 1.4779 seconds
[36m(head, rank=0, pid=3864)[0m Completed processing directory 2/2
[36m(head, rank=0, pid=3864)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3864)[0m vmtouch output: Files: 96
[36m(head, rank=0, pid=3864)[0m      Directories: 15
[36m(head, rank=0, pid=3864)[0m    Evicted Pages: 10568728 (40G)
[36m(head, rank=0, pid=3864)[0m          Elapsed: 0.10812 seconds
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Copying cached data to S3 directories ===
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(head, rank=0, pid=3864)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:22<00:05,  5.41s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.27s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.46s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m      Directories: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m          Elapsed: 1.3109 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed processing directory 2/2
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m vmtouch output: Files: 96
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m      Directories: 15
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m    Evicted Pages: 10568728 (40G)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m          Elapsed: 0.11553 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Copying cached data to S3 directories ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3864)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Model cache copied successfully
[36m(head, rank=0, pid=3864)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3864)[0m Completed copying to S3 directory 1/2
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(head, rank=0, pid=3864)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3864)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed copying to S3 directory 1/2
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Model cache copied successfully
[36m(head, rank=0, pid=3864)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3864)[0m Completed copying to S3 directory 2/2
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Download and caching completed ===
[36m(head, rank=0, pid=3864)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed copying to S3 directory 2/2
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Download and caching completed ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.13 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.13 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.15 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.13 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.13 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.13 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.14 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.15 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.15 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.18 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.23 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.28 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.33 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.33 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.44 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.50 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 129.33it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 127.67it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 134.25it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 123.41it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 122.19it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.92 seconds
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 130.39it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 0.94 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 0.94 seconds
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 128.71it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 129.02it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 0.93 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 128.22it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 130.40it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 130.91it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.07 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.08 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 130.65it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.14 seconds
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 120.61it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 129.76it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.08 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.19 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.98 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.06 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:19,  4.83s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:19,  4.84s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09<00:13,  4.47s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:09<00:13,  4.55s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13<00:08,  4.29s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:13<00:08,  4.41s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:04,  4.22s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.12s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.24s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 22.07 seconds
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:17<00:04,  4.28s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.13s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.28s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Completed Load model in 22.33 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:16<37:19:45,  2.81s/ examples]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   0%|          | 33/47780 [00:17<5:09:33,  2.57 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   0%|          | 65/47780 [00:17<2:09:58,  6.12 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   0%|          | 110/47780 [00:17<1:02:13, 12.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   0%|          | 177/47780 [00:18<30:45, 25.79 examples/s]  
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   1%|          | 250/47780 [00:18<18:19, 43.23 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   1%|          | 332/47780 [00:18<11:50, 66.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   1%|          | 424/47780 [00:19<08:09, 96.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   1%|          | 559/47780 [00:19<05:15, 149.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 702/47780 [00:19<03:48, 205.79 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 870/47780 [00:20<02:52, 271.75 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1019/47780 [00:20<02:31, 309.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1199/47780 [00:20<02:06, 369.11 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1373/47780 [00:21<01:53, 409.99 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1580/47780 [00:21<01:40, 460.61 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1834/47780 [00:21<01:26, 533.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2078/47780 [00:22<01:19, 571.52 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2329/47780 [00:22<01:14, 609.06 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2600/47780 [00:22<01:10, 643.99 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2834/47780 [00:23<01:09, 643.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3073/47780 [00:23<01:09, 645.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3339/47780 [00:23<01:05, 676.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3636/47780 [00:24<01:01, 722.74 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3931/47780 [00:24<00:58, 745.54 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4221/47780 [00:25<00:56, 770.45 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4566/47780 [00:25<00:51, 832.95 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4905/47780 [00:25<00:49, 865.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5257/47780 [00:25<00:37, 1147.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5422/47780 [00:26<00:38, 1112.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5567/47780 [00:26<00:38, 1101.25 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5702/47780 [00:26<00:38, 1102.79 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5830/47780 [00:26<00:38, 1090.90 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5950/47780 [00:26<00:38, 1098.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6068/47780 [00:26<00:38, 1091.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6183/47780 [00:26<00:38, 1093.52 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6297/47780 [00:26<00:37, 1094.28 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6413/47780 [00:26<00:38, 1078.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6523/47780 [00:27<00:38, 1070.14 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6641/47780 [00:27<00:37, 1099.64 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6761/47780 [00:27<00:36, 1123.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6895/47780 [00:27<00:34, 1177.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7014/47780 [00:27<00:34, 1177.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7142/47780 [00:27<00:33, 1196.87 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7263/47780 [00:27<00:34, 1190.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7383/47780 [00:27<00:36, 1121.57 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7508/47780 [00:27<00:34, 1153.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7638/47780 [00:27<00:34, 1161.05 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7760/47780 [00:28<00:34, 1176.99 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7879/47780 [00:28<00:36, 1103.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8007/47780 [00:28<00:34, 1149.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8125/47780 [00:28<00:34, 1152.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8242/47780 [00:28<00:34, 1129.81 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8368/47780 [00:28<00:33, 1161.12 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8494/47780 [00:28<00:33, 1182.44 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8620/47780 [00:28<00:32, 1197.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8744/47780 [00:28<00:33, 1182.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8864/47780 [00:29<00:34, 1140.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8979/47780 [00:29<00:34, 1123.23 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9093/47780 [00:29<00:34, 1120.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9206/47780 [00:29<00:36, 1056.23 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9332/47780 [00:29<00:34, 1105.95 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9467/47780 [00:29<00:32, 1171.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9611/47780 [00:29<00:30, 1242.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9737/47780 [00:29<00:32, 1175.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9856/47780 [00:29<00:32, 1157.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9973/47780 [00:30<00:33, 1119.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10097/47780 [00:30<00:32, 1149.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10214/47780 [00:30<00:34, 1100.37 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10326/47780 [00:30<00:34, 1081.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10440/47780 [00:30<00:34, 1078.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10560/47780 [00:30<00:34, 1093.82 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10671/47780 [00:30<00:34, 1073.57 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10791/47780 [00:30<00:33, 1108.34 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10904/47780 [00:30<00:34, 1069.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11013/47780 [00:30<00:34, 1067.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11145/47780 [00:31<00:32, 1132.26 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11261/47780 [00:31<00:32, 1124.10 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11385/47780 [00:31<00:31, 1149.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11508/47780 [00:31<00:31, 1150.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11644/47780 [00:31<00:30, 1199.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11766/47780 [00:31<00:30, 1183.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11886/47780 [00:31<00:30, 1175.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12004/47780 [00:31<00:30, 1158.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12120/47780 [00:31<00:31, 1138.11 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12237/47780 [00:32<00:30, 1147.09 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12355/47780 [00:32<00:30, 1153.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12485/47780 [00:32<00:29, 1194.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12606/47780 [00:32<00:30, 1153.02 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12733/47780 [00:32<00:30, 1162.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12850/47780 [00:32<00:30, 1151.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12972/47780 [00:32<00:29, 1169.03 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13095/47780 [00:32<00:29, 1175.75 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13213/47780 [00:32<00:30, 1136.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13328/47780 [00:32<00:30, 1111.94 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13441/47780 [00:33<00:31, 1090.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13570/47780 [00:33<00:29, 1141.52 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13685/47780 [00:33<00:30, 1099.86 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13798/47780 [00:33<00:32, 1033.51 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13903/47780 [00:33<00:32, 1028.81 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14012/47780 [00:33<00:32, 1045.69 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14118/47780 [00:33<00:33, 1010.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14230/47780 [00:33<00:32, 1039.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14351/47780 [00:33<00:30, 1087.43 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14462/47780 [00:34<00:31, 1070.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14570/47780 [00:34<00:31, 1049.54 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14688/47780 [00:34<00:30, 1086.85 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14802/47780 [00:34<00:29, 1102.19 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14915/47780 [00:34<00:29, 1103.94 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15030/47780 [00:34<00:29, 1099.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15142/47780 [00:34<00:30, 1079.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15256/47780 [00:34<00:29, 1094.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15370/47780 [00:34<00:29, 1105.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15482/47780 [00:34<00:29, 1096.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15594/47780 [00:35<00:29, 1099.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15727/47780 [00:35<00:27, 1164.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15845/47780 [00:35<00:28, 1119.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15968/47780 [00:35<00:27, 1146.24 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16084/47780 [00:35<00:28, 1123.94 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16199/47780 [00:35<00:28, 1123.47 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16312/47780 [00:35<00:29, 1056.06 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16424/47780 [00:35<00:29, 1063.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16534/47780 [00:35<00:29, 1070.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16642/47780 [00:36<00:29, 1053.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16749/47780 [00:36<00:29, 1056.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16860/47780 [00:36<00:29, 1057.07 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16967/47780 [00:36<00:29, 1048.15 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17088/47780 [00:36<00:28, 1081.21 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17209/47780 [00:36<00:27, 1108.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17337/47780 [00:36<00:26, 1132.02 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17453/47780 [00:36<00:26, 1139.19 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17567/47780 [00:36<00:26, 1134.71 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17685/47780 [00:36<00:26, 1146.12 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17800/47780 [00:37<00:26, 1140.17 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17915/47780 [00:37<00:27, 1093.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18025/47780 [00:37<00:27, 1085.03 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18135/47780 [00:37<00:27, 1069.86 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18248/47780 [00:37<00:27, 1082.02 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18360/47780 [00:37<00:27, 1067.33 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18475/47780 [00:37<00:26, 1089.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18586/47780 [00:37<00:28, 1039.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18703/47780 [00:37<00:27, 1058.57 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18810/47780 [00:38<00:27, 1051.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18933/47780 [00:38<00:26, 1098.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19044/47780 [00:38<00:26, 1067.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19160/47780 [00:38<00:26, 1092.38 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19270/47780 [00:38<00:26, 1063.51 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19404/47780 [00:38<00:24, 1142.38 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19519/47780 [00:38<00:24, 1141.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19638/47780 [00:38<00:24, 1145.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19753/47780 [00:38<00:25, 1111.31 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19869/47780 [00:38<00:24, 1124.47 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19983/47780 [00:39<00:26, 1057.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20090/47780 [00:39<00:27, 1016.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20200/47780 [00:39<00:26, 1039.67 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20305/47780 [00:39<00:26, 1030.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20409/47780 [00:39<00:26, 1017.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20540/47780 [00:39<00:24, 1096.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20651/47780 [00:39<00:26, 1036.10 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20765/47780 [00:39<00:25, 1062.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20878/47780 [00:39<00:25, 1067.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20987/47780 [00:40<00:25, 1060.94 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21095/47780 [00:40<00:26, 1024.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21204/47780 [00:40<00:25, 1042.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21310/47780 [00:40<00:25, 1043.75 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21423/47780 [00:40<00:25, 1052.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21531/47780 [00:40<00:25, 1036.01 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21643/47780 [00:40<00:24, 1059.21 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21757/47780 [00:40<00:24, 1070.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21866/47780 [00:40<00:25, 1019.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21970/47780 [00:41<00:25, 1013.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22073/47780 [00:41<00:25, 1002.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22182/47780 [00:41<00:25, 1016.44 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22294/47780 [00:41<00:24, 1042.16 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22400/47780 [00:41<00:25, 993.82 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22500/47780 [00:41<00:25, 976.99 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22599/47780 [00:41<00:26, 947.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22695/47780 [00:41<00:27, 918.91 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22789/47780 [00:41<00:27, 915.54 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22889/47780 [00:41<00:26, 939.05 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23003/47780 [00:42<00:24, 996.14 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23105/47780 [00:42<00:24, 991.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23240/47780 [00:42<00:22, 1085.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23373/47780 [00:42<00:21, 1147.10 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23496/47780 [00:42<00:21, 1108.12 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23610/47780 [00:42<00:23, 1011.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23713/47780 [00:42<00:24, 985.04 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23820/47780 [00:42<00:24, 995.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23929/47780 [00:42<00:23, 1019.17 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24032/47780 [00:43<00:23, 992.65 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24141/47780 [00:43<00:23, 1013.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24264/47780 [00:43<00:22, 1054.01 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24400/47780 [00:43<00:20, 1134.90 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24515/47780 [00:43<00:21, 1089.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24626/47780 [00:43<00:22, 1034.61 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24733/47780 [00:43<00:22, 1036.33 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24838/47780 [00:43<00:22, 1038.38 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24958/47780 [00:43<00:21, 1073.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25079/47780 [00:44<00:20, 1112.03 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25191/47780 [00:44<00:20, 1088.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25305/47780 [00:44<00:20, 1100.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25416/47780 [00:44<00:20, 1085.45 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25526/47780 [00:44<00:21, 1030.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25630/47780 [00:44<00:23, 954.84 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25727/47780 [00:44<00:23, 932.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25829/47780 [00:44<00:23, 953.71 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25928/47780 [00:44<00:23, 946.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26027/47780 [00:45<00:23, 941.85 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26145/47780 [00:45<00:21, 1005.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26248/47780 [00:45<00:21, 1009.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26360/47780 [00:45<00:20, 1030.76 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26468/47780 [00:45<00:20, 1044.06 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26582/47780 [00:45<00:19, 1070.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26691/47780 [00:45<00:20, 1017.54 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26796/47780 [00:45<00:21, 985.41 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26898/47780 [00:45<00:20, 995.11 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26999/47780 [00:45<00:22, 939.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27095/47780 [00:46<00:21, 944.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27196/47780 [00:46<00:21, 962.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27294/47780 [00:46<00:21, 937.25 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27389/47780 [00:46<00:22, 909.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27484/47780 [00:46<00:22, 883.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27573/47780 [00:46<00:23, 862.93 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27679/47780 [00:46<00:22, 912.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27771/47780 [00:46<00:21, 911.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27867/47780 [00:46<00:21, 917.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27960/47780 [00:47<00:21, 905.64 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28051/47780 [00:47<00:22, 882.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28143/47780 [00:47<00:22, 882.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28232/47780 [00:47<00:22, 857.95 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28329/47780 [00:47<00:21, 886.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28430/47780 [00:47<00:21, 902.11 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28522/47780 [00:47<00:21, 906.98 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28614/47780 [00:47<00:22, 866.17 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28703/47780 [00:47<00:22, 862.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28814/47780 [00:48<00:20, 913.47 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28914/47780 [00:48<00:20, 934.71 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29008/47780 [00:48<00:20, 906.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29128/47780 [00:48<00:18, 986.17 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29228/47780 [00:48<00:19, 947.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29324/47780 [00:48<00:20, 922.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29418/47780 [00:48<00:20, 889.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29515/47780 [00:48<00:20, 912.17 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29608/47780 [00:48<00:20, 905.45 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29719/47780 [00:48<00:18, 954.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29822/47780 [00:49<00:18, 961.10 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29928/47780 [00:49<00:18, 978.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30027/47780 [00:49<00:18, 957.20 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30133/47780 [00:49<00:18, 958.86 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30237/47780 [00:49<00:17, 978.38 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30340/47780 [00:49<00:17, 992.54 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30441/47780 [00:49<00:18, 949.96 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30537/47780 [00:49<00:18, 939.63 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30633/47780 [00:49<00:18, 929.79 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30733/47780 [00:50<00:18, 933.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30829/47780 [00:50<00:18, 937.57 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30934/47780 [00:50<00:17, 969.45 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31033/47780 [00:50<00:18, 924.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31127/47780 [00:50<00:18, 922.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31220/47780 [00:50<00:18, 915.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31319/47780 [00:50<00:17, 922.06 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31419/47780 [00:50<00:17, 927.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31526/47780 [00:50<00:16, 961.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31632/47780 [00:50<00:16, 989.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31735/47780 [00:51<00:16, 995.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31849/47780 [00:51<00:15, 1028.52 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31960/47780 [00:51<00:15, 1051.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32069/47780 [00:51<00:14, 1057.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32178/47780 [00:51<00:14, 1066.21 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32285/47780 [00:51<00:14, 1047.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32394/47780 [00:51<00:14, 1048.81 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32509/47780 [00:51<00:14, 1057.82 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32616/47780 [00:51<00:14, 1046.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32735/47780 [00:52<00:14, 1068.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32842/47780 [00:52<00:14, 1065.98 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32963/47780 [00:52<00:13, 1102.14 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33074/47780 [00:52<00:13, 1071.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33200/47780 [00:52<00:13, 1115.49 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33319/47780 [00:52<00:12, 1127.95 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33432/47780 [00:52<00:13, 1065.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33541/47780 [00:52<00:14, 985.28 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33643/47780 [00:52<00:14, 975.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33742/47780 [00:52<00:14, 974.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33846/47780 [00:53<00:14, 992.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33947/47780 [00:53<00:13, 994.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34049/47780 [00:53<00:14, 962.43 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34146/47780 [00:53<00:14, 924.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34245/47780 [00:53<00:14, 941.45 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34341/47780 [00:53<00:14, 921.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34434/47780 [00:53<00:14, 911.02 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34535/47780 [00:53<00:14, 936.96 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34630/47780 [00:53<00:14, 898.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34721/47780 [00:54<00:14, 875.87 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34810/47780 [00:54<00:15, 850.59 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34912/47780 [00:54<00:14, 896.19 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35003/47780 [00:54<00:14, 871.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35091/47780 [00:54<00:14, 863.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35184/47780 [00:54<00:14, 870.38 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35283/47780 [00:54<00:13, 892.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35374/47780 [00:54<00:14, 854.23 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35460/47780 [00:54<00:14, 848.12 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35547/47780 [00:55<00:14, 848.09 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35643/47780 [00:55<00:13, 876.14 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35731/47780 [00:55<00:13, 861.48 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35819/47780 [00:55<00:14, 838.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35910/47780 [00:55<00:14, 843.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36006/47780 [00:55<00:13, 875.89 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36096/47780 [00:55<00:13, 853.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36186/47780 [00:55<00:13, 863.24 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36285/47780 [00:55<00:13, 860.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36378/47780 [00:55<00:13, 876.31 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36467/47780 [00:56<00:13, 857.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36573/47780 [00:56<00:12, 905.10 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36664/47780 [00:56<00:12, 896.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36774/47780 [00:56<00:11, 954.94 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36870/47780 [00:56<00:11, 924.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36963/47780 [00:56<00:12, 844.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37051/47780 [00:56<00:12, 848.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37148/47780 [00:56<00:12, 877.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37240/47780 [00:56<00:11, 883.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37336/47780 [00:57<00:11, 903.24 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37428/47780 [00:57<00:12, 856.96 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37517/47780 [00:57<00:11, 860.82 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37607/47780 [00:57<00:11, 867.05 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37695/47780 [00:57<00:12, 838.91 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37789/47780 [00:57<00:11, 858.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37881/47780 [00:57<00:11, 872.43 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37975/47780 [00:57<00:11, 879.35 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38065/47780 [00:57<00:11, 862.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38152/47780 [00:58<00:11, 852.64 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38244/47780 [00:58<00:11, 847.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38334/47780 [00:58<00:11, 851.71 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38420/47780 [00:58<00:11, 846.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38505/47780 [00:58<00:11, 820.36 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38597/47780 [00:58<00:10, 843.28 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38682/47780 [00:58<00:11, 819.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38775/47780 [00:58<00:10, 847.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38862/47780 [00:58<00:10, 812.75 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38961/47780 [00:58<00:10, 860.95 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39073/47780 [00:59<00:09, 905.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39176/47780 [00:59<00:09, 928.86 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39270/47780 [00:59<00:09, 865.06 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39376/47780 [00:59<00:09, 916.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39481/47780 [00:59<00:08, 939.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39585/47780 [00:59<00:08, 967.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39686/47780 [00:59<00:08, 973.41 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39785/47780 [00:59<00:08, 975.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39892/47780 [00:59<00:07, 1002.46 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39994/47780 [01:00<00:08, 961.19 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40091/47780 [01:00<00:07, 962.10 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40209/47780 [01:00<00:07, 1005.01 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40318/47780 [01:00<00:07, 1023.25 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40428/47780 [01:00<00:07, 1037.39 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40539/47780 [01:00<00:06, 1048.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40645/47780 [01:00<00:07, 1011.29 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40749/47780 [01:00<00:07, 990.41 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40850/47780 [01:00<00:07, 944.79 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40948/47780 [01:01<00:07, 951.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41047/47780 [01:01<00:07, 928.39 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41161/47780 [01:01<00:06, 984.93 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41262/47780 [01:01<00:06, 980.47 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41364/47780 [01:01<00:06, 971.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41464/47780 [01:01<00:06, 976.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41577/47780 [01:01<00:06, 990.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41677/47780 [01:01<00:06, 956.91 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41774/47780 [01:01<00:06, 920.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41869/47780 [01:01<00:06, 927.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41964/47780 [01:02<00:06, 929.87 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42059/47780 [01:02<00:06, 908.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42152/47780 [01:02<00:06, 867.82 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42241/47780 [01:02<00:06, 866.98 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42329/47780 [01:02<00:06, 847.44 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42416/47780 [01:02<00:06, 847.18 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42502/47780 [01:02<00:06, 825.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42587/47780 [01:02<00:06, 831.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42672/47780 [01:02<00:06, 826.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42772/47780 [01:03<00:05, 874.20 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42864/47780 [01:03<00:05, 826.63 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42966/47780 [01:03<00:05, 877.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43056/47780 [01:03<00:05, 859.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43150/47780 [01:03<00:05, 872.26 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43238/47780 [01:03<00:05, 791.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43320/47780 [01:03<00:06, 739.34 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43397/47780 [01:03<00:06, 706.41 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43475/47780 [01:03<00:06, 677.59 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43545/47780 [01:04<00:06, 670.45 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43619/47780 [01:04<00:06, 671.85 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43688/47780 [01:04<00:06, 628.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43752/47780 [01:04<00:06, 620.69 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43815/47780 [01:04<00:06, 597.33 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43883/47780 [01:04<00:06, 617.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43946/47780 [01:04<00:06, 617.34 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44008/47780 [01:04<00:06, 615.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44078/47780 [01:04<00:05, 639.21 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44165/47780 [01:05<00:05, 703.90 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44237/47780 [01:05<00:05, 695.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44308/47780 [01:05<00:05, 657.59 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44397/47780 [01:05<00:04, 718.68 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44471/47780 [01:05<00:04, 702.06 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44543/47780 [01:05<00:04, 702.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44615/47780 [01:05<00:04, 686.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44686/47780 [01:05<00:04, 692.61 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44756/47780 [01:05<00:04, 632.40 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44824/47780 [01:06<00:04, 640.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44889/47780 [01:06<00:04, 617.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44953/47780 [01:06<00:04, 592.31 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45014/47780 [01:06<00:04, 565.29 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45075/47780 [01:06<00:04, 572.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45134/47780 [01:06<00:04, 562.11 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45191/47780 [01:06<00:04, 552.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45248/47780 [01:06<00:04, 546.86 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45303/47780 [01:06<00:04, 536.52 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45365/47780 [01:07<00:04, 552.83 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45429/47780 [01:07<00:04, 575.58 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45488/47780 [01:07<00:04, 519.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45542/47780 [01:07<00:04, 505.00 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45596/47780 [01:07<00:04, 480.68 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45649/47780 [01:07<00:04, 486.15 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45702/47780 [01:07<00:04, 482.91 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45754/47780 [01:07<00:04, 483.56 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45804/47780 [01:07<00:04, 479.27 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45855/47780 [01:08<00:04, 480.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45905/47780 [01:08<00:04, 453.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45952/47780 [01:08<00:04, 446.85 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45997/47780 [01:08<00:04, 435.05 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46046/47780 [01:08<00:03, 444.37 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46111/47780 [01:08<00:03, 494.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46164/47780 [01:08<00:03, 481.85 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46233/47780 [01:08<00:02, 537.85 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46289/47780 [01:08<00:02, 504.70 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46345/47780 [01:09<00:03, 459.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46393/47780 [01:09<00:03, 437.77 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46438/47780 [01:09<00:03, 371.91 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46479/47780 [01:09<00:03, 371.05 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46519/47780 [01:09<00:03, 340.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46558/47780 [01:09<00:03, 331.60 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46597/47780 [01:09<00:03, 343.14 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46633/47780 [01:10<00:03, 312.30 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46668/47780 [01:10<00:03, 305.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46702/47780 [01:10<00:03, 308.69 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46735/47780 [01:10<00:03, 289.22 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46767/47780 [01:10<00:03, 293.51 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46802/47780 [01:10<00:03, 308.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46836/47780 [01:10<00:03, 287.97 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46868/47780 [01:10<00:03, 277.17 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46908/47780 [01:10<00:02, 300.52 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46940/47780 [01:11<00:02, 300.12 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46972/47780 [01:11<00:02, 301.92 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47006/47780 [01:11<00:02, 304.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47042/47780 [01:11<00:02, 318.65 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47079/47780 [01:11<00:02, 331.91 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47115/47780 [01:11<00:02, 311.26 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47147/47780 [01:11<00:02, 299.55 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47178/47780 [01:11<00:02, 297.86 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47217/47780 [01:11<00:01, 314.04 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47252/47780 [01:12<00:01, 320.34 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47285/47780 [01:12<00:01, 300.18 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47316/47780 [01:12<00:01, 296.64 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47346/47780 [01:12<00:01, 289.18 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47380/47780 [01:12<00:01, 301.32 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47412/47780 [01:12<00:01, 277.20 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47442/47780 [01:12<00:01, 248.88 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47468/47780 [01:12<00:01, 227.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47492/47780 [01:13<00:01, 196.50 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47513/47780 [01:13<00:01, 191.84 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47534/47780 [01:13<00:01, 192.90 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47556/47780 [01:13<00:01, 188.82 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47579/47780 [01:13<00:01, 189.80 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47600/47780 [01:13<00:01, 165.51 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47619/47780 [01:13<00:00, 162.63 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47637/47780 [01:14<00:01, 141.66 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47652/47780 [01:14<00:01, 121.13 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47666/47780 [01:14<00:00, 117.62 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47679/47780 [01:14<00:00, 118.01 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47697/47780 [01:14<00:00, 126.34 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47710/47780 [01:14<00:00, 116.53 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47722/47780 [01:14<00:00, 112.08 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47735/47780 [01:15<00:00, 89.06 examples/s] 
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47746/47780 [01:15<00:00, 80.73 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47756/47780 [01:15<00:00, 68.78 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47764/47780 [01:15<00:00, 56.42 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47771/47780 [01:15<00:00, 54.46 examples/s]
[36m(head, rank=0, pid=3864)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47777/47780 [01:16<00:00, 47.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [01:19<00:00, 601.01 examples/s]
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3864)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:15<12:08, 64.20 examples/s]
[36m(head, rank=0, pid=3864)[0m Truncating train dataset (num_proc=32):   6%|â–‹         | 3000/47780 [00:15<03:02, 245.37 examples/s]
[36m(head, rank=0, pid=3864)[0m Truncating train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18494/47780 [00:15<00:13, 2226.61 examples/s]
[36m(head, rank=0, pid=3864)[0m Truncating train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39891/47780 [00:15<00:01, 6020.49 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:22<00:00, 2104.42 examples/s]
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,200] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3864)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,851] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,860] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,878] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,906] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,906] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,910] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:09,927] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:29:10,  2.96 examples/s]
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 07:44:11,542] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<4:45:48,  2.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:22:28,  9.65 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 11/47780 [00:02<2:35:55,  5.11 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:21:21,  2.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:29:00,  2.42 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:02<6:47:59,  1.95 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:40:28,  2.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:42:43,  2.32 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 45/47780 [00:02<33:55, 23.45 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 34/47780 [00:02<43:42, 18.21 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:02<1:56:43,  6.82 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 11/47780 [00:02<3:07:53,  4.24 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 32/47780 [00:02<57:02, 13.95 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 23/47780 [00:02<1:22:59,  9.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:03<1:21:32,  9.76 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 81/47780 [00:03<19:24, 40.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 67/47780 [00:03<22:11, 35.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 40/47780 [00:03<43:17, 18.38 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 55/47780 [00:03<33:11, 23.97 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 66/47780 [00:03<28:33, 27.85 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 39/47780 [00:03<47:11, 16.86 examples/s]  
Tokenizing train dataset (num_proc=32):   0%|          | 51/47780 [00:03<37:24, 21.26 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 152/47780 [00:03<10:07, 78.45 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 70/47780 [00:03<22:08, 35.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 116/47780 [00:03<13:41, 58.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 72/47780 [00:03<24:23, 32.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 131/47780 [00:03<13:43, 57.85 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 96/47780 [00:03<19:18, 41.15 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 219/47780 [00:03<07:38, 103.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 92/47780 [00:03<20:44, 38.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 85/47780 [00:03<21:38, 36.74 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 196/47780 [00:04<08:34, 92.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 124/47780 [00:04<14:07, 56.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 162/47780 [00:04<11:39, 68.09 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 135/47780 [00:04<13:34, 58.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 201/47780 [00:04<10:20, 76.64 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 294/47780 [00:04<07:04, 111.81 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 211/47780 [00:04<06:40, 118.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 203/47780 [00:04<08:48, 90.04 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 294/47780 [00:04<06:24, 123.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 182/47780 [00:04<11:05, 71.51 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 248/47780 [00:04<07:03, 112.29 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 240/47780 [00:04<09:00, 88.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 417/47780 [00:04<04:53, 161.56 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 276/47780 [00:04<07:02, 112.41 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 281/47780 [00:04<07:15, 109.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 314/47780 [00:05<07:04, 111.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 401/47780 [00:05<05:28, 144.36 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 461/47780 [00:05<04:46, 165.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 328/47780 [00:05<07:30, 105.43 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 536/47780 [00:05<04:37, 170.04 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 280/47780 [00:05<09:28, 83.58 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 372/47780 [00:05<06:10, 128.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 351/47780 [00:05<07:16, 108.59 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 388/47780 [00:05<04:42, 167.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 596/47780 [00:05<03:51, 204.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 599/47780 [00:06<04:19, 181.78 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 742/47780 [00:06<03:30, 223.84 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 572/47780 [00:06<04:03, 194.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 448/47780 [00:06<06:02, 130.74 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 429/47780 [00:06<06:19, 124.78 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 515/47780 [00:06<05:04, 155.26 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 606/47780 [00:06<03:28, 225.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 823/47780 [00:06<02:59, 261.39 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 515/47780 [00:06<04:08, 190.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 692/47780 [00:06<03:00, 261.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 769/47780 [00:06<03:30, 223.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 768/47780 [00:06<03:24, 230.27 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 925/47780 [00:06<03:16, 238.06 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 660/47780 [00:06<04:24, 178.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 975/47780 [00:07<03:01, 257.79 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 754/47780 [00:06<03:46, 207.65 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 796/47780 [00:06<02:53, 271.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 561/47780 [00:07<05:43, 137.31 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 897/47780 [00:07<02:33, 305.34 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 913/47780 [00:07<03:10, 245.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|â–         | 709/47780 [00:07<03:02, 257.98 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 862/47780 [00:07<03:21, 233.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1140/47780 [00:07<02:49, 275.62 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 946/47780 [00:07<03:12, 243.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 940/47780 [00:07<02:43, 285.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1143/47780 [00:07<02:59, 260.31 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1043/47780 [00:07<03:24, 228.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 774/47780 [00:07<04:11, 187.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1239/47780 [00:07<02:13, 349.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 895/47780 [00:07<02:48, 278.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 973/47780 [00:07<03:50, 202.70 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1107/47780 [00:08<02:40, 289.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1001/47780 [00:08<03:42, 210.47 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1107/47780 [00:08<03:12, 242.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1314/47780 [00:08<02:54, 266.29 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1321/47780 [00:08<02:58, 260.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1300/47780 [00:08<02:12, 350.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1315/47780 [00:08<02:56, 263.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 964/47780 [00:08<03:55, 198.87 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1081/47780 [00:08<02:42, 287.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1183/47780 [00:08<03:40, 211.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1322/47780 [00:08<02:30, 307.78 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1071/47780 [00:08<05:07, 151.72 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1502/47780 [00:08<02:50, 271.10 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1372/47780 [00:08<02:55, 264.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1504/47780 [00:08<02:55, 263.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1717/47780 [00:09<02:02, 375.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1438/47780 [00:09<03:18, 233.23 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1638/47780 [00:09<02:07, 362.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   2%|â–         | 1152/47780 [00:09<03:50, 202.21 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1403/47780 [00:09<03:16, 235.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1253/47780 [00:09<02:49, 275.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1479/47780 [00:09<02:45, 280.24 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1484/47780 [00:09<03:22, 229.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1683/47780 [00:09<02:52, 267.16 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1664/47780 [00:09<02:15, 340.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1879/47780 [00:09<02:04, 367.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1277/47780 [00:09<04:15, 181.84 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1729/47780 [00:09<02:46, 277.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1325/47780 [00:09<03:52, 200.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1544/47780 [00:10<03:45, 205.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1687/47780 [00:10<02:25, 315.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1796/47780 [00:10<03:56, 194.53 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1878/47780 [00:10<03:02, 251.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1946/47780 [00:10<03:11, 239.80 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2215/47780 [00:10<01:53, 401.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2123/47780 [00:10<01:51, 410.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1363/47780 [00:10<05:57, 129.71 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1634/47780 [00:10<02:33, 301.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1759/47780 [00:10<03:40, 208.43 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1748/47780 [00:10<04:14, 180.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1919/47780 [00:11<02:19, 328.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1936/47780 [00:11<02:45, 276.64 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1320/47780 [00:11<07:03, 109.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2167/47780 [00:11<02:43, 279.59 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1368/47780 [00:11<06:00, 128.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2416/47780 [00:11<01:55, 391.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2230/47780 [00:11<02:31, 300.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2351/47780 [00:11<02:02, 369.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2028/47780 [00:11<03:17, 231.25 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1735/47780 [00:11<03:34, 214.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2137/47780 [00:11<02:36, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1746/47780 [00:12<02:59, 256.45 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2518/47780 [00:12<02:30, 300.79 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2441/47780 [00:12<02:45, 273.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2330/47780 [00:12<03:34, 211.72 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 1999/47780 [00:12<01:55, 396.50 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2562/47780 [00:12<02:08, 352.96 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2667/47780 [00:12<02:01, 371.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 2004/47780 [00:12<04:18, 176.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2330/47780 [00:12<01:58, 382.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1850/47780 [00:12<04:18, 177.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   4%|â–         | 1905/47780 [00:12<03:50, 198.64 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 2103/47780 [00:12<02:34, 296.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2216/47780 [00:12<04:21, 173.92 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2227/47780 [00:13<02:05, 363.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2636/47780 [00:13<01:45, 429.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2416/47780 [00:13<04:33, 165.83 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2808/47780 [00:13<02:09, 348.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2758/47780 [00:13<03:14, 231.13 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2465/47780 [00:13<02:55, 258.94 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3053/47780 [00:13<01:32, 484.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3040/47780 [00:13<01:54, 389.66 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2800/47780 [00:13<01:44, 431.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2630/47780 [00:13<02:10, 347.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2746/47780 [00:13<02:06, 356.30 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 2014/47780 [00:13<04:56, 154.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2839/47780 [00:13<01:55, 390.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–         | 2370/47780 [00:13<02:06, 357.65 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2928/47780 [00:14<03:13, 231.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3170/47780 [00:14<03:24, 217.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3290/47780 [00:14<01:47, 413.69 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2922/47780 [00:15<03:42, 201.90 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3238/47780 [00:15<02:55, 253.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3265/47780 [00:15<03:01, 244.93 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2318/47780 [00:15<05:14, 144.66 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3197/47780 [00:15<01:58, 376.76 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3639/47780 [00:15<01:33, 473.82 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3449/47780 [00:15<02:09, 343.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2544/47780 [00:15<03:03, 245.96 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2824/47780 [00:15<02:04, 361.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2977/47780 [00:15<01:34, 474.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3222/47780 [00:15<01:12, 613.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2645/47780 [00:15<08:32, 88.14 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 2999/47780 [00:15<03:43, 200.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3337/47780 [00:15<02:10, 341.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3453/47780 [00:15<02:20, 316.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3633/47780 [00:16<01:48, 405.90 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3807/47780 [00:16<02:45, 266.16 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3320/47780 [00:16<03:39, 202.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3601/47780 [00:16<03:20, 220.63 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4148/47780 [00:16<01:40, 434.07 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3425/47780 [00:16<02:08, 344.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3910/47780 [00:16<02:04, 353.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3665/47780 [00:16<01:35, 463.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3770/47780 [00:17<02:52, 255.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4062/47780 [00:17<01:47, 407.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3540/47780 [00:17<03:21, 219.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3685/47780 [00:17<02:44, 267.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3409/47780 [00:17<04:50, 152.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4336/47780 [00:17<02:17, 315.55 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3744/47780 [00:17<02:25, 302.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4547/47780 [00:18<01:44, 414.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 4037/47780 [00:18<01:34, 465.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   6%|â–‹         | 3016/47780 [00:18<04:21, 171.43 examples/s]
Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3465/47780 [00:18<02:25, 305.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4079/47780 [00:18<03:08, 232.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4508/47780 [00:18<01:44, 415.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3837/47780 [00:18<02:46, 264.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4119/47780 [00:18<01:52, 387.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4219/47780 [00:18<02:57, 245.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4541/47780 [00:18<01:49, 394.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3834/47780 [00:19<03:33, 205.90 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4710/47780 [00:19<01:35, 449.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4092/47780 [00:19<02:18, 314.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4853/47780 [00:19<01:40, 428.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4702/47780 [00:19<03:07, 230.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5065/47780 [00:19<01:50, 384.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4964/47780 [00:19<01:41, 420.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4721/47780 [00:20<02:35, 276.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4983/47780 [00:20<01:52, 379.12 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3702/47780 [00:20<03:19, 220.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4220/47780 [00:20<03:25, 211.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4439/47780 [00:20<02:27, 292.95 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3864/47780 [00:20<02:49, 259.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4642/47780 [00:20<01:51, 387.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5234/47780 [00:20<02:29, 284.77 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4345/47780 [00:21<03:35, 201.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5055/47780 [00:21<03:32, 201.49 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4577/47780 [00:21<02:34, 280.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5507/47780 [00:21<01:35, 441.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4280/47780 [00:21<04:21, 166.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4495/47780 [00:21<03:09, 228.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5167/47780 [00:21<02:56, 241.77 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5340/47780 [00:21<02:19, 303.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4180/47780 [00:21<03:00, 241.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4416/47780 [00:21<02:14, 321.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5392/47780 [00:22<03:11, 221.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5762/47780 [00:22<01:51, 375.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4639/47780 [00:22<03:34, 201.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4767/47780 [00:22<02:54, 246.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4810/47780 [00:22<04:05, 175.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5050/47780 [00:23<02:46, 256.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5325/47780 [00:23<01:52, 375.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4718/47780 [00:23<04:08, 173.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5044/47780 [00:23<02:30, 283.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4872/47780 [00:23<03:36, 198.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5422/47780 [00:23<01:28, 476.71 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5483/47780 [00:24<04:08, 170.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4560/47780 [00:24<03:49, 188.51 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5740/47780 [00:24<02:44, 256.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5055/47780 [00:24<02:00, 355.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆâ–        | 5377/47780 [00:24<01:26, 487.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5641/47780 [00:24<01:56, 360.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5500/47780 [00:24<03:02, 231.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5853/47780 [00:24<01:51, 377.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5680/47780 [00:25<04:58, 140.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6062/47780 [00:25<02:54, 239.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5210/47780 [00:25<03:55, 180.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5936/47780 [00:25<04:32, 153.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6299/47780 [00:25<02:46, 249.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5966/47780 [00:26<03:44, 186.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6362/47780 [00:26<02:09, 320.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5614/47780 [00:26<02:38, 265.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6045/47780 [00:26<03:10, 219.18 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6262/47780 [00:27<02:21, 293.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5855/47780 [00:27<03:26, 203.15 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6162/47780 [00:27<02:17, 302.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6554/47780 [00:27<02:33, 269.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6867/47780 [00:27<01:43, 395.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5329/47780 [00:27<05:25, 130.22 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6257/47780 [00:27<04:01, 171.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5685/47780 [00:27<03:03, 229.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6526/47780 [00:27<02:48, 244.54 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5783/47780 [00:27<03:14, 215.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6486/47780 [00:27<03:49, 179.55 examples/s]
Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6183/47780 [00:27<01:59, 349.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6782/47780 [00:27<02:35, 264.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7247/47780 [00:28<01:30, 445.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7507/47780 [00:28<01:21, 494.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7052/47780 [00:28<02:12, 308.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6421/47780 [00:28<03:23, 203.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6429/47780 [00:28<02:54, 236.99 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6593/47780 [00:28<02:22, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7710/47780 [00:29<01:32, 435.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5848/47780 [00:29<03:46, 185.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7862/47780 [00:29<01:41, 394.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6389/47780 [00:29<02:56, 235.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6707/47780 [00:29<02:00, 341.09 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6933/47780 [00:29<01:34, 434.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7977/47780 [00:30<01:48, 367.59 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6701/47780 [00:30<04:27, 153.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8066/47780 [00:30<01:51, 356.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6917/47780 [00:30<03:14, 209.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7205/47780 [00:30<02:10, 311.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8138/47780 [00:30<01:55, 343.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8197/47780 [00:30<01:58, 333.71 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5966/47780 [00:30<05:03, 137.65 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7138/47780 [00:30<01:56, 347.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8247/47780 [00:30<02:03, 319.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6168/47780 [00:30<03:33, 195.02 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6580/47780 [00:31<01:54, 359.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8290/47780 [00:31<02:09, 304.52 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7001/47780 [00:31<01:10, 576.42 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6727/47780 [00:31<04:05, 167.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8328/47780 [00:31<02:08, 308.18 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7267/47780 [00:31<00:55, 728.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8364/47780 [00:31<02:06, 310.38 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7721/47780 [00:31<00:36, 1092.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7187/47780 [00:31<04:40, 144.88 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8399/47780 [00:31<02:16, 287.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7533/47780 [00:31<02:47, 239.96 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6539/47780 [00:31<06:02, 113.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7739/47780 [00:31<02:08, 311.61 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8430/47780 [00:31<02:35, 252.92 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 6977/47780 [00:31<03:00, 225.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7948/47780 [00:31<01:38, 404.54 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8460/47780 [00:31<02:31, 259.93 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8038/47780 [00:31<00:42, 941.04 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7290/47780 [00:31<02:25, 277.75 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8488/47780 [00:31<02:28, 264.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7451/47780 [00:31<01:56, 346.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8516/47780 [00:32<02:31, 258.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8545/47780 [00:32<02:28, 263.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8572/47780 [00:32<02:32, 257.25 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8133/47780 [00:32<01:46, 373.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8599/47780 [00:32<02:39, 245.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8624/47780 [00:32<02:58, 218.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8661/47780 [00:32<02:37, 249.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8281/47780 [00:32<01:03, 621.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8687/47780 [00:32<02:41, 241.92 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8272/47780 [00:32<01:52, 351.59 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7576/47780 [00:32<02:30, 267.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8712/47780 [00:32<02:45, 236.63 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7703/47780 [00:32<02:02, 327.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8736/47780 [00:32<02:46, 234.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8760/47780 [00:33<02:50, 229.02 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7392/47780 [00:33<03:59, 168.53 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8784/47780 [00:33<02:57, 219.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8378/47780 [00:33<01:59, 331.04 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7668/47780 [00:33<02:41, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7168/47780 [00:33<03:35, 188.43 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8807/47780 [00:33<02:55, 222.41 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8460/47780 [00:33<01:18, 501.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7805/47780 [00:33<02:08, 310.39 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7641/47780 [00:33<01:59, 336.77 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8115/47780 [00:33<01:33, 423.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8834/47780 [00:33<02:45, 235.56 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8411/47780 [00:33<01:09, 564.67 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8858/47780 [00:33<02:45, 234.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8460/47780 [00:33<02:02, 320.93 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8673/47780 [00:33<00:54, 715.44 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8882/47780 [00:33<03:00, 215.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7884/47780 [00:33<02:11, 302.42 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8974/47780 [00:33<00:41, 931.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8920/47780 [00:33<02:30, 258.44 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7094/47780 [00:33<04:22, 155.14 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8594/47780 [00:33<01:30, 434.98 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8526/47780 [00:33<02:10, 301.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8956/47780 [00:33<02:15, 286.50 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7948/47780 [00:33<02:14, 295.77 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9238/47780 [00:33<00:37, 1014.40 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7253/47780 [00:33<03:31, 191.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8987/47780 [00:33<02:24, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7532/47780 [00:33<02:22, 283.25 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8579/47780 [00:33<02:12, 295.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9023/47780 [00:34<02:11, 293.63 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8001/47780 [00:34<02:19, 285.06 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7915/47780 [00:34<01:27, 453.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8696/47780 [00:34<01:37, 402.45 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9055/47780 [00:34<02:14, 288.24 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8625/47780 [00:34<02:14, 290.15 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8325/47780 [00:34<00:57, 685.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8045/47780 [00:34<02:16, 290.19 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9085/47780 [00:34<02:27, 262.33 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8639/47780 [00:34<00:44, 886.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8665/47780 [00:34<02:17, 283.70 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9462/47780 [00:34<00:50, 766.25 examples/s] 
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8087/47780 [00:34<02:21, 281.41 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8776/47780 [00:34<01:40, 387.91 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9112/47780 [00:34<02:26, 263.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8701/47780 [00:34<02:19, 280.84 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9142/47780 [00:34<02:22, 271.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8123/47780 [00:34<02:30, 264.37 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8734/47780 [00:34<02:20, 277.08 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9170/47780 [00:34<02:20, 273.86 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8155/47780 [00:34<02:25, 271.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8847/47780 [00:34<01:47, 360.77 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8765/47780 [00:34<02:28, 261.90 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9198/47780 [00:34<02:36, 247.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8187/47780 [00:34<02:22, 276.91 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 2/47780 [00:34<230:17:02, 17.35s/ examples]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8807/47780 [00:34<02:14, 288.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9225/47780 [00:34<02:35, 248.33 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8901/47780 [00:34<01:55, 335.81 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8218/47780 [00:34<02:32, 260.05 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9255/47780 [00:34<02:28, 259.57 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9632/47780 [00:34<01:07, 567.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 24/47780 [00:34<13:50:38,  1.04s/ examples]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8840/47780 [00:34<02:23, 271.57 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8256/47780 [00:34<02:19, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8946/47780 [00:35<02:01, 319.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9282/47780 [00:35<02:34, 248.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8872/47780 [00:35<02:18, 279.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8291/47780 [00:35<02:14, 293.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8906/47780 [00:35<02:13, 291.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9308/47780 [00:35<02:43, 235.11 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8327/47780 [00:35<02:07, 309.80 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8985/47780 [00:35<02:07, 304.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8921/47780 [00:35<01:08, 571.02 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8937/47780 [00:35<02:15, 286.95 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9335/47780 [00:35<02:39, 240.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7872/47780 [00:35<02:54, 229.20 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8360/47780 [00:35<02:22, 277.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9020/47780 [00:35<02:13, 290.23 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8969/47780 [00:35<02:13, 290.01 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9360/47780 [00:35<02:39, 240.53 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8072/47780 [00:35<02:18, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9760/47780 [00:35<01:23, 456.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8390/47780 [00:35<02:25, 271.05 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9052/47780 [00:35<02:17, 282.24 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9388/47780 [00:35<02:34, 248.66 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8999/47780 [00:35<02:16, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8320/47780 [00:35<01:42, 385.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8432/47780 [00:35<02:08, 306.95 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9414/47780 [00:35<02:33, 249.22 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9082/47780 [00:35<02:22, 271.30 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9028/47780 [00:35<02:23, 270.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8592/47780 [00:35<01:14, 526.02 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8466/47780 [00:35<02:08, 305.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9444/47780 [00:35<02:29, 256.36 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9110/47780 [00:35<02:23, 268.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9056/47780 [00:35<02:30, 257.03 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8506/47780 [00:35<01:59, 327.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9861/47780 [00:35<01:31, 413.62 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9470/47780 [00:35<02:29, 255.79 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9139/47780 [00:35<02:21, 273.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9089/47780 [00:35<02:21, 273.43 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8553/47780 [00:35<01:48, 362.58 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9496/47780 [00:35<02:29, 256.72 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9169/47780 [00:35<02:20, 274.71 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9126/47780 [00:35<01:21, 475.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9118/47780 [00:35<02:25, 266.18 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9523/47780 [00:36<02:28, 258.06 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 43/47780 [00:35<6:48:36,  1.95 examples/s] 
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9198/47780 [00:35<02:18, 278.44 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8591/47780 [00:35<02:00, 324.27 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9145/47780 [00:36<02:24, 267.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9938/47780 [00:36<01:38, 385.74 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9553/47780 [00:36<02:24, 264.78 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8625/47780 [00:36<02:02, 320.72 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9227/47780 [00:36<02:25, 264.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 61/47780 [00:36<3:59:28,  3.32 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9172/47780 [00:36<02:36, 246.11 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9591/47780 [00:36<02:10, 292.45 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8664/47780 [00:36<01:57, 333.05 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9260/47780 [00:36<02:18, 278.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8805/47780 [00:36<01:23, 464.50 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9197/47780 [00:36<02:37, 245.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10002/47780 [00:36<01:44, 360.07 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9621/47780 [00:36<02:13, 285.68 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8707/47780 [00:36<01:49, 355.55 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9278/47780 [00:36<01:27, 439.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9289/47780 [00:36<02:28, 259.19 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9223/47780 [00:36<02:37, 245.23 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8748/47780 [00:36<01:46, 366.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9651/47780 [00:36<02:19, 273.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9317/47780 [00:36<02:26, 262.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10054/47780 [00:36<01:49, 343.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9248/47780 [00:36<02:53, 221.87 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9684/47780 [00:36<02:14, 283.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8787/47780 [00:36<01:48, 360.70 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9344/47780 [00:36<02:42, 236.01 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9275/47780 [00:36<02:49, 227.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9714/47780 [00:36<02:13, 285.20 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8824/47780 [00:36<01:59, 326.98 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10099/47780 [00:36<02:04, 302.76 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9370/47780 [00:36<02:45, 232.79 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9395/47780 [00:36<01:33, 410.48 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9299/47780 [00:36<02:50, 226.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9743/47780 [00:36<02:18, 274.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8860/47780 [00:36<01:57, 332.25 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10143/47780 [00:36<01:57, 319.82 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9394/47780 [00:36<02:48, 227.39 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9322/47780 [00:36<02:49, 227.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8967/47780 [00:36<01:36, 400.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9772/47780 [00:36<02:22, 266.57 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8894/47780 [00:36<02:06, 307.52 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9421/47780 [00:36<02:43, 234.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9356/47780 [00:36<02:30, 255.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10182/47780 [00:36<02:00, 312.93 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9800/47780 [00:37<02:28, 255.11 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8931/47780 [00:37<02:01, 320.65 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9087/47780 [00:37<01:29, 430.90 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9486/47780 [00:37<01:39, 385.15 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9453/47780 [00:37<02:30, 254.48 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9382/47780 [00:37<02:34, 248.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10219/47780 [00:37<02:02, 307.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9841/47780 [00:37<02:09, 292.13 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 72/47780 [00:37<3:13:50,  4.10 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9482/47780 [00:37<02:28, 258.66 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9417/47780 [00:37<02:18, 277.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8964/47780 [00:37<02:13, 291.19 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10253/47780 [00:37<02:01, 308.94 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9871/47780 [00:37<02:12, 286.72 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 113/47780 [00:37<1:20:50,  9.83 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9446/47780 [00:37<02:18, 277.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8994/47780 [00:37<02:16, 284.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10286/47780 [00:37<02:05, 298.09 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9559/47780 [00:37<01:46, 357.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9511/47780 [00:37<02:53, 221.12 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9900/47780 [00:37<02:21, 267.59 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9190/47780 [00:37<01:35, 402.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9482/47780 [00:37<02:09, 294.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9024/47780 [00:37<02:14, 288.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10319/47780 [00:37<02:04, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9559/47780 [00:37<02:14, 284.50 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9928/47780 [00:37<02:22, 265.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9512/47780 [00:37<02:19, 273.96 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9054/47780 [00:37<02:22, 271.63 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9618/47780 [00:37<01:51, 341.33 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10350/47780 [00:37<02:08, 291.17 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9590/47780 [00:37<02:18, 276.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9955/47780 [00:37<02:24, 261.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9543/47780 [00:37<02:17, 277.87 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9088/47780 [00:37<02:14, 287.29 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9272/47780 [00:37<01:40, 381.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9982/47780 [00:37<02:23, 263.59 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10380/47780 [00:37<02:16, 274.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9620/47780 [00:37<02:26, 260.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9572/47780 [00:37<02:15, 281.12 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9118/47780 [00:37<02:17, 281.39 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9668/47780 [00:37<01:58, 320.29 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10009/47780 [00:37<02:24, 262.08 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10415/47780 [00:37<02:08, 290.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9648/47780 [00:37<02:29, 254.45 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9601/47780 [00:37<02:22, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9147/47780 [00:37<02:19, 276.02 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9339/47780 [00:37<01:45, 364.68 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10041/47780 [00:37<02:16, 275.89 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10445/47780 [00:37<02:10, 287.00 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9710/47780 [00:37<02:01, 313.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9678/47780 [00:37<02:24, 262.86 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9175/47780 [00:37<02:23, 269.21 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9629/47780 [00:37<02:29, 255.13 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10070/47780 [00:38<02:19, 270.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10475/47780 [00:37<02:09, 287.36 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9395/47780 [00:38<01:47, 357.09 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9205/47780 [00:38<02:18, 277.66 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9705/47780 [00:38<02:42, 233.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9748/47780 [00:38<02:07, 297.83 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10099/47780 [00:38<02:19, 269.90 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10509/47780 [00:38<02:06, 295.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9655/47780 [00:38<02:52, 220.58 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9444/47780 [00:38<01:44, 368.25 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9234/47780 [00:38<02:18, 278.03 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9741/47780 [00:38<02:24, 263.06 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10131/47780 [00:38<02:12, 283.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10539/47780 [00:38<02:05, 296.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9782/47780 [00:38<02:13, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9678/47780 [00:38<03:06, 204.04 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9267/47780 [00:38<02:14, 286.37 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9769/47780 [00:38<02:26, 259.06 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9491/47780 [00:38<01:46, 358.49 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10569/47780 [00:38<02:08, 288.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10163/47780 [00:38<02:15, 278.46 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9735/47780 [00:38<02:10, 291.88 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9814/47780 [00:38<02:21, 267.99 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9297/47780 [00:38<02:17, 280.71 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9796/47780 [00:38<02:26, 259.46 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10598/47780 [00:38<02:10, 284.97 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10192/47780 [00:38<02:14, 278.74 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 134/47780 [00:38<1:10:05, 11.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9534/47780 [00:38<01:48, 351.64 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9845/47780 [00:38<02:19, 272.04 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9339/47780 [00:38<02:01, 316.42 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9767/47780 [00:38<02:25, 261.41 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10627/47780 [00:38<02:11, 282.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9823/47780 [00:38<02:41, 235.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10225/47780 [00:38<02:10, 286.78 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9574/47780 [00:38<01:54, 335.00 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9371/47780 [00:38<02:03, 310.02 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9796/47780 [00:38<02:22, 267.18 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9875/47780 [00:38<02:29, 253.43 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10658/47780 [00:38<02:09, 287.71 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9857/47780 [00:38<02:25, 261.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10261/47780 [00:38<02:01, 307.56 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9612/47780 [00:38<01:50, 343.89 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9903/47780 [00:38<02:26, 258.12 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10293/47780 [00:38<02:01, 307.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9403/47780 [00:38<02:20, 272.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9884/47780 [00:38<02:28, 255.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9825/47780 [00:38<02:29, 253.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10687/47780 [00:38<02:17, 269.71 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9649/47780 [00:38<01:54, 332.09 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9930/47780 [00:38<02:29, 253.81 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9446/47780 [00:38<02:02, 313.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10325/47780 [00:38<02:04, 300.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9852/47780 [00:38<02:31, 249.94 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10716/47780 [00:38<02:17, 269.29 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9911/47780 [00:38<02:38, 238.52 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9684/47780 [00:38<01:54, 333.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9956/47780 [00:38<02:32, 248.05 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10744/47780 [00:38<02:19, 266.21 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9479/47780 [00:38<02:10, 292.50 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10356/47780 [00:39<02:17, 271.71 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9878/47780 [00:39<02:42, 233.04 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9936/47780 [00:38<02:46, 227.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9720/47780 [00:38<01:54, 332.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9981/47780 [00:39<02:41, 234.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10775/47780 [00:39<02:14, 275.61 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9513/47780 [00:39<02:08, 298.94 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9912/47780 [00:39<02:26, 257.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9960/47780 [00:39<02:45, 228.15 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10384/47780 [00:39<02:26, 255.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9756/47780 [00:39<01:55, 330.08 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10005/47780 [00:39<02:41, 233.34 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9549/47780 [00:39<02:02, 312.02 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10803/47780 [00:39<02:19, 264.81 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9984/47780 [00:39<02:48, 224.10 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9794/47780 [00:39<01:50, 343.18 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10411/47780 [00:39<02:25, 256.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9939/47780 [00:39<02:40, 235.60 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9585/47780 [00:39<01:57, 325.05 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10030/47780 [00:39<02:47, 225.69 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10834/47780 [00:39<02:14, 274.43 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10009/47780 [00:39<02:45, 228.66 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10437/47780 [00:39<02:28, 251.68 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9976/47780 [00:39<02:21, 267.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9829/47780 [00:39<01:59, 316.88 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10056/47780 [00:39<02:44, 229.99 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9619/47780 [00:39<02:02, 311.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10863/47780 [00:39<02:16, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10037/47780 [00:39<02:40, 235.07 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10464/47780 [00:39<02:26, 254.16 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10004/47780 [00:39<02:23, 262.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9862/47780 [00:39<02:00, 314.16 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10089/47780 [00:39<02:28, 254.26 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10891/47780 [00:39<02:18, 266.49 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9651/47780 [00:39<02:09, 294.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10061/47780 [00:39<02:44, 228.89 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9894/47780 [00:39<02:00, 315.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10031/47780 [00:39<02:26, 258.09 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10490/47780 [00:39<02:45, 225.70 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10124/47780 [00:39<02:15, 277.65 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10924/47780 [00:39<02:11, 281.18 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9681/47780 [00:39<02:08, 295.66 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10086/47780 [00:39<02:40, 234.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10066/47780 [00:39<02:17, 275.03 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9926/47780 [00:39<02:04, 303.28 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10528/47780 [00:39<02:20, 265.74 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10153/47780 [00:39<02:15, 277.66 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9715/47780 [00:39<02:04, 305.09 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10953/47780 [00:39<02:15, 271.43 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10110/47780 [00:39<02:39, 235.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   0%|          | 202/47780 [00:39<38:14, 20.74 examples/s]  
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9961/47780 [00:39<02:02, 309.58 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10094/47780 [00:39<02:22, 264.45 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10557/47780 [00:39<02:18, 269.01 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10182/47780 [00:39<02:13, 281.14 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10981/47780 [00:39<02:17, 267.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10134/47780 [00:39<02:47, 224.28 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9746/47780 [00:39<02:20, 269.79 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 294/47780 [00:39<18:34, 42.60 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10589/47780 [00:39<02:14, 277.47 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9994/47780 [00:39<02:06, 298.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10121/47780 [00:39<02:31, 248.25 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10211/47780 [00:39<02:16, 274.53 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11008/47780 [00:39<02:18, 265.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10158/47780 [00:39<02:48, 223.86 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9780/47780 [00:39<02:14, 282.33 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10618/47780 [00:40<02:12, 279.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10029/47780 [00:39<02:03, 306.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10148/47780 [00:40<02:30, 250.55 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10241/47780 [00:39<02:13, 281.38 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11035/47780 [00:40<02:20, 260.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10183/47780 [00:40<02:44, 229.16 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10064/47780 [00:40<01:58, 318.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9809/47780 [00:40<02:23, 264.50 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10647/47780 [00:40<02:21, 262.85 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10175/47780 [00:40<02:28, 252.80 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10274/47780 [00:40<02:12, 282.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11069/47780 [00:40<02:10, 280.27 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10207/47780 [00:40<02:51, 219.30 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10674/47780 [00:40<02:21, 261.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10201/47780 [00:40<02:27, 254.76 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9837/47780 [00:40<02:27, 257.77 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10097/47780 [00:40<02:05, 300.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10309/47780 [00:40<02:09, 288.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11099/47780 [00:40<02:08, 285.48 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10234/47780 [00:40<02:44, 228.70 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10701/47780 [00:40<02:20, 263.75 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10227/47780 [00:40<02:31, 248.14 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9864/47780 [00:40<02:26, 258.28 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10128/47780 [00:40<02:05, 299.38 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10342/47780 [00:40<02:06, 297.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11128/47780 [00:40<02:15, 271.20 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10259/47780 [00:40<02:40, 234.25 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10161/47780 [00:40<02:03, 305.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10728/47780 [00:40<02:27, 251.32 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9891/47780 [00:40<02:29, 253.10 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10253/47780 [00:40<02:37, 237.99 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11156/47780 [00:40<02:16, 267.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10372/47780 [00:40<02:18, 269.89 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10283/47780 [00:40<02:40, 233.06 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10193/47780 [00:40<02:03, 304.73 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10758/47780 [00:40<02:22, 259.43 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10281/47780 [00:40<02:31, 246.89 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9917/47780 [00:40<02:37, 239.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11183/47780 [00:40<02:19, 261.94 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10401/47780 [00:40<02:19, 267.16 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10307/47780 [00:40<02:41, 232.52 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10231/47780 [00:40<01:55, 324.03 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10312/47780 [00:40<02:21, 264.54 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10785/47780 [00:40<02:30, 245.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9942/47780 [00:40<02:44, 229.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11211/47780 [00:40<02:17, 265.07 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10429/47780 [00:40<02:28, 251.53 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10331/47780 [00:40<02:56, 212.69 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10341/47780 [00:40<02:19, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10264/47780 [00:40<01:59, 314.64 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10814/47780 [00:40<02:24, 255.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9966/47780 [00:40<02:46, 227.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11238/47780 [00:40<02:20, 260.23 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10374/47780 [00:40<02:17, 271.69 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10455/47780 [00:40<02:31, 246.02 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10372/47780 [00:40<02:14, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10305/47780 [00:40<01:53, 330.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10841/47780 [00:40<02:24, 256.42 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9996/47780 [00:40<02:36, 242.15 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11267/47780 [00:40<02:19, 261.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10480/47780 [00:40<02:36, 239.06 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10403/47780 [00:40<02:24, 259.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10400/47780 [00:41<02:16, 274.68 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10340/47780 [00:40<01:54, 328.18 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10874/47780 [00:41<02:14, 274.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10021/47780 [00:40<02:34, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11295/47780 [00:40<02:17, 264.87 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10507/47780 [00:41<02:31, 246.17 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10428/47780 [00:41<02:17, 272.61 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10382/47780 [00:41<01:46, 350.81 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10903/47780 [00:41<02:12, 278.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10430/47780 [00:41<02:37, 236.60 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10056/47780 [00:41<02:23, 262.40 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10532/47780 [00:41<02:31, 246.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11322/47780 [00:41<02:37, 231.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10456/47780 [00:41<02:23, 260.35 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10418/47780 [00:41<01:50, 338.52 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10931/47780 [00:41<02:20, 261.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10460/47780 [00:41<02:27, 253.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10083/47780 [00:41<02:27, 256.07 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10562/47780 [00:41<02:22, 261.16 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11370/47780 [00:41<02:04, 293.13 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10487/47780 [00:41<02:17, 271.35 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 323/47780 [00:41<22:24, 35.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10459/47780 [00:41<01:45, 353.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10487/47780 [00:41<02:32, 244.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10958/47780 [00:41<02:29, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10114/47780 [00:41<02:20, 267.98 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10591/47780 [00:41<02:19, 266.68 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11401/47780 [00:41<02:12, 274.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 408/47780 [00:41<12:52, 61.29 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10515/47780 [00:41<02:25, 256.34 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10495/47780 [00:41<01:53, 329.56 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10516/47780 [00:41<02:29, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10986/47780 [00:41<02:26, 250.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10144/47780 [00:41<02:15, 276.77 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10618/47780 [00:41<02:25, 255.55 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11431/47780 [00:41<02:13, 272.64 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10542/47780 [00:41<02:23, 259.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10529/47780 [00:41<01:53, 328.13 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10174/47780 [00:41<02:12, 283.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10544/47780 [00:41<02:26, 254.39 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11012/47780 [00:41<02:33, 239.82 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10650/47780 [00:41<02:17, 270.95 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11460/47780 [00:41<02:13, 271.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10569/47780 [00:41<02:26, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10563/47780 [00:41<01:55, 320.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10570/47780 [00:41<02:28, 250.40 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10203/47780 [00:41<02:17, 272.66 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11037/47780 [00:41<02:36, 234.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10678/47780 [00:41<02:16, 272.28 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11490/47780 [00:41<02:11, 276.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10595/47780 [00:41<02:30, 247.14 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10600/47780 [00:41<01:52, 331.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10597/47780 [00:41<02:25, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10233/47780 [00:41<02:17, 273.07 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11062/47780 [00:41<02:33, 238.99 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 447/47780 [00:41<11:45, 67.14 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10706/47780 [00:41<02:19, 266.26 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11520/47780 [00:41<02:08, 281.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10622/47780 [00:41<02:27, 251.26 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10635/47780 [00:41<01:55, 322.12 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10623/47780 [00:41<02:37, 235.67 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10734/47780 [00:41<02:17, 270.14 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11087/47780 [00:41<02:46, 219.95 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11549/47780 [00:41<02:09, 280.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10261/47780 [00:41<02:45, 227.24 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10648/47780 [00:41<02:31, 245.38 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10762/47780 [00:41<02:17, 270.13 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10647/47780 [00:41<02:43, 226.80 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 477/47780 [00:41<10:25, 75.58 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10668/47780 [00:41<02:07, 291.54 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11578/47780 [00:41<02:08, 281.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11112/47780 [00:42<02:59, 204.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10673/47780 [00:42<02:37, 235.59 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10297/47780 [00:42<02:46, 225.67 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10796/47780 [00:42<02:10, 283.88 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10670/47780 [00:42<02:49, 218.36 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10712/47780 [00:42<01:56, 317.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11607/47780 [00:42<02:08, 280.93 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10698/47780 [00:42<02:35, 237.94 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10351/47780 [00:42<02:05, 298.49 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11133/47780 [00:42<03:27, 176.80 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10830/47780 [00:42<02:05, 293.32 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10745/47780 [00:42<01:58, 313.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11636/47780 [00:42<02:13, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10693/47780 [00:42<03:12, 192.42 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10723/47780 [00:42<02:44, 225.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10385/47780 [00:42<02:04, 299.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10870/47780 [00:42<01:57, 313.14 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10788/47780 [00:42<01:50, 334.83 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11664/47780 [00:42<02:13, 270.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11152/47780 [00:42<03:46, 161.48 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10713/47780 [00:42<03:26, 179.54 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10746/47780 [00:42<02:43, 226.49 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10905/47780 [00:42<01:55, 320.65 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10417/47780 [00:42<02:10, 286.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10826/47780 [00:42<01:46, 347.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11692/47780 [00:42<02:17, 262.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11170/47780 [00:42<03:46, 161.37 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10759/47780 [00:42<02:31, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10776/47780 [00:42<02:36, 236.78 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10938/47780 [00:42<01:56, 315.45 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10447/47780 [00:42<02:19, 268.45 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11722/47780 [00:42<02:12, 272.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10862/47780 [00:42<01:54, 321.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11255/47780 [00:42<01:51, 326.83 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10785/47780 [00:42<02:28, 248.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10800/47780 [00:42<02:41, 229.62 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10970/47780 [00:42<02:02, 299.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10477/47780 [00:42<02:16, 273.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10895/47780 [00:42<01:55, 320.40 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11750/47780 [00:42<02:14, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11292/47780 [00:42<01:58, 308.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10811/47780 [00:42<02:29, 246.51 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10832/47780 [00:42<02:29, 246.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11001/47780 [00:42<02:05, 292.72 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11777/47780 [00:42<02:18, 259.83 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10932/47780 [00:42<01:55, 319.83 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10506/47780 [00:42<02:23, 258.92 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10841/47780 [00:42<02:27, 250.18 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10862/47780 [00:42<02:24, 256.09 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11327/47780 [00:42<02:07, 285.15 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11031/47780 [00:42<02:08, 285.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   1%|          | 503/47780 [00:42<13:38, 57.75 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11812/47780 [00:42<02:07, 282.11 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10539/47780 [00:42<02:14, 277.32 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10965/47780 [00:42<01:57, 312.46 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10875/47780 [00:42<02:17, 268.81 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10889/47780 [00:42<02:21, 259.89 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11358/47780 [00:43<02:08, 282.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11063/47780 [00:42<02:05, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11844/47780 [00:42<02:04, 288.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11003/47780 [00:42<01:51, 330.33 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10568/47780 [00:43<02:24, 258.37 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10916/47780 [00:43<02:21, 260.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10910/47780 [00:43<02:10, 281.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11100/47780 [00:43<01:58, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11388/47780 [00:43<02:14, 270.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11875/47780 [00:43<02:02, 292.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11039/47780 [00:43<01:54, 321.55 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10605/47780 [00:43<02:11, 281.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10939/47780 [00:43<02:15, 272.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10943/47780 [00:43<02:34, 238.67 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11132/47780 [00:43<02:06, 289.96 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11905/47780 [00:43<02:05, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11072/47780 [00:43<01:55, 318.44 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10638/47780 [00:43<02:06, 294.71 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11416/47780 [00:43<02:31, 239.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10967/47780 [00:43<02:21, 260.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10968/47780 [00:43<02:42, 226.20 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11935/47780 [00:43<02:05, 285.79 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11162/47780 [00:43<02:06, 289.46 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11106/47780 [00:43<01:53, 322.83 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10670/47780 [00:43<02:06, 294.31 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11460/47780 [00:43<02:06, 287.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11000/47780 [00:43<02:11, 278.69 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11200/47780 [00:43<01:57, 311.34 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10992/47780 [00:43<02:45, 222.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11141/47780 [00:43<01:52, 326.81 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11964/47780 [00:43<02:10, 274.52 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10700/47780 [00:43<02:07, 289.89 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11491/47780 [00:43<02:08, 282.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11036/47780 [00:43<02:04, 295.06 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11236/47780 [00:43<01:55, 317.18 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11019/47780 [00:43<02:41, 228.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11993/47780 [00:43<02:08, 278.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11175/47780 [00:43<01:56, 315.23 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10730/47780 [00:43<02:12, 280.51 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11527/47780 [00:43<02:02, 295.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11070/47780 [00:43<02:00, 305.54 examples/s]
Tokenizing train dataset (num_proc=32):   1%|          | 596/47780 [00:43<09:56, 79.05 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11044/47780 [00:43<02:38, 231.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12021/47780 [00:43<02:12, 270.02 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11268/47780 [00:43<02:01, 301.37 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11209/47780 [00:43<01:57, 312.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11566/47780 [00:43<01:54, 317.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10759/47780 [00:43<02:14, 276.27 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11101/47780 [00:43<02:02, 298.67 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 673/47780 [00:43<06:39, 117.97 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11074/47780 [00:43<02:28, 247.58 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12049/47780 [00:43<02:11, 272.42 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11241/47780 [00:43<01:57, 311.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11299/47780 [00:43<02:08, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10790/47780 [00:43<02:12, 280.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11599/47780 [00:43<01:59, 303.92 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11134/47780 [00:43<02:05, 290.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11099/47780 [00:43<02:29, 245.21 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12080/47780 [00:43<02:08, 277.33 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11273/47780 [00:43<02:04, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11333/47780 [00:43<02:08, 284.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10826/47780 [00:43<02:08, 286.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11631/47780 [00:43<02:00, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11127/47780 [00:43<02:25, 252.22 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12113/47780 [00:43<02:03, 289.14 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11164/47780 [00:43<02:21, 259.15 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11304/47780 [00:43<02:03, 295.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11363/47780 [00:43<02:10, 279.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11662/47780 [00:44<02:01, 298.43 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10855/47780 [00:44<02:15, 272.22 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12144/47780 [00:44<02:00, 294.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11194/47780 [00:44<02:17, 266.94 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11153/47780 [00:44<02:36, 233.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11336/47780 [00:44<02:03, 295.49 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11693/47780 [00:44<02:06, 285.97 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10883/47780 [00:44<02:20, 262.97 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11392/47780 [00:44<02:24, 252.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12174/47780 [00:44<02:04, 286.57 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11177/47780 [00:44<02:37, 232.69 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11222/47780 [00:44<02:22, 256.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11368/47780 [00:44<02:00, 302.26 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11421/47780 [00:44<02:21, 256.90 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11722/47780 [00:44<02:13, 269.32 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10910/47780 [00:44<02:31, 243.92 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12204/47780 [00:44<02:09, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11400/47780 [00:44<01:58, 307.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11249/47780 [00:44<02:23, 254.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11201/47780 [00:44<02:46, 220.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11448/47780 [00:44<02:21, 257.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11750/47780 [00:44<02:16, 263.83 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10935/47780 [00:44<02:34, 238.01 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12239/47780 [00:44<02:05, 283.25 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11433/47780 [00:44<01:58, 306.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11275/47780 [00:44<02:30, 242.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11224/47780 [00:44<03:00, 202.70 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11778/47780 [00:44<02:15, 265.23 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11486/47780 [00:44<02:10, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):   1%|â–         | 705/47780 [00:44<08:47, 89.30 examples/s] 
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10959/47780 [00:44<02:36, 236.01 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11470/47780 [00:44<01:51, 324.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12268/47780 [00:44<02:06, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11301/47780 [00:44<02:33, 237.53 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11247/47780 [00:44<02:58, 204.50 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11808/47780 [00:44<02:12, 271.94 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11515/47780 [00:44<02:11, 275.85 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 795/47780 [00:44<05:27, 143.53 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12298/47780 [00:44<02:05, 283.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11507/47780 [00:44<01:49, 330.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10983/47780 [00:44<02:47, 220.05 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11273/47780 [00:44<02:48, 216.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11325/47780 [00:44<02:43, 223.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11840/47780 [00:44<02:08, 279.14 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11550/47780 [00:44<02:03, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12328/47780 [00:44<02:04, 285.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11006/47780 [00:44<02:50, 215.27 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11541/47780 [00:44<01:53, 318.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11295/47780 [00:44<02:49, 214.81 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11349/47780 [00:44<02:43, 223.25 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11870/47780 [00:44<02:07, 281.87 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11584/47780 [00:44<01:59, 302.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12357/47780 [00:44<02:04, 283.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11034/47780 [00:44<02:39, 231.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11580/47780 [00:44<01:50, 327.66 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11317/47780 [00:44<02:54, 209.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11381/47780 [00:44<02:29, 244.06 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11616/47780 [00:44<02:04, 291.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11059/47780 [00:44<02:35, 236.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11899/47780 [00:44<02:23, 250.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12386/47780 [00:44<02:14, 263.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11617/47780 [00:44<01:50, 328.43 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11345/47780 [00:45<02:40, 226.52 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11406/47780 [00:44<02:32, 237.96 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11649/47780 [00:44<02:00, 299.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11090/47780 [00:45<02:22, 257.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11941/47780 [00:45<02:04, 288.67 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12413/47780 [00:45<02:14, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11656/47780 [00:45<01:45, 342.02 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11369/47780 [00:45<02:39, 227.73 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11430/47780 [00:45<02:32, 238.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11680/47780 [00:45<02:02, 294.65 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11117/47780 [00:45<02:28, 246.56 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12440/47780 [00:45<02:16, 259.18 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11696/47780 [00:45<01:41, 354.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11971/47780 [00:45<02:09, 276.86 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11392/47780 [00:45<02:41, 225.78 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11454/47780 [00:45<02:34, 235.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11710/47780 [00:45<02:05, 286.44 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11148/47780 [00:45<02:21, 258.52 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12476/47780 [00:45<02:04, 284.23 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12005/47780 [00:45<02:03, 290.61 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11418/47780 [00:45<02:37, 230.32 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11487/47780 [00:45<02:19, 260.30 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11732/47780 [00:45<01:53, 316.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11739/47780 [00:45<02:09, 278.10 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11177/47780 [00:45<02:17, 267.17 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12507/47780 [00:45<02:03, 285.52 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12035/47780 [00:45<02:04, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11448/47780 [00:45<02:28, 244.44 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11514/47780 [00:45<02:21, 257.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11773/47780 [00:45<01:46, 338.06 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11213/47780 [00:45<02:05, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12066/47780 [00:45<02:04, 287.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11768/47780 [00:45<02:21, 254.15 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12536/47780 [00:45<02:11, 268.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11473/47780 [00:45<02:31, 240.20 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11542/47780 [00:45<02:22, 254.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11808/47780 [00:45<01:47, 333.39 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11243/47780 [00:45<02:07, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12099/47780 [00:45<01:59, 298.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11804/47780 [00:45<02:09, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12565/47780 [00:45<02:12, 265.34 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11498/47780 [00:45<02:34, 235.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11568/47780 [00:45<02:24, 250.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11842/47780 [00:45<01:53, 316.99 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 838/47780 [00:45<08:38, 90.49 examples/s] 
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12131/47780 [00:45<01:58, 301.54 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11272/47780 [00:45<02:15, 269.07 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11833/47780 [00:45<02:14, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12592/47780 [00:45<02:14, 260.84 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11529/47780 [00:45<02:24, 250.87 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11875/47780 [00:45<01:54, 314.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11594/47780 [00:45<02:30, 239.72 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11304/47780 [00:45<02:10, 280.18 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11863/47780 [00:45<02:11, 273.20 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12624/47780 [00:45<02:06, 277.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12162/47780 [00:45<02:12, 269.80 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11556/47780 [00:45<02:21, 256.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11619/47780 [00:45<02:35, 232.42 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11907/47780 [00:45<02:07, 281.70 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11340/47780 [00:45<02:00, 302.33 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12652/47780 [00:45<02:15, 259.93 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11585/47780 [00:45<02:20, 258.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11892/47780 [00:45<02:20, 255.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11645/47780 [00:45<02:30, 239.93 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12190/47780 [00:46<02:24, 246.34 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11944/47780 [00:45<01:58, 301.51 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11372/47780 [00:45<02:04, 292.45 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11617/47780 [00:46<02:11, 274.92 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12680/47780 [00:46<02:15, 259.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11918/47780 [00:46<02:21, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11670/47780 [00:46<02:32, 237.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12217/47780 [00:46<02:22, 249.91 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11975/47780 [00:46<02:02, 291.32 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11405/47780 [00:46<02:02, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11650/47780 [00:46<02:05, 287.61 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12707/47780 [00:46<02:14, 260.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11944/47780 [00:46<02:21, 252.71 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12249/47780 [00:46<02:12, 268.48 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11694/47780 [00:46<02:35, 232.73 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12012/47780 [00:46<01:55, 309.16 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11436/47780 [00:46<02:03, 294.47 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11679/47780 [00:46<02:05, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12734/47780 [00:46<02:16, 256.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11972/47780 [00:46<02:20, 254.57 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11718/47780 [00:46<02:38, 227.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12277/47780 [00:46<02:22, 249.51 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12044/47780 [00:46<01:57, 305.04 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11466/47780 [00:46<02:08, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11709/47780 [00:46<02:10, 275.72 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12000/47780 [00:46<02:21, 253.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12760/47780 [00:46<02:22, 245.41 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11751/47780 [00:46<02:22, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12310/47780 [00:46<02:12, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12084/47780 [00:46<01:48, 328.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11497/47780 [00:46<02:04, 290.79 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 968/47780 [00:46<06:40, 116.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12029/47780 [00:46<02:15, 263.28 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12791/47780 [00:46<02:13, 261.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11739/47780 [00:46<02:11, 273.04 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11780/47780 [00:46<02:16, 263.69 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12338/47780 [00:46<02:14, 262.79 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12118/47780 [00:46<01:51, 320.71 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1106/47780 [00:46<04:03, 191.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12821/47780 [00:46<02:09, 269.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12060/47780 [00:46<02:11, 270.62 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11527/47780 [00:46<02:18, 260.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11808/47780 [00:46<02:15, 265.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11767/47780 [00:46<02:18, 260.38 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12371/47780 [00:46<02:07, 278.18 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12152/47780 [00:46<01:50, 322.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12853/47780 [00:46<02:02, 284.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12089/47780 [00:46<02:12, 270.08 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11554/47780 [00:46<02:19, 260.50 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11835/47780 [00:46<02:14, 266.68 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11796/47780 [00:46<02:14, 268.36 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12402/47780 [00:46<02:03, 287.05 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12189/47780 [00:46<01:47, 332.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12888/47780 [00:46<01:55, 302.19 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12118/47780 [00:46<02:12, 269.30 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11862/47780 [00:46<02:14, 267.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11590/47780 [00:46<02:09, 278.53 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11824/47780 [00:46<02:18, 259.98 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12432/47780 [00:46<02:16, 258.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12223/47780 [00:46<01:57, 303.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12919/47780 [00:46<01:58, 295.13 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11892/47780 [00:46<02:12, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11854/47780 [00:46<02:13, 268.29 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11619/47780 [00:46<02:16, 264.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12145/47780 [00:46<02:25, 244.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12259/47780 [00:46<01:55, 308.54 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12949/47780 [00:46<02:01, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11887/47780 [00:47<02:05, 285.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11920/47780 [00:47<02:15, 263.95 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12182/47780 [00:47<02:09, 274.21 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11646/47780 [00:47<02:20, 257.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12460/47780 [00:47<02:39, 221.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12295/47780 [00:47<01:51, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12980/47780 [00:47<02:00, 289.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11947/47780 [00:47<02:19, 256.44 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11916/47780 [00:47<02:12, 271.45 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12495/47780 [00:47<02:20, 250.61 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11678/47780 [00:47<02:12, 271.66 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12213/47780 [00:47<02:07, 279.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12333/47780 [00:47<01:46, 332.30 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13010/47780 [00:47<02:07, 272.34 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11980/47780 [00:47<02:11, 271.94 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11706/47780 [00:47<02:11, 273.65 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12544/47780 [00:47<01:54, 308.30 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11951/47780 [00:47<02:06, 283.84 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12242/47780 [00:47<02:19, 254.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12367/47780 [00:47<01:47, 330.70 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12010/47780 [00:47<02:07, 279.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13040/47780 [00:47<02:07, 272.69 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11980/47780 [00:47<02:05, 285.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12577/47780 [00:47<01:55, 305.26 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11734/47780 [00:47<02:18, 260.90 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12270/47780 [00:47<02:16, 260.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12404/47780 [00:47<01:43, 341.68 examples/s]
Tokenizing train dataset (num_proc=32):   2%|â–         | 1165/47780 [00:47<05:35, 139.12 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12041/47780 [00:47<02:04, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13069/47780 [00:47<02:07, 271.52 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12009/47780 [00:47<02:06, 283.79 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12610/47780 [00:47<01:53, 311.13 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12297/47780 [00:47<02:17, 257.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11761/47780 [00:47<02:27, 244.25 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12439/47780 [00:47<01:47, 329.11 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12072/47780 [00:47<02:05, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13097/47780 [00:47<02:12, 262.15 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12643/47780 [00:47<01:56, 301.32 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12038/47780 [00:47<02:14, 264.84 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11788/47780 [00:47<02:24, 249.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12325/47780 [00:47<02:18, 255.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12473/47780 [00:47<01:57, 301.41 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12101/47780 [00:47<02:13, 268.24 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13124/47780 [00:47<02:15, 255.63 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12066/47780 [00:47<02:16, 262.57 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12674/47780 [00:47<02:01, 289.05 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11818/47780 [00:47<02:19, 257.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12361/47780 [00:47<02:06, 281.09 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12515/47780 [00:47<01:46, 329.77 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12129/47780 [00:47<02:15, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13151/47780 [00:47<02:14, 257.01 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12093/47780 [00:47<02:17, 258.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12390/47780 [00:47<02:04, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12704/47780 [00:47<02:11, 266.31 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11844/47780 [00:47<02:34, 232.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12549/47780 [00:47<01:52, 312.03 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12156/47780 [00:47<02:17, 259.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12419/47780 [00:47<02:06, 278.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13177/47780 [00:47<02:26, 236.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12736/47780 [00:47<02:07, 274.73 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12120/47780 [00:47<02:33, 232.83 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11868/47780 [00:47<02:35, 231.12 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12593/47780 [00:47<01:42, 342.80 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12183/47780 [00:48<02:20, 253.58 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13208/47780 [00:47<02:19, 248.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12448/47780 [00:48<02:09, 273.08 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12764/47780 [00:48<02:09, 270.12 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12154/47780 [00:48<02:20, 253.61 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11892/47780 [00:48<02:35, 231.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12628/47780 [00:48<01:44, 337.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12209/47780 [00:48<02:27, 241.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12478/47780 [00:48<02:07, 277.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13237/47780 [00:48<02:14, 256.89 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12793/47780 [00:48<02:07, 275.43 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12182/47780 [00:48<02:18, 257.82 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11916/47780 [00:48<02:47, 214.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12665/47780 [00:48<01:42, 342.61 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12246/47780 [00:48<02:18, 257.37 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12506/47780 [00:48<02:15, 260.13 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12821/47780 [00:48<02:09, 270.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12214/47780 [00:48<02:12, 269.04 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11939/47780 [00:48<02:45, 216.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12701/47780 [00:48<01:41, 347.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13263/47780 [00:48<02:40, 214.95 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12278/47780 [00:48<02:10, 271.17 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12533/47780 [00:48<02:14, 262.71 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12849/47780 [00:48<02:15, 258.65 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11961/47780 [00:48<02:44, 217.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12242/47780 [00:48<02:21, 251.34 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12747/47780 [00:48<01:32, 379.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13313/47780 [00:48<02:00, 285.65 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12306/47780 [00:48<02:14, 264.50 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12877/47780 [00:48<02:14, 259.13 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11990/47780 [00:48<02:32, 235.16 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12561/47780 [00:48<02:25, 242.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12278/47780 [00:48<02:08, 275.69 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12786/47780 [00:48<01:33, 374.30 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1274/47780 [00:48<06:19, 122.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13344/47780 [00:48<02:02, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12337/47780 [00:48<02:11, 268.57 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12907/47780 [00:48<02:11, 264.60 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12017/47780 [00:48<02:27, 242.65 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12590/47780 [00:48<02:18, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12307/47780 [00:48<02:12, 267.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13377/47780 [00:48<01:58, 289.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1529/47780 [00:48<03:04, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12824/47780 [00:48<01:50, 317.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12364/47780 [00:48<02:13, 265.49 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12942/47780 [00:48<02:02, 285.37 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12042/47780 [00:48<02:27, 242.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12616/47780 [00:48<02:24, 243.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12335/47780 [00:48<02:19, 254.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13409/47780 [00:48<02:04, 276.99 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12858/47780 [00:48<01:49, 319.52 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12395/47780 [00:48<02:08, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12971/47780 [00:48<02:02, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12071/47780 [00:48<02:24, 247.22 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12641/47780 [00:48<02:29, 235.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12369/47780 [00:48<02:07, 277.51 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13438/47780 [00:48<02:10, 263.62 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12892/47780 [00:48<01:47, 323.63 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12427/47780 [00:48<02:04, 284.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13000/47780 [00:48<02:06, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12097/47780 [00:48<02:28, 239.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12668/47780 [00:48<02:24, 242.49 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12398/47780 [00:48<02:11, 269.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13466/47780 [00:48<02:13, 257.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12456/47780 [00:49<02:06, 278.95 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13028/47780 [00:49<02:05, 275.90 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12927/47780 [00:49<01:56, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12122/47780 [00:49<02:28, 240.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12696/47780 [00:49<02:18, 252.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12426/47780 [00:49<02:23, 247.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13493/47780 [00:49<02:15, 252.47 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12484/47780 [00:49<02:10, 270.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13056/47780 [00:49<02:06, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12965/47780 [00:49<01:49, 317.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12723/47780 [00:49<02:17, 254.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12147/47780 [00:49<02:31, 234.85 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12452/47780 [00:49<02:25, 243.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13530/47780 [00:49<02:04, 275.23 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12512/47780 [00:49<02:11, 268.84 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13084/47780 [00:49<02:08, 270.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13000/47780 [00:49<01:50, 315.63 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12749/47780 [00:49<02:16, 256.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12177/47780 [00:49<02:22, 250.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12477/47780 [00:49<02:27, 239.79 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12540/47780 [00:49<02:11, 267.58 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13120/47780 [00:49<01:58, 293.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13558/47780 [00:49<02:09, 265.02 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13040/47780 [00:49<01:43, 335.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12780/47780 [00:49<02:11, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12203/47780 [00:49<02:28, 239.31 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12502/47780 [00:49<02:31, 232.68 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13154/47780 [00:49<01:52, 306.60 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12567/47780 [00:49<02:13, 264.06 examples/s]
Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 1619/47780 [00:49<03:53, 197.54 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13585/47780 [00:49<02:09, 263.28 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13075/47780 [00:49<01:43, 335.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12807/47780 [00:49<02:12, 263.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12234/47780 [00:49<02:17, 258.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13185/47780 [00:49<01:55, 300.65 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12594/47780 [00:49<02:17, 256.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12526/47780 [00:49<02:36, 224.84 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13613/47780 [00:49<02:11, 259.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13110/47780 [00:49<01:46, 325.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12834/47780 [00:49<02:22, 245.80 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12261/47780 [00:49<02:18, 256.40 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13224/47780 [00:49<01:48, 319.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12629/47780 [00:49<02:06, 278.40 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12557/47780 [00:49<02:25, 241.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13644/47780 [00:49<02:07, 267.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13143/47780 [00:49<01:46, 325.58 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12288/47780 [00:49<02:16, 259.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12870/47780 [00:49<02:07, 274.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13672/47780 [00:49<02:05, 270.98 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13178/47780 [00:49<01:44, 329.59 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13256/47780 [00:49<01:54, 302.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12662/47780 [00:49<02:04, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12315/47780 [00:49<02:22, 249.09 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12898/47780 [00:49<02:14, 259.87 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12582/47780 [00:49<02:50, 206.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13287/47780 [00:49<01:55, 297.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13701/47780 [00:49<02:10, 261.53 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12691/47780 [00:49<02:16, 257.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12341/47780 [00:49<02:22, 249.07 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12929/47780 [00:49<02:08, 272.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12630/47780 [00:49<02:10, 268.82 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13212/47780 [00:49<02:08, 270.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13319/47780 [00:50<01:53, 303.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13737/47780 [00:49<01:59, 285.82 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12957/47780 [00:50<02:11, 265.24 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12367/47780 [00:50<02:27, 239.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12718/47780 [00:50<02:24, 242.42 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12659/47780 [00:50<02:12, 265.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13269/47780 [00:50<01:40, 342.21 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13767/47780 [00:50<02:06, 267.92 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13350/47780 [00:50<02:05, 274.88 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12993/47780 [00:50<02:03, 282.41 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12747/47780 [00:50<02:20, 249.32 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13306/47780 [00:50<01:38, 349.18 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12392/47780 [00:50<02:37, 224.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12687/47780 [00:50<02:25, 241.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13800/47780 [00:50<02:00, 282.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13023/47780 [00:50<02:01, 286.17 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13379/47780 [00:50<02:11, 261.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13346/47780 [00:50<01:34, 362.93 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12773/47780 [00:50<02:24, 241.86 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12419/47780 [00:50<02:31, 233.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12715/47780 [00:50<02:22, 246.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13829/47780 [00:50<02:00, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13053/47780 [00:50<02:00, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13408/47780 [00:50<02:10, 263.38 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13385/47780 [00:50<01:37, 354.07 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12447/47780 [00:50<02:27, 239.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12798/47780 [00:50<02:28, 236.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12741/47780 [00:50<02:26, 239.58 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13858/47780 [00:50<02:05, 271.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13083/47780 [00:50<02:00, 288.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13440/47780 [00:50<02:03, 278.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13425/47780 [00:50<01:34, 363.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12472/47780 [00:50<02:27, 239.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12823/47780 [00:50<02:28, 235.25 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12766/47780 [00:50<02:25, 240.27 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13115/47780 [00:50<01:56, 297.37 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13886/47780 [00:50<02:06, 267.77 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–Ž         | 1750/47780 [00:50<04:44, 161.95 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13469/47780 [00:50<02:10, 263.91 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13464/47780 [00:50<01:34, 364.19 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12497/47780 [00:50<02:28, 237.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12853/47780 [00:50<02:19, 250.26 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13146/47780 [00:50<01:57, 294.14 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12793/47780 [00:50<02:33, 228.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13914/47780 [00:50<02:08, 262.74 examples/s]
Tokenizing train dataset (num_proc=32):   4%|â–         | 2071/47780 [00:50<02:23, 319.34 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13501/47780 [00:50<02:02, 278.92 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13501/47780 [00:50<01:35, 359.43 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12523/47780 [00:50<02:28, 238.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12882/47780 [00:50<02:16, 255.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13176/47780 [00:50<01:57, 295.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12817/47780 [00:50<02:35, 224.48 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13941/47780 [00:50<02:09, 261.37 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13538/47780 [00:50<01:37, 351.49 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12910/47780 [00:50<02:14, 259.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13530/47780 [00:50<02:09, 264.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12547/47780 [00:50<02:34, 228.04 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13206/47780 [00:50<02:00, 286.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12842/47780 [00:50<02:40, 217.97 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13968/47780 [00:50<02:16, 247.47 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12937/47780 [00:50<02:12, 262.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13557/47780 [00:50<02:08, 265.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12580/47780 [00:50<02:20, 251.07 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13574/47780 [00:50<01:44, 327.97 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13235/47780 [00:50<02:04, 277.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13993/47780 [00:50<02:18, 244.44 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12964/47780 [00:50<02:12, 261.82 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12864/47780 [00:51<02:50, 204.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13608/47780 [00:51<01:43, 331.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13584/47780 [00:51<02:17, 248.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12606/47780 [00:51<02:28, 237.59 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13266/47780 [00:51<02:01, 284.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14019/47780 [00:51<02:18, 244.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12890/47780 [00:51<02:39, 219.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13651/47780 [00:51<01:36, 354.99 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13610/47780 [00:51<02:20, 243.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12991/47780 [00:51<02:28, 234.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12630/47780 [00:51<02:35, 225.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13311/47780 [00:51<01:43, 331.73 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12916/47780 [00:51<02:33, 227.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14044/47780 [00:51<02:27, 228.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13687/47780 [00:51<01:35, 355.53 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13638/47780 [00:51<02:14, 253.36 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13017/47780 [00:51<02:25, 239.69 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12661/47780 [00:51<02:22, 246.09 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13345/47780 [00:51<01:49, 315.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12941/47780 [00:51<02:30, 231.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13723/47780 [00:51<01:36, 352.91 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14074/47780 [00:51<02:20, 239.72 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13664/47780 [00:51<02:15, 252.39 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13043/47780 [00:51<02:23, 241.57 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12686/47780 [00:51<02:29, 235.06 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2202/47780 [00:51<02:47, 271.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13377/47780 [00:51<01:52, 306.64 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12965/47780 [00:51<02:35, 223.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13760/47780 [00:51<01:37, 349.79 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14103/47780 [00:51<02:18, 242.84 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13693/47780 [00:51<02:13, 254.38 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13068/47780 [00:51<02:39, 217.32 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12710/47780 [00:51<02:35, 225.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13408/47780 [00:51<01:55, 297.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12993/47780 [00:51<02:26, 236.77 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14132/47780 [00:51<02:14, 250.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13796/47780 [00:51<01:42, 330.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13728/47780 [00:51<02:07, 266.31 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13101/47780 [00:51<02:20, 246.77 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12733/47780 [00:51<02:39, 220.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13017/47780 [00:51<02:26, 237.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13438/47780 [00:51<02:01, 282.11 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14160/47780 [00:51<02:10, 258.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13830/47780 [00:51<01:44, 326.03 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13755/47780 [00:51<02:08, 264.46 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12756/47780 [00:51<02:42, 215.40 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13127/47780 [00:51<02:38, 219.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13041/47780 [00:51<02:29, 232.99 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13468/47780 [00:51<02:04, 275.16 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13863/47780 [00:51<01:43, 326.86 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14187/47780 [00:51<02:11, 256.42 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13782/47780 [00:51<02:16, 249.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12778/47780 [00:51<02:46, 209.70 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13066/47780 [00:51<02:30, 230.08 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13496/47780 [00:51<02:05, 273.41 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13896/47780 [00:51<01:46, 316.89 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14213/47780 [00:51<02:16, 245.80 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13152/47780 [00:51<02:54, 198.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13808/47780 [00:51<02:16, 249.41 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13096/47780 [00:51<02:19, 248.56 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13525/47780 [00:51<02:07, 269.31 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14241/47780 [00:51<02:11, 255.08 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13928/47780 [00:51<01:48, 310.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12800/47780 [00:51<03:10, 183.93 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13179/47780 [00:51<02:41, 213.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13838/47780 [00:52<02:11, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13557/47780 [00:52<02:00, 283.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14268/47780 [00:52<02:09, 259.22 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13964/47780 [00:52<01:45, 321.23 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12832/47780 [00:52<02:41, 216.56 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13121/47780 [00:52<02:36, 221.99 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–         | 2314/47780 [00:52<03:14, 234.01 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13866/47780 [00:52<02:08, 263.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13203/47780 [00:52<02:56, 196.34 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13587/47780 [00:52<02:02, 278.67 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12855/47780 [00:52<02:38, 220.07 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14295/47780 [00:52<02:11, 253.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14003/47780 [00:52<01:42, 329.60 examples/s]
Tokenizing train dataset (num_proc=32):   5%|â–Œ         | 2552/47780 [00:52<02:03, 366.05 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13902/47780 [00:52<01:58, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13144/47780 [00:52<02:42, 213.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13227/47780 [00:52<02:48, 205.33 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13623/47780 [00:52<01:54, 298.18 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12878/47780 [00:52<02:39, 218.62 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14329/47780 [00:52<02:01, 275.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14036/47780 [00:52<01:45, 318.90 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13167/47780 [00:52<02:39, 217.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13931/47780 [00:52<02:00, 280.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13255/47780 [00:52<02:35, 221.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14362/47780 [00:52<01:54, 290.86 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12901/47780 [00:52<02:37, 221.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13653/47780 [00:52<01:58, 288.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13191/47780 [00:52<02:36, 221.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14069/47780 [00:52<01:56, 289.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13278/47780 [00:52<02:35, 221.63 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13961/47780 [00:52<02:14, 251.34 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13687/47780 [00:52<01:54, 296.77 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14403/47780 [00:52<01:44, 318.08 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12924/47780 [00:52<02:44, 211.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13217/47780 [00:52<02:28, 232.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13307/47780 [00:52<02:24, 238.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14108/47780 [00:52<01:51, 300.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13987/47780 [00:52<02:14, 251.56 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14436/47780 [00:52<01:46, 314.29 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13718/47780 [00:52<01:59, 284.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12948/47780 [00:52<02:45, 210.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13241/47780 [00:52<02:42, 212.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14140/47780 [00:52<01:50, 305.66 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14013/47780 [00:52<02:16, 247.92 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13332/47780 [00:52<02:33, 224.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14475/47780 [00:52<01:39, 335.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13751/47780 [00:52<01:54, 297.04 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12978/47780 [00:52<02:28, 234.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13263/47780 [00:52<02:46, 207.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14174/47780 [00:52<01:47, 313.43 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13361/47780 [00:52<02:24, 238.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14039/47780 [00:52<02:23, 235.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14509/47780 [00:52<01:44, 318.84 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13782/47780 [00:52<01:58, 287.37 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13002/47780 [00:52<02:38, 219.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13287/47780 [00:52<02:41, 214.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13387/47780 [00:52<02:22, 241.02 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14206/47780 [00:52<01:55, 290.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14066/47780 [00:52<02:19, 242.30 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14542/47780 [00:52<01:45, 314.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13812/47780 [00:52<02:03, 275.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13309/47780 [00:53<02:40, 214.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13025/47780 [00:52<02:43, 212.88 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13412/47780 [00:53<02:23, 239.53 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14242/47780 [00:52<01:50, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14097/47780 [00:53<02:09, 260.78 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14578/47780 [00:53<01:43, 320.22 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13849/47780 [00:53<01:53, 298.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13048/47780 [00:53<02:41, 215.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13336/47780 [00:53<02:33, 224.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14274/47780 [00:53<01:49, 307.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13439/47780 [00:53<02:21, 242.62 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14129/47780 [00:53<02:03, 271.49 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14618/47780 [00:53<01:38, 334.98 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13880/47780 [00:53<01:57, 289.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13077/47780 [00:53<02:27, 235.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13363/47780 [00:53<02:25, 236.97 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14312/47780 [00:53<01:42, 327.66 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14161/47780 [00:53<01:57, 284.93 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13465/47780 [00:53<02:20, 243.38 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14652/47780 [00:53<01:46, 311.98 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13101/47780 [00:53<02:29, 231.76 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13388/47780 [00:53<02:24, 238.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13910/47780 [00:53<01:58, 285.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14346/47780 [00:53<01:42, 326.28 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13495/47780 [00:53<02:14, 255.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14191/47780 [00:53<02:03, 272.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13939/47780 [00:53<02:00, 280.37 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13128/47780 [00:53<02:30, 229.54 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14684/47780 [00:53<01:54, 288.91 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13412/47780 [00:53<02:40, 214.65 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14392/47780 [00:53<01:35, 349.91 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13529/47780 [00:53<02:03, 276.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14228/47780 [00:53<01:53, 296.87 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13971/47780 [00:53<01:57, 288.22 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13155/47780 [00:53<02:25, 238.11 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14714/47780 [00:53<01:58, 279.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13558/47780 [00:53<02:07, 267.57 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13434/47780 [00:53<02:55, 195.95 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14429/47780 [00:53<01:43, 322.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14258/47780 [00:53<02:00, 278.79 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14000/47780 [00:53<02:02, 276.17 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13179/47780 [00:53<02:33, 225.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14745/47780 [00:53<01:59, 276.29 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13585/47780 [00:53<02:12, 258.62 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13493/47780 [00:53<01:56, 295.40 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14292/47780 [00:53<01:54, 293.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14462/47780 [00:53<01:44, 319.56 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13202/47780 [00:53<02:34, 224.46 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14776/47780 [00:53<01:55, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14028/47780 [00:53<02:15, 249.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13525/47780 [00:53<02:01, 280.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14322/47780 [00:53<02:02, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13611/47780 [00:53<02:31, 224.96 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14495/47780 [00:53<01:55, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13226/47780 [00:53<02:36, 221.48 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14805/47780 [00:53<01:57, 280.44 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14054/47780 [00:53<02:20, 239.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13560/47780 [00:53<01:54, 299.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14352/47780 [00:53<02:01, 274.73 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14526/47780 [00:53<01:53, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13642/47780 [00:53<02:29, 227.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13249/47780 [00:53<02:35, 221.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14838/47780 [00:53<01:53, 291.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14081/47780 [00:53<02:18, 242.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14381/47780 [00:54<02:01, 275.97 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14556/47780 [00:54<01:56, 284.83 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13592/47780 [00:54<02:04, 274.94 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13667/47780 [00:54<02:27, 231.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14868/47780 [00:54<01:54, 286.73 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13272/47780 [00:54<02:48, 205.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14114/47780 [00:54<02:06, 265.94 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14413/47780 [00:54<01:56, 286.66 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14588/47780 [00:54<01:54, 289.07 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13621/47780 [00:54<02:07, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13693/47780 [00:54<02:28, 229.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14899/47780 [00:54<01:53, 289.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14142/47780 [00:54<02:08, 261.36 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13293/47780 [00:54<03:05, 186.40 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14442/47780 [00:54<02:01, 273.77 examples/s]
Tokenizing train dataset (num_proc=32):   6%|â–Œ         | 2672/47780 [00:54<04:28, 168.00 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13653/47780 [00:54<02:02, 278.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14620/47780 [00:54<02:00, 274.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13723/47780 [00:54<02:18, 245.34 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14928/47780 [00:54<01:55, 283.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14176/47780 [00:54<01:58, 283.19 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13313/47780 [00:54<03:16, 175.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14471/47780 [00:54<02:07, 260.76 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13682/47780 [00:54<02:02, 277.99 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13761/47780 [00:54<02:01, 279.19 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14958/47780 [00:54<01:54, 286.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14658/47780 [00:54<01:54, 288.62 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14205/47780 [00:54<02:13, 250.79 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13375/47780 [00:54<01:59, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14499/47780 [00:54<02:06, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13790/47780 [00:54<02:03, 275.96 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14988/47780 [00:54<01:53, 289.50 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13711/47780 [00:54<02:10, 261.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14689/47780 [00:54<01:57, 281.86 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14231/47780 [00:54<02:15, 248.04 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14526/47780 [00:54<02:05, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15022/47780 [00:54<01:47, 303.65 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13407/47780 [00:54<02:04, 275.08 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13738/47780 [00:54<02:14, 252.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14718/47780 [00:54<02:01, 272.43 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13818/47780 [00:54<02:24, 235.33 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14262/47780 [00:54<02:07, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14555/47780 [00:54<02:03, 269.23 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15053/47780 [00:54<01:52, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13437/47780 [00:54<02:09, 266.06 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13769/47780 [00:54<02:10, 260.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14746/47780 [00:54<02:01, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13848/47780 [00:54<02:16, 248.76 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14289/47780 [00:54<02:15, 246.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14583/47780 [00:54<02:10, 254.77 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13465/47780 [00:54<02:09, 264.23 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15083/47780 [00:54<01:57, 278.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13798/47780 [00:54<02:08, 265.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14774/47780 [00:54<02:03, 267.78 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13881/47780 [00:54<02:10, 259.24 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14609/47780 [00:54<02:09, 255.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13493/47780 [00:54<02:11, 259.87 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15112/47780 [00:54<02:00, 271.32 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14315/47780 [00:54<02:34, 216.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14803/47780 [00:54<02:02, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13825/47780 [00:55<02:22, 237.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13912/47780 [00:54<02:05, 268.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14638/47780 [00:55<02:07, 260.07 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14349/47780 [00:55<02:15, 247.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14846/47780 [00:55<01:46, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13522/47780 [00:55<02:20, 244.52 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13857/47780 [00:55<02:12, 256.57 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13941/47780 [00:55<02:05, 269.76 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14665/47780 [00:55<02:06, 262.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15140/47780 [00:55<02:23, 227.27 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14378/47780 [00:55<02:10, 255.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14878/47780 [00:55<01:47, 305.96 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13547/47780 [00:55<02:19, 245.90 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13884/47780 [00:55<02:13, 254.65 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13969/47780 [00:55<02:04, 272.56 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14705/47780 [00:55<01:53, 292.43 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15164/47780 [00:55<02:28, 219.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3185/47780 [00:55<02:41, 276.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14409/47780 [00:55<02:04, 267.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14909/47780 [00:55<01:49, 300.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13910/47780 [00:55<02:13, 252.92 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13997/47780 [00:55<02:08, 262.93 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13572/47780 [00:55<02:32, 225.05 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14736/47780 [00:55<01:54, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15193/47780 [00:55<02:20, 232.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):   7%|â–‹         | 3518/47780 [00:55<01:49, 405.59 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14438/47780 [00:55<02:05, 265.15 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14941/47780 [00:55<01:48, 302.25 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13936/47780 [00:55<02:18, 244.21 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13610/47780 [00:55<02:08, 265.39 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14025/47780 [00:55<02:13, 253.44 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14765/47780 [00:55<01:58, 278.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15258/47780 [00:55<01:35, 341.32 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14972/47780 [00:55<01:51, 294.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14467/47780 [00:55<02:07, 260.39 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13963/47780 [00:55<02:14, 251.28 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13639/47780 [00:55<02:08, 266.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15295/47780 [00:55<01:34, 345.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14794/47780 [00:55<02:02, 269.49 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14051/47780 [00:55<02:30, 223.51 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15007/47780 [00:55<01:45, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14495/47780 [00:55<02:06, 262.96 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13667/47780 [00:55<02:09, 264.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13989/47780 [00:55<02:23, 235.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14821/47780 [00:55<02:07, 258.56 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14085/47780 [00:55<02:13, 253.13 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15332/47780 [00:55<01:46, 305.11 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14522/47780 [00:55<02:11, 253.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15039/47780 [00:55<01:52, 291.91 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14019/47780 [00:55<02:16, 247.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13695/47780 [00:55<02:13, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14850/47780 [00:55<02:04, 264.29 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14114/47780 [00:55<02:08, 262.69 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14553/47780 [00:55<02:04, 266.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15365/47780 [00:55<01:50, 293.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15069/47780 [00:55<02:00, 270.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13721/47780 [00:55<02:13, 255.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14048/47780 [00:55<02:11, 256.53 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14143/47780 [00:55<02:05, 267.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14878/47780 [00:55<02:03, 265.72 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14582/47780 [00:55<02:02, 270.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15106/47780 [00:55<01:50, 294.39 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13747/47780 [00:55<02:12, 256.75 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14074/47780 [00:55<02:10, 257.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15396/47780 [00:55<01:58, 272.56 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14171/47780 [00:55<02:13, 251.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14905/47780 [00:56<02:13, 246.88 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14611/47780 [00:55<02:02, 271.23 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14106/47780 [00:56<02:05, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15136/47780 [00:56<01:53, 286.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13773/47780 [00:56<02:16, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15428/47780 [00:56<02:02, 263.06 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14201/47780 [00:56<02:07, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14639/47780 [00:56<02:01, 272.57 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14930/47780 [00:56<02:14, 245.11 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14133/47780 [00:56<02:05, 267.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15168/47780 [00:56<01:51, 292.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13800/47780 [00:56<02:16, 249.50 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15456/47780 [00:56<02:05, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14958/47780 [00:56<02:10, 252.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14674/47780 [00:56<01:52, 293.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14228/47780 [00:56<02:20, 239.47 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14160/47780 [00:56<02:07, 264.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15199/47780 [00:56<01:54, 284.67 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13826/47780 [00:56<02:33, 221.25 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14984/47780 [00:56<02:09, 253.43 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15483/47780 [00:56<02:06, 255.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14707/47780 [00:56<01:51, 297.54 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14190/47780 [00:56<02:02, 274.77 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15229/47780 [00:56<01:54, 285.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14253/47780 [00:56<02:31, 221.30 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13850/47780 [00:56<02:31, 223.84 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15512/47780 [00:56<02:04, 258.95 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14746/47780 [00:56<01:43, 320.53 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15010/47780 [00:56<02:13, 244.92 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14218/47780 [00:56<02:03, 272.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15264/47780 [00:56<01:48, 300.71 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14276/47780 [00:56<02:43, 204.36 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13873/47780 [00:56<02:35, 217.40 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14779/47780 [00:56<01:43, 319.60 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15035/47780 [00:56<02:14, 243.66 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15539/47780 [00:56<02:11, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14247/47780 [00:56<02:00, 277.78 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3669/47780 [00:56<02:34, 286.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15303/47780 [00:56<01:40, 322.84 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13905/47780 [00:56<02:18, 244.97 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14298/47780 [00:56<02:45, 202.27 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15062/47780 [00:56<02:13, 245.99 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14812/47780 [00:56<01:44, 315.26 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14276/47780 [00:56<01:59, 281.28 examples/s]
Tokenizing train dataset (num_proc=32):   8%|â–Š         | 3963/47780 [00:56<01:46, 411.40 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15564/47780 [00:56<02:20, 228.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15348/47780 [00:56<01:30, 358.55 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14319/47780 [00:56<02:48, 198.26 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13931/47780 [00:56<02:23, 235.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15087/47780 [00:56<02:16, 238.82 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14844/47780 [00:56<01:51, 295.89 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14305/47780 [00:56<02:04, 268.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15596/47780 [00:56<02:09, 248.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15385/47780 [00:56<01:43, 311.49 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14345/47780 [00:56<02:35, 214.37 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15122/47780 [00:56<02:01, 267.83 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13955/47780 [00:56<02:27, 229.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14875/47780 [00:56<01:50, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15627/47780 [00:56<02:05, 256.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14332/47780 [00:56<02:11, 254.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15429/47780 [00:56<01:34, 341.67 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14372/47780 [00:56<02:28, 224.80 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13981/47780 [00:56<02:23, 235.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14911/47780 [00:56<01:44, 314.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15150/47780 [00:57<02:10, 250.75 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14358/47780 [00:57<02:25, 230.29 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15653/47780 [00:57<02:20, 227.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15465/47780 [00:57<01:36, 335.66 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14006/47780 [00:57<02:24, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14943/47780 [00:57<01:48, 303.33 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14395/47780 [00:57<02:42, 205.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15181/47780 [00:57<02:02, 266.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15705/47780 [00:57<01:47, 299.45 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14396/47780 [00:57<02:07, 261.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15501/47780 [00:57<01:35, 338.71 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14033/47780 [00:57<02:22, 236.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15212/47780 [00:57<02:00, 269.87 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14974/47780 [00:57<01:59, 275.57 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14417/47780 [00:57<03:01, 184.27 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14424/47780 [00:57<02:06, 263.77 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15737/47780 [00:57<01:55, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14060/47780 [00:57<02:18, 242.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15537/47780 [00:57<01:42, 313.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15243/47780 [00:57<01:56, 278.17 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15003/47780 [00:57<02:02, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14437/47780 [00:57<02:59, 185.85 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14451/47780 [00:57<02:08, 259.82 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14089/47780 [00:57<02:14, 250.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15570/47780 [00:57<01:43, 311.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15278/47780 [00:57<01:50, 294.97 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15767/47780 [00:57<02:04, 256.95 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14492/47780 [00:57<01:59, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15031/47780 [00:57<02:05, 260.28 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14478/47780 [00:57<02:13, 248.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14123/47780 [00:57<02:07, 263.86 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15309/47780 [00:57<01:54, 283.20 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15825/47780 [00:57<01:36, 331.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15058/47780 [00:57<02:08, 254.44 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14522/47780 [00:57<02:06, 263.00 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14504/47780 [00:57<02:18, 241.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15602/47780 [00:57<02:12, 242.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14158/47780 [00:57<01:58, 284.57 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15860/47780 [00:57<01:35, 332.70 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15338/47780 [00:57<02:02, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15092/47780 [00:57<01:58, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14550/47780 [00:57<02:10, 255.29 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14532/47780 [00:57<02:17, 241.34 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14191/47780 [00:57<01:52, 297.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15676/47780 [00:57<01:31, 350.58 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15365/47780 [00:57<02:06, 256.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15122/47780 [00:57<01:56, 281.14 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15895/47780 [00:57<01:44, 304.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14584/47780 [00:57<01:59, 277.48 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14569/47780 [00:57<02:04, 267.55 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14223/47780 [00:57<02:01, 276.61 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15391/47780 [00:57<02:06, 255.27 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–Š         | 4127/47780 [00:57<02:31, 287.72 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15717/47780 [00:57<01:40, 318.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15151/47780 [00:57<02:07, 255.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14613/47780 [00:57<02:03, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14596/47780 [00:57<02:10, 254.07 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14252/47780 [00:57<02:03, 272.49 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15927/47780 [00:57<02:06, 251.53 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15420/47780 [00:58<02:02, 264.54 examples/s]
Tokenizing train dataset (num_proc=32):   9%|â–‰         | 4466/47780 [00:57<01:38, 441.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15760/47780 [00:57<01:35, 335.16 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15185/47780 [00:57<01:58, 275.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14641/47780 [00:58<02:06, 261.02 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14622/47780 [00:58<02:13, 247.94 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14280/47780 [00:58<02:02, 274.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15972/47780 [00:58<01:47, 294.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15447/47780 [00:58<02:10, 247.18 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15797/47780 [00:58<01:34, 336.69 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15218/47780 [00:58<01:54, 283.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14668/47780 [00:58<02:08, 257.84 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14311/47780 [00:58<01:58, 282.38 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14647/47780 [00:58<02:20, 235.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15833/47780 [00:58<01:35, 336.24 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15473/47780 [00:58<02:14, 240.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16005/47780 [00:58<02:02, 260.14 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14697/47780 [00:58<02:08, 258.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15247/47780 [00:58<02:05, 259.45 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14340/47780 [00:58<02:00, 278.01 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14675/47780 [00:58<02:17, 239.90 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15868/47780 [00:58<01:33, 339.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15505/47780 [00:58<02:04, 259.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16052/47780 [00:58<01:43, 305.91 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14724/47780 [00:58<02:10, 252.75 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15286/47780 [00:58<01:51, 291.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14371/47780 [00:58<02:01, 274.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14701/47780 [00:58<02:14, 245.12 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15907/47780 [00:58<01:30, 353.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15535/47780 [00:58<01:59, 270.23 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14750/47780 [00:58<02:14, 246.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16086/47780 [00:58<01:48, 291.18 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15316/47780 [00:58<01:54, 283.79 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14399/47780 [00:58<02:00, 276.21 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14727/47780 [00:58<02:18, 238.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15563/47780 [00:58<02:01, 264.10 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15944/47780 [00:58<01:39, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15348/47780 [00:58<01:51, 291.04 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14776/47780 [00:58<02:16, 242.61 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16119/47780 [00:58<01:49, 288.76 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14427/47780 [00:58<02:03, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14757/47780 [00:58<02:11, 250.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15590/47780 [00:58<02:06, 254.56 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15983/47780 [00:58<01:34, 337.37 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15383/47780 [00:58<01:45, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14801/47780 [00:58<02:14, 244.41 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16151/47780 [00:58<01:47, 293.72 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14459/47780 [00:58<02:00, 275.98 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14783/47780 [00:58<02:14, 244.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15627/47780 [00:58<01:52, 286.62 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16018/47780 [00:58<01:41, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15415/47780 [00:58<01:48, 297.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14827/47780 [00:58<02:21, 232.85 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14488/47780 [00:58<02:01, 273.80 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16182/47780 [00:58<01:57, 269.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14808/47780 [00:58<02:17, 240.55 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15657/47780 [00:58<01:58, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15446/47780 [00:58<01:48, 297.81 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16051/47780 [00:58<01:45, 299.67 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14851/47780 [00:58<02:23, 229.82 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14518/47780 [00:58<01:58, 280.96 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14838/47780 [00:58<02:09, 254.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16210/47780 [00:58<02:01, 260.24 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15686/47780 [00:59<01:58, 271.26 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14881/47780 [00:59<02:13, 246.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16083/47780 [00:58<01:46, 298.17 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15478/47780 [00:59<01:53, 284.29 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14547/47780 [00:59<02:01, 273.73 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14869/47780 [00:59<02:01, 270.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16240/47780 [00:59<01:56, 269.74 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15715/47780 [00:59<02:03, 258.92 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14909/47780 [00:59<02:08, 256.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16115/47780 [00:59<01:45, 301.39 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14576/47780 [00:59<02:00, 275.76 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15508/47780 [00:59<01:59, 270.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14898/47780 [00:59<02:04, 263.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16268/47780 [00:59<02:08, 245.76 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15750/47780 [00:59<01:54, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14938/47780 [00:59<02:04, 262.77 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16149/47780 [00:59<01:41, 310.35 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14604/47780 [00:59<02:05, 264.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15536/47780 [00:59<01:59, 270.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14939/47780 [00:59<01:48, 301.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16294/47780 [00:59<02:12, 237.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15780/47780 [00:59<01:59, 268.14 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16181/47780 [00:59<01:45, 300.93 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14965/47780 [00:59<02:12, 247.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14972/47780 [00:59<01:45, 309.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15564/47780 [00:59<02:03, 260.29 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14631/47780 [00:59<02:14, 246.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16323/47780 [00:59<02:07, 246.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15821/47780 [00:59<01:44, 306.55 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16213/47780 [00:59<01:43, 303.97 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14991/47780 [00:59<02:14, 243.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15600/47780 [00:59<01:52, 286.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15004/47780 [00:59<01:47, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14657/47780 [00:59<02:12, 250.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16350/47780 [00:59<02:07, 246.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16252/47780 [00:59<01:37, 324.62 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15853/47780 [00:59<01:49, 290.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15017/47780 [00:59<02:13, 245.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15040/47780 [00:59<01:41, 321.21 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14684/47780 [00:59<02:10, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15629/47780 [00:59<02:05, 255.36 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–‰         | 4639/47780 [00:59<02:45, 259.96 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16375/47780 [00:59<02:18, 226.01 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15883/47780 [00:59<01:52, 284.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16285/47780 [00:59<01:44, 301.21 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14710/47780 [00:59<02:11, 252.18 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15043/47780 [00:59<02:20, 233.52 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15073/47780 [00:59<01:45, 309.13 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15669/47780 [00:59<01:50, 290.65 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15912/47780 [00:59<01:51, 284.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16316/47780 [00:59<01:43, 303.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16409/47780 [00:59<02:06, 247.96 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14736/47780 [00:59<02:11, 251.55 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15071/47780 [00:59<02:14, 243.61 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15106/47780 [00:59<01:46, 307.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15699/47780 [00:59<01:53, 283.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16439/47780 [00:59<02:03, 253.72 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14762/47780 [00:59<02:10, 253.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16347/47780 [00:59<01:47, 292.04 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15941/47780 [00:59<02:00, 263.31 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15098/47780 [00:59<02:15, 241.92 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15137/47780 [00:59<01:50, 294.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15730/47780 [00:59<01:50, 290.25 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16384/47780 [00:59<01:40, 313.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16468/47780 [00:59<01:59, 262.58 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14791/47780 [00:59<02:06, 261.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15974/47780 [01:00<01:53, 281.10 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15123/47780 [01:00<02:21, 230.05 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15167/47780 [01:00<01:58, 275.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15760/47780 [01:00<01:58, 269.72 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16421/47780 [01:00<01:36, 326.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16500/47780 [01:00<01:53, 276.42 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14830/47780 [01:00<01:51, 295.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16003/47780 [01:00<01:56, 271.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15155/47780 [01:00<02:11, 249.04 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15201/47780 [01:00<01:53, 287.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15790/47780 [01:00<01:56, 274.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16531/47780 [01:00<01:50, 282.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14862/47780 [01:00<01:48, 302.34 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16454/47780 [01:00<01:40, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16031/47780 [01:00<01:57, 271.14 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15191/47780 [01:00<01:56, 279.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15233/47780 [01:00<01:49, 295.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15818/47780 [01:00<02:00, 264.70 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16561/47780 [01:00<01:52, 278.65 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16489/47780 [01:00<01:36, 323.17 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16062/47780 [01:00<01:53, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15220/47780 [01:00<01:59, 271.36 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14893/47780 [01:00<02:04, 264.38 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15263/47780 [01:00<01:52, 290.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15850/47780 [01:00<01:56, 273.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16590/47780 [01:00<01:52, 277.75 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16092/47780 [01:00<01:51, 284.72 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15248/47780 [01:00<01:59, 271.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14921/47780 [01:00<02:02, 267.96 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15295/47780 [01:00<01:49, 295.72 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16522/47780 [01:00<01:49, 285.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15882/47780 [01:00<01:52, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16620/47780 [01:00<01:50, 281.32 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16126/47780 [01:00<01:46, 297.32 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15276/47780 [01:00<02:01, 268.16 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14950/47780 [01:00<02:03, 266.02 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16572/47780 [01:00<01:31, 339.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15325/47780 [01:00<01:51, 290.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15911/47780 [01:00<01:58, 269.83 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16652/47780 [01:00<01:46, 292.16 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16156/47780 [01:00<01:49, 287.99 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14982/47780 [01:00<01:56, 280.89 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15304/47780 [01:00<02:00, 269.03 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16622/47780 [01:00<01:22, 378.96 examples/s]
Tokenizing train dataset (num_proc=32):  10%|â–ˆ         | 4819/47780 [01:00<03:06, 229.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15356/47780 [01:00<01:55, 279.91 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15941/47780 [01:00<01:55, 275.20 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16682/47780 [01:00<01:47, 287.95 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16185/47780 [01:00<01:53, 279.42 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15333/47780 [01:00<02:00, 268.86 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5149/47780 [01:00<01:57, 361.81 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15011/47780 [01:00<02:06, 259.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16662/47780 [01:00<01:28, 353.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15385/47780 [01:00<02:00, 267.87 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15969/47780 [01:00<01:57, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16723/47780 [01:00<01:37, 317.47 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16214/47780 [01:00<01:51, 281.85 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15038/47780 [01:00<02:04, 262.59 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15365/47780 [01:00<02:03, 261.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16699/47780 [01:00<01:30, 342.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15412/47780 [01:00<02:05, 257.20 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16001/47780 [01:00<01:52, 281.39 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16243/47780 [01:00<01:53, 277.17 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16755/47780 [01:00<01:45, 292.71 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15397/47780 [01:00<01:57, 275.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15066/47780 [01:00<02:09, 253.01 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16735/47780 [01:01<01:31, 340.35 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15438/47780 [01:01<02:08, 251.05 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16030/47780 [01:01<01:57, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16271/47780 [01:01<01:56, 269.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16787/47780 [01:01<01:49, 281.99 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15425/47780 [01:01<01:57, 276.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15092/47780 [01:01<02:10, 249.82 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15471/47780 [01:01<02:00, 268.42 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16770/47780 [01:01<01:35, 325.25 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16075/47780 [01:01<01:40, 314.59 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16819/47780 [01:01<01:49, 283.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16299/47780 [01:01<02:11, 239.93 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15118/47780 [01:01<02:13, 244.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16804/47780 [01:01<01:35, 325.79 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15453/47780 [01:01<02:10, 246.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16109/47780 [01:01<01:40, 315.01 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15498/47780 [01:01<02:09, 249.07 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16851/47780 [01:01<01:47, 286.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16326/47780 [01:01<02:08, 245.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16841/47780 [01:01<01:32, 334.06 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15143/47780 [01:01<02:18, 235.41 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15479/47780 [01:01<02:14, 239.95 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15524/47780 [01:01<02:09, 249.53 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16141/47780 [01:01<01:44, 302.58 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16880/47780 [01:01<01:48, 284.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16358/47780 [01:01<02:00, 259.83 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16878/47780 [01:01<01:30, 340.57 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15167/47780 [01:01<02:32, 213.26 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15504/47780 [01:01<02:22, 225.72 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16172/47780 [01:01<01:49, 288.71 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16909/47780 [01:01<01:50, 279.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15550/47780 [01:01<02:25, 220.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16385/47780 [01:01<02:06, 249.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16913/47780 [01:01<01:30, 339.40 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15193/47780 [01:01<02:24, 225.21 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15529/47780 [01:01<02:21, 227.58 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16204/47780 [01:01<01:49, 287.87 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15573/47780 [01:01<02:24, 223.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16938/47780 [01:01<01:50, 279.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16411/47780 [01:01<02:08, 243.70 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16948/47780 [01:01<01:34, 327.39 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15216/47780 [01:01<02:28, 219.27 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15556/47780 [01:01<02:17, 233.79 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16240/47780 [01:01<01:44, 302.43 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16971/47780 [01:01<01:47, 287.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15612/47780 [01:01<02:03, 259.42 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16437/47780 [01:01<02:07, 245.77 examples/s]
Tokenizing train dataset (num_proc=32):  11%|â–ˆ         | 5313/47780 [01:01<02:27, 287.76 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16987/47780 [01:01<01:30, 341.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15242/47780 [01:01<02:24, 225.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15584/47780 [01:01<02:16, 236.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16271/47780 [01:01<01:46, 296.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15639/47780 [01:01<02:07, 251.94 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16464/47780 [01:01<02:05, 249.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17027/47780 [01:01<01:26, 353.89 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5681/47780 [01:01<01:31, 460.69 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17000/47780 [01:01<02:12, 232.67 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15273/47780 [01:01<02:14, 241.15 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16301/47780 [01:01<01:47, 293.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15608/47780 [01:01<02:21, 226.94 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15666/47780 [01:01<02:08, 250.64 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16492/47780 [01:02<02:03, 253.66 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17063/47780 [01:01<01:30, 340.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15298/47780 [01:02<02:14, 240.92 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16331/47780 [01:02<01:54, 274.35 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15631/47780 [01:02<02:30, 214.07 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15696/47780 [01:02<02:03, 258.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17025/47780 [01:02<02:31, 202.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16518/47780 [01:02<02:05, 248.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17103/47780 [01:02<01:27, 349.03 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15323/47780 [01:02<02:28, 218.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15724/47780 [01:02<02:02, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15663/47780 [01:02<02:17, 232.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17047/47780 [01:02<02:28, 206.85 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16359/47780 [01:02<02:01, 258.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16552/47780 [01:02<01:58, 262.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17140/47780 [01:02<01:29, 341.26 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15751/47780 [01:02<02:05, 254.88 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17140/47780 [01:02<01:20, 382.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16391/47780 [01:02<01:55, 272.42 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15687/47780 [01:02<02:21, 227.11 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15346/47780 [01:02<02:35, 208.45 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16585/47780 [01:02<01:50, 281.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17178/47780 [01:02<01:30, 338.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15713/47780 [01:02<02:18, 231.01 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15780/47780 [01:02<02:06, 253.82 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15375/47780 [01:02<02:25, 222.98 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16419/47780 [01:02<02:04, 252.30 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16623/47780 [01:02<01:46, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17214/47780 [01:02<01:30, 337.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17183/47780 [01:02<01:30, 338.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15814/47780 [01:02<01:56, 274.71 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15737/47780 [01:02<02:20, 228.03 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16654/47780 [01:02<01:45, 294.19 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15398/47780 [01:02<02:34, 209.26 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16456/47780 [01:02<01:55, 271.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17248/47780 [01:02<01:35, 320.28 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15842/47780 [01:02<01:55, 275.81 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17221/47780 [01:02<01:39, 307.15 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15766/47780 [01:02<02:16, 235.21 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15420/47780 [01:02<02:34, 209.89 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16689/47780 [01:02<01:42, 303.35 examples/s]
Tokenizing train dataset (num_proc=32):  12%|â–ˆâ–        | 5865/47780 [01:02<01:49, 382.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16484/47780 [01:02<02:01, 257.44 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17281/47780 [01:02<01:45, 288.29 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15874/47780 [01:02<01:51, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17257/47780 [01:02<01:37, 313.54 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15798/47780 [01:02<02:04, 257.18 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15442/47780 [01:02<02:37, 205.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16511/47780 [01:02<01:59, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16720/47780 [01:02<01:53, 274.34 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15903/47780 [01:02<01:53, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15825/47780 [01:02<02:03, 259.25 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17311/47780 [01:02<01:54, 265.81 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17291/47780 [01:02<01:44, 291.41 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16541/47780 [01:02<01:55, 271.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15463/47780 [01:02<02:43, 198.09 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15932/47780 [01:02<01:56, 273.14 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17374/47780 [01:02<01:25, 355.17 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17334/47780 [01:02<01:34, 321.98 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16571/47780 [01:02<01:51, 279.30 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15484/47780 [01:02<02:42, 199.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15852/47780 [01:02<02:17, 232.83 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16748/47780 [01:03<02:30, 205.73 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15960/47780 [01:03<01:56, 272.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17417/47780 [01:03<01:21, 374.78 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15876/47780 [01:03<02:16, 234.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16604/47780 [01:03<01:50, 281.41 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15504/47780 [01:03<02:52, 187.26 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17368/47780 [01:03<01:43, 293.57 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16812/47780 [01:03<01:42, 301.61 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15989/47780 [01:03<01:56, 273.24 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17457/47780 [01:03<01:24, 357.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16633/47780 [01:03<01:49, 283.81 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15900/47780 [01:03<02:19, 228.99 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15531/47780 [01:03<02:35, 207.39 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17405/47780 [01:03<01:38, 309.44 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16848/47780 [01:03<01:44, 295.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16019/47780 [01:03<01:53, 279.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17494/47780 [01:03<01:25, 353.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16669/47780 [01:03<01:44, 298.89 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15553/47780 [01:03<02:34, 208.61 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17439/47780 [01:03<01:36, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15924/47780 [01:03<02:29, 213.38 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16047/47780 [01:03<01:53, 279.33 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16882/47780 [01:03<01:44, 295.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6001/47780 [01:03<02:10, 319.43 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17531/47780 [01:03<01:28, 343.54 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16699/47780 [01:03<01:50, 280.70 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15587/47780 [01:03<02:14, 240.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17472/47780 [01:03<01:39, 305.65 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16083/47780 [01:03<01:45, 299.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15946/47780 [01:03<02:40, 198.21 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–Ž        | 6454/47780 [01:03<01:11, 575.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16915/47780 [01:03<01:51, 275.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17567/47780 [01:03<01:27, 344.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16728/47780 [01:03<01:52, 276.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15614/47780 [01:03<02:12, 243.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17514/47780 [01:03<01:29, 336.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15967/47780 [01:03<02:41, 196.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16113/47780 [01:03<01:49, 287.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17605/47780 [01:03<01:27, 344.43 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15650/47780 [01:03<01:58, 270.05 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16945/47780 [01:03<01:59, 258.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16756/47780 [01:03<02:00, 257.04 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17550/47780 [01:03<01:36, 313.88 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16016/47780 [01:03<01:57, 271.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16142/47780 [01:03<01:51, 282.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17640/47780 [01:03<01:30, 333.88 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15678/47780 [01:03<02:01, 263.90 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16973/47780 [01:03<02:02, 250.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16783/47780 [01:03<02:00, 258.03 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16045/47780 [01:03<01:57, 270.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17585/47780 [01:03<01:36, 314.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16171/47780 [01:03<01:53, 278.58 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15710/47780 [01:03<01:54, 279.49 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17674/47780 [01:03<01:32, 323.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16815/47780 [01:03<01:56, 266.33 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16073/47780 [01:03<01:56, 271.31 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17000/47780 [01:03<02:13, 229.93 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17618/47780 [01:03<01:41, 296.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16199/47780 [01:03<02:02, 258.44 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17715/47780 [01:03<01:27, 344.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16842/47780 [01:03<01:57, 263.14 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16102/47780 [01:03<01:59, 264.26 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15739/47780 [01:03<02:11, 243.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17030/47780 [01:04<02:04, 246.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17650/47780 [01:03<01:39, 302.27 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16226/47780 [01:04<02:13, 236.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17753/47780 [01:04<01:28, 338.47 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16873/47780 [01:04<01:52, 275.93 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17059/47780 [01:04<01:59, 257.38 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15768/47780 [01:04<02:05, 255.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16129/47780 [01:04<02:01, 260.04 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17687/47780 [01:04<01:36, 310.73 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16271/47780 [01:04<01:52, 279.95 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17788/47780 [01:04<01:30, 330.86 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16901/47780 [01:04<01:55, 267.76 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15795/47780 [01:04<02:03, 258.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17086/47780 [01:04<01:58, 259.83 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16156/47780 [01:04<02:08, 246.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17719/47780 [01:04<01:38, 305.97 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16305/47780 [01:04<01:47, 292.57 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17822/47780 [01:04<01:30, 329.46 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16935/47780 [01:04<01:48, 283.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17113/47780 [01:04<02:01, 252.02 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16182/47780 [01:04<02:07, 247.47 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15823/47780 [01:04<02:13, 239.38 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17750/47780 [01:04<01:47, 279.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16969/47780 [01:04<01:43, 296.77 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16335/47780 [01:04<01:55, 271.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17856/47780 [01:04<01:35, 314.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17139/47780 [01:04<02:01, 251.93 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6661/47780 [01:04<01:39, 412.69 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16207/47780 [01:04<02:10, 242.86 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15849/47780 [01:04<02:12, 241.79 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17779/47780 [01:04<01:49, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17001/47780 [01:04<01:41, 302.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17893/47780 [01:04<01:34, 315.92 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17175/47780 [01:04<01:49, 279.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16363/47780 [01:04<02:03, 254.85 examples/s]
Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 6919/47780 [01:04<01:14, 549.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16236/47780 [01:04<02:04, 253.23 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15875/47780 [01:04<02:12, 241.46 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17807/47780 [01:04<01:51, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17926/47780 [01:04<01:34, 316.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17204/47780 [01:04<01:48, 281.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17032/47780 [01:04<01:50, 279.22 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16391/47780 [01:04<02:06, 248.46 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16262/47780 [01:04<02:06, 249.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15900/47780 [01:04<02:12, 240.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17838/47780 [01:04<01:47, 277.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17234/47780 [01:04<01:47, 284.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17958/47780 [01:04<01:36, 307.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17072/47780 [01:04<01:41, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16420/47780 [01:04<02:02, 256.46 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15925/47780 [01:04<02:13, 238.32 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16288/47780 [01:04<02:09, 243.93 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17867/47780 [01:04<01:48, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17269/47780 [01:04<01:41, 299.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17990/47780 [01:04<01:36, 307.48 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17103/47780 [01:04<01:48, 282.78 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16446/47780 [01:04<02:07, 246.48 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15949/47780 [01:04<02:22, 223.83 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17901/47780 [01:04<01:42, 290.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16313/47780 [01:04<02:21, 222.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18021/47780 [01:04<01:38, 301.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17300/47780 [01:04<01:47, 282.77 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16472/47780 [01:05<02:07, 245.20 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17133/47780 [01:04<01:50, 278.45 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15975/47780 [01:04<02:20, 226.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17931/47780 [01:04<01:45, 283.05 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16343/47780 [01:04<02:13, 236.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–        | 7101/47780 [01:04<01:22, 495.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18055/47780 [01:05<01:39, 298.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17329/47780 [01:05<01:49, 278.37 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16002/47780 [01:05<02:13, 238.31 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16497/47780 [01:05<02:15, 231.24 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17162/47780 [01:05<01:59, 256.66 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16368/47780 [01:05<02:12, 237.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17961/47780 [01:05<01:48, 275.36 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18090/47780 [01:05<01:36, 306.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17358/47780 [01:05<01:51, 272.54 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16032/47780 [01:05<02:04, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17206/47780 [01:05<01:42, 298.06 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17994/47780 [01:05<01:43, 287.36 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16521/47780 [01:05<02:26, 213.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16392/47780 [01:05<02:19, 225.53 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17391/47780 [01:05<01:48, 279.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18121/47780 [01:05<01:44, 283.60 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16058/47780 [01:05<02:13, 237.79 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18025/47780 [01:05<01:41, 293.58 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17237/47780 [01:05<01:46, 286.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16428/47780 [01:05<02:02, 256.73 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16548/47780 [01:05<02:22, 218.74 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7240/47780 [01:05<01:26, 466.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17420/47780 [01:05<01:48, 279.47 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18164/47780 [01:05<01:34, 313.75 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16083/47780 [01:05<02:15, 233.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18055/47780 [01:05<01:43, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17267/47780 [01:05<01:45, 289.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16454/47780 [01:05<02:04, 251.79 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16571/47780 [01:05<02:23, 217.19 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18196/47780 [01:05<01:36, 307.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17449/47780 [01:05<01:59, 253.41 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18084/47780 [01:05<01:43, 286.70 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17298/47780 [01:05<01:44, 292.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16107/47780 [01:05<02:19, 227.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16482/47780 [01:05<02:03, 254.29 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16597/47780 [01:05<02:19, 223.97 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18227/47780 [01:05<01:40, 293.83 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17477/47780 [01:05<01:58, 255.20 examples/s]
Tokenizing train dataset (num_proc=32):  15%|â–ˆâ–Œ        | 7351/47780 [01:05<01:28, 458.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18113/47780 [01:05<01:45, 281.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16131/47780 [01:05<02:17, 230.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17328/47780 [01:05<01:45, 287.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16511/47780 [01:05<01:59, 261.35 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16628/47780 [01:05<02:05, 247.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18257/47780 [01:05<01:45, 280.34 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17359/47780 [01:05<01:43, 294.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16157/47780 [01:05<02:15, 233.93 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16656/47780 [01:05<02:01, 256.48 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18142/47780 [01:05<01:50, 268.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17503/47780 [01:05<02:08, 236.25 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16538/47780 [01:05<02:05, 249.39 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7440/47780 [01:05<01:29, 451.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17395/47780 [01:05<01:38, 309.42 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18292/47780 [01:05<01:39, 295.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16182/47780 [01:05<02:13, 235.96 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16686/47780 [01:05<01:56, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18170/47780 [01:05<01:49, 269.74 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16570/47780 [01:05<01:58, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17528/47780 [01:05<02:15, 223.12 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17437/47780 [01:05<01:29, 337.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18326/47780 [01:05<01:37, 301.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16211/47780 [01:05<02:07, 248.56 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7515/47780 [01:05<01:24, 476.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18200/47780 [01:05<01:50, 267.63 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16713/47780 [01:06<02:05, 247.29 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17551/47780 [01:06<02:15, 223.91 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16597/47780 [01:06<02:09, 241.58 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18369/47780 [01:06<01:27, 336.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17473/47780 [01:06<01:29, 338.21 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16236/47780 [01:06<02:11, 240.45 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18227/47780 [01:06<01:53, 259.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17576/47780 [01:06<02:11, 229.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16739/47780 [01:06<02:05, 247.85 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7587/47780 [01:06<01:23, 483.02 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16626/47780 [01:06<02:04, 251.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17507/47780 [01:06<01:30, 333.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18404/47780 [01:06<01:28, 333.10 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16262/47780 [01:06<02:08, 245.99 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17600/47780 [01:06<02:09, 232.59 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18254/47780 [01:06<01:55, 255.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16765/47780 [01:06<02:06, 245.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16652/47780 [01:06<02:04, 250.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7653/47780 [01:06<01:24, 475.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18446/47780 [01:06<01:23, 350.20 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18281/47780 [01:06<01:54, 257.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17632/47780 [01:06<02:00, 251.03 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16795/47780 [01:06<02:04, 249.49 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17541/47780 [01:06<01:44, 288.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16684/47780 [01:06<01:56, 267.30 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16287/47780 [01:06<02:32, 206.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7716/47780 [01:06<01:22, 485.28 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18482/47780 [01:06<01:25, 341.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18307/47780 [01:06<01:56, 252.46 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17665/47780 [01:06<01:54, 262.12 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16821/47780 [01:06<02:03, 250.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17579/47780 [01:06<01:36, 311.62 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16719/47780 [01:06<01:47, 288.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16316/47780 [01:06<02:19, 225.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18524/47780 [01:06<01:21, 359.49 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7774/47780 [01:06<01:25, 470.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16847/47780 [01:06<02:03, 251.15 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18339/47780 [01:06<01:54, 257.34 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17612/47780 [01:06<01:37, 310.18 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16751/47780 [01:06<01:44, 296.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17692/47780 [01:06<01:58, 253.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16340/47780 [01:06<02:17, 228.41 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18561/47780 [01:06<01:26, 338.99 examples/s]
Tokenizing train dataset (num_proc=32):  16%|â–ˆâ–‹        | 7832/47780 [01:06<01:22, 485.41 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16876/47780 [01:06<01:59, 258.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17647/47780 [01:06<01:34, 317.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18368/47780 [01:06<01:51, 263.39 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17730/47780 [01:06<01:45, 285.28 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16781/47780 [01:06<01:47, 287.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16364/47780 [01:06<02:25, 216.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18596/47780 [01:06<01:26, 338.64 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7886/47780 [01:06<01:22, 484.25 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17680/47780 [01:06<01:33, 321.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18395/47780 [01:06<01:50, 264.99 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16903/47780 [01:06<02:00, 255.78 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16810/47780 [01:06<01:51, 278.40 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16388/47780 [01:06<02:21, 222.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17759/47780 [01:06<01:56, 257.37 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18631/47780 [01:06<01:29, 327.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18422/47780 [01:06<01:51, 263.79 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16942/47780 [01:06<01:46, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7938/47780 [01:06<01:23, 478.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17713/47780 [01:06<01:41, 296.57 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16411/47780 [01:06<02:24, 217.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17789/47780 [01:06<01:53, 264.10 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16839/47780 [01:06<02:02, 253.16 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16982/47780 [01:06<01:36, 318.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18452/47780 [01:06<01:49, 268.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18670/47780 [01:06<01:27, 332.57 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 7990/47780 [01:06<01:25, 466.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16435/47780 [01:06<02:20, 223.30 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17745/47780 [01:06<01:48, 275.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16865/47780 [01:07<02:06, 243.65 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17816/47780 [01:07<02:03, 243.46 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17020/47780 [01:07<01:32, 332.77 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18482/47780 [01:07<01:46, 274.07 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18706/47780 [01:07<01:26, 337.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8039/47780 [01:06<01:29, 444.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16458/47780 [01:07<02:23, 217.87 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17774/47780 [01:07<01:48, 276.72 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16896/47780 [01:07<01:58, 259.56 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17841/47780 [01:07<02:08, 233.14 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18510/47780 [01:07<01:46, 275.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17057/47780 [01:07<01:29, 343.14 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18747/47780 [01:07<01:22, 353.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8114/47780 [01:07<01:16, 518.00 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17805/47780 [01:07<01:45, 284.52 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16481/47780 [01:07<02:32, 205.18 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16923/47780 [01:07<02:04, 248.76 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17865/47780 [01:07<02:08, 232.48 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18542/47780 [01:07<01:41, 286.75 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18784/47780 [01:07<01:21, 354.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17092/47780 [01:07<01:36, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17841/47780 [01:07<01:38, 303.30 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8168/47780 [01:07<01:20, 491.86 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16510/47780 [01:07<02:19, 223.52 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16952/47780 [01:07<01:59, 257.15 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17889/47780 [01:07<02:10, 229.46 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18576/47780 [01:07<01:37, 300.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18820/47780 [01:07<01:24, 343.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17125/47780 [01:07<01:39, 308.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17872/47780 [01:07<01:39, 301.91 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8219/47780 [01:07<01:20, 492.84 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16533/47780 [01:07<02:18, 225.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16980/47780 [01:07<01:59, 257.75 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17913/47780 [01:07<02:13, 224.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18607/47780 [01:07<01:45, 277.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18855/47780 [01:07<01:29, 323.82 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17157/47780 [01:07<01:48, 283.45 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16562/47780 [01:07<02:09, 240.94 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17903/47780 [01:07<01:46, 281.71 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8271/47780 [01:07<01:24, 468.98 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17007/47780 [01:07<01:59, 258.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17941/47780 [01:07<02:05, 238.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18643/47780 [01:07<01:37, 299.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18888/47780 [01:07<01:30, 318.75 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17187/47780 [01:07<01:47, 284.76 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16587/47780 [01:07<02:12, 235.40 examples/s]
Tokenizing train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8319/47780 [01:07<01:24, 466.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17039/47780 [01:07<01:53, 271.94 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17932/47780 [01:07<01:53, 263.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17966/47780 [01:07<02:09, 230.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18674/47780 [01:07<01:39, 291.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18929/47780 [01:07<01:23, 343.86 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16612/47780 [01:07<02:10, 239.31 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8367/47780 [01:07<01:24, 465.17 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17216/47780 [01:07<01:52, 271.44 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17962/47780 [01:07<01:50, 270.45 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17997/47780 [01:07<02:00, 247.22 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17069/47780 [01:07<01:59, 256.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18704/47780 [01:07<01:39, 291.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18964/47780 [01:07<01:27, 329.80 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16644/47780 [01:07<01:59, 259.89 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17249/47780 [01:07<01:46, 287.13 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8414/47780 [01:07<01:29, 441.77 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17990/47780 [01:07<01:52, 264.42 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17100/47780 [01:07<01:55, 265.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18022/47780 [01:07<02:04, 239.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18734/47780 [01:07<01:40, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18999/47780 [01:07<01:32, 312.15 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17280/47780 [01:07<01:44, 293.18 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16671/47780 [01:07<02:00, 257.96 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8464/47780 [01:07<01:32, 426.28 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18017/47780 [01:07<01:55, 257.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18769/47780 [01:07<01:35, 302.67 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17129/47780 [01:08<01:57, 260.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18047/47780 [01:08<02:08, 231.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17313/47780 [01:08<01:40, 303.56 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16698/47780 [01:08<01:59, 260.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19031/47780 [01:08<01:43, 277.05 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8513/47780 [01:08<01:29, 437.80 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18044/47780 [01:08<01:56, 254.78 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17160/47780 [01:08<01:52, 271.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18074/47780 [01:08<02:02, 242.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18800/47780 [01:08<01:38, 294.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17344/47780 [01:08<01:41, 298.82 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16725/47780 [01:08<02:02, 253.77 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19070/47780 [01:08<01:34, 303.84 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8558/47780 [01:08<01:29, 436.50 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18835/47780 [01:08<01:34, 306.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18099/47780 [01:08<02:05, 237.09 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18072/47780 [01:08<02:07, 232.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17188/47780 [01:08<02:02, 248.81 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16751/47780 [01:08<02:02, 252.87 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17375/47780 [01:08<01:45, 289.36 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19116/47780 [01:08<01:23, 345.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8602/47780 [01:08<01:35, 409.29 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18123/47780 [01:08<02:07, 232.66 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18866/47780 [01:08<01:37, 297.43 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18104/47780 [01:08<01:56, 254.03 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17224/47780 [01:08<01:49, 278.31 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16777/47780 [01:08<02:01, 254.77 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17405/47780 [01:08<01:54, 264.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19152/47780 [01:08<01:29, 321.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8658/47780 [01:08<01:28, 441.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18896/47780 [01:08<01:36, 297.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18148/47780 [01:08<02:13, 222.51 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18131/47780 [01:08<01:58, 250.88 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16812/47780 [01:08<01:51, 278.47 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17253/47780 [01:08<02:04, 245.02 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17432/47780 [01:08<01:58, 255.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8707/47780 [01:08<01:26, 449.84 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19187/47780 [01:08<01:30, 315.07 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18928/47780 [01:08<01:39, 291.25 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18174/47780 [01:08<02:07, 232.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18157/47780 [01:08<02:02, 241.19 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16840/47780 [01:08<01:54, 270.37 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17281/47780 [01:08<02:05, 242.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17466/47780 [01:08<01:50, 275.47 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19222/47780 [01:08<01:28, 324.29 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8753/47780 [01:08<01:30, 432.85 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18968/47780 [01:08<01:30, 318.41 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18185/47780 [01:08<01:59, 247.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17498/47780 [01:08<01:45, 287.67 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17307/47780 [01:08<02:05, 242.13 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16868/47780 [01:08<02:09, 237.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18199/47780 [01:08<02:33, 192.36 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19256/47780 [01:08<01:33, 305.39 examples/s]
Tokenizing train dataset (num_proc=32):  18%|â–ˆâ–Š        | 8798/47780 [01:08<01:34, 410.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18210/47780 [01:08<02:05, 235.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19000/47780 [01:08<01:42, 280.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17528/47780 [01:08<01:46, 284.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18234/47780 [01:08<02:07, 230.97 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16893/47780 [01:08<02:14, 228.94 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17332/47780 [01:08<02:16, 223.09 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19295/47780 [01:08<01:27, 324.75 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8841/47780 [01:08<01:37, 399.33 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19029/47780 [01:08<01:43, 277.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18234/47780 [01:08<02:10, 226.61 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17560/47780 [01:08<01:44, 289.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18259/47780 [01:08<02:06, 233.54 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16918/47780 [01:08<02:11, 234.45 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17356/47780 [01:08<02:16, 222.88 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19329/47780 [01:08<01:30, 314.98 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8893/47780 [01:08<01:31, 426.71 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19061/47780 [01:08<01:40, 285.58 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18259/47780 [01:09<02:09, 228.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17594/47780 [01:09<01:40, 299.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18284/47780 [01:09<02:07, 230.51 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16942/47780 [01:09<02:18, 223.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17383/47780 [01:09<02:11, 230.46 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–Š        | 8938/47780 [01:09<01:29, 432.77 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19365/47780 [01:09<01:30, 313.30 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19092/47780 [01:09<01:39, 287.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18286/47780 [01:09<02:03, 239.59 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17625/47780 [01:09<01:41, 296.73 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18312/47780 [01:09<02:03, 239.49 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16967/47780 [01:09<02:14, 228.51 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17407/47780 [01:09<02:10, 232.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19403/47780 [01:09<01:25, 331.38 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 8983/47780 [01:09<01:31, 423.88 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19132/47780 [01:09<01:30, 316.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18323/47780 [01:09<01:46, 276.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17656/47780 [01:09<01:40, 299.51 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18337/47780 [01:09<02:05, 233.72 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16991/47780 [01:09<02:13, 231.18 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17431/47780 [01:09<02:19, 217.41 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9026/47780 [01:09<01:31, 423.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19441/47780 [01:09<01:24, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18354/47780 [01:09<01:43, 285.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19164/47780 [01:09<01:37, 294.81 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17018/47780 [01:09<02:08, 240.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18361/47780 [01:09<02:07, 230.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17687/47780 [01:09<01:49, 274.03 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9075/47780 [01:09<01:27, 442.06 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19483/47780 [01:09<01:20, 350.26 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17463/47780 [01:09<02:08, 235.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18384/47780 [01:09<01:47, 274.18 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19194/47780 [01:09<01:40, 283.38 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17049/47780 [01:09<01:59, 257.13 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17721/47780 [01:09<01:42, 291.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18385/47780 [01:09<02:14, 218.64 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9121/47780 [01:09<01:26, 444.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19534/47780 [01:09<01:14, 378.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18415/47780 [01:09<01:43, 284.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17487/47780 [01:09<02:17, 220.01 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19227/47780 [01:09<01:40, 284.25 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17076/47780 [01:09<02:00, 254.89 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18409/47780 [01:09<02:12, 222.01 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17753/47780 [01:09<01:50, 272.38 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9166/47780 [01:09<01:30, 425.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19572/47780 [01:09<01:16, 368.97 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18449/47780 [01:09<01:38, 298.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17510/47780 [01:09<02:17, 220.08 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17102/47780 [01:09<02:04, 246.16 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18442/47780 [01:09<02:04, 236.22 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9209/47780 [01:09<01:32, 417.61 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18480/47780 [01:09<01:38, 298.42 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19613/47780 [01:09<01:15, 373.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19256/47780 [01:09<02:00, 236.90 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17781/47780 [01:09<01:58, 252.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17535/47780 [01:09<02:14, 225.56 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17131/47780 [01:09<02:01, 251.56 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9251/47780 [01:09<01:32, 417.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18470/47780 [01:09<01:59, 245.52 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18516/47780 [01:09<01:33, 314.50 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19651/47780 [01:09<01:15, 370.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19312/47780 [01:09<01:31, 312.35 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17558/47780 [01:09<02:21, 213.18 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17807/47780 [01:09<02:06, 237.33 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17157/47780 [01:09<02:07, 240.64 examples/s]
Tokenizing train dataset (num_proc=32):  19%|â–ˆâ–‰        | 9293/47780 [01:09<01:35, 404.34 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18495/47780 [01:09<02:02, 238.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19346/47780 [01:09<01:31, 309.27 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17580/47780 [01:09<02:20, 214.90 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17835/47780 [01:10<02:00, 248.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19690/47780 [01:09<01:21, 345.26 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18548/47780 [01:09<01:42, 285.20 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9340/47780 [01:09<01:31, 419.25 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17182/47780 [01:10<02:10, 235.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18521/47780 [01:10<02:01, 241.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19379/47780 [01:10<01:31, 308.91 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17868/47780 [01:10<01:51, 269.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17606/47780 [01:10<02:17, 220.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19725/47780 [01:10<01:21, 342.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18578/47780 [01:10<01:49, 266.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18547/47780 [01:10<01:58, 246.76 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17206/47780 [01:10<02:11, 232.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9391/47780 [01:10<01:28, 435.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19416/47780 [01:10<01:27, 323.88 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17629/47780 [01:10<02:16, 220.55 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19763/47780 [01:10<01:20, 349.55 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17896/47780 [01:10<01:55, 259.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18614/47780 [01:10<01:42, 285.28 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17235/47780 [01:10<02:03, 247.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18574/47780 [01:10<01:56, 250.98 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19450/47780 [01:10<01:28, 318.66 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19799/47780 [01:10<01:19, 352.48 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17652/47780 [01:10<02:17, 218.92 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17924/47780 [01:10<01:54, 261.54 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9435/47780 [01:10<01:43, 369.17 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18647/47780 [01:10<01:38, 295.50 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17267/47780 [01:10<01:55, 265.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18600/47780 [01:10<01:59, 245.19 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19835/47780 [01:10<01:19, 350.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17675/47780 [01:10<02:17, 218.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19484/47780 [01:10<01:31, 308.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17955/47780 [01:10<01:49, 272.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18679/47780 [01:10<01:37, 297.65 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17303/47780 [01:10<01:44, 292.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18626/47780 [01:10<01:59, 243.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19873/47780 [01:10<01:19, 351.09 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17697/47780 [01:10<02:17, 219.12 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9474/47780 [01:10<02:09, 295.52 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19516/47780 [01:10<01:36, 292.14 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17983/47780 [01:10<01:56, 256.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18710/47780 [01:10<01:39, 291.34 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18663/47780 [01:10<01:51, 261.74 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17333/47780 [01:10<01:56, 262.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19910/47780 [01:10<01:18, 356.12 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17725/47780 [01:10<02:09, 231.49 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19546/47780 [01:10<01:36, 293.67 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18009/47780 [01:10<01:57, 252.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18741/47780 [01:10<01:42, 283.90 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18699/47780 [01:10<01:41, 285.77 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9507/47780 [01:10<02:30, 255.14 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17360/47780 [01:10<01:58, 257.54 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17752/47780 [01:10<02:03, 242.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19946/47780 [01:10<01:21, 341.52 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19577/47780 [01:10<01:38, 286.18 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18035/47780 [01:10<02:02, 243.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18773/47780 [01:10<01:41, 286.74 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18734/47780 [01:10<01:36, 300.40 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17779/47780 [01:10<02:01, 247.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19987/47780 [01:10<01:17, 357.17 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17387/47780 [01:10<02:05, 241.98 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19609/47780 [01:10<01:35, 294.24 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 9536/47780 [01:10<02:43, 234.26 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18060/47780 [01:10<02:06, 235.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18802/47780 [01:10<01:48, 267.53 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18765/47780 [01:10<01:38, 295.76 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17806/47780 [01:10<01:59, 251.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20023/47780 [01:10<01:17, 355.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19647/47780 [01:10<01:30, 309.27 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17412/47780 [01:10<02:11, 230.09 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9720/47780 [01:10<01:06, 572.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18089/47780 [01:11<02:00, 247.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18830/47780 [01:10<01:48, 265.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18795/47780 [01:11<01:38, 294.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17834/47780 [01:11<01:57, 255.49 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20059/47780 [01:11<01:19, 346.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19679/47780 [01:11<01:34, 298.53 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18115/47780 [01:11<01:59, 247.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17436/47780 [01:11<02:18, 219.81 examples/s]
Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 9793/47780 [01:11<01:10, 539.06 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17860/47780 [01:11<01:58, 252.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20095/47780 [01:11<01:18, 350.60 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18825/47780 [01:11<01:46, 272.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18857/47780 [01:11<02:01, 237.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19710/47780 [01:11<01:37, 289.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17475/47780 [01:11<01:57, 257.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18140/47780 [01:11<02:11, 225.90 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20134/47780 [01:11<01:17, 358.20 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17886/47780 [01:11<02:01, 245.91 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18882/47780 [01:11<02:01, 237.95 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18853/47780 [01:11<01:49, 264.20 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9858/47780 [01:11<01:16, 496.36 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17502/47780 [01:11<01:57, 258.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19741/47780 [01:11<01:36, 291.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18163/47780 [01:11<02:12, 222.96 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20174/47780 [01:11<01:14, 370.36 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17912/47780 [01:11<02:00, 247.10 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18907/47780 [01:11<02:04, 232.38 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18880/47780 [01:11<01:52, 257.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19776/47780 [01:11<01:33, 298.06 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9915/47780 [01:11<01:22, 456.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17530/47780 [01:11<02:07, 238.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20219/47780 [01:11<01:10, 389.22 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18186/47780 [01:11<02:20, 210.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17937/47780 [01:11<02:02, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18931/47780 [01:11<02:04, 231.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18916/47780 [01:11<01:43, 279.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19808/47780 [01:11<01:32, 300.80 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17555/47780 [01:11<02:08, 235.15 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20270/47780 [01:11<01:05, 421.98 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18212/47780 [01:11<02:13, 221.30 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17968/47780 [01:11<01:53, 261.86 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9967/47780 [01:11<01:27, 434.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18958/47780 [01:11<02:01, 237.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18947/47780 [01:11<01:42, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19839/47780 [01:11<01:39, 281.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20314/47780 [01:11<01:04, 424.77 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17579/47780 [01:11<02:10, 230.75 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17995/47780 [01:11<01:59, 249.21 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18235/47780 [01:11<02:22, 207.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18986/47780 [01:11<01:55, 248.63 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10014/47780 [01:11<01:29, 420.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18976/47780 [01:11<01:44, 274.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20357/47780 [01:11<01:05, 421.02 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17607/47780 [01:11<02:03, 243.60 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19868/47780 [01:11<01:43, 268.81 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18032/47780 [01:11<01:47, 277.25 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19018/47780 [01:11<01:48, 265.88 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18269/47780 [01:11<02:06, 233.00 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10059/47780 [01:11<01:29, 419.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19004/47780 [01:11<01:45, 273.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19899/47780 [01:11<01:39, 279.52 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17632/47780 [01:11<02:06, 237.39 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20400/47780 [01:11<01:08, 400.59 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19046/47780 [01:11<01:49, 263.60 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18060/47780 [01:11<01:49, 270.94 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19033/47780 [01:11<01:43, 277.90 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10105/47780 [01:11<01:30, 417.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18293/47780 [01:11<02:16, 216.49 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17661/47780 [01:11<01:59, 251.71 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19928/47780 [01:11<01:45, 265.16 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18089/47780 [01:12<01:47, 275.76 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20441/47780 [01:11<01:13, 373.60 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19073/47780 [01:12<01:52, 254.11 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 10150/47780 [01:11<01:29, 421.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19062/47780 [01:12<01:46, 269.05 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18315/47780 [01:12<02:27, 200.37 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17687/47780 [01:12<02:01, 246.78 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19963/47780 [01:12<01:36, 288.16 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18118/47780 [01:12<01:46, 277.95 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19105/47780 [01:12<01:46, 269.57 examples/s]
Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10200/47780 [01:12<01:24, 442.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20480/47780 [01:12<01:18, 349.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19090/47780 [01:12<01:51, 257.38 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18358/47780 [01:12<01:54, 256.69 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17717/47780 [01:12<01:55, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19995/47780 [01:12<01:35, 290.53 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19133/47780 [01:12<01:48, 263.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  21%|â–ˆâ–ˆâ–       | 10246/47780 [01:12<01:25, 441.40 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18146/47780 [01:12<02:05, 236.93 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20518/47780 [01:12<01:21, 333.47 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19116/47780 [01:12<01:58, 241.15 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18385/47780 [01:12<01:57, 249.58 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17753/47780 [01:12<01:44, 286.08 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20028/47780 [01:12<01:34, 295.02 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10297/47780 [01:12<01:22, 456.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19160/47780 [01:12<01:52, 253.91 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18193/47780 [01:12<01:41, 292.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20553/47780 [01:12<01:22, 331.54 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18416/47780 [01:12<01:51, 263.01 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17791/47780 [01:12<01:36, 309.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20059/47780 [01:12<01:34, 294.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19141/47780 [01:12<02:12, 216.64 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19186/47780 [01:12<01:56, 244.51 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10344/47780 [01:12<01:27, 426.05 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18227/47780 [01:12<01:38, 301.33 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18445/47780 [01:12<01:48, 270.23 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20587/47780 [01:12<01:26, 315.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20089/47780 [01:12<01:33, 295.60 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17824/47780 [01:12<01:43, 288.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19165/47780 [01:12<02:13, 213.71 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19217/47780 [01:12<01:49, 261.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18263/47780 [01:12<01:33, 314.03 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10389/47780 [01:12<01:30, 414.91 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18474/47780 [01:12<01:49, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20620/47780 [01:12<01:28, 307.42 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20124/47780 [01:12<01:31, 302.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17854/47780 [01:12<01:44, 286.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19189/47780 [01:12<02:09, 220.47 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19246/47780 [01:12<01:46, 267.84 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10437/47780 [01:12<01:26, 432.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20657/47780 [01:12<01:24, 321.19 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18504/47780 [01:12<01:48, 269.69 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18296/47780 [01:12<01:41, 289.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20159/47780 [01:12<01:28, 312.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19213/47780 [01:12<02:07, 223.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19275/47780 [01:12<01:43, 274.16 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17884/47780 [01:12<01:56, 257.72 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10481/47780 [01:12<01:28, 420.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20690/47780 [01:12<01:27, 310.01 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18326/47780 [01:12<01:44, 282.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19244/47780 [01:12<01:56, 244.81 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18532/47780 [01:12<01:58, 245.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20191/47780 [01:12<01:34, 291.23 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17913/47780 [01:12<01:54, 261.03 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10546/47780 [01:12<01:17, 480.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19303/47780 [01:12<01:56, 244.43 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20722/47780 [01:12<01:28, 305.75 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18561/47780 [01:12<01:53, 256.77 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18355/47780 [01:12<01:50, 266.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19272/47780 [01:12<01:54, 248.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20228/47780 [01:12<01:28, 312.70 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17941/47780 [01:12<01:53, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10595/47780 [01:12<01:18, 476.00 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19335/47780 [01:13<01:47, 263.74 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20753/47780 [01:13<01:32, 292.91 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19303/47780 [01:13<01:48, 263.21 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18588/47780 [01:13<01:57, 249.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18383/47780 [01:13<01:53, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20260/47780 [01:13<01:35, 288.96 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17968/47780 [01:13<01:57, 254.10 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10643/47780 [01:13<01:21, 455.39 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19363/47780 [01:13<01:53, 250.06 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20788/47780 [01:13<01:28, 306.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19330/47780 [01:13<01:51, 256.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18614/47780 [01:13<02:03, 236.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18410/47780 [01:13<01:58, 247.16 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20290/47780 [01:13<01:39, 277.10 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17996/47780 [01:13<01:55, 257.13 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10693/47780 [01:13<01:19, 467.74 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19389/47780 [01:13<01:52, 252.25 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20827/47780 [01:13<01:22, 326.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19357/47780 [01:13<01:51, 254.64 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18439/47780 [01:13<01:54, 255.95 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18639/47780 [01:13<02:02, 237.48 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20319/47780 [01:13<01:39, 274.65 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18023/47780 [01:13<01:56, 256.17 examples/s]
Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10741/47780 [01:13<01:22, 449.35 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19415/47780 [01:13<01:53, 249.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19388/47780 [01:13<01:46, 267.27 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20860/47780 [01:13<01:30, 297.00 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18467/47780 [01:13<01:51, 262.29 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18665/47780 [01:13<01:59, 243.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20357/47780 [01:13<01:33, 292.87 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18049/47780 [01:13<01:59, 248.90 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10788/47780 [01:13<01:23, 442.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19441/47780 [01:13<01:59, 236.40 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19415/47780 [01:13<01:49, 259.26 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20893/47780 [01:13<01:27, 305.82 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18499/47780 [01:13<01:47, 272.65 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18690/47780 [01:13<02:09, 225.46 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20388/47780 [01:13<01:32, 294.72 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18075/47780 [01:13<01:59, 249.24 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10833/47780 [01:13<01:27, 421.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19468/47780 [01:13<01:56, 242.99 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19446/47780 [01:13<01:43, 273.53 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20929/47780 [01:13<01:24, 317.42 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18530/47780 [01:13<01:43, 282.91 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18103/47780 [01:13<01:56, 255.52 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20422/47780 [01:13<01:30, 301.71 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18716/47780 [01:13<02:09, 224.85 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10877/47780 [01:13<01:28, 417.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19494/47780 [01:13<01:55, 244.96 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20964/47780 [01:13<01:22, 326.51 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19474/47780 [01:13<01:47, 262.67 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18561/47780 [01:13<01:42, 284.32 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18133/47780 [01:13<01:51, 264.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20453/47780 [01:13<01:31, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18739/47780 [01:13<02:13, 217.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10928/47780 [01:13<01:23, 443.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19519/47780 [01:13<01:55, 243.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20998/47780 [01:13<01:21, 326.72 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19501/47780 [01:13<01:52, 250.79 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18590/47780 [01:13<01:49, 267.25 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20488/47780 [01:13<01:28, 307.41 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18164/47780 [01:13<01:49, 271.36 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18762/47780 [01:13<02:14, 215.84 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10981/47780 [01:13<01:19, 464.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19550/47780 [01:13<01:48, 259.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21032/47780 [01:13<01:20, 330.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19532/47780 [01:13<01:49, 259.07 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18623/47780 [01:13<01:43, 281.89 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18194/47780 [01:13<01:48, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18784/47780 [01:14<02:19, 207.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20519/47780 [01:13<01:36, 282.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19577/47780 [01:13<01:49, 256.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21066/47780 [01:13<01:20, 332.77 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11028/47780 [01:13<01:27, 420.92 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18652/47780 [01:14<01:50, 263.17 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18222/47780 [01:14<01:52, 263.31 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19561/47780 [01:14<02:00, 234.00 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18805/47780 [01:14<02:22, 203.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19604/47780 [01:14<01:48, 260.50 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11072/47780 [01:14<01:26, 426.06 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20549/47780 [01:14<01:41, 267.01 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21100/47780 [01:14<01:23, 319.47 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18686/47780 [01:14<01:43, 281.21 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18249/47780 [01:14<01:57, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18831/47780 [01:14<02:13, 217.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19631/47780 [01:14<01:48, 260.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19597/47780 [01:14<01:48, 260.74 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11122/47780 [01:14<01:23, 436.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21150/47780 [01:14<01:14, 357.52 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20577/47780 [01:14<01:47, 254.05 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18715/47780 [01:14<01:44, 277.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18853/47780 [01:14<02:19, 207.57 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18275/47780 [01:14<02:02, 240.11 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11168/47780 [01:14<01:23, 437.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19625/47780 [01:14<01:52, 249.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20613/47780 [01:14<01:38, 276.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21193/47780 [01:14<01:12, 367.91 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19658/47780 [01:14<02:01, 230.93 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18744/47780 [01:14<01:50, 263.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18300/47780 [01:14<02:01, 242.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18874/47780 [01:14<02:22, 202.42 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19654/47780 [01:14<01:51, 252.72 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21237/47780 [01:14<01:09, 383.95 examples/s]
Tokenizing train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 11213/47780 [01:14<01:28, 411.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20646/47780 [01:14<01:35, 284.62 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19688/47780 [01:14<01:53, 246.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18773/47780 [01:14<01:50, 262.09 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18330/47780 [01:14<01:58, 247.92 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18898/47780 [01:14<02:20, 206.18 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19681/47780 [01:14<01:50, 254.54 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21293/47780 [01:14<01:01, 434.09 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11260/47780 [01:14<01:25, 425.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19724/47780 [01:14<01:43, 271.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20677/47780 [01:14<01:35, 282.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18801/47780 [01:14<01:52, 258.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18359/47780 [01:14<01:53, 259.04 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18928/47780 [01:14<02:05, 229.96 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19707/47780 [01:14<01:55, 242.54 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21337/47780 [01:14<01:03, 416.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19762/47780 [01:14<01:33, 298.59 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20706/47780 [01:14<01:36, 281.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11303/47780 [01:14<01:30, 401.84 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18831/47780 [01:14<01:50, 261.49 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18958/47780 [01:14<01:55, 249.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18387/47780 [01:14<02:01, 241.97 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19794/47780 [01:14<01:32, 301.14 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20736/47780 [01:14<01:36, 280.76 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19733/47780 [01:14<01:57, 239.43 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21380/47780 [01:14<01:05, 401.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–Ž       | 11344/47780 [01:14<01:35, 380.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18867/47780 [01:14<01:40, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18994/47780 [01:14<01:43, 277.80 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19830/47780 [01:14<01:27, 317.86 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18413/47780 [01:14<02:07, 230.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21421/47780 [01:14<01:08, 382.97 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19759/47780 [01:14<02:05, 223.30 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11383/47780 [01:14<01:41, 360.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20765/47780 [01:14<01:50, 245.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18908/47780 [01:14<01:30, 318.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19022/47780 [01:14<01:44, 275.25 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19865/47780 [01:14<01:26, 323.20 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19784/47780 [01:15<02:02, 228.04 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18437/47780 [01:15<02:14, 218.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21460/47780 [01:15<01:14, 353.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20791/47780 [01:14<01:48, 248.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11421/47780 [01:14<01:45, 343.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18941/47780 [01:15<01:31, 315.67 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19050/47780 [01:15<01:52, 256.05 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19898/47780 [01:15<01:28, 314.42 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19814/47780 [01:15<01:54, 245.03 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18464/47780 [01:15<02:07, 230.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21496/47780 [01:15<01:14, 351.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20840/47780 [01:15<01:27, 309.24 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18974/47780 [01:15<01:32, 312.07 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11456/47780 [01:15<01:49, 331.31 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19078/47780 [01:15<01:50, 259.64 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19930/47780 [01:15<01:31, 305.56 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18488/47780 [01:15<02:05, 233.12 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19840/47780 [01:15<01:55, 241.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21532/47780 [01:15<01:15, 346.02 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11498/47780 [01:15<01:42, 354.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19007/47780 [01:15<01:31, 313.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20872/47780 [01:15<01:34, 284.47 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19105/47780 [01:15<01:54, 251.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19965/47780 [01:15<01:31, 304.31 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19865/47780 [01:15<01:54, 243.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21571/47780 [01:15<01:14, 351.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11538/47780 [01:15<01:38, 366.90 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18512/47780 [01:15<02:19, 209.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20902/47780 [01:15<01:33, 288.37 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20000/47780 [01:15<01:28, 313.50 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19131/47780 [01:15<01:59, 239.61 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19039/47780 [01:15<01:47, 266.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19890/47780 [01:15<01:57, 237.27 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18536/47780 [01:15<02:16, 213.57 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11576/47780 [01:15<01:41, 354.99 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20933/47780 [01:15<01:33, 288.24 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21607/47780 [01:15<01:19, 327.37 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19158/47780 [01:15<01:56, 245.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20032/47780 [01:15<01:31, 304.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19077/47780 [01:15<01:38, 289.93 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11619/47780 [01:15<01:36, 373.38 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19914/47780 [01:15<02:10, 214.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21642/47780 [01:15<01:20, 323.38 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20968/47780 [01:15<01:30, 295.53 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18558/47780 [01:15<02:23, 203.53 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19186/47780 [01:15<01:55, 247.48 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19108/47780 [01:15<01:38, 292.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20063/47780 [01:15<01:37, 282.90 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19936/47780 [01:15<02:10, 213.42 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21003/47780 [01:15<01:26, 310.55 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18587/47780 [01:15<02:10, 224.28 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11658/47780 [01:15<01:41, 356.05 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21678/47780 [01:15<01:25, 305.90 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19212/47780 [01:15<01:53, 250.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20098/47780 [01:15<01:32, 299.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19139/47780 [01:15<01:44, 273.05 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21040/47780 [01:15<01:22, 323.81 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19958/47780 [01:15<02:14, 207.21 examples/s]
Tokenizing train dataset (num_proc=32):  24%|â–ˆâ–ˆâ–       | 11698/47780 [01:15<01:38, 364.83 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18610/47780 [01:15<02:12, 219.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19239/47780 [01:15<01:53, 250.57 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21709/47780 [01:15<01:28, 295.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19168/47780 [01:15<01:43, 277.34 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20129/47780 [01:15<01:37, 283.07 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21075/47780 [01:15<01:20, 331.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19983/47780 [01:15<02:07, 217.84 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11748/47780 [01:15<01:29, 402.24 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18633/47780 [01:15<02:14, 216.59 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19265/47780 [01:15<01:53, 250.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21743/47780 [01:15<01:30, 289.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19197/47780 [01:15<01:44, 273.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20160/47780 [01:15<01:36, 287.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21109/47780 [01:15<01:22, 323.97 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11790/47780 [01:15<01:29, 403.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20010/47780 [01:16<02:02, 227.30 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18659/47780 [01:16<02:08, 226.29 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19291/47780 [01:16<02:00, 236.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21773/47780 [01:16<01:31, 285.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20191/47780 [01:16<01:38, 279.58 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11835/47780 [01:16<01:26, 416.30 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19225/47780 [01:16<01:51, 256.68 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20033/47780 [01:16<02:01, 227.91 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18682/47780 [01:16<02:15, 215.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21142/47780 [01:16<01:30, 293.78 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19317/47780 [01:16<01:57, 243.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21808/47780 [01:16<01:25, 302.66 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11879/47780 [01:16<01:26, 416.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20060/47780 [01:16<01:58, 234.64 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19252/47780 [01:16<01:56, 244.69 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21172/47780 [01:16<01:32, 289.20 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18711/47780 [01:16<02:08, 225.77 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20220/47780 [01:16<01:52, 244.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19342/47780 [01:16<01:58, 239.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21843/47780 [01:16<01:25, 302.64 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–       | 11921/47780 [01:16<01:27, 409.63 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20088/47780 [01:16<01:55, 239.75 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19277/47780 [01:16<01:57, 243.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20249/47780 [01:16<01:48, 252.66 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21202/47780 [01:16<01:35, 277.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19367/47780 [01:16<01:59, 238.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18734/47780 [01:16<02:17, 210.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21880/47780 [01:16<01:25, 304.41 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11964/47780 [01:16<01:27, 410.98 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19313/47780 [01:16<01:46, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20114/47780 [01:16<02:01, 227.18 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20276/47780 [01:16<01:48, 254.48 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18757/47780 [01:16<02:14, 215.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19393/47780 [01:16<01:57, 240.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21232/47780 [01:16<01:38, 268.76 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21912/47780 [01:16<01:25, 302.87 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12007/47780 [01:16<01:27, 407.03 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19349/47780 [01:16<01:37, 292.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20137/47780 [01:16<02:05, 220.67 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19422/47780 [01:16<01:51, 254.59 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20303/47780 [01:16<01:52, 245.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18779/47780 [01:16<02:17, 210.21 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21267/47780 [01:16<01:33, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12057/47780 [01:16<01:22, 433.65 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21943/47780 [01:16<01:30, 285.26 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19379/47780 [01:16<01:38, 288.23 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20164/47780 [01:16<02:00, 229.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20335/47780 [01:16<01:43, 265.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21304/47780 [01:16<01:26, 304.58 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18804/47780 [01:16<02:16, 211.79 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19448/47780 [01:16<01:58, 239.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21985/47780 [01:16<01:21, 314.71 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12101/47780 [01:16<01:30, 393.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19409/47780 [01:16<01:42, 275.68 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20363/47780 [01:16<01:47, 255.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21335/47780 [01:16<01:29, 296.90 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19474/47780 [01:16<01:56, 242.68 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20188/47780 [01:16<02:13, 206.87 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18828/47780 [01:16<02:16, 212.74 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22020/47780 [01:16<01:20, 320.88 examples/s]
Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 12145/47780 [01:16<01:28, 402.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19438/47780 [01:16<01:44, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20397/47780 [01:16<01:38, 278.39 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18856/47780 [01:16<02:06, 228.33 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19499/47780 [01:16<02:03, 228.81 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21365/47780 [01:16<01:36, 272.82 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20210/47780 [01:17<02:24, 190.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22054/47780 [01:16<01:21, 315.34 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12186/47780 [01:16<01:29, 399.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19468/47780 [01:16<01:43, 272.91 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20428/47780 [01:17<01:37, 281.06 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18879/47780 [01:17<02:07, 226.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21393/47780 [01:17<01:39, 266.18 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19525/47780 [01:17<02:05, 224.29 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20233/47780 [01:17<02:18, 199.21 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22089/47780 [01:17<01:20, 318.23 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12236/47780 [01:17<01:24, 418.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19496/47780 [01:17<01:43, 274.35 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20465/47780 [01:17<01:30, 302.76 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18903/47780 [01:17<02:08, 225.32 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21420/47780 [01:17<01:39, 265.29 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19548/47780 [01:17<02:08, 219.53 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22123/47780 [01:17<01:20, 317.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19525/47780 [01:17<01:42, 275.70 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20502/47780 [01:17<01:24, 321.87 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20254/47780 [01:17<02:38, 173.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18929/47780 [01:17<02:03, 233.06 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12280/47780 [01:17<01:38, 359.98 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21449/47780 [01:17<01:38, 268.13 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22161/47780 [01:17<01:17, 331.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19571/47780 [01:17<02:12, 213.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19553/47780 [01:17<01:48, 259.49 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20543/47780 [01:17<01:19, 343.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20275/47780 [01:17<02:31, 181.08 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18956/47780 [01:17<02:01, 238.00 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12356/47780 [01:17<01:17, 457.26 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21476/47780 [01:17<01:42, 257.21 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19607/47780 [01:17<01:51, 251.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22196/47780 [01:17<01:18, 325.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19582/47780 [01:17<01:46, 264.98 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20582/47780 [01:17<01:16, 356.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20294/47780 [01:17<02:34, 177.87 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18981/47780 [01:17<01:59, 241.04 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12406/47780 [01:17<01:22, 427.69 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21503/47780 [01:17<01:43, 254.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22229/47780 [01:17<01:21, 312.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19633/47780 [01:17<01:59, 234.85 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19609/47780 [01:17<01:50, 255.02 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20618/47780 [01:17<01:21, 333.68 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19013/47780 [01:17<01:50, 260.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20320/47780 [01:17<02:23, 191.35 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12459/47780 [01:17<01:18, 449.37 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21533/47780 [01:17<01:38, 267.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19657/47780 [01:17<01:59, 234.87 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22261/47780 [01:17<01:27, 290.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19637/47780 [01:17<01:49, 257.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20652/47780 [01:17<01:21, 332.26 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20340/47780 [01:17<02:23, 191.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19040/47780 [01:17<02:00, 238.70 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–Œ       | 12512/47780 [01:17<01:14, 470.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21560/47780 [01:17<01:41, 258.17 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19681/47780 [01:17<02:03, 227.12 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22298/47780 [01:17<01:22, 310.07 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20362/47780 [01:17<02:17, 199.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19663/47780 [01:17<01:54, 244.56 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20686/47780 [01:17<01:27, 309.43 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19077/47780 [01:17<01:44, 274.46 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21593/47780 [01:17<01:35, 273.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12561/47780 [01:17<01:21, 432.80 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19711/47780 [01:17<01:55, 242.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22337/47780 [01:17<01:17, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20388/47780 [01:17<02:07, 214.05 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19688/47780 [01:17<01:57, 239.51 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19106/47780 [01:17<01:47, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21624/47780 [01:17<01:32, 283.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20718/47780 [01:17<01:36, 279.20 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22374/47780 [01:17<01:15, 336.76 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12606/47780 [01:17<01:30, 388.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20410/47780 [01:18<02:12, 206.36 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19718/47780 [01:17<01:49, 255.32 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19737/47780 [01:18<02:06, 222.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19134/47780 [01:17<01:46, 268.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21654/47780 [01:17<01:31, 285.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20759/47780 [01:18<01:27, 310.06 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22418/47780 [01:18<01:10, 362.11 examples/s]
Tokenizing train dataset (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 12655/47780 [01:18<01:26, 405.96 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20431/47780 [01:18<02:16, 200.70 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19760/47780 [01:18<02:07, 219.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19744/47780 [01:18<01:53, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21683/47780 [01:18<01:39, 262.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22460/47780 [01:18<01:07, 374.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20791/47780 [01:18<01:35, 282.45 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12697/47780 [01:18<01:27, 401.28 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19163/47780 [01:18<02:10, 219.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20452/47780 [01:18<02:17, 198.80 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19778/47780 [01:18<01:43, 269.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19783/47780 [01:18<02:19, 200.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21711/47780 [01:18<01:37, 267.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20828/47780 [01:18<01:30, 298.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22498/47780 [01:18<01:12, 347.48 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19211/47780 [01:18<01:42, 278.09 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20472/47780 [01:18<02:20, 194.78 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19808/47780 [01:18<01:43, 269.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12739/47780 [01:18<01:33, 374.30 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21743/47780 [01:18<01:32, 280.27 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19804/47780 [01:18<02:23, 195.15 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20860/47780 [01:18<01:30, 298.13 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20500/47780 [01:18<02:04, 218.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22534/47780 [01:18<01:16, 329.51 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19241/47780 [01:18<01:44, 272.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19844/47780 [01:18<01:37, 285.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12782/47780 [01:18<01:30, 388.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21776/47780 [01:18<01:31, 283.59 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19824/47780 [01:18<02:36, 178.57 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20525/47780 [01:18<01:59, 227.52 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20891/47780 [01:18<01:35, 282.61 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22580/47780 [01:18<01:09, 360.85 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12825/47780 [01:18<01:28, 395.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19876/47780 [01:18<01:35, 291.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19270/47780 [01:18<01:53, 250.54 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21809/47780 [01:18<01:27, 296.68 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19849/47780 [01:18<02:23, 194.02 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20548/47780 [01:18<02:03, 220.83 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20920/47780 [01:18<01:38, 272.95 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22617/47780 [01:18<01:11, 350.57 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12866/47780 [01:18<01:29, 390.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19906/47780 [01:18<01:39, 281.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21839/47780 [01:18<01:30, 287.74 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19297/47780 [01:18<01:55, 245.57 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19869/47780 [01:18<02:27, 189.60 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20574/47780 [01:18<01:57, 231.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22654/47780 [01:18<01:11, 353.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20948/47780 [01:18<01:39, 269.21 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12909/47780 [01:18<01:28, 393.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19935/47780 [01:18<01:41, 274.48 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21868/47780 [01:18<01:29, 288.19 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19897/47780 [01:18<02:10, 213.58 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19323/47780 [01:18<02:02, 232.38 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20601/47780 [01:18<01:52, 241.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22695/47780 [01:18<01:07, 369.10 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20982/47780 [01:18<01:33, 285.52 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12950/47780 [01:18<01:29, 387.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19964/47780 [01:18<01:39, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21901/47780 [01:18<01:27, 297.01 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19928/47780 [01:18<01:56, 240.01 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19347/47780 [01:18<02:02, 232.06 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20626/47780 [01:18<01:51, 242.84 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22733/47780 [01:18<01:08, 367.65 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21012/47780 [01:18<01:36, 276.95 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19993/47780 [01:18<01:39, 278.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12992/47780 [01:18<01:29, 389.71 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21931/47780 [01:18<01:30, 284.47 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19955/47780 [01:19<01:54, 243.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19371/47780 [01:19<02:06, 224.41 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22770/47780 [01:19<01:09, 360.41 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20026/47780 [01:19<01:34, 292.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20651/47780 [01:19<02:04, 218.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21041/47780 [01:19<01:39, 268.96 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13032/47780 [01:18<01:31, 377.79 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21961/47780 [01:19<01:30, 285.84 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19397/47780 [01:19<02:01, 233.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19981/47780 [01:19<02:03, 225.12 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13089/47780 [01:19<01:20, 429.07 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22807/47780 [01:19<01:15, 332.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21070/47780 [01:19<01:39, 268.97 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20675/47780 [01:19<02:05, 215.91 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20056/47780 [01:19<01:48, 256.43 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21990/47780 [01:19<01:33, 275.87 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19421/47780 [01:19<02:05, 225.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20005/47780 [01:19<02:09, 214.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22841/47780 [01:19<01:15, 330.91 examples/s]
Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13133/47780 [01:19<01:21, 426.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21101/47780 [01:19<01:37, 274.99 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20697/47780 [01:19<02:11, 205.91 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20090/47780 [01:19<01:42, 270.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22018/47780 [01:19<01:38, 261.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19447/47780 [01:19<02:00, 235.06 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20030/47780 [01:19<02:06, 219.98 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13177/47780 [01:19<01:21, 426.11 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21129/47780 [01:19<01:39, 266.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20721/47780 [01:19<02:07, 212.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22875/47780 [01:19<01:20, 309.60 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20126/47780 [01:19<01:34, 291.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22047/47780 [01:19<01:36, 266.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19472/47780 [01:19<02:00, 234.20 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13223/47780 [01:19<01:21, 426.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21156/47780 [01:19<01:41, 261.65 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20053/47780 [01:19<02:13, 206.98 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22912/47780 [01:19<01:16, 323.87 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20745/47780 [01:19<02:06, 213.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22077/47780 [01:19<01:34, 272.78 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20156/47780 [01:19<01:39, 277.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19499/47780 [01:19<01:57, 240.45 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13268/47780 [01:19<01:19, 432.11 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20076/47780 [01:19<02:11, 210.92 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22946/47780 [01:19<01:17, 319.14 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21183/47780 [01:19<01:45, 250.95 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20767/47780 [01:19<02:18, 195.72 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20200/47780 [01:19<01:27, 315.57 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19533/47780 [01:19<01:51, 252.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22105/47780 [01:19<01:43, 248.87 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13312/47780 [01:19<01:22, 420.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20102/47780 [01:19<02:04, 221.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22982/47780 [01:19<01:16, 324.84 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20793/47780 [01:19<02:09, 209.10 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20245/47780 [01:19<01:18, 348.77 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21210/47780 [01:19<01:56, 228.98 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19559/47780 [01:19<01:52, 251.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22140/47780 [01:19<01:35, 269.69 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13355/47780 [01:19<01:27, 393.28 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20126/47780 [01:19<02:07, 216.95 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23015/47780 [01:19<01:19, 310.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20815/47780 [01:19<02:18, 194.46 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21234/47780 [01:19<02:02, 217.04 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20281/47780 [01:19<01:26, 319.38 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19585/47780 [01:19<01:58, 238.28 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22168/47780 [01:19<01:39, 258.66 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20151/47780 [01:19<02:02, 225.02 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13395/47780 [01:19<01:28, 389.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23047/47780 [01:19<01:19, 310.64 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21258/47780 [01:19<02:00, 220.50 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20314/47780 [01:20<01:27, 315.70 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20835/47780 [01:20<02:26, 184.02 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22198/47780 [01:19<01:37, 261.93 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19609/47780 [01:20<02:04, 226.33 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13446/47780 [01:19<01:22, 414.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23094/47780 [01:20<01:10, 350.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20174/47780 [01:20<02:08, 214.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21281/47780 [01:20<01:59, 220.89 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20348/47780 [01:20<01:27, 315.15 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20854/47780 [01:20<02:27, 182.01 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22225/47780 [01:20<01:37, 261.28 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19633/47780 [01:20<02:03, 227.56 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20205/47780 [01:20<01:56, 236.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23130/47780 [01:20<01:12, 342.07 examples/s]
Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13489/47780 [01:20<01:36, 354.92 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21304/47780 [01:20<01:59, 221.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20873/47780 [01:20<02:29, 180.20 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22253/47780 [01:20<01:37, 260.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20382/47780 [01:20<01:29, 304.47 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19656/47780 [01:20<02:10, 216.32 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20230/47780 [01:20<01:55, 239.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23165/47780 [01:20<01:11, 343.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21328/47780 [01:20<01:58, 223.78 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20892/47780 [01:20<02:27, 182.79 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20416/47780 [01:20<01:27, 312.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22288/47780 [01:20<01:31, 279.45 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19679/47780 [01:20<02:09, 217.07 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20260/47780 [01:20<01:47, 254.84 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23205/47780 [01:20<01:10, 349.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13528/47780 [01:20<01:52, 303.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21353/47780 [01:20<01:55, 228.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20913/47780 [01:20<02:21, 189.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20448/47780 [01:20<01:27, 311.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22318/47780 [01:20<01:29, 285.19 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19707/47780 [01:20<02:02, 230.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23246/47780 [01:20<01:06, 366.46 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20286/47780 [01:20<01:50, 247.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13561/47780 [01:20<01:55, 297.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21378/47780 [01:20<01:55, 229.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20934/47780 [01:20<02:18, 193.91 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22349/47780 [01:20<01:29, 285.74 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20480/47780 [01:20<01:35, 287.35 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20311/47780 [01:20<01:50, 248.22 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19738/47780 [01:20<01:56, 241.61 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–Š       | 13702/47780 [01:20<01:00, 560.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23283/47780 [01:20<01:13, 332.91 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21406/47780 [01:20<01:48, 243.12 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20954/47780 [01:20<02:26, 183.19 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22378/47780 [01:20<01:34, 269.40 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20511/47780 [01:20<01:35, 286.71 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19764/47780 [01:20<01:54, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20336/47780 [01:20<01:58, 232.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23317/47780 [01:20<01:13, 334.52 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21431/47780 [01:20<01:55, 227.41 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13767/47780 [01:20<01:07, 501.35 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20973/47780 [01:20<02:31, 177.21 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22406/47780 [01:20<01:36, 263.32 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19791/47780 [01:20<01:52, 249.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20544/47780 [01:20<01:34, 287.42 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20360/47780 [01:20<02:05, 218.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23351/47780 [01:20<01:17, 315.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21459/47780 [01:20<01:48, 241.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20992/47780 [01:20<02:29, 178.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20574/47780 [01:20<01:34, 286.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22433/47780 [01:20<01:40, 253.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19817/47780 [01:20<02:00, 232.18 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13824/47780 [01:20<01:13, 464.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20383/47780 [01:20<02:06, 215.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21487/47780 [01:20<01:45, 250.08 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23384/47780 [01:20<01:22, 296.19 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21019/47780 [01:21<02:11, 204.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20607/47780 [01:20<01:31, 298.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19846/47780 [01:21<01:54, 243.43 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22459/47780 [01:20<01:46, 236.69 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21514/47780 [01:21<01:42, 255.77 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13875/47780 [01:20<01:19, 427.39 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20405/47780 [01:21<02:18, 198.22 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21040/47780 [01:21<02:15, 196.96 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23415/47780 [01:21<01:28, 275.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20638/47780 [01:21<01:32, 292.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19873/47780 [01:21<01:52, 248.03 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22485/47780 [01:21<01:47, 235.70 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20435/47780 [01:21<02:01, 224.90 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21540/47780 [01:21<01:49, 240.27 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13921/47780 [01:21<01:22, 411.58 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23451/47780 [01:21<01:22, 295.56 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21060/47780 [01:21<02:16, 195.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20671/47780 [01:21<01:30, 299.35 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19904/47780 [01:21<01:50, 251.29 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22509/47780 [01:21<01:53, 222.24 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20460/47780 [01:21<02:06, 215.24 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23482/47780 [01:21<01:22, 296.29 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21565/47780 [01:21<01:55, 227.73 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21090/47780 [01:21<01:58, 225.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 13965/47780 [01:21<01:23, 402.80 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19934/47780 [01:21<01:45, 264.35 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20702/47780 [01:21<01:38, 274.60 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22546/47780 [01:21<01:36, 261.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21113/47780 [01:21<01:59, 222.39 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23513/47780 [01:21<01:21, 296.79 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14008/47780 [01:21<01:22, 406.93 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21589/47780 [01:21<02:00, 217.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20483/47780 [01:21<02:13, 204.03 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19964/47780 [01:21<01:42, 271.19 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20730/47780 [01:21<01:41, 267.57 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22579/47780 [01:21<01:30, 277.64 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14051/47780 [01:21<01:22, 407.62 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21139/47780 [01:21<01:57, 227.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21613/47780 [01:21<01:57, 222.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20509/47780 [01:21<02:06, 216.36 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23544/47780 [01:21<01:29, 269.78 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19992/47780 [01:21<01:45, 262.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22608/47780 [01:21<01:32, 273.49 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20758/47780 [01:21<01:49, 246.02 examples/s]
Tokenizing train dataset (num_proc=32):  29%|â–ˆâ–ˆâ–‰       | 14093/47780 [01:21<01:24, 396.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21636/47780 [01:21<01:58, 220.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21163/47780 [01:21<02:03, 216.15 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20532/47780 [01:21<02:11, 206.58 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23572/47780 [01:21<01:34, 256.66 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20790/47780 [01:21<01:42, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22636/47780 [01:21<01:39, 253.91 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20020/47780 [01:21<01:57, 237.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14134/47780 [01:21<01:25, 393.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21196/47780 [01:21<01:48, 244.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21659/47780 [01:21<02:01, 215.61 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20560/47780 [01:21<02:01, 223.90 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23605/47780 [01:21<01:27, 275.69 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22667/47780 [01:21<01:33, 269.04 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20817/47780 [01:21<01:43, 260.55 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20061/47780 [01:21<01:41, 271.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14178/47780 [01:21<01:24, 397.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21684/47780 [01:21<01:58, 220.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21221/47780 [01:21<01:53, 233.31 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20583/47780 [01:21<02:04, 218.19 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23634/47780 [01:21<01:30, 267.87 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20848/47780 [01:21<01:38, 272.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22695/47780 [01:21<01:35, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20089/47780 [01:21<01:41, 273.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14224/47780 [01:21<01:20, 414.94 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21709/47780 [01:21<01:55, 226.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21249/47780 [01:22<01:50, 240.88 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20606/47780 [01:22<02:04, 218.16 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23662/47780 [01:21<01:31, 262.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20878/47780 [01:22<01:37, 277.24 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20117/47780 [01:22<01:41, 272.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22722/47780 [01:22<01:39, 252.70 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21737/47780 [01:22<01:50, 236.02 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14266/47780 [01:22<01:30, 370.08 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21274/47780 [01:22<01:54, 230.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23698/47780 [01:22<01:24, 286.30 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20629/47780 [01:22<02:14, 202.21 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20922/47780 [01:22<01:24, 319.73 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22751/47780 [01:22<01:35, 262.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20151/47780 [01:22<01:36, 285.15 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21761/47780 [01:22<01:52, 231.84 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–‰       | 14318/47780 [01:22<01:22, 407.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21298/47780 [01:22<01:54, 230.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23733/47780 [01:22<01:20, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20652/47780 [01:22<02:09, 209.40 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20185/47780 [01:22<01:31, 300.36 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20955/47780 [01:22<01:27, 305.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22778/47780 [01:22<01:36, 260.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21785/47780 [01:22<01:52, 231.34 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21323/47780 [01:22<01:53, 233.47 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14363/47780 [01:22<01:24, 396.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23775/47780 [01:22<01:12, 330.68 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20683/47780 [01:22<01:55, 234.67 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22808/47780 [01:22<01:34, 264.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20986/47780 [01:22<01:31, 293.39 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20216/47780 [01:22<01:38, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21814/47780 [01:22<01:44, 247.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21347/47780 [01:22<01:56, 227.09 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14409/47780 [01:22<01:21, 410.20 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23809/47780 [01:22<01:13, 325.90 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20709/47780 [01:22<01:53, 239.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22835/47780 [01:22<01:36, 258.76 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21016/47780 [01:22<01:35, 280.70 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20245/47780 [01:22<01:40, 274.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21840/47780 [01:22<01:43, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14460/47780 [01:22<01:16, 437.31 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20736/47780 [01:22<01:49, 246.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21375/47780 [01:22<01:51, 237.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23842/47780 [01:22<01:15, 316.27 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21867/47780 [01:22<01:41, 254.67 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20276/47780 [01:22<01:37, 281.09 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22861/47780 [01:22<01:42, 242.68 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21047/47780 [01:22<01:37, 273.05 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20761/47780 [01:22<01:49, 246.24 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14505/47780 [01:22<01:21, 407.40 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21399/47780 [01:22<02:01, 217.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23874/47780 [01:22<01:22, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22891/47780 [01:22<01:39, 250.16 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21893/47780 [01:22<01:45, 244.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20305/47780 [01:22<01:42, 268.43 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21075/47780 [01:22<01:42, 260.98 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20787/47780 [01:22<01:47, 250.16 examples/s]
Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 14559/47780 [01:22<01:15, 438.66 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21425/47780 [01:22<01:56, 227.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23910/47780 [01:22<01:18, 304.06 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22925/47780 [01:22<01:33, 266.09 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21919/47780 [01:22<01:50, 233.87 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20817/47780 [01:22<01:43, 261.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21102/47780 [01:22<01:46, 249.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20333/47780 [01:22<01:50, 247.42 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14604/47780 [01:22<01:16, 432.16 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23942/47780 [01:22<01:18, 305.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21448/47780 [01:22<02:03, 213.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22957/47780 [01:22<01:28, 280.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20844/47780 [01:22<01:42, 263.41 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21956/47780 [01:22<01:37, 264.92 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20366/47780 [01:22<01:44, 263.55 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21128/47780 [01:22<01:51, 239.89 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14648/47780 [01:22<01:17, 425.89 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23977/47780 [01:22<01:15, 317.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21473/47780 [01:23<01:58, 221.37 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22993/47780 [01:22<01:21, 303.03 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20871/47780 [01:23<01:42, 262.64 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20394/47780 [01:23<01:44, 262.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21984/47780 [01:23<01:42, 252.28 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14706/47780 [01:22<01:10, 468.05 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21161/47780 [01:23<01:46, 250.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24023/47780 [01:23<01:07, 354.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21497/47780 [01:23<01:57, 224.10 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23024/47780 [01:23<01:22, 298.40 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20900/47780 [01:23<01:41, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22010/47780 [01:23<01:42, 251.63 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20421/47780 [01:23<01:45, 258.47 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14754/47780 [01:23<01:13, 450.90 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21190/47780 [01:23<01:42, 258.21 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24061/47780 [01:23<01:06, 357.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21527/47780 [01:23<01:48, 242.65 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23055/47780 [01:23<01:22, 298.31 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20928/47780 [01:23<01:44, 257.71 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22042/47780 [01:23<01:35, 270.30 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20449/47780 [01:23<01:47, 253.85 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21219/47780 [01:23<01:40, 264.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24098/47780 [01:23<01:07, 352.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21552/47780 [01:23<01:49, 239.21 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14800/47780 [01:23<01:17, 424.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23086/47780 [01:23<01:24, 291.64 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20962/47780 [01:23<01:41, 263.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21246/47780 [01:23<01:44, 253.96 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21580/47780 [01:23<01:45, 248.04 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20475/47780 [01:23<01:54, 237.97 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22070/47780 [01:23<01:48, 236.39 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14843/47780 [01:23<01:20, 407.87 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23116/47780 [01:23<01:24, 290.45 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24134/47780 [01:23<01:21, 291.59 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20989/47780 [01:23<01:46, 251.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21609/47780 [01:23<01:40, 259.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21274/47780 [01:23<01:42, 258.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20503/47780 [01:23<01:51, 245.57 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 14890/47780 [01:23<01:17, 423.49 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23148/47780 [01:23<01:23, 295.66 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22095/47780 [01:23<01:55, 222.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21015/47780 [01:23<01:47, 250.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21301/47780 [01:23<01:42, 259.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20528/47780 [01:23<01:50, 246.75 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21637/47780 [01:23<01:43, 251.39 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24165/47780 [01:23<01:34, 248.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22123/47780 [01:23<01:51, 229.29 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23178/47780 [01:23<01:29, 273.79 examples/s]
Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14934/47780 [01:23<01:31, 357.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20553/47780 [01:23<01:50, 246.77 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21328/47780 [01:23<01:46, 249.27 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21663/47780 [01:23<01:47, 242.82 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21041/47780 [01:23<01:57, 227.23 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24192/47780 [01:23<01:36, 244.50 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22147/47780 [01:23<01:53, 226.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23210/47780 [01:23<01:27, 281.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14999/47780 [01:23<01:17, 422.41 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20578/47780 [01:23<01:53, 240.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21354/47780 [01:23<01:48, 243.08 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21065/47780 [01:23<02:00, 221.79 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21688/47780 [01:23<01:52, 231.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22179/47780 [01:23<01:42, 248.67 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24218/47780 [01:23<01:40, 234.59 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23243/47780 [01:23<01:25, 288.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 15044/47780 [01:23<01:16, 429.53 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20603/47780 [01:23<01:54, 237.63 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21720/47780 [01:24<01:42, 253.48 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21379/47780 [01:23<01:56, 227.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21093/47780 [01:24<01:54, 232.08 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22205/47780 [01:23<01:44, 243.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24310/47780 [01:23<00:58, 403.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23273/47780 [01:23<01:28, 276.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15089/47780 [01:23<01:17, 421.36 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20634/47780 [01:24<01:47, 252.51 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21410/47780 [01:24<01:47, 244.28 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21117/47780 [01:24<01:57, 226.47 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21746/47780 [01:24<01:49, 237.78 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23303/47780 [01:24<01:26, 282.60 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15133/47780 [01:24<01:16, 426.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22230/47780 [01:24<01:52, 226.61 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24356/47780 [01:24<01:04, 365.63 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20667/47780 [01:24<01:41, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21441/47780 [01:24<01:40, 262.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21771/47780 [01:24<01:52, 230.67 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21140/47780 [01:24<02:05, 211.83 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23332/47780 [01:24<01:26, 281.76 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15183/47780 [01:24<01:14, 437.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22259/47780 [01:24<01:46, 239.84 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20694/47780 [01:24<01:45, 257.19 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24397/47780 [01:24<01:07, 345.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21472/47780 [01:24<01:37, 270.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21799/47780 [01:24<01:46, 243.34 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21169/47780 [01:24<01:55, 230.13 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23370/47780 [01:24<01:20, 305.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22284/47780 [01:24<01:46, 238.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15228/47780 [01:24<01:17, 421.34 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20721/47780 [01:24<01:44, 257.89 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21504/47780 [01:24<01:32, 283.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24435/47780 [01:24<01:11, 325.39 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21824/47780 [01:24<01:47, 242.58 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21194/47780 [01:24<01:53, 234.77 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22309/47780 [01:24<01:46, 240.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23401/47780 [01:24<01:22, 293.87 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21535/47780 [01:24<01:30, 291.08 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20747/47780 [01:24<01:50, 244.62 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15271/47780 [01:24<01:32, 350.49 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21218/47780 [01:24<01:53, 234.44 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21854/47780 [01:24<01:42, 253.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23431/47780 [01:24<01:24, 289.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22334/47780 [01:24<01:50, 229.98 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24471/47780 [01:24<01:16, 304.27 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21574/47780 [01:24<01:22, 316.17 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20776/47780 [01:24<01:46, 254.00 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21247/47780 [01:24<01:46, 248.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21880/47780 [01:24<01:46, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22364/47780 [01:24<01:44, 244.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23461/47780 [01:24<01:29, 270.63 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15309/47780 [01:24<01:47, 301.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21607/47780 [01:24<01:22, 316.37 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24505/47780 [01:24<01:22, 280.53 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21273/47780 [01:24<01:46, 249.24 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20802/47780 [01:24<01:54, 234.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21909/47780 [01:24<01:41, 254.92 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22392/47780 [01:24<01:39, 254.26 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23492/47780 [01:24<01:27, 278.62 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15412/47780 [01:24<01:11, 454.46 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24535/47780 [01:24<01:22, 282.46 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21640/47780 [01:24<01:25, 306.28 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21300/47780 [01:24<01:44, 253.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20826/47780 [01:24<01:55, 233.48 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22422/47780 [01:24<01:35, 264.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21935/47780 [01:24<01:50, 234.31 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23523/47780 [01:24<01:25, 284.14 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24565/47780 [01:24<01:22, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21672/47780 [01:24<01:25, 306.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21326/47780 [01:24<01:43, 255.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20850/47780 [01:24<01:58, 228.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15463/47780 [01:24<01:18, 412.16 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22449/47780 [01:24<01:36, 262.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21959/47780 [01:25<01:49, 235.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23556/47780 [01:24<01:23, 291.03 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24596/47780 [01:25<01:21, 285.68 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21356/47780 [01:25<01:39, 265.60 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21703/47780 [01:25<01:29, 290.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20873/47780 [01:25<02:03, 218.54 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22479/47780 [01:25<01:36, 261.62 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21983/47780 [01:25<01:51, 231.99 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23588/47780 [01:25<01:20, 298.80 examples/s]
Tokenizing train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15508/47780 [01:25<01:23, 385.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21739/47780 [01:25<01:24, 306.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24626/47780 [01:25<01:24, 274.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21384/47780 [01:25<01:44, 252.80 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20895/47780 [01:25<02:03, 216.91 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22507/47780 [01:25<01:35, 264.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22007/47780 [01:25<01:51, 231.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23621/47780 [01:25<01:19, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15550/47780 [01:25<01:22, 390.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21773/47780 [01:25<01:23, 312.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24654/47780 [01:25<01:26, 267.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21429/47780 [01:25<01:27, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20923/47780 [01:25<01:59, 224.30 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22035/47780 [01:25<01:44, 245.31 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22534/47780 [01:25<01:38, 256.88 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23653/47780 [01:25<01:20, 298.51 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15591/47780 [01:25<01:25, 376.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24681/47780 [01:25<01:27, 265.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21805/47780 [01:25<01:25, 304.31 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21478/47780 [01:25<01:16, 342.37 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20949/47780 [01:25<01:55, 231.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22568/47780 [01:25<01:30, 280.03 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23685/47780 [01:25<01:19, 301.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22060/47780 [01:25<01:54, 225.58 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15630/47780 [01:25<01:24, 379.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24714/47780 [01:25<01:21, 281.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21837/47780 [01:25<01:24, 305.34 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20978/47780 [01:25<01:50, 242.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21513/47780 [01:25<01:19, 329.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23726/47780 [01:25<01:14, 321.34 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22086/47780 [01:25<01:49, 234.96 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15670/47780 [01:25<01:24, 381.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22597/47780 [01:25<01:36, 259.77 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21547/47780 [01:25<01:19, 328.36 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21009/47780 [01:25<01:44, 255.87 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21869/47780 [01:25<01:33, 277.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22112/47780 [01:25<01:46, 241.92 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24743/47780 [01:25<01:36, 239.60 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15710/47780 [01:25<01:23, 386.34 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23760/47780 [01:25<01:18, 305.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22624/47780 [01:25<01:39, 253.47 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21035/47780 [01:25<01:44, 256.88 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21899/47780 [01:25<01:36, 268.83 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21580/47780 [01:25<01:26, 302.11 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15772/47780 [01:25<01:11, 446.94 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22137/47780 [01:25<01:49, 233.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22650/47780 [01:25<01:40, 250.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23791/47780 [01:25<01:21, 296.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24769/47780 [01:25<01:43, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21061/47780 [01:25<01:46, 251.84 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21618/47780 [01:25<01:20, 323.01 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15818/47780 [01:25<01:11, 445.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21927/47780 [01:25<01:41, 254.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22164/47780 [01:25<01:47, 238.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22676/47780 [01:25<01:41, 247.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23821/47780 [01:25<01:24, 282.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24793/47780 [01:25<01:51, 206.23 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21088/47780 [01:25<01:46, 251.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21957/47780 [01:25<01:36, 266.33 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21651/47780 [01:25<01:26, 301.63 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15863/47780 [01:25<01:17, 413.35 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22189/47780 [01:26<01:55, 221.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22701/47780 [01:25<01:48, 231.37 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23850/47780 [01:25<01:28, 270.02 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24873/47780 [01:25<01:05, 347.20 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21114/47780 [01:26<01:46, 250.73 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21986/47780 [01:26<01:36, 266.00 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15912/47780 [01:25<01:14, 430.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21683/47780 [01:26<01:30, 288.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22214/47780 [01:26<01:52, 227.10 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22729/47780 [01:26<01:44, 240.59 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23885/47780 [01:26<01:22, 288.52 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24911/47780 [01:26<01:08, 334.88 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21140/47780 [01:26<01:50, 240.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22015/47780 [01:26<01:35, 269.15 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22237/47780 [01:26<01:52, 227.57 examples/s]
Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15956/47780 [01:26<01:17, 411.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21713/47780 [01:26<01:32, 281.43 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22768/47780 [01:26<01:30, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23917/47780 [01:26<01:22, 287.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24947/47780 [01:26<01:08, 334.72 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21165/47780 [01:26<01:55, 229.95 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22043/47780 [01:26<01:38, 260.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15998/47780 [01:26<01:17, 412.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22260/47780 [01:26<01:55, 220.76 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22799/47780 [01:26<01:29, 278.58 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23946/47780 [01:26<01:23, 285.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21742/47780 [01:26<01:40, 258.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24983/47780 [01:26<01:10, 323.89 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21192/47780 [01:26<01:52, 235.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22286/47780 [01:26<01:52, 227.03 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16040/47780 [01:26<01:19, 396.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22070/47780 [01:26<01:45, 243.58 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22832/47780 [01:26<01:26, 289.69 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23981/47780 [01:26<01:19, 300.02 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21769/47780 [01:26<01:45, 246.79 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21223/47780 [01:26<01:44, 253.54 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25017/47780 [01:26<01:13, 308.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22314/47780 [01:26<01:45, 241.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 16081/47780 [01:26<01:20, 396.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22101/47780 [01:26<01:40, 256.79 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22864/47780 [01:26<01:24, 294.96 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24013/47780 [01:26<01:23, 286.21 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21799/47780 [01:26<01:41, 255.16 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21249/47780 [01:26<01:47, 246.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25054/47780 [01:26<01:11, 318.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16127/47780 [01:26<01:16, 414.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22339/47780 [01:26<01:49, 233.24 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22894/47780 [01:26<01:27, 283.46 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22127/47780 [01:26<01:52, 227.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21829/47780 [01:26<01:38, 264.39 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24045/47780 [01:26<01:24, 279.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21279/47780 [01:26<01:42, 258.90 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16169/47780 [01:26<01:18, 401.84 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22374/47780 [01:26<01:38, 257.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22930/47780 [01:26<01:22, 301.53 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25088/47780 [01:26<01:20, 281.81 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22159/47780 [01:26<01:41, 251.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21856/47780 [01:26<01:40, 257.09 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24074/47780 [01:26<01:28, 268.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21307/47780 [01:26<01:46, 248.05 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16210/47780 [01:26<01:21, 386.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22400/47780 [01:26<01:41, 249.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25119/47780 [01:26<01:20, 283.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22186/47780 [01:26<01:42, 250.80 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21882/47780 [01:26<01:41, 255.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22961/47780 [01:26<01:32, 267.38 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24102/47780 [01:26<01:27, 270.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21337/47780 [01:26<01:41, 259.43 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16251/47780 [01:26<01:20, 393.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22435/47780 [01:26<01:33, 269.76 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25156/47780 [01:26<01:14, 305.67 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22212/47780 [01:26<01:42, 249.61 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21913/47780 [01:27<01:36, 269.20 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22989/47780 [01:26<01:32, 267.58 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24130/47780 [01:26<01:31, 259.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21364/47780 [01:27<01:42, 257.03 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16292/47780 [01:26<01:21, 388.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25193/47780 [01:27<01:10, 319.64 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22464/47780 [01:27<01:37, 260.34 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22238/47780 [01:27<01:41, 250.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23021/47780 [01:27<01:28, 279.22 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21943/47780 [01:27<01:35, 270.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24157/47780 [01:27<01:30, 259.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21393/47780 [01:27<01:39, 265.93 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16339/47780 [01:27<01:17, 407.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25226/47780 [01:27<01:11, 315.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22264/47780 [01:27<01:44, 245.18 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21974/47780 [01:27<01:32, 277.57 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22491/47780 [01:27<01:44, 241.79 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23050/47780 [01:27<01:31, 270.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21425/47780 [01:27<01:34, 278.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24184/47780 [01:27<01:35, 246.41 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16390/47780 [01:27<01:15, 413.32 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25265/47780 [01:27<01:07, 332.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22297/47780 [01:27<01:34, 268.71 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22003/47780 [01:27<01:32, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23095/47780 [01:27<01:17, 319.66 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22522/47780 [01:27<01:43, 244.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21459/47780 [01:27<01:29, 292.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24209/47780 [01:27<01:37, 242.09 examples/s]
Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 16444/47780 [01:27<01:10, 443.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22330/47780 [01:27<01:29, 283.33 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25300/47780 [01:27<01:11, 312.55 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23128/47780 [01:27<01:17, 317.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22031/47780 [01:27<01:36, 266.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22547/47780 [01:27<01:44, 240.62 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21489/47780 [01:27<01:32, 284.85 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24236/47780 [01:27<01:35, 245.59 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16489/47780 [01:27<01:12, 432.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22360/47780 [01:27<01:29, 284.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25334/47780 [01:27<01:12, 309.90 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22060/47780 [01:27<01:34, 272.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23163/47780 [01:27<01:16, 320.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24271/47780 [01:27<01:26, 270.58 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22573/47780 [01:27<01:48, 233.14 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21518/47780 [01:27<01:42, 257.07 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16533/47780 [01:27<01:16, 409.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22389/47780 [01:27<01:31, 276.71 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23196/47780 [01:27<01:16, 323.14 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25369/47780 [01:27<01:11, 313.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22089/47780 [01:27<01:34, 272.07 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24299/47780 [01:27<01:29, 263.41 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22601/47780 [01:27<01:47, 233.18 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21550/47780 [01:27<01:37, 268.09 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16575/47780 [01:27<01:19, 394.81 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22117/47780 [01:27<01:33, 273.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22417/47780 [01:27<01:36, 263.48 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23229/47780 [01:27<01:17, 317.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25401/47780 [01:27<01:13, 305.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24326/47780 [01:27<01:32, 253.74 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22625/47780 [01:27<01:48, 232.42 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21583/47780 [01:27<01:31, 284.94 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16621/47780 [01:27<01:16, 408.70 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22447/47780 [01:27<01:34, 268.06 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22151/47780 [01:27<01:30, 283.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25432/47780 [01:27<01:14, 300.46 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23261/47780 [01:27<01:23, 293.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24353/47780 [01:27<01:31, 256.22 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22649/47780 [01:27<01:57, 213.81 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21613/47780 [01:27<01:37, 268.16 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16666/47780 [01:27<01:14, 420.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25463/47780 [01:27<01:13, 302.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22474/47780 [01:27<01:38, 255.72 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23292/47780 [01:27<01:22, 297.77 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22181/47780 [01:28<01:37, 261.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24379/47780 [01:27<01:32, 254.04 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22684/47780 [01:28<01:41, 246.80 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 16709/47780 [01:27<01:15, 413.58 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21641/47780 [01:28<01:41, 257.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25499/47780 [01:28<01:10, 315.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22501/47780 [01:28<01:38, 257.02 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23323/47780 [01:28<01:25, 286.86 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22211/47780 [01:28<01:35, 268.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24418/47780 [01:28<01:20, 289.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22713/47780 [01:28<01:39, 253.03 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21668/47780 [01:28<01:40, 259.25 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25531/47780 [01:28<01:10, 315.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16752/47780 [01:28<01:18, 396.72 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22529/47780 [01:28<01:39, 252.95 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23352/47780 [01:28<01:24, 287.46 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24448/47780 [01:28<01:20, 289.43 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22239/47780 [01:28<01:42, 249.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22739/47780 [01:28<01:39, 252.13 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21705/47780 [01:28<01:30, 288.43 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25564/47780 [01:28<01:11, 311.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16792/47780 [01:28<01:19, 387.53 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22555/47780 [01:28<01:41, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23381/47780 [01:28<01:28, 275.95 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24478/47780 [01:28<01:22, 282.71 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22265/47780 [01:28<01:44, 244.48 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22772/47780 [01:28<01:31, 273.61 examples/s]
Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16841/47780 [01:28<01:14, 414.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25596/47780 [01:28<01:13, 302.17 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21735/47780 [01:28<01:37, 267.31 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22586/47780 [01:28<01:35, 262.79 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23414/47780 [01:28<01:25, 284.65 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24507/47780 [01:28<01:25, 273.46 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22800/47780 [01:28<01:32, 269.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22291/47780 [01:28<01:47, 236.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25629/47780 [01:28<01:12, 307.07 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21768/47780 [01:28<01:32, 280.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22621/47780 [01:28<01:29, 282.19 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23453/47780 [01:28<01:19, 307.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24535/47780 [01:28<01:26, 267.59 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22832/47780 [01:28<01:27, 283.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22315/47780 [01:28<01:51, 228.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 16883/47780 [01:28<01:36, 321.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25662/47780 [01:28<01:15, 293.42 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22650/47780 [01:28<01:32, 271.03 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21797/47780 [01:28<01:40, 257.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23484/47780 [01:28<01:23, 291.62 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24562/47780 [01:28<01:30, 257.20 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22861/47780 [01:28<01:29, 278.81 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22340/47780 [01:28<01:48, 233.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16966/47780 [01:28<01:10, 435.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25707/47780 [01:28<01:06, 333.11 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21840/47780 [01:28<01:26, 300.77 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22678/47780 [01:28<01:34, 264.63 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23516/47780 [01:28<01:21, 297.85 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22367/47780 [01:28<01:44, 243.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24588/47780 [01:28<01:32, 249.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17015/47780 [01:28<01:09, 440.61 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22891/47780 [01:28<01:36, 258.12 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21871/47780 [01:28<01:26, 299.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25741/47780 [01:28<01:10, 313.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22708/47780 [01:28<01:33, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23546/47780 [01:28<01:27, 277.64 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24617/47780 [01:28<01:31, 252.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22392/47780 [01:28<01:48, 234.04 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22923/47780 [01:28<01:30, 274.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17063/47780 [01:28<01:09, 440.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22739/47780 [01:28<01:29, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25781/47780 [01:28<01:06, 328.86 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21902/47780 [01:28<01:28, 293.08 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24643/47780 [01:28<01:30, 254.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22416/47780 [01:29<01:51, 228.32 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22953/47780 [01:29<01:29, 276.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23575/47780 [01:28<01:36, 251.32 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17110/47780 [01:28<01:13, 419.63 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22769/47780 [01:29<01:28, 282.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25819/47780 [01:29<01:04, 340.62 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21932/47780 [01:29<01:36, 268.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22444/47780 [01:29<01:45, 240.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24669/47780 [01:29<01:35, 242.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22986/47780 [01:29<01:25, 291.14 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23606/47780 [01:29<01:30, 266.29 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17154/47780 [01:29<01:13, 414.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22807/47780 [01:29<01:21, 307.14 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25856/47780 [01:29<01:05, 336.30 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21961/47780 [01:29<01:34, 274.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24697/47780 [01:29<01:31, 252.80 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23635/47780 [01:29<01:33, 258.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22469/47780 [01:29<01:56, 217.71 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23017/47780 [01:29<01:32, 266.40 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17198/47780 [01:29<01:14, 410.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22842/47780 [01:29<01:18, 318.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25891/47780 [01:29<01:08, 319.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21990/47780 [01:29<01:35, 268.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24723/47780 [01:29<01:31, 251.99 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23673/47780 [01:29<01:23, 288.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23050/47780 [01:29<01:28, 279.83 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22492/47780 [01:29<01:58, 213.53 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22875/47780 [01:29<01:20, 310.70 examples/s]
Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17240/47780 [01:29<01:22, 370.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25925/47780 [01:29<01:10, 308.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24756/47780 [01:29<01:24, 271.20 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22018/47780 [01:29<01:40, 255.17 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23707/47780 [01:29<01:21, 295.76 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23079/47780 [01:29<01:32, 268.08 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22519/47780 [01:29<01:55, 218.23 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22907/47780 [01:29<01:22, 300.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17279/47780 [01:29<01:25, 358.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24786/47780 [01:29<01:24, 273.19 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25966/47780 [01:29<01:09, 312.52 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22047/47780 [01:29<01:41, 253.12 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23738/47780 [01:29<01:23, 287.05 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22543/47780 [01:29<01:54, 219.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23108/47780 [01:29<01:33, 262.93 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22938/47780 [01:29<01:29, 278.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 17316/47780 [01:29<01:24, 359.66 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26006/47780 [01:29<01:05, 332.12 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24814/47780 [01:29<01:28, 260.32 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22080/47780 [01:29<01:34, 271.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23768/47780 [01:29<01:26, 278.05 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23135/47780 [01:29<01:33, 264.56 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22566/47780 [01:29<01:58, 213.08 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22967/47780 [01:29<01:30, 275.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17361/47780 [01:29<01:21, 373.93 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22110/47780 [01:29<01:31, 279.44 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26041/47780 [01:29<01:05, 333.39 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24841/47780 [01:29<01:31, 251.74 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23797/47780 [01:29<01:28, 269.60 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23164/47780 [01:29<01:33, 262.94 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22589/47780 [01:29<01:57, 215.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 17400/47780 [01:29<01:21, 372.64 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26082/47780 [01:29<01:01, 354.60 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22139/47780 [01:29<01:31, 280.39 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22995/47780 [01:29<01:38, 251.90 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24867/47780 [01:29<01:37, 235.79 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23827/47780 [01:29<01:26, 277.83 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23193/47780 [01:29<01:33, 261.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22613/47780 [01:29<01:55, 217.36 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17453/47780 [01:29<01:16, 398.76 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26132/47780 [01:29<00:55, 391.51 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22168/47780 [01:29<01:31, 278.87 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23030/47780 [01:29<01:30, 274.77 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24891/47780 [01:29<01:37, 234.20 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23860/47780 [01:29<01:23, 287.12 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22638/47780 [01:30<01:52, 224.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23220/47780 [01:30<01:35, 258.28 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17508/47780 [01:29<01:08, 440.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26175/47780 [01:30<00:54, 394.59 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23059/47780 [01:30<01:29, 274.92 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22197/47780 [01:30<01:36, 265.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24919/47780 [01:30<01:34, 241.62 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22663/47780 [01:30<01:48, 231.39 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23891/47780 [01:30<01:25, 280.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23246/47780 [01:30<01:35, 256.21 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17553/47780 [01:30<01:09, 433.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26215/47780 [01:30<00:55, 386.22 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22224/47780 [01:30<01:36, 265.89 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23087/47780 [01:30<01:35, 258.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24954/47780 [01:30<01:24, 271.39 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22687/47780 [01:30<01:48, 230.98 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23920/47780 [01:30<01:25, 280.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23273/47780 [01:30<01:38, 248.66 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26256/47780 [01:30<00:55, 388.47 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17597/47780 [01:30<01:12, 414.65 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22255/47780 [01:30<01:33, 274.27 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23115/47780 [01:30<01:33, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24982/47780 [01:30<01:25, 267.81 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22711/47780 [01:30<01:48, 231.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23949/47780 [01:30<01:27, 272.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23302/47780 [01:30<01:35, 257.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26295/47780 [01:30<00:55, 384.33 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17639/47780 [01:30<01:14, 404.36 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22283/47780 [01:30<01:32, 275.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25020/47780 [01:30<01:15, 299.62 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23142/47780 [01:30<01:40, 245.66 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22737/47780 [01:30<01:44, 239.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23329/47780 [01:30<01:34, 257.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23977/47780 [01:30<01:30, 263.23 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26334/47780 [01:30<00:56, 381.45 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22314/47780 [01:30<01:34, 270.23 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25051/47780 [01:30<01:18, 289.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23174/47780 [01:30<01:33, 263.05 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22766/47780 [01:30<01:38, 254.11 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17680/47780 [01:30<01:24, 357.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23357/47780 [01:30<01:33, 261.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24008/47780 [01:30<01:27, 270.41 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22345/47780 [01:30<01:30, 281.36 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26373/47780 [01:30<00:59, 358.91 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22792/47780 [01:30<01:38, 252.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23201/47780 [01:30<01:33, 261.85 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17726/47780 [01:30<01:19, 376.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25081/47780 [01:30<01:24, 268.27 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23386/47780 [01:30<01:33, 262.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24036/47780 [01:30<01:31, 258.22 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26415/47780 [01:30<00:56, 375.80 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22389/47780 [01:30<01:19, 319.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23228/47780 [01:30<01:32, 264.00 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22820/47780 [01:30<01:36, 257.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17766/47780 [01:30<01:19, 378.68 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25110/47780 [01:30<01:23, 271.24 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23417/47780 [01:30<01:30, 267.91 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24063/47780 [01:30<01:32, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26454/47780 [01:30<00:56, 379.73 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22428/47780 [01:30<01:16, 332.05 examples/s]
Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17806/47780 [01:30<01:19, 376.64 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22846/47780 [01:30<01:40, 246.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23255/47780 [01:30<01:38, 249.10 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23446/47780 [01:30<01:30, 269.05 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24089/47780 [01:30<01:37, 243.63 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22462/47780 [01:30<01:15, 334.13 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25138/47780 [01:30<01:38, 230.42 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26493/47780 [01:30<01:01, 345.33 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22876/47780 [01:30<01:35, 262.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17845/47780 [01:30<01:22, 364.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23282/47780 [01:30<01:45, 231.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24120/47780 [01:30<01:30, 261.50 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22496/47780 [01:30<01:17, 324.82 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23473/47780 [01:31<01:43, 235.38 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25163/47780 [01:30<01:41, 223.54 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22904/47780 [01:31<01:36, 257.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17882/47780 [01:30<01:21, 365.67 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26530/47780 [01:31<01:06, 319.17 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23342/47780 [01:31<01:14, 328.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24161/47780 [01:31<01:18, 300.22 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22529/47780 [01:31<01:18, 321.44 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23505/47780 [01:31<01:35, 253.06 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25237/47780 [01:31<01:05, 346.52 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22931/47780 [01:31<01:36, 258.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17922/47780 [01:31<01:20, 371.23 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26563/47780 [01:31<01:07, 315.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24192/47780 [01:31<01:18, 299.29 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23377/47780 [01:31<01:22, 295.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22562/47780 [01:31<01:18, 320.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23533/47780 [01:31<01:35, 254.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22958/47780 [01:31<01:37, 253.30 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25274/47780 [01:31<01:08, 329.64 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17960/47780 [01:31<01:24, 353.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26596/47780 [01:31<01:07, 312.64 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24227/47780 [01:31<01:16, 307.09 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23414/47780 [01:31<01:17, 314.88 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22600/47780 [01:31<01:16, 329.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23560/47780 [01:31<01:34, 256.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22987/47780 [01:31<01:34, 262.29 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25315/47780 [01:31<01:04, 347.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26632/47780 [01:31<01:05, 322.00 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17996/47780 [01:31<01:26, 344.16 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23447/47780 [01:31<01:17, 313.31 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22633/47780 [01:31<01:16, 327.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24258/47780 [01:31<01:23, 281.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23586/47780 [01:31<01:41, 238.34 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23014/47780 [01:31<01:35, 260.03 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26678/47780 [01:31<00:59, 356.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25351/47780 [01:31<01:06, 339.27 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18039/47780 [01:31<01:21, 363.75 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23480/47780 [01:31<01:21, 297.28 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24287/47780 [01:31<01:26, 272.23 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22666/47780 [01:31<01:23, 300.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23613/47780 [01:31<01:38, 244.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23043/47780 [01:31<01:32, 268.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26717/47780 [01:31<00:57, 365.49 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25386/47780 [01:31<01:05, 341.82 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18083/47780 [01:31<01:17, 381.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22697/47780 [01:31<01:23, 299.65 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24315/47780 [01:31<01:28, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23070/47780 [01:31<01:32, 267.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23646/47780 [01:31<01:31, 262.37 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23511/47780 [01:31<01:27, 278.41 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18127/47780 [01:31<01:15, 393.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26754/47780 [01:31<00:59, 351.04 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25421/47780 [01:31<01:11, 313.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22728/47780 [01:31<01:23, 299.27 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24342/47780 [01:31<01:29, 262.30 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23098/47780 [01:31<01:32, 266.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23673/47780 [01:31<01:35, 253.19 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23540/47780 [01:31<01:32, 263.08 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26790/47780 [01:31<01:02, 338.33 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18168/47780 [01:31<01:19, 372.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25454/47780 [01:31<01:10, 314.63 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24369/47780 [01:31<01:29, 260.68 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23131/47780 [01:31<01:30, 271.90 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22759/47780 [01:31<01:27, 284.79 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23699/47780 [01:31<01:38, 244.32 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23569/47780 [01:31<01:30, 267.73 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18207/47780 [01:31<01:18, 376.99 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26826/47780 [01:31<01:02, 333.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25487/47780 [01:31<01:12, 308.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24399/47780 [01:31<01:28, 265.69 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23164/47780 [01:32<01:26, 284.86 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22792/47780 [01:31<01:24, 294.22 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23725/47780 [01:32<01:36, 248.54 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18250/47780 [01:31<01:16, 388.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26865/47780 [01:32<01:00, 346.99 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23597/47780 [01:32<01:34, 257.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25523/47780 [01:31<01:09, 319.41 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24427/47780 [01:32<01:27, 266.82 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22823/47780 [01:32<01:29, 277.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23194/47780 [01:32<01:32, 264.99 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18291/47780 [01:32<01:16, 384.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23751/47780 [01:32<01:44, 231.04 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25557/47780 [01:32<01:09, 320.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26900/47780 [01:32<01:03, 331.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23624/47780 [01:32<01:36, 249.69 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24454/47780 [01:32<01:29, 261.65 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18334/47780 [01:32<01:14, 394.20 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23221/47780 [01:32<01:34, 261.16 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23784/47780 [01:32<01:33, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26935/47780 [01:32<01:02, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22852/47780 [01:32<01:40, 248.86 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23650/47780 [01:32<01:41, 237.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25590/47780 [01:32<01:15, 293.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24481/47780 [01:32<01:28, 263.63 examples/s]
Tokenizing train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18381/47780 [01:32<01:10, 415.94 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23811/47780 [01:32<01:32, 258.62 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23248/47780 [01:32<01:34, 259.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26969/47780 [01:32<01:03, 327.02 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22889/47780 [01:32<01:28, 279.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25622/47780 [01:32<01:14, 298.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23674/47780 [01:32<01:47, 223.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24508/47780 [01:32<01:29, 259.64 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23838/47780 [01:32<01:34, 253.17 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23275/47780 [01:32<01:37, 252.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27003/47780 [01:32<01:02, 329.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18423/47780 [01:32<01:19, 369.80 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22918/47780 [01:32<01:33, 265.56 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25657/47780 [01:32<01:13, 302.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23705/47780 [01:32<01:40, 238.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24534/47780 [01:32<01:31, 253.89 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23304/47780 [01:32<01:33, 261.80 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23864/47780 [01:32<01:35, 251.30 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27038/47780 [01:32<01:03, 328.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18469/47780 [01:32<01:14, 394.07 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25688/47780 [01:32<01:13, 301.23 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23731/47780 [01:32<01:39, 242.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24563/47780 [01:32<01:28, 261.58 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22946/47780 [01:32<01:38, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27073/47780 [01:32<01:01, 334.35 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23890/47780 [01:32<01:38, 243.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23331/47780 [01:32<01:37, 250.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25719/47780 [01:32<01:12, 303.15 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 18511/47780 [01:32<01:17, 375.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23770/47780 [01:32<01:24, 282.51 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22973/47780 [01:32<01:37, 255.01 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24590/47780 [01:32<01:37, 236.66 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27116/47780 [01:32<00:58, 354.05 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23916/47780 [01:32<01:38, 243.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23358/47780 [01:32<01:36, 253.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25751/47780 [01:32<01:13, 298.24 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23799/47780 [01:32<01:26, 277.96 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23000/47780 [01:32<01:35, 258.99 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18550/47780 [01:32<01:23, 350.88 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24626/47780 [01:32<01:28, 261.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27158/47780 [01:32<00:55, 372.94 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23390/47780 [01:32<01:29, 272.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23941/47780 [01:32<01:39, 239.40 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25784/47780 [01:32<01:12, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23029/47780 [01:32<01:37, 255.08 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23828/47780 [01:32<01:30, 263.83 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24653/47780 [01:32<01:29, 257.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18587/47780 [01:32<01:32, 315.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27197/47780 [01:32<00:56, 364.97 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23418/47780 [01:33<01:31, 265.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23970/47780 [01:33<01:36, 246.39 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25815/47780 [01:32<01:12, 302.10 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23058/47780 [01:33<01:33, 263.10 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23856/47780 [01:33<01:30, 265.44 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18639/47780 [01:32<01:19, 366.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24684/47780 [01:33<01:26, 266.80 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27234/47780 [01:33<00:57, 357.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23446/47780 [01:33<01:32, 263.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23995/47780 [01:33<01:38, 240.91 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25846/47780 [01:33<01:12, 300.94 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23085/47780 [01:33<01:34, 262.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23883/47780 [01:33<01:31, 260.88 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24718/47780 [01:33<01:20, 287.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18678/47780 [01:33<01:21, 356.98 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24023/47780 [01:33<01:35, 248.88 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23473/47780 [01:33<01:35, 255.42 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25883/47780 [01:33<01:09, 317.21 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27270/47780 [01:33<01:04, 315.83 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23910/47780 [01:33<01:31, 260.11 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23112/47780 [01:33<01:40, 244.86 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24750/47780 [01:33<01:20, 286.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18715/47780 [01:33<01:22, 352.00 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23511/47780 [01:33<01:24, 288.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24056/47780 [01:33<01:28, 269.50 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25915/47780 [01:33<01:16, 284.74 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23143/47780 [01:33<01:36, 254.27 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23937/47780 [01:33<01:39, 238.86 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24782/47780 [01:33<01:18, 292.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18764/47780 [01:33<01:15, 386.67 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24090/47780 [01:33<01:22, 286.46 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27303/47780 [01:33<01:21, 250.62 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25948/47780 [01:33<01:14, 294.09 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23171/47780 [01:33<01:36, 255.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23962/47780 [01:33<01:42, 231.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23541/47780 [01:33<01:46, 227.04 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24119/47780 [01:33<01:23, 284.47 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24812/47780 [01:33<01:23, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18804/47780 [01:33<01:18, 369.55 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27392/47780 [01:33<00:51, 396.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25978/47780 [01:33<01:21, 268.29 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23988/47780 [01:33<01:40, 237.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23592/47780 [01:33<01:22, 292.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24151/47780 [01:33<01:21, 291.24 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24852/47780 [01:33<01:13, 310.18 examples/s]
Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18848/47780 [01:33<01:15, 380.80 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23197/47780 [01:33<01:54, 214.25 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27438/47780 [01:33<00:51, 392.99 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26013/47780 [01:33<01:15, 287.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24012/47780 [01:33<01:39, 237.82 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24885/47780 [01:33<01:14, 308.32 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18888/47780 [01:33<01:17, 373.32 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24181/47780 [01:33<01:28, 265.51 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23250/47780 [01:33<01:23, 292.27 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27482/47780 [01:33<00:51, 396.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23625/47780 [01:33<01:35, 252.61 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24036/47780 [01:33<01:41, 233.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26043/47780 [01:33<01:17, 281.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24917/47780 [01:33<01:14, 305.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24212/47780 [01:33<01:25, 275.04 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23282/47780 [01:33<01:21, 299.26 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18926/47780 [01:33<01:21, 355.93 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27525/47780 [01:33<00:52, 384.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23671/47780 [01:33<01:20, 298.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26074/47780 [01:33<01:15, 289.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24066/47780 [01:33<01:34, 249.77 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24948/47780 [01:33<01:18, 290.12 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24240/47780 [01:34<01:29, 262.00 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18962/47780 [01:33<01:25, 338.62 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27567/47780 [01:33<00:53, 376.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26111/47780 [01:33<01:09, 311.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23315/47780 [01:34<01:31, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24092/47780 [01:34<01:45, 223.65 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19001/47780 [01:34<01:21, 352.39 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23705/47780 [01:34<01:35, 251.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24267/47780 [01:34<01:30, 259.68 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24979/47780 [01:34<01:24, 268.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27607/47780 [01:34<00:53, 376.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26143/47780 [01:34<01:11, 304.05 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24121/47780 [01:34<01:39, 238.93 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19050/47780 [01:34<01:13, 390.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23740/47780 [01:34<01:29, 270.07 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23344/47780 [01:34<01:50, 221.86 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27646/47780 [01:34<00:54, 372.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24294/47780 [01:34<01:37, 239.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25007/47780 [01:34<01:31, 248.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26177/47780 [01:34<01:08, 313.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24146/47780 [01:34<01:42, 229.95 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23770/47780 [01:34<01:28, 270.42 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23371/47780 [01:34<01:44, 232.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25037/47780 [01:34<01:27, 258.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24319/47780 [01:34<01:42, 229.02 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27684/47780 [01:34<00:57, 351.55 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19090/47780 [01:34<01:32, 310.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26209/47780 [01:34<01:22, 261.82 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24170/47780 [01:34<01:47, 220.56 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23411/47780 [01:34<01:29, 270.93 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23800/47780 [01:34<01:31, 262.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25064/47780 [01:34<01:26, 261.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27723/47780 [01:34<00:55, 361.88 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24349/47780 [01:34<01:34, 246.82 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19174/47780 [01:34<01:05, 436.69 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26247/47780 [01:34<01:13, 291.76 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23445/47780 [01:34<01:24, 288.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24193/47780 [01:34<01:47, 219.77 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24379/47780 [01:34<01:30, 257.24 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25091/47780 [01:34<01:31, 248.09 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27761/47780 [01:34<00:56, 354.38 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23828/47780 [01:34<01:38, 242.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26279/47780 [01:34<01:12, 295.82 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19223/47780 [01:34<01:08, 418.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24216/47780 [01:34<01:48, 217.38 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23476/47780 [01:34<01:29, 271.28 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25123/47780 [01:34<01:24, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24407/47780 [01:34<01:30, 259.11 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27805/47780 [01:34<00:53, 375.66 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26310/47780 [01:34<01:13, 293.57 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19269/47780 [01:34<01:07, 422.34 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24247/47780 [01:34<01:38, 238.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23854/47780 [01:34<01:55, 207.86 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23505/47780 [01:34<01:29, 269.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25154/47780 [01:34<01:21, 275.96 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27843/47780 [01:34<00:53, 375.53 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24434/47780 [01:34<01:36, 243.12 examples/s]
Tokenizing train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19314/47780 [01:34<01:06, 425.18 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24280/47780 [01:34<01:30, 258.65 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26341/47780 [01:34<01:16, 279.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23907/47780 [01:34<01:24, 281.44 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27883/47780 [01:34<00:52, 378.54 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23535/47780 [01:34<01:29, 269.82 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25191/47780 [01:34<01:17, 292.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24464/47780 [01:34<01:30, 258.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19366/47780 [01:34<01:03, 446.00 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24307/47780 [01:34<01:33, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27922/47780 [01:34<00:52, 381.18 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23939/47780 [01:35<01:26, 274.49 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23571/47780 [01:34<01:23, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25222/47780 [01:34<01:15, 297.23 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26370/47780 [01:34<01:24, 253.30 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24493/47780 [01:35<01:28, 264.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19412/47780 [01:34<01:05, 435.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24338/47780 [01:35<01:27, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23601/47780 [01:35<01:23, 290.21 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24520/47780 [01:35<01:28, 262.85 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26397/47780 [01:35<01:26, 248.60 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23970/47780 [01:35<01:30, 262.14 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27961/47780 [01:35<00:57, 344.14 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25252/47780 [01:35<01:22, 272.92 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19457/47780 [01:35<01:04, 439.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24365/47780 [01:35<01:27, 267.26 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23635/47780 [01:35<01:20, 298.77 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26423/47780 [01:35<01:25, 249.25 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23999/47780 [01:35<01:29, 267.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25280/47780 [01:35<01:22, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27997/47780 [01:35<00:59, 334.10 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24547/47780 [01:35<01:35, 242.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19503/47780 [01:35<01:05, 434.96 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24399/47780 [01:35<01:22, 282.49 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23666/47780 [01:35<01:23, 288.04 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26449/47780 [01:35<01:26, 247.08 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25313/47780 [01:35<01:19, 282.00 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24027/47780 [01:35<01:33, 254.58 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24572/47780 [01:35<01:34, 244.60 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28032/47780 [01:35<01:00, 323.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19551/47780 [01:35<01:03, 445.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24428/47780 [01:35<01:24, 275.04 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23696/47780 [01:35<01:25, 281.80 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26474/47780 [01:35<01:27, 244.54 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25346/47780 [01:35<01:15, 295.40 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24597/47780 [01:35<01:34, 245.58 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28066/47780 [01:35<01:01, 321.21 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19596/47780 [01:35<01:03, 443.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24054/47780 [01:35<01:39, 238.74 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24464/47780 [01:35<01:20, 289.54 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23725/47780 [01:35<01:26, 277.53 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26500/47780 [01:35<01:30, 236.26 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25376/47780 [01:35<01:19, 283.57 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24627/47780 [01:35<01:31, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19646/47780 [01:35<01:01, 459.18 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28101/47780 [01:35<01:00, 324.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24080/47780 [01:35<01:39, 238.13 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24493/47780 [01:35<01:20, 289.39 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23753/47780 [01:35<01:30, 266.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24661/47780 [01:35<01:23, 277.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25408/47780 [01:35<01:17, 287.57 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26526/47780 [01:35<01:33, 227.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28135/47780 [01:35<01:00, 323.13 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19693/47780 [01:35<01:04, 438.13 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24105/47780 [01:35<01:38, 239.90 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24524/47780 [01:35<01:21, 285.73 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23781/47780 [01:35<01:29, 267.61 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24689/47780 [01:35<01:24, 274.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25437/47780 [01:35<01:19, 281.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26556/47780 [01:35<01:26, 244.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24131/47780 [01:35<01:37, 242.80 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19738/47780 [01:35<01:04, 435.71 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28169/47780 [01:35<01:03, 307.16 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24553/47780 [01:35<01:28, 263.07 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23810/47780 [01:35<01:27, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25467/47780 [01:35<01:18, 285.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26581/47780 [01:35<01:27, 243.39 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24717/47780 [01:35<01:32, 248.09 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24161/47780 [01:35<01:33, 252.96 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28211/47780 [01:35<00:59, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19782/47780 [01:35<01:07, 414.01 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23838/47780 [01:35<01:27, 272.50 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24580/47780 [01:35<01:32, 251.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25497/47780 [01:35<01:22, 269.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24749/47780 [01:36<01:27, 264.10 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24189/47780 [01:36<01:32, 254.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28246/47780 [01:35<00:59, 326.34 examples/s]
Tokenizing train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19824/47780 [01:35<01:09, 402.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26606/47780 [01:35<01:41, 207.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24606/47780 [01:36<01:33, 248.34 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23866/47780 [01:36<01:39, 241.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25525/47780 [01:36<01:24, 262.99 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24216/47780 [01:36<01:31, 256.26 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28279/47780 [01:36<00:59, 326.15 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24776/47780 [01:36<01:31, 252.53 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19865/47780 [01:36<01:09, 400.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26641/47780 [01:36<01:27, 241.47 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24248/47780 [01:36<01:26, 271.29 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25553/47780 [01:36<01:24, 262.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24631/47780 [01:36<01:44, 222.56 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23918/47780 [01:36<01:17, 307.04 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28320/47780 [01:36<00:56, 347.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24802/47780 [01:36<01:30, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19907/47780 [01:36<01:08, 405.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26667/47780 [01:36<01:26, 243.90 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24660/47780 [01:36<01:36, 238.47 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24277/47780 [01:36<01:28, 265.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28355/47780 [01:36<00:57, 340.31 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23955/47780 [01:36<01:16, 312.33 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25580/47780 [01:36<01:27, 252.95 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24832/47780 [01:36<01:28, 259.29 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19948/47780 [01:36<01:10, 392.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26693/47780 [01:36<01:25, 248.00 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24685/47780 [01:36<01:36, 240.05 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28394/47780 [01:36<00:55, 350.46 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24859/47780 [01:36<01:27, 261.56 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24304/47780 [01:36<01:30, 259.97 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19988/47780 [01:36<01:12, 382.35 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25607/47780 [01:36<01:30, 244.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26719/47780 [01:36<01:25, 246.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23987/47780 [01:36<01:23, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24716/47780 [01:36<01:29, 256.43 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24331/47780 [01:36<01:32, 253.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25634/47780 [01:36<01:28, 248.99 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20037/47780 [01:36<01:08, 403.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26751/47780 [01:36<01:19, 263.93 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28430/47780 [01:36<01:00, 320.11 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24886/47780 [01:36<01:37, 234.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24017/47780 [01:36<01:28, 269.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24743/47780 [01:36<01:32, 249.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25661/47780 [01:36<01:26, 254.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24357/47780 [01:36<01:35, 244.94 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20078/47780 [01:36<01:11, 387.90 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28463/47780 [01:36<01:03, 305.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24917/47780 [01:36<01:33, 244.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26778/47780 [01:36<01:28, 238.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24045/47780 [01:36<01:32, 255.78 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25690/47780 [01:36<01:23, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24769/47780 [01:36<01:35, 241.20 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24382/47780 [01:36<01:35, 244.74 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20120/47780 [01:36<01:10, 392.44 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28494/47780 [01:36<01:03, 304.09 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26803/47780 [01:36<01:28, 236.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24942/47780 [01:36<01:36, 235.63 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24071/47780 [01:36<01:40, 234.86 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25720/47780 [01:36<01:22, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24802/47780 [01:36<01:27, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24409/47780 [01:36<01:34, 247.50 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20174/47780 [01:36<01:04, 429.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28525/47780 [01:36<01:04, 298.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26828/47780 [01:36<01:27, 240.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24966/47780 [01:36<01:39, 229.57 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24099/47780 [01:36<01:38, 240.57 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24831/47780 [01:36<01:25, 267.32 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25747/47780 [01:36<01:22, 266.03 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24439/47780 [01:37<01:30, 259.20 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20218/47780 [01:36<01:05, 418.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28566/47780 [01:36<00:58, 328.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26858/47780 [01:36<01:23, 251.38 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24990/47780 [01:37<01:49, 207.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25777/47780 [01:37<01:19, 275.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24858/47780 [01:37<01:26, 265.08 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24129/47780 [01:37<01:34, 250.84 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24474/47780 [01:37<01:22, 282.68 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20260/47780 [01:37<01:06, 413.91 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26884/47780 [01:37<01:22, 253.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28600/47780 [01:37<01:00, 314.98 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25807/47780 [01:37<01:18, 279.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25031/47780 [01:37<01:30, 252.61 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24158/47780 [01:37<01:31, 258.49 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24885/47780 [01:37<01:28, 257.44 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24504/47780 [01:37<01:21, 285.80 examples/s]
Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20302/47780 [01:37<01:08, 401.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26912/47780 [01:37<01:20, 258.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28639/47780 [01:37<00:58, 329.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24191/47780 [01:37<01:25, 275.09 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24536/47780 [01:37<01:18, 294.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25058/47780 [01:37<01:31, 248.40 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24911/47780 [01:37<01:31, 249.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25836/47780 [01:37<01:23, 263.89 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20362/47780 [01:37<01:01, 442.79 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26941/47780 [01:37<01:18, 264.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28680/47780 [01:37<00:54, 351.78 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24219/47780 [01:37<01:25, 274.96 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25086/47780 [01:37<01:28, 256.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25872/47780 [01:37<01:16, 287.98 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24566/47780 [01:37<01:21, 285.76 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20407/47780 [01:37<01:02, 439.54 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24937/47780 [01:37<01:39, 228.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26969/47780 [01:37<01:19, 262.90 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28716/47780 [01:37<00:56, 337.48 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25118/47780 [01:37<01:24, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25903/47780 [01:37<01:16, 287.63 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24247/47780 [01:37<01:31, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24602/47780 [01:37<01:18, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20455/47780 [01:37<01:00, 450.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27004/47780 [01:37<01:12, 284.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24963/47780 [01:37<01:37, 232.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28759/47780 [01:37<00:53, 356.24 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25934/47780 [01:37<01:15, 287.47 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24276/47780 [01:37<01:30, 260.73 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20505/47780 [01:37<00:59, 461.76 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24633/47780 [01:37<01:22, 282.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24987/47780 [01:37<01:37, 234.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25146/47780 [01:37<01:36, 235.08 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27033/47780 [01:37<01:15, 273.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28796/47780 [01:37<01:01, 311.04 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25966/47780 [01:37<01:13, 296.48 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24308/47780 [01:37<01:26, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20555/47780 [01:37<00:57, 471.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24662/47780 [01:37<01:22, 281.46 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25177/47780 [01:37<01:29, 251.42 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27061/47780 [01:37<01:17, 266.42 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25011/47780 [01:37<01:46, 214.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25996/47780 [01:37<01:14, 291.06 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28829/47780 [01:37<01:03, 300.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24691/47780 [01:37<01:22, 280.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20603/47780 [01:37<01:00, 447.65 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27089/47780 [01:37<01:16, 270.21 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25203/47780 [01:37<01:31, 245.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25033/47780 [01:37<01:46, 213.94 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24336/47780 [01:37<01:46, 219.69 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28860/47780 [01:37<01:03, 299.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26027/47780 [01:37<01:19, 275.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24722/47780 [01:37<01:22, 278.75 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20657/47780 [01:37<00:58, 463.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25229/47780 [01:38<01:31, 247.60 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27117/47780 [01:37<01:20, 255.51 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25055/47780 [01:37<01:50, 205.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28898/47780 [01:38<00:59, 318.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24760/47780 [01:38<01:15, 304.63 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24360/47780 [01:38<01:56, 201.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26055/47780 [01:38<01:21, 266.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25255/47780 [01:38<01:31, 247.52 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20705/47780 [01:37<01:02, 434.49 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27149/47780 [01:38<01:16, 270.37 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25076/47780 [01:38<01:51, 203.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28946/47780 [01:38<00:52, 359.68 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24420/47780 [01:38<01:21, 287.33 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24792/47780 [01:38<01:18, 292.21 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26082/47780 [01:38<01:29, 243.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25281/47780 [01:38<01:34, 238.02 examples/s]
Tokenizing train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20750/47780 [01:38<01:03, 423.28 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25106/47780 [01:38<01:38, 230.05 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27177/47780 [01:38<01:22, 250.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28986/47780 [01:38<00:50, 370.65 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24824/47780 [01:38<01:17, 296.72 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26119/47780 [01:38<01:19, 271.13 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20793/47780 [01:38<01:04, 416.61 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24452/47780 [01:38<01:25, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25130/47780 [01:38<01:38, 230.28 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25307/47780 [01:38<01:34, 238.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29028/47780 [01:38<00:48, 384.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27203/47780 [01:38<01:24, 242.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24859/47780 [01:38<01:13, 311.52 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25155/47780 [01:38<01:35, 235.88 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25332/47780 [01:38<01:33, 241.27 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26152/47780 [01:38<01:16, 284.09 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20838/47780 [01:38<01:04, 416.73 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24481/47780 [01:38<01:28, 264.45 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29069/47780 [01:38<00:47, 391.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27229/47780 [01:38<01:27, 234.71 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24891/47780 [01:38<01:13, 310.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25185/47780 [01:38<01:30, 248.71 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24511/47780 [01:38<01:25, 270.97 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20880/47780 [01:38<01:08, 395.53 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29109/47780 [01:38<00:48, 384.85 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26181/47780 [01:38<01:24, 256.94 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25357/47780 [01:38<01:44, 215.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27256/47780 [01:38<01:25, 239.05 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24923/47780 [01:38<01:12, 313.31 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25210/47780 [01:38<01:34, 239.83 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24541/47780 [01:38<01:23, 278.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20921/47780 [01:38<01:08, 390.90 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26208/47780 [01:38<01:23, 258.06 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29148/47780 [01:38<00:50, 369.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25380/47780 [01:38<01:46, 210.14 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27281/47780 [01:38<01:30, 227.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24956/47780 [01:38<01:16, 296.83 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24571/47780 [01:38<01:21, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25240/47780 [01:38<01:30, 249.54 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20961/47780 [01:38<01:11, 373.49 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26235/47780 [01:38<01:24, 255.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25403/47780 [01:38<01:46, 210.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29186/47780 [01:38<00:53, 348.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27310/47780 [01:38<01:23, 243.87 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24988/47780 [01:38<01:15, 301.81 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24603/47780 [01:38<01:19, 291.30 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21010/47780 [01:38<01:06, 404.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26264/47780 [01:38<01:23, 256.85 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25425/47780 [01:38<01:47, 208.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29223/47780 [01:38<00:54, 343.23 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25266/47780 [01:38<01:46, 211.79 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27336/47780 [01:38<01:31, 223.67 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25019/47780 [01:38<01:22, 277.25 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21059/47780 [01:38<01:03, 423.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24633/47780 [01:38<01:27, 263.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26299/47780 [01:38<01:16, 282.23 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25447/47780 [01:39<01:50, 202.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25292/47780 [01:38<01:40, 223.91 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27360/47780 [01:39<01:35, 214.29 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21102/47780 [01:38<01:02, 424.75 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25048/47780 [01:39<01:25, 266.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29258/47780 [01:39<01:04, 285.44 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24661/47780 [01:39<01:30, 255.03 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26329/47780 [01:39<01:21, 263.66 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25468/47780 [01:39<01:52, 198.74 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25320/47780 [01:39<01:39, 224.60 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27400/47780 [01:39<01:19, 254.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29321/47780 [01:39<00:49, 369.98 examples/s]
Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21148/47780 [01:39<01:06, 403.16 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25075/47780 [01:39<01:32, 246.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24691/47780 [01:39<01:28, 262.29 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25493/47780 [01:39<01:45, 210.32 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26356/47780 [01:39<01:23, 256.84 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25347/47780 [01:39<01:35, 234.11 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27427/47780 [01:39<01:19, 255.57 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29365/47780 [01:39<00:47, 387.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21193/47780 [01:39<01:03, 415.85 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24719/47780 [01:39<01:26, 265.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25105/47780 [01:39<01:27, 257.68 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26384/47780 [01:39<01:23, 257.74 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25521/47780 [01:39<01:40, 222.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25376/47780 [01:39<01:31, 243.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27454/47780 [01:39<01:19, 257.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21235/47780 [01:39<01:03, 416.92 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24746/47780 [01:39<01:26, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25133/47780 [01:39<01:28, 255.71 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29407/47780 [01:39<00:50, 361.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26412/47780 [01:39<01:21, 261.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25547/47780 [01:39<01:35, 232.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25401/47780 [01:39<01:41, 221.27 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27480/47780 [01:39<01:24, 239.35 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21278/47780 [01:39<01:06, 397.74 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24773/47780 [01:39<01:32, 247.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29446/47780 [01:39<00:51, 353.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26442/47780 [01:39<01:19, 269.35 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25571/47780 [01:39<01:35, 232.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25159/47780 [01:39<01:39, 227.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25429/47780 [01:39<01:35, 234.20 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21320/47780 [01:39<01:06, 399.88 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27505/47780 [01:39<01:28, 229.62 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26470/47780 [01:39<01:18, 270.92 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29486/47780 [01:39<00:51, 355.21 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25603/47780 [01:39<01:28, 251.59 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24799/47780 [01:39<01:37, 235.76 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25204/47780 [01:39<01:19, 283.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25457/47780 [01:39<01:32, 241.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21361/47780 [01:39<01:05, 402.72 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29523/47780 [01:39<00:51, 351.32 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27531/47780 [01:39<01:32, 219.01 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26498/47780 [01:39<01:23, 253.94 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25630/47780 [01:39<01:31, 243.00 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24823/47780 [01:39<01:39, 231.58 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25235/47780 [01:39<01:19, 285.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25483/47780 [01:39<01:30, 246.31 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21403/47780 [01:39<01:05, 403.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29564/47780 [01:39<00:49, 367.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24850/47780 [01:39<01:35, 239.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25655/47780 [01:39<01:31, 242.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26532/47780 [01:39<01:17, 274.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27555/47780 [01:39<01:32, 217.90 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25265/47780 [01:39<01:19, 283.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25508/47780 [01:39<01:35, 234.30 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21447/47780 [01:39<01:04, 407.90 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29603/47780 [01:39<00:49, 365.58 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24878/47780 [01:39<01:32, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25680/47780 [01:40<01:31, 241.48 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27577/47780 [01:39<01:34, 214.74 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25294/47780 [01:40<01:19, 282.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26560/47780 [01:39<01:23, 253.45 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21491/47780 [01:39<01:03, 413.54 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25532/47780 [01:40<01:40, 221.22 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25705/47780 [01:40<01:33, 236.72 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29642/47780 [01:40<00:51, 349.71 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27599/47780 [01:40<01:35, 210.78 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24904/47780 [01:40<01:36, 238.15 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25323/47780 [01:40<01:24, 266.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26586/47780 [01:40<01:24, 249.55 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21537/47780 [01:40<01:02, 422.11 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25555/47780 [01:40<01:42, 216.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25733/47780 [01:40<01:28, 248.35 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29682/47780 [01:40<00:52, 347.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27623/47780 [01:40<01:36, 209.54 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25359/47780 [01:40<01:16, 291.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24932/47780 [01:40<01:37, 234.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26613/47780 [01:40<01:26, 244.72 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21580/47780 [01:40<01:03, 409.53 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25577/47780 [01:40<01:44, 212.93 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25760/47780 [01:40<01:28, 248.81 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29727/47780 [01:40<00:48, 375.19 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27649/47780 [01:40<01:30, 223.27 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24959/47780 [01:40<01:34, 241.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26638/47780 [01:40<01:26, 245.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25389/47780 [01:40<01:23, 269.39 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21633/47780 [01:40<01:00, 434.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25599/47780 [01:40<01:43, 214.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29779/47780 [01:40<00:43, 415.64 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27672/47780 [01:40<01:32, 217.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25785/47780 [01:40<01:35, 231.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24984/47780 [01:40<01:33, 243.51 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25431/47780 [01:40<01:13, 303.73 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26663/47780 [01:40<01:32, 227.07 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21678/47780 [01:40<00:59, 438.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25623/47780 [01:40<01:42, 217.20 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25011/47780 [01:40<01:30, 250.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27699/47780 [01:40<01:28, 227.53 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25818/47780 [01:40<01:27, 252.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29822/47780 [01:40<00:46, 389.11 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25463/47780 [01:40<01:13, 301.61 examples/s]
Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21722/47780 [01:40<01:00, 429.55 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26687/47780 [01:40<01:35, 221.01 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25648/47780 [01:40<01:39, 221.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27733/47780 [01:40<01:17, 259.03 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29864/47780 [01:40<00:45, 393.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25041/47780 [01:40<01:28, 256.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25844/47780 [01:40<01:30, 243.58 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21766/47780 [01:40<01:00, 427.65 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25494/47780 [01:40<01:16, 291.22 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26715/47780 [01:40<01:30, 231.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25672/47780 [01:40<01:43, 214.62 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27760/47780 [01:40<01:18, 255.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25076/47780 [01:40<01:21, 279.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29904/47780 [01:40<00:46, 386.00 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25869/47780 [01:40<01:33, 234.45 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21809/47780 [01:40<01:00, 427.71 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25530/47780 [01:40<01:11, 309.27 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26743/47780 [01:40<01:26, 242.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25702/47780 [01:40<01:37, 226.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27787/47780 [01:40<01:17, 257.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29944/47780 [01:40<00:46, 386.10 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25106/47780 [01:40<01:22, 276.03 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25897/47780 [01:40<01:29, 244.93 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26768/47780 [01:40<01:30, 231.55 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21853/47780 [01:40<01:07, 382.74 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25562/47780 [01:40<01:21, 273.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25725/47780 [01:40<01:41, 217.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29985/47780 [01:40<00:45, 391.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27816/47780 [01:40<01:17, 257.55 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25134/47780 [01:40<01:24, 269.29 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25922/47780 [01:41<01:32, 235.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26792/47780 [01:40<01:33, 224.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21912/47780 [01:40<01:00, 429.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27855/47780 [01:40<01:07, 293.67 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30025/47780 [01:41<00:46, 382.22 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25751/47780 [01:41<01:42, 214.85 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25591/47780 [01:41<01:26, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25162/47780 [01:41<01:26, 262.28 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25946/47780 [01:41<01:39, 219.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26818/47780 [01:41<01:29, 233.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21956/47780 [01:41<00:59, 431.77 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27901/47780 [01:41<00:59, 335.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25776/47780 [01:41<01:38, 224.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25625/47780 [01:41<01:20, 275.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30064/47780 [01:41<00:48, 363.56 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25204/47780 [01:41<01:15, 299.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26842/47780 [01:41<01:29, 233.05 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22000/47780 [01:41<01:00, 429.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25969/47780 [01:41<01:42, 213.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25799/47780 [01:41<01:37, 225.54 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25654/47780 [01:41<01:21, 272.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30107/47780 [01:41<00:46, 377.97 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25235/47780 [01:41<01:15, 298.98 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27935/47780 [01:41<01:04, 305.57 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26866/47780 [01:41<01:28, 235.00 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22050/47780 [01:41<00:57, 444.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25995/47780 [01:41<01:39, 219.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25828/47780 [01:41<01:31, 239.06 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25682/47780 [01:41<01:21, 272.59 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25271/47780 [01:41<01:12, 309.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30146/47780 [01:41<00:48, 364.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27968/47780 [01:41<01:05, 304.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26890/47780 [01:41<01:29, 233.48 examples/s]
Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22095/47780 [01:41<00:58, 435.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26021/47780 [01:41<01:38, 220.75 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25852/47780 [01:41<01:33, 233.73 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25712/47780 [01:41<01:19, 276.34 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25308/47780 [01:41<01:09, 323.30 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28001/47780 [01:41<01:03, 311.41 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30187/47780 [01:41<00:49, 357.69 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26915/47780 [01:41<01:27, 238.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22139/47780 [01:41<00:59, 427.69 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25876/47780 [01:41<01:34, 231.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26044/47780 [01:41<01:47, 201.44 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25341/47780 [01:41<01:09, 323.71 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25740/47780 [01:41<01:24, 259.46 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28033/47780 [01:41<01:04, 304.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30225/47780 [01:41<00:48, 362.41 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26942/47780 [01:41<01:26, 242.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22184/47780 [01:41<00:59, 429.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25900/47780 [01:41<01:36, 227.19 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26088/47780 [01:41<01:24, 257.70 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25767/47780 [01:41<01:26, 254.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30262/47780 [01:41<00:48, 361.90 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25374/47780 [01:41<01:18, 286.93 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22236/47780 [01:41<00:56, 450.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26967/47780 [01:41<01:30, 231.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28064/47780 [01:41<01:13, 269.64 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25924/47780 [01:41<01:35, 228.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30300/47780 [01:41<00:48, 362.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26115/47780 [01:41<01:28, 244.98 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25794/47780 [01:41<01:28, 247.87 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25409/47780 [01:41<01:14, 300.30 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22283/47780 [01:41<00:55, 455.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27001/47780 [01:41<01:20, 258.82 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28092/47780 [01:41<01:15, 259.11 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25953/47780 [01:41<01:31, 237.90 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30343/47780 [01:41<00:46, 377.90 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25824/47780 [01:41<01:24, 259.35 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26141/47780 [01:41<01:29, 241.40 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25445/47780 [01:41<01:12, 310.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27029/47780 [01:41<01:20, 258.70 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28124/47780 [01:41<01:11, 275.02 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22330/47780 [01:41<01:02, 407.07 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25977/47780 [01:41<01:31, 237.37 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25859/47780 [01:42<01:17, 281.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30381/47780 [01:42<00:49, 353.09 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26166/47780 [01:42<01:37, 222.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25478/47780 [01:42<01:14, 301.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22397/47780 [01:42<00:53, 473.76 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27056/47780 [01:42<01:26, 240.29 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28153/47780 [01:42<01:14, 264.22 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26003/47780 [01:42<01:30, 241.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25897/47780 [01:42<01:10, 309.15 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30418/47780 [01:42<00:49, 350.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25510/47780 [01:42<01:13, 303.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27085/47780 [01:42<01:22, 251.09 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22446/47780 [01:42<00:53, 472.13 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28180/47780 [01:42<01:15, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26028/47780 [01:42<01:31, 238.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26189/47780 [01:42<01:48, 199.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25929/47780 [01:42<01:12, 302.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30454/47780 [01:42<00:51, 336.12 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25541/47780 [01:42<01:19, 280.75 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22495/47780 [01:42<00:55, 456.48 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26210/47780 [01:42<01:48, 198.12 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28207/47780 [01:42<01:18, 247.96 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26052/47780 [01:42<01:37, 223.83 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27111/47780 [01:42<01:30, 228.30 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25969/47780 [01:42<01:06, 326.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30495/47780 [01:42<00:48, 355.02 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25572/47780 [01:42<01:16, 288.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26236/47780 [01:42<01:41, 213.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28235/47780 [01:42<01:17, 252.70 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27139/47780 [01:42<01:25, 241.82 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22542/47780 [01:42<00:58, 432.20 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26004/47780 [01:42<01:05, 332.92 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26075/47780 [01:42<01:39, 218.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30532/47780 [01:42<00:48, 359.00 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26261/47780 [01:42<01:38, 219.41 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25602/47780 [01:42<01:24, 262.24 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22588/47780 [01:42<00:58, 430.58 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27164/47780 [01:42<01:27, 236.42 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26104/47780 [01:42<01:32, 233.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28262/47780 [01:42<01:21, 240.09 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26038/47780 [01:42<01:07, 323.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30570/47780 [01:42<00:47, 364.70 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26290/47780 [01:42<01:31, 233.77 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25631/47780 [01:42<01:23, 265.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26128/47780 [01:42<01:32, 235.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28290/47780 [01:42<01:17, 249.92 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27196/47780 [01:42<01:22, 250.98 examples/s]
Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22632/47780 [01:42<01:01, 410.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30612/47780 [01:42<00:45, 376.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26071/47780 [01:42<01:12, 298.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27222/47780 [01:42<01:21, 253.41 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26155/47780 [01:42<01:30, 239.60 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26314/47780 [01:42<01:38, 218.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22674/47780 [01:42<01:01, 409.39 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30650/47780 [01:42<00:47, 357.05 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28316/47780 [01:42<01:25, 227.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26103/47780 [01:42<01:12, 297.74 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25659/47780 [01:42<01:34, 233.05 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26180/47780 [01:42<01:30, 239.89 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26339/47780 [01:42<01:35, 224.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27258/47780 [01:42<01:14, 274.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22716/47780 [01:42<01:03, 394.26 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26138/47780 [01:42<01:09, 312.08 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30686/47780 [01:42<00:48, 353.93 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28346/47780 [01:42<01:19, 243.84 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25686/47780 [01:42<01:33, 235.24 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26205/47780 [01:42<01:29, 239.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26364/47780 [01:43<01:33, 229.04 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27286/47780 [01:42<01:18, 261.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22756/47780 [01:42<01:04, 386.66 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30723/47780 [01:42<00:49, 346.60 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25717/47780 [01:42<01:27, 251.90 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28372/47780 [01:42<01:23, 233.10 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26170/47780 [01:43<01:22, 261.32 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26232/47780 [01:43<01:27, 245.81 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26402/47780 [01:43<01:19, 268.28 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27316/47780 [01:43<01:15, 271.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22801/47780 [01:43<01:01, 403.94 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30762/47780 [01:43<00:47, 357.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28403/47780 [01:43<01:17, 250.97 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25744/47780 [01:43<01:27, 251.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26262/47780 [01:43<01:23, 258.57 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26430/47780 [01:43<01:22, 259.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27350/47780 [01:43<01:10, 287.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22842/47780 [01:43<01:02, 397.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30798/47780 [01:43<00:47, 355.18 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26198/47780 [01:43<01:32, 233.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28432/47780 [01:43<01:14, 258.81 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25770/47780 [01:43<01:35, 231.10 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27379/47780 [01:43<01:11, 286.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22882/47780 [01:43<01:02, 397.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26458/47780 [01:43<01:24, 252.98 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26288/47780 [01:43<01:31, 234.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30834/47780 [01:43<00:48, 352.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26255/47780 [01:43<01:09, 310.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28459/47780 [01:43<01:16, 253.46 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25794/47780 [01:43<01:34, 232.99 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22937/47780 [01:43<00:56, 438.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27409/47780 [01:43<01:11, 286.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26315/47780 [01:43<01:28, 241.33 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30871/47780 [01:43<00:47, 353.72 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26484/47780 [01:43<01:29, 239.12 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26289/47780 [01:43<01:10, 305.61 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28485/47780 [01:43<01:18, 246.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27441/47780 [01:43<01:08, 295.38 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22984/47780 [01:43<00:55, 443.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25818/47780 [01:43<01:46, 206.29 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26340/47780 [01:43<01:29, 238.61 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26509/47780 [01:43<01:29, 236.92 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28511/47780 [01:43<01:17, 248.05 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30907/47780 [01:43<00:52, 320.75 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26322/47780 [01:43<01:13, 293.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23040/47780 [01:43<00:52, 469.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26373/47780 [01:43<01:21, 264.05 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25843/47780 [01:43<01:42, 213.03 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27471/47780 [01:43<01:14, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26533/47780 [01:43<01:35, 221.92 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30940/47780 [01:43<00:53, 317.47 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26355/47780 [01:43<01:11, 300.19 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28536/47780 [01:43<01:20, 237.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26403/47780 [01:43<01:17, 274.19 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23090/47780 [01:43<00:53, 458.80 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27503/47780 [01:43<01:11, 283.89 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25865/47780 [01:43<01:47, 204.08 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26558/47780 [01:43<01:32, 229.24 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28566/47780 [01:43<01:16, 249.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30973/47780 [01:43<00:54, 307.02 examples/s]
Tokenizing train dataset (num_proc=32):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23142/47780 [01:43<00:51, 474.59 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26387/47780 [01:43<01:20, 264.93 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26431/47780 [01:43<01:19, 269.96 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27532/47780 [01:43<01:11, 282.47 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25900/47780 [01:43<01:32, 237.40 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28594/47780 [01:43<01:14, 258.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26582/47780 [01:43<01:36, 220.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31005/47780 [01:43<00:59, 279.75 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26424/47780 [01:43<01:13, 288.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27566/47780 [01:43<01:09, 292.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26459/47780 [01:43<01:23, 255.12 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23190/47780 [01:43<00:57, 426.92 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25925/47780 [01:43<01:36, 226.20 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28635/47780 [01:43<01:04, 298.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26605/47780 [01:44<01:43, 205.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26455/47780 [01:44<01:14, 285.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31034/47780 [01:44<01:02, 266.17 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27597/47780 [01:44<01:08, 294.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26490/47780 [01:44<01:19, 267.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23234/47780 [01:43<00:57, 425.95 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25949/47780 [01:44<01:36, 225.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28666/47780 [01:44<01:05, 291.60 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26632/47780 [01:44<01:39, 213.16 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26488/47780 [01:44<01:13, 291.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31066/47780 [01:44<01:01, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27630/47780 [01:44<01:09, 291.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26518/47780 [01:44<01:21, 259.34 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23278/47780 [01:44<01:00, 407.33 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25972/47780 [01:44<01:41, 214.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28707/47780 [01:44<01:00, 315.43 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26657/47780 [01:44<01:37, 216.04 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26518/47780 [01:44<01:13, 290.59 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31098/47780 [01:44<00:59, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27662/47780 [01:44<01:08, 295.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26545/47780 [01:44<01:20, 262.25 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23320/47780 [01:44<01:00, 401.96 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25999/47780 [01:44<01:35, 227.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28742/47780 [01:44<00:58, 324.02 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26552/47780 [01:44<01:09, 304.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26679/47780 [01:44<01:40, 209.20 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27696/47780 [01:44<01:05, 304.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26574/47780 [01:44<01:19, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31127/47780 [01:44<01:02, 266.61 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23363/47780 [01:44<00:59, 409.31 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26025/47780 [01:44<01:33, 233.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28775/47780 [01:44<01:00, 314.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26704/47780 [01:44<01:37, 216.70 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27727/47780 [01:44<01:05, 306.19 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26601/47780 [01:44<01:20, 261.69 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26583/47780 [01:44<01:14, 282.93 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31155/47780 [01:44<01:02, 267.41 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23405/47780 [01:44<01:03, 386.57 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28808/47780 [01:44<01:00, 315.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26049/47780 [01:44<01:39, 217.97 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26726/47780 [01:44<01:40, 208.63 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27758/47780 [01:44<01:07, 298.25 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31185/47780 [01:44<01:00, 276.29 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26612/47780 [01:44<01:18, 269.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28847/47780 [01:44<00:56, 336.69 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26628/47780 [01:44<01:29, 236.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26075/47780 [01:44<01:35, 227.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23445/47780 [01:44<01:06, 363.72 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27792/47780 [01:44<01:04, 308.90 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26750/47780 [01:44<01:38, 212.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31213/47780 [01:44<01:00, 274.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26653/47780 [01:44<01:30, 233.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23486/47780 [01:44<01:04, 374.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26640/47780 [01:44<01:28, 239.64 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26099/47780 [01:44<01:37, 221.41 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27823/47780 [01:44<01:04, 309.21 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26774/47780 [01:44<01:35, 220.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31244/47780 [01:44<00:58, 284.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28881/47780 [01:44<01:09, 271.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26677/47780 [01:44<01:33, 225.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26679/47780 [01:44<01:16, 275.98 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23525/47780 [01:44<01:06, 366.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26128/47780 [01:44<01:31, 236.23 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27858/47780 [01:44<01:03, 313.77 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26797/47780 [01:44<01:37, 216.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31273/47780 [01:44<01:01, 266.98 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28911/47780 [01:44<01:16, 247.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26707/47780 [01:44<01:27, 241.11 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23568/47780 [01:44<01:03, 380.08 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26152/47780 [01:44<01:32, 233.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26709/47780 [01:45<01:19, 264.67 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27890/47780 [01:44<01:04, 308.40 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26819/47780 [01:45<01:37, 214.22 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31305/47780 [01:45<00:59, 276.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26732/47780 [01:45<01:27, 240.03 examples/s]
Tokenizing train dataset (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23613/47780 [01:44<01:01, 395.23 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26181/47780 [01:45<01:28, 243.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26744/47780 [01:45<01:14, 283.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28942/47780 [01:45<01:17, 244.11 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27926/47780 [01:45<01:02, 315.57 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26843/47780 [01:45<01:38, 213.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31333/47780 [01:45<01:00, 271.00 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26760/47780 [01:45<01:24, 248.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23654/47780 [01:45<01:00, 399.14 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26211/47780 [01:45<01:23, 259.44 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28978/47780 [01:45<01:09, 270.66 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27958/47780 [01:45<01:04, 309.29 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26869/47780 [01:45<01:34, 222.31 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26774/47780 [01:45<01:21, 258.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31367/47780 [01:45<00:57, 283.52 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26786/47780 [01:45<01:24, 248.92 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23696/47780 [01:45<01:00, 396.02 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26238/47780 [01:45<01:23, 259.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29075/47780 [01:45<00:41, 449.53 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27989/47780 [01:45<01:04, 306.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26804/47780 [01:45<01:19, 265.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26893/47780 [01:45<01:33, 222.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31396/47780 [01:45<01:01, 267.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26816/47780 [01:45<01:20, 260.48 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23736/47780 [01:45<01:01, 389.88 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26265/47780 [01:45<01:31, 234.56 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26924/47780 [01:45<01:25, 244.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26832/47780 [01:45<01:18, 265.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29124/47780 [01:45<00:47, 392.93 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31425/47780 [01:45<01:00, 270.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26843/47780 [01:45<01:19, 262.91 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28020/47780 [01:45<01:15, 260.06 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23776/47780 [01:45<01:04, 373.82 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26950/47780 [01:45<01:24, 246.01 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26863/47780 [01:45<01:16, 272.83 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26289/47780 [01:45<01:37, 220.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31454/47780 [01:45<00:59, 273.16 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26870/47780 [01:45<01:19, 262.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29168/47780 [01:45<00:49, 378.75 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28061/47780 [01:45<01:08, 289.64 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23814/47780 [01:45<01:05, 367.72 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26976/47780 [01:45<01:24, 247.12 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26892/47780 [01:45<01:17, 270.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26312/47780 [01:45<01:43, 207.48 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29215/47780 [01:45<00:47, 391.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31482/47780 [01:45<01:05, 249.75 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26897/47780 [01:45<01:25, 244.62 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 23851/47780 [01:45<01:06, 360.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28097/47780 [01:45<01:09, 284.17 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26928/47780 [01:45<01:11, 293.60 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27003/47780 [01:45<01:21, 253.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26336/47780 [01:45<01:40, 213.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26922/47780 [01:45<01:25, 243.43 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29257/47780 [01:45<00:49, 374.11 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23890/47780 [01:45<01:05, 364.14 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31519/47780 [01:45<01:00, 267.52 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28127/47780 [01:45<01:09, 282.22 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27032/47780 [01:45<01:19, 261.35 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26958/47780 [01:45<01:10, 294.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26360/47780 [01:45<01:38, 218.25 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26947/47780 [01:45<01:26, 239.85 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23929/47780 [01:45<01:04, 371.34 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31554/47780 [01:45<00:56, 289.31 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29296/47780 [01:45<00:52, 352.95 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28156/47780 [01:45<01:14, 264.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26988/47780 [01:46<01:14, 280.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27059/47780 [01:46<01:26, 238.79 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26397/47780 [01:45<01:24, 251.86 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23968/47780 [01:45<01:03, 373.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31584/47780 [01:46<00:56, 289.08 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26972/47780 [01:46<01:33, 222.70 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29333/47780 [01:46<00:54, 336.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27018/47780 [01:46<01:14, 279.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27085/47780 [01:46<01:25, 241.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28183/47780 [01:46<01:19, 245.81 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26423/47780 [01:46<01:26, 245.95 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24007/47780 [01:46<01:03, 373.58 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31614/47780 [01:46<00:59, 273.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27005/47780 [01:46<01:24, 246.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27054/47780 [01:46<01:08, 302.19 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29368/47780 [01:46<00:56, 323.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28209/47780 [01:46<01:18, 248.98 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27110/47780 [01:46<01:29, 231.06 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26454/47780 [01:46<01:23, 255.19 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24047/47780 [01:46<01:04, 368.40 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31648/47780 [01:46<00:55, 289.01 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27033/47780 [01:46<01:22, 249.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27086/47780 [01:46<01:08, 303.20 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28235/47780 [01:46<01:19, 244.34 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29401/47780 [01:46<01:00, 303.55 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26483/47780 [01:46<01:20, 264.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27135/47780 [01:46<01:31, 225.84 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24084/47780 [01:46<01:06, 356.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31678/47780 [01:46<00:59, 270.53 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28267/47780 [01:46<01:13, 264.73 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27059/47780 [01:46<01:33, 221.03 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27117/47780 [01:46<01:14, 277.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29435/47780 [01:46<00:59, 306.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27159/47780 [01:46<01:30, 227.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26510/47780 [01:46<01:25, 248.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28294/47780 [01:46<01:13, 263.72 examples/s]
Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24120/47780 [01:46<01:18, 299.90 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31706/47780 [01:46<01:03, 251.52 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27146/47780 [01:46<01:14, 277.10 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29467/47780 [01:46<01:00, 305.08 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27182/47780 [01:46<01:33, 221.46 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26539/47780 [01:46<01:22, 257.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27082/47780 [01:46<01:44, 198.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28323/47780 [01:46<01:11, 271.05 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24173/47780 [01:46<01:06, 354.54 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31733/47780 [01:46<01:03, 251.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27175/47780 [01:46<01:14, 275.07 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29498/47780 [01:46<01:01, 298.56 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27205/47780 [01:46<01:38, 209.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26566/47780 [01:46<01:25, 247.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27103/47780 [01:46<01:45, 195.86 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24216/47780 [01:46<01:02, 374.42 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28351/47780 [01:46<01:13, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31760/47780 [01:46<01:02, 256.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29531/47780 [01:46<01:00, 303.79 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27203/47780 [01:46<01:20, 256.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27240/47780 [01:46<01:22, 247.69 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26591/47780 [01:46<01:27, 242.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27124/47780 [01:46<01:48, 189.57 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28378/47780 [01:46<01:13, 265.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31789/47780 [01:46<01:01, 259.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24255/47780 [01:46<01:05, 359.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29563/47780 [01:46<00:59, 308.02 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27266/47780 [01:46<01:23, 245.83 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26616/47780 [01:46<01:29, 235.65 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27229/47780 [01:46<01:25, 241.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27182/47780 [01:46<01:11, 287.34 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28405/47780 [01:46<01:13, 263.02 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31821/47780 [01:46<00:57, 276.51 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24301/47780 [01:46<01:00, 386.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29594/47780 [01:46<01:02, 289.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27297/47780 [01:47<01:21, 252.33 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27258/47780 [01:47<01:20, 253.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26646/47780 [01:46<01:25, 246.62 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27213/47780 [01:47<01:14, 274.44 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28439/47780 [01:47<01:09, 276.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24342/47780 [01:46<01:02, 374.69 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31849/47780 [01:47<01:01, 258.89 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29633/47780 [01:47<00:57, 315.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27332/47780 [01:47<01:13, 276.57 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27284/47780 [01:47<01:21, 250.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26671/47780 [01:47<01:30, 232.10 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27242/47780 [01:47<01:14, 276.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28467/47780 [01:47<01:12, 265.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31877/47780 [01:47<01:00, 262.93 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24381/47780 [01:47<01:04, 360.68 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29665/47780 [01:47<01:02, 291.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27310/47780 [01:47<01:22, 248.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27273/47780 [01:47<01:13, 279.79 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27360/47780 [01:47<01:23, 244.10 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26695/47780 [01:47<01:36, 217.75 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28496/47780 [01:47<01:11, 270.81 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31912/47780 [01:47<00:55, 284.06 examples/s]
Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24426/47780 [01:47<01:00, 384.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29695/47780 [01:47<01:05, 276.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27387/47780 [01:47<01:22, 248.68 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26718/47780 [01:47<01:35, 220.99 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27335/47780 [01:47<01:33, 217.75 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27302/47780 [01:47<01:15, 269.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31942/47780 [01:47<00:55, 285.23 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28524/47780 [01:47<01:15, 254.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24467/47780 [01:47<01:04, 360.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29724/47780 [01:47<01:06, 270.93 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27368/47780 [01:47<01:23, 245.88 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26744/47780 [01:47<01:32, 226.77 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27413/47780 [01:47<01:25, 238.88 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28552/47780 [01:47<01:14, 258.41 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27330/47780 [01:47<01:22, 249.05 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31971/47780 [01:47<00:58, 268.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24504/47780 [01:47<01:04, 361.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27400/47780 [01:47<01:16, 265.54 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29753/47780 [01:47<01:12, 247.08 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26767/47780 [01:47<01:39, 211.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28582/47780 [01:47<01:11, 267.45 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27438/47780 [01:47<01:29, 227.35 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31999/47780 [01:47<00:58, 271.29 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27356/47780 [01:47<01:24, 241.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24541/47780 [01:47<01:04, 360.49 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27428/47780 [01:47<01:16, 264.47 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26797/47780 [01:47<01:29, 235.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29779/47780 [01:47<01:13, 245.23 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27462/47780 [01:47<01:30, 225.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32031/47780 [01:47<00:55, 282.19 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27383/47780 [01:47<01:24, 242.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28609/47780 [01:47<01:17, 248.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24578/47780 [01:47<01:09, 336.14 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27456/47780 [01:47<01:19, 256.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32061/47780 [01:47<00:55, 284.02 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29808/47780 [01:47<01:12, 246.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27485/47780 [01:47<01:36, 210.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28638/47780 [01:47<01:16, 251.48 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27408/47780 [01:47<01:26, 235.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26821/47780 [01:47<01:41, 206.94 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24615/47780 [01:47<01:08, 338.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27488/47780 [01:47<01:13, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32090/47780 [01:47<00:55, 285.17 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27512/47780 [01:47<01:30, 224.19 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29833/47780 [01:47<01:17, 232.72 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28667/47780 [01:47<01:13, 259.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27434/47780 [01:47<01:25, 237.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24653/47780 [01:47<01:06, 349.65 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26843/47780 [01:47<01:46, 197.47 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27516/47780 [01:48<01:14, 273.59 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32119/47780 [01:47<00:55, 280.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29857/47780 [01:47<01:16, 232.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27538/47780 [01:48<01:28, 228.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27458/47780 [01:48<01:26, 235.56 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24691/47780 [01:47<01:06, 346.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26864/47780 [01:48<01:47, 194.99 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28694/47780 [01:48<01:22, 230.94 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27544/47780 [01:48<01:15, 267.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32148/47780 [01:48<00:56, 274.87 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29881/47780 [01:48<01:18, 229.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27483/47780 [01:48<01:25, 236.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27562/47780 [01:48<01:30, 222.23 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24726/47780 [01:48<01:07, 343.84 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28723/47780 [01:48<01:18, 244.13 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26884/47780 [01:48<01:51, 188.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27577/47780 [01:48<01:12, 280.20 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32176/47780 [01:48<00:57, 272.24 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27592/47780 [01:48<01:23, 240.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29905/47780 [01:48<01:20, 221.84 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24767/47780 [01:48<01:04, 358.49 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27507/47780 [01:48<01:32, 218.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28749/47780 [01:48<01:17, 245.71 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26907/47780 [01:48<01:48, 192.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27608/47780 [01:48<01:12, 279.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32212/47780 [01:48<00:52, 297.21 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27617/47780 [01:48<01:25, 235.66 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24813/47780 [01:48<00:59, 383.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29928/47780 [01:48<01:22, 215.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27540/47780 [01:48<01:23, 243.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28780/47780 [01:48<01:12, 260.63 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26927/47780 [01:48<01:48, 192.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27641/47780 [01:48<01:09, 290.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32242/47780 [01:48<00:54, 285.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29952/47780 [01:48<01:20, 221.29 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27641/47780 [01:48<01:27, 229.04 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24852/47780 [01:48<01:01, 372.39 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28807/47780 [01:48<01:12, 263.15 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27567/47780 [01:48<01:23, 243.26 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26947/47780 [01:48<01:47, 193.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27672/47780 [01:48<01:12, 277.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32273/47780 [01:48<00:58, 265.02 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27679/47780 [01:48<01:15, 265.21 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29975/47780 [01:48<01:22, 214.81 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24892/47780 [01:48<01:00, 375.92 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28834/47780 [01:48<01:12, 260.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27598/47780 [01:48<01:19, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26970/47780 [01:48<01:43, 201.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27703/47780 [01:48<01:10, 286.31 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32304/47780 [01:48<00:56, 273.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24932/47780 [01:48<00:59, 382.82 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27706/47780 [01:48<01:18, 256.74 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29997/47780 [01:48<01:24, 209.25 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28861/47780 [01:48<01:16, 247.42 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26993/47780 [01:48<01:42, 202.31 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27624/47780 [01:48<01:24, 239.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27733/47780 [01:48<01:10, 284.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32332/47780 [01:48<00:57, 267.25 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27732/47780 [01:48<01:19, 253.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30018/47780 [01:48<01:27, 202.76 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28892/47780 [01:48<01:11, 262.51 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27022/47780 [01:48<01:32, 224.53 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24971/47780 [01:48<01:06, 343.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27649/47780 [01:48<01:24, 237.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27762/47780 [01:48<01:10, 284.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32359/47780 [01:48<00:58, 262.19 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27758/47780 [01:48<01:22, 244.11 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30039/47780 [01:48<01:30, 195.60 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27045/47780 [01:48<01:32, 223.21 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25026/47780 [01:48<00:57, 393.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27674/47780 [01:48<01:25, 236.39 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27791/47780 [01:48<01:11, 280.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28919/47780 [01:48<01:19, 237.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32395/47780 [01:48<00:53, 289.36 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27783/47780 [01:49<01:25, 234.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30070/47780 [01:49<01:20, 220.15 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27072/47780 [01:49<01:32, 224.45 examples/s]
Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25068/47780 [01:48<00:59, 382.73 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27699/47780 [01:49<01:25, 234.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27820/47780 [01:49<01:13, 272.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28950/47780 [01:49<01:15, 248.85 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32428/47780 [01:49<00:55, 274.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30097/47780 [01:49<01:16, 231.47 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27812/47780 [01:49<01:21, 245.13 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27728/47780 [01:49<01:21, 246.75 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25107/47780 [01:49<01:01, 368.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27095/47780 [01:49<01:35, 215.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28976/47780 [01:49<01:15, 250.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27848/47780 [01:49<01:15, 263.12 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32461/47780 [01:49<00:52, 289.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30125/47780 [01:49<01:12, 245.06 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27754/47780 [01:49<01:20, 248.59 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27837/47780 [01:49<01:26, 231.20 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27117/47780 [01:49<01:36, 214.61 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25154/47780 [01:49<00:58, 387.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29002/47780 [01:49<01:14, 251.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27880/47780 [01:49<01:12, 273.37 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30150/47780 [01:49<01:12, 243.50 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32491/47780 [01:49<00:56, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25194/47780 [01:49<00:57, 390.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27139/47780 [01:49<01:38, 209.26 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27869/47780 [01:49<01:19, 249.34 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29028/47780 [01:49<01:15, 248.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27910/47780 [01:49<01:11, 279.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27787/47780 [01:49<01:20, 248.81 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30177/47780 [01:49<01:12, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25234/47780 [01:49<00:57, 391.83 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32524/47780 [01:49<00:56, 271.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27896/47780 [01:49<01:19, 249.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27944/47780 [01:49<01:08, 291.10 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27160/47780 [01:49<01:44, 198.20 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29054/47780 [01:49<01:20, 233.33 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27813/47780 [01:49<01:27, 227.83 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30208/47780 [01:49<01:06, 262.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25276/47780 [01:49<00:56, 397.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27922/47780 [01:49<01:22, 242.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27975/47780 [01:49<01:08, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27186/47780 [01:49<01:36, 212.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32552/47780 [01:49<00:59, 254.65 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29082/47780 [01:49<01:16, 246.00 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27837/47780 [01:49<01:30, 220.80 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25321/47780 [01:49<00:54, 412.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30235/47780 [01:49<01:13, 239.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27954/47780 [01:49<01:16, 260.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27212/47780 [01:49<01:34, 218.80 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28005/47780 [01:49<01:10, 278.76 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32578/47780 [01:49<01:01, 248.21 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29108/47780 [01:49<01:23, 224.76 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27863/47780 [01:49<01:31, 217.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25363/47780 [01:49<00:57, 387.32 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27237/47780 [01:49<01:30, 227.35 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27981/47780 [01:49<01:19, 249.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30260/47780 [01:49<01:17, 224.67 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32604/47780 [01:49<01:02, 243.68 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28033/47780 [01:49<01:13, 268.35 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29141/47780 [01:49<01:16, 242.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27891/47780 [01:49<01:25, 231.79 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25403/47780 [01:49<00:59, 375.78 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27262/47780 [01:49<01:28, 231.37 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28007/47780 [01:49<01:18, 252.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32630/47780 [01:49<01:01, 248.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28069/47780 [01:49<01:07, 293.75 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30283/47780 [01:49<01:22, 212.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27915/47780 [01:49<01:26, 229.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29166/47780 [01:49<01:19, 234.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28035/47780 [01:50<01:16, 257.27 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25441/47780 [01:49<01:02, 355.79 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32656/47780 [01:50<01:01, 245.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27286/47780 [01:50<01:32, 220.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30305/47780 [01:50<01:22, 212.02 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28099/47780 [01:50<01:14, 262.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27939/47780 [01:50<01:28, 225.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29190/47780 [01:50<01:25, 217.37 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28062/47780 [01:50<01:15, 260.78 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25478/47780 [01:50<01:02, 359.65 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32684/47780 [01:50<00:59, 252.72 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27309/47780 [01:50<01:35, 214.12 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30327/47780 [01:50<01:24, 206.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28132/47780 [01:50<01:10, 279.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27973/47780 [01:50<01:18, 253.32 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29214/47780 [01:50<01:24, 218.74 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28089/47780 [01:50<01:14, 263.03 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25515/47780 [01:50<01:02, 358.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32712/47780 [01:50<00:57, 260.34 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27335/47780 [01:50<01:30, 225.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30352/47780 [01:50<01:21, 212.78 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28164/47780 [01:50<01:08, 285.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28008/47780 [01:50<01:13, 270.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29240/47780 [01:50<01:21, 227.59 examples/s]
Tokenizing train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25561/47780 [01:50<00:58, 383.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32757/47780 [01:50<00:48, 310.94 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28116/47780 [01:50<01:20, 245.13 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27358/47780 [01:50<01:31, 223.16 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30375/47780 [01:50<01:20, 215.11 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28203/47780 [01:50<01:02, 311.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28041/47780 [01:50<01:09, 284.56 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29264/47780 [01:50<01:21, 228.20 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25601/47780 [01:50<00:57, 383.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32791/47780 [01:50<00:48, 309.01 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28147/47780 [01:50<01:16, 257.24 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30400/47780 [01:50<01:18, 222.39 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27381/47780 [01:50<01:34, 214.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28236/47780 [01:50<01:03, 309.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28070/47780 [01:50<01:09, 283.93 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29291/47780 [01:50<01:17, 239.68 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25641/47780 [01:50<00:57, 383.80 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28174/47780 [01:50<01:16, 257.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32822/47780 [01:50<00:49, 302.14 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30428/47780 [01:50<01:14, 233.06 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27407/47780 [01:50<01:34, 216.49 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28268/47780 [01:50<01:04, 301.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28104/47780 [01:50<01:06, 295.54 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29321/47780 [01:50<01:13, 251.39 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 25680/47780 [01:50<00:58, 380.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32855/47780 [01:50<00:48, 306.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28200/47780 [01:50<01:17, 253.35 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30454/47780 [01:50<01:15, 230.28 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27429/47780 [01:50<01:41, 201.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28300/47780 [01:50<01:06, 290.94 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28134/47780 [01:50<01:11, 275.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29347/47780 [01:50<01:15, 245.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32887/47780 [01:50<00:48, 307.14 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28226/47780 [01:50<01:17, 252.38 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25719/47780 [01:50<01:04, 340.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30481/47780 [01:50<01:13, 236.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28332/47780 [01:50<01:06, 292.76 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27451/47780 [01:50<01:41, 199.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29378/47780 [01:50<01:11, 257.84 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28162/47780 [01:50<01:13, 266.90 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32924/47780 [01:50<00:45, 325.24 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28262/47780 [01:50<01:09, 282.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25757/47780 [01:50<01:02, 351.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30505/47780 [01:50<01:18, 220.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27473/47780 [01:50<01:39, 204.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28362/47780 [01:51<01:09, 280.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28196/47780 [01:50<01:08, 286.87 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29404/47780 [01:50<01:14, 247.36 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28295/47780 [01:51<01:05, 295.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32960/47780 [01:50<00:45, 327.67 examples/s]
Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25793/47780 [01:50<01:06, 328.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27496/47780 [01:51<01:36, 211.27 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30529/47780 [01:51<01:19, 218.32 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28391/47780 [01:51<01:09, 278.08 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28226/47780 [01:51<01:08, 284.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29431/47780 [01:51<01:13, 248.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33000/47780 [01:51<00:42, 344.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28325/47780 [01:51<01:08, 284.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25836/47780 [01:51<01:02, 351.68 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28255/47780 [01:51<01:09, 282.87 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27519/47780 [01:51<01:41, 199.65 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28419/47780 [01:51<01:14, 261.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29459/47780 [01:51<01:12, 254.21 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28358/47780 [01:51<01:06, 291.31 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30551/47780 [01:51<01:29, 193.55 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33037/47780 [01:51<00:46, 318.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25877/47780 [01:51<01:00, 363.64 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28287/47780 [01:51<01:07, 287.07 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27541/47780 [01:51<01:40, 200.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29494/47780 [01:51<01:05, 278.13 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28446/47780 [01:51<01:15, 256.83 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28389/47780 [01:51<01:05, 296.52 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30575/47780 [01:51<01:25, 201.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33072/47780 [01:51<00:45, 323.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25922/47780 [01:51<00:57, 379.40 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28320/47780 [01:51<01:05, 295.95 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27568/47780 [01:51<01:33, 215.11 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28476/47780 [01:51<01:12, 267.53 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29523/47780 [01:51<01:06, 275.00 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28421/47780 [01:51<01:04, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30598/47780 [01:51<01:23, 206.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25962/47780 [01:51<00:56, 385.18 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33105/47780 [01:51<00:50, 289.97 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28351/47780 [01:51<01:06, 293.14 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27592/47780 [01:51<01:31, 219.63 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29551/47780 [01:51<01:06, 273.57 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28453/47780 [01:51<01:04, 300.58 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30623/47780 [01:51<01:19, 216.15 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28503/47780 [01:51<01:15, 254.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26006/47780 [01:51<00:54, 400.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33137/47780 [01:51<00:49, 294.51 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27622/47780 [01:51<01:23, 241.99 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28381/47780 [01:51<01:06, 291.54 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30646/47780 [01:51<01:17, 219.98 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28485/47780 [01:51<01:04, 300.45 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28534/47780 [01:51<01:12, 266.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29579/47780 [01:51<01:10, 257.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26058/47780 [01:51<00:50, 432.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33168/47780 [01:51<00:51, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28411/47780 [01:51<01:10, 275.22 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27647/47780 [01:51<01:28, 226.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28565/47780 [01:51<01:09, 275.45 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30669/47780 [01:51<01:20, 212.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29605/47780 [01:51<01:11, 252.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26102/47780 [01:51<00:51, 422.55 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28516/47780 [01:51<01:19, 241.89 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33197/47780 [01:51<00:53, 274.02 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28596/47780 [01:51<01:07, 284.92 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27670/47780 [01:51<01:30, 222.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28439/47780 [01:51<01:11, 270.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30691/47780 [01:51<01:21, 210.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26146/47780 [01:51<00:50, 425.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29631/47780 [01:51<01:16, 237.06 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33232/47780 [01:51<00:49, 292.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28543/47780 [01:51<01:24, 226.44 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30713/47780 [01:51<01:20, 210.97 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27694/47780 [01:51<01:35, 211.31 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28625/47780 [01:52<01:13, 262.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28467/47780 [01:51<01:16, 250.85 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26189/47780 [01:51<00:52, 414.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29660/47780 [01:51<01:13, 245.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28604/47780 [01:52<01:00, 316.61 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33262/47780 [01:52<00:54, 266.16 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27723/47780 [01:52<01:26, 232.08 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28497/47780 [01:52<01:13, 263.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30735/47780 [01:52<01:24, 200.53 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26231/47780 [01:51<00:52, 411.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29686/47780 [01:52<01:13, 246.68 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28656/47780 [01:52<01:16, 250.87 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28527/47780 [01:52<01:11, 268.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26293/47780 [01:52<00:45, 471.72 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30756/47780 [01:52<01:27, 193.91 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28687/47780 [01:52<01:12, 264.31 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33290/47780 [01:52<00:59, 242.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28639/47780 [01:52<01:06, 289.53 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29712/47780 [01:52<01:17, 232.34 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27747/47780 [01:52<01:42, 196.04 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28555/47780 [01:52<01:11, 269.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26344/47780 [01:52<00:44, 482.49 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30780/47780 [01:52<01:24, 202.13 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28714/47780 [01:52<01:13, 259.58 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29743/47780 [01:52<01:11, 250.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28671/47780 [01:52<01:06, 288.49 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27781/47780 [01:52<01:28, 226.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33315/47780 [01:52<01:09, 208.50 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28583/47780 [01:52<01:15, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26394/47780 [01:52<00:47, 445.99 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30805/47780 [01:52<01:21, 208.45 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29769/47780 [01:52<01:12, 250.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28717/47780 [01:52<00:57, 328.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28741/47780 [01:52<01:14, 254.13 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27807/47780 [01:52<01:26, 230.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33337/47780 [01:52<01:09, 207.30 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28612/47780 [01:52<01:14, 257.92 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30832/47780 [01:52<01:19, 213.65 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28752/47780 [01:52<00:58, 323.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28767/47780 [01:52<01:16, 249.47 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29795/47780 [01:52<01:14, 241.73 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26440/47780 [01:52<00:50, 420.66 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27833/47780 [01:52<01:27, 227.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33395/47780 [01:52<00:48, 296.63 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28646/47780 [01:52<01:09, 274.58 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28797/47780 [01:52<01:12, 261.34 examples/s]
Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26483/47780 [01:52<00:50, 419.83 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28786/47780 [01:52<01:01, 308.35 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30855/47780 [01:52<01:26, 196.46 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27857/47780 [01:52<01:27, 227.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29820/47780 [01:52<01:21, 219.93 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33427/47780 [01:52<00:49, 290.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28674/47780 [01:52<01:12, 264.34 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26529/47780 [01:52<00:49, 426.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28825/47780 [01:52<01:15, 251.14 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28818/47780 [01:52<01:02, 304.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30881/47780 [01:52<01:20, 211.02 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27881/47780 [01:52<01:27, 227.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29843/47780 [01:52<01:22, 218.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33458/47780 [01:52<00:49, 289.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28702/47780 [01:52<01:12, 262.78 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26572/47780 [01:52<00:52, 404.49 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30904/47780 [01:52<01:18, 215.07 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27905/47780 [01:52<01:26, 230.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28850/47780 [01:52<01:06, 284.63 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33492/47780 [01:52<00:47, 300.86 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29866/47780 [01:52<01:26, 206.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28852/47780 [01:52<01:25, 221.06 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28729/47780 [01:52<01:12, 262.06 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26613/47780 [01:52<00:53, 397.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30926/47780 [01:52<01:18, 215.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28880/47780 [01:53<01:06, 283.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28908/47780 [01:53<01:01, 306.74 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27929/47780 [01:53<01:34, 209.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29887/47780 [01:53<01:29, 200.32 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33529/47780 [01:53<00:46, 305.62 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28757/47780 [01:53<01:11, 266.83 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26654/47780 [01:52<00:53, 396.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28909/47780 [01:53<01:06, 284.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30948/47780 [01:53<01:23, 202.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27952/47780 [01:53<01:33, 213.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29912/47780 [01:53<01:24, 211.55 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33565/47780 [01:53<00:44, 317.08 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28941/47780 [01:53<01:03, 296.94 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28791/47780 [01:53<01:07, 281.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26703/47780 [01:53<00:50, 418.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30978/47780 [01:53<01:18, 215.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29935/47780 [01:53<01:23, 214.36 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33603/47780 [01:53<00:43, 327.22 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27974/47780 [01:53<01:36, 205.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28938/47780 [01:53<01:13, 258.07 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28821/47780 [01:53<01:08, 275.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28973/47780 [01:53<01:09, 268.89 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26745/47780 [01:53<00:55, 381.17 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29964/47780 [01:53<01:15, 235.41 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31009/47780 [01:53<01:11, 235.66 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27996/47780 [01:53<01:35, 207.56 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33637/47780 [01:53<00:43, 326.81 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28965/47780 [01:53<01:14, 253.70 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28849/47780 [01:53<01:08, 275.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29002/47780 [01:53<01:09, 268.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26818/47780 [01:53<00:44, 473.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29992/47780 [01:53<01:11, 247.63 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28019/47780 [01:53<01:32, 213.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33672/47780 [01:53<00:43, 326.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28991/47780 [01:53<01:17, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31033/47780 [01:53<01:18, 213.52 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28877/47780 [01:53<01:09, 271.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29031/47780 [01:53<01:10, 265.70 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26867/47780 [01:53<00:44, 467.70 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28042/47780 [01:53<01:30, 218.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30018/47780 [01:53<01:14, 237.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33706/47780 [01:53<00:44, 315.90 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29020/47780 [01:53<01:13, 256.24 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28909/47780 [01:53<01:06, 284.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31055/47780 [01:53<01:19, 210.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29059/47780 [01:53<01:12, 259.92 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26915/47780 [01:53<00:45, 455.07 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28067/47780 [01:53<01:26, 227.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30047/47780 [01:53<01:11, 248.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33738/47780 [01:53<00:45, 310.09 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29046/47780 [01:53<01:13, 254.19 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28941/47780 [01:53<01:03, 294.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31077/47780 [01:53<01:22, 202.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29095/47780 [01:53<01:05, 285.42 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30076/47780 [01:53<01:09, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28090/47780 [01:53<01:31, 214.48 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29072/47780 [01:53<01:18, 239.27 examples/s]
Tokenizing train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26962/47780 [01:53<00:54, 380.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28971/47780 [01:53<01:09, 270.98 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31098/47780 [01:53<01:25, 195.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33770/47780 [01:53<00:50, 275.83 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29125/47780 [01:53<01:07, 278.08 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30109/47780 [01:53<01:04, 274.09 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29100/47780 [01:53<01:15, 248.58 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28112/47780 [01:53<01:40, 195.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28999/47780 [01:53<01:08, 273.44 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31129/47780 [01:53<01:14, 224.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27036/47780 [01:53<00:46, 450.75 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29154/47780 [01:53<01:09, 268.25 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30138/47780 [01:53<01:04, 274.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33799/47780 [01:53<01:00, 231.21 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29131/47780 [01:54<01:11, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28143/47780 [01:54<01:31, 214.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31152/47780 [01:53<01:14, 223.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29027/47780 [01:54<01:11, 263.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27084/47780 [01:53<00:47, 439.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29188/47780 [01:54<01:05, 285.27 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30166/47780 [01:54<01:08, 255.89 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29161/47780 [01:54<01:08, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31176/47780 [01:54<01:12, 227.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28165/47780 [01:54<01:32, 211.42 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29054/47780 [01:54<01:14, 250.80 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29219/47780 [01:54<01:04, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27130/47780 [01:54<00:48, 422.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33824/47780 [01:54<01:08, 204.63 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30192/47780 [01:54<01:09, 251.51 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28191/47780 [01:54<01:27, 224.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31199/47780 [01:54<01:13, 224.71 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29081/47780 [01:54<01:13, 256.06 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29259/47780 [01:54<00:58, 316.79 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29189/47780 [01:54<01:18, 237.83 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33923/47780 [01:54<00:36, 375.69 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27174/47780 [01:54<00:53, 387.59 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28214/47780 [01:54<01:26, 226.00 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30218/47780 [01:54<01:15, 233.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31222/47780 [01:54<01:15, 219.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29220/47780 [01:54<01:13, 253.95 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29291/47780 [01:54<01:00, 306.26 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29107/47780 [01:54<01:19, 236.18 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33966/47780 [01:54<00:36, 377.48 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27214/47780 [01:54<00:56, 362.03 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28238/47780 [01:54<01:26, 224.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30254/47780 [01:54<01:06, 264.31 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31249/47780 [01:54<01:13, 224.07 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29247/47780 [01:54<01:11, 258.29 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29133/47780 [01:54<01:21, 230.01 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29322/47780 [01:54<01:06, 279.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34009/47780 [01:54<00:39, 351.89 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27262/47780 [01:54<00:52, 391.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28265/47780 [01:54<01:22, 237.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31285/47780 [01:54<01:03, 259.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30281/47780 [01:54<01:11, 244.46 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29278/47780 [01:54<01:09, 266.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29158/47780 [01:54<01:19, 233.02 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29351/47780 [01:54<01:07, 273.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34059/47780 [01:54<00:35, 384.67 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28289/47780 [01:54<01:24, 230.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27303/47780 [01:54<00:53, 379.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31319/47780 [01:54<00:59, 278.78 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29306/47780 [01:54<01:09, 267.69 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30307/47780 [01:54<01:11, 243.40 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29189/47780 [01:54<01:13, 251.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29379/47780 [01:54<01:11, 256.18 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27342/47780 [01:54<00:55, 371.23 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31352/47780 [01:54<00:56, 290.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34101/47780 [01:54<00:38, 353.77 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28313/47780 [01:54<01:32, 211.49 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29334/47780 [01:54<01:12, 253.77 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30332/47780 [01:54<01:15, 232.62 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29221/47780 [01:54<01:10, 264.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29412/47780 [01:54<01:07, 272.79 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27384/47780 [01:54<00:53, 380.22 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31383/47780 [01:54<00:56, 290.26 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28341/47780 [01:54<01:24, 229.74 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34140/47780 [01:54<00:39, 344.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30358/47780 [01:54<01:14, 235.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29360/47780 [01:54<01:13, 249.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29248/47780 [01:54<01:11, 259.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29445/47780 [01:55<01:04, 283.35 examples/s]
Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27437/47780 [01:54<00:49, 412.35 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31413/47780 [01:54<00:59, 276.82 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29386/47780 [01:55<01:13, 250.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30382/47780 [01:55<01:14, 233.18 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29284/47780 [01:55<01:04, 285.39 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34176/47780 [01:55<00:42, 323.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28365/47780 [01:55<01:37, 199.05 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27485/47780 [01:54<00:47, 426.40 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29474/47780 [01:55<01:08, 268.91 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30418/47780 [01:55<01:04, 267.17 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31441/47780 [01:55<01:03, 259.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29414/47780 [01:55<01:13, 249.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34212/47780 [01:55<00:42, 316.87 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28395/47780 [01:55<01:27, 220.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29313/47780 [01:55<01:11, 257.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29504/47780 [01:55<01:06, 274.74 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27528/47780 [01:55<00:49, 408.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31472/47780 [01:55<01:00, 270.53 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29443/47780 [01:55<01:12, 252.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34245/47780 [01:55<00:43, 308.88 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28419/47780 [01:55<01:30, 214.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30446/47780 [01:55<01:16, 226.39 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29532/47780 [01:55<01:06, 272.75 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27578/47780 [01:55<00:47, 429.61 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29340/47780 [01:55<01:16, 239.99 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31501/47780 [01:55<00:59, 275.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34285/47780 [01:55<00:40, 331.15 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28443/47780 [01:55<01:27, 221.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29469/47780 [01:55<01:20, 226.85 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29563/47780 [01:55<01:04, 283.18 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27635/47780 [01:55<00:43, 463.92 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29365/47780 [01:55<01:17, 237.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30471/47780 [01:55<01:21, 212.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31532/47780 [01:55<00:58, 276.22 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28469/47780 [01:55<01:24, 229.80 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29493/47780 [01:55<01:21, 223.47 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34319/47780 [01:55<00:44, 303.50 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27683/47780 [01:55<00:43, 463.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29396/47780 [01:55<01:11, 255.82 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30534/47780 [01:55<00:54, 316.60 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29592/47780 [01:55<01:10, 258.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31561/47780 [01:55<00:59, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28493/47780 [01:55<01:27, 219.97 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34361/47780 [01:55<00:40, 330.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27731/47780 [01:55<00:43, 462.76 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29516/47780 [01:55<01:26, 211.31 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29423/47780 [01:55<01:13, 249.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29620/47780 [01:55<01:10, 259.05 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30570/47780 [01:55<00:56, 302.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31595/47780 [01:55<00:57, 283.94 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34395/47780 [01:55<00:41, 322.84 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29543/47780 [01:55<01:20, 226.73 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28516/47780 [01:55<01:32, 208.90 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27778/47780 [01:55<00:46, 434.69 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29449/47780 [01:55<01:15, 242.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29647/47780 [01:55<01:10, 258.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31628/47780 [01:55<00:54, 296.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30603/47780 [01:55<00:57, 300.05 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28549/47780 [01:55<01:20, 238.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34428/47780 [01:55<00:42, 314.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29475/47780 [01:55<01:14, 247.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29674/47780 [01:55<01:10, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29567/47780 [01:55<01:29, 203.91 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27825/47780 [01:55<00:49, 405.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30635/47780 [01:55<00:57, 296.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31659/47780 [01:55<00:56, 284.44 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34460/47780 [01:55<00:42, 315.79 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28575/47780 [01:55<01:23, 229.57 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29502/47780 [01:55<01:15, 242.60 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29700/47780 [01:56<01:14, 241.30 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27867/47780 [01:55<00:49, 404.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29589/47780 [01:56<01:31, 197.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31690/47780 [01:55<00:56, 284.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30667/47780 [01:55<01:00, 281.69 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34498/47780 [01:56<00:41, 323.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29534/47780 [01:56<01:09, 264.01 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27908/47780 [01:55<00:49, 404.48 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29736/47780 [01:56<01:07, 267.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28599/47780 [01:56<01:30, 211.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29612/47780 [01:56<01:29, 202.92 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31719/47780 [01:56<00:58, 274.39 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34531/47780 [01:56<00:41, 318.12 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29561/47780 [01:56<01:09, 262.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30696/47780 [01:56<01:10, 240.96 examples/s]
Tokenizing train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27950/47780 [01:56<00:48, 408.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28622/47780 [01:56<01:29, 213.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29643/47780 [01:56<01:19, 227.92 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31747/47780 [01:56<00:58, 275.86 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29764/47780 [01:56<01:13, 246.49 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34564/47780 [01:56<00:42, 314.34 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29588/47780 [01:56<01:09, 261.79 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27995/47780 [01:56<00:47, 416.45 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30757/47780 [01:56<00:52, 324.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28645/47780 [01:56<01:28, 216.50 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29667/47780 [01:56<01:18, 231.11 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29791/47780 [01:56<01:12, 248.45 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31775/47780 [01:56<01:00, 262.96 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29618/47780 [01:56<01:07, 269.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34603/47780 [01:56<00:40, 328.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28046/47780 [01:56<00:44, 443.35 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28667/47780 [01:56<01:28, 215.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30793/47780 [01:56<00:53, 315.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29694/47780 [01:56<01:16, 236.72 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29818/47780 [01:56<01:11, 250.58 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31802/47780 [01:56<01:05, 242.39 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34637/47780 [01:56<00:39, 331.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29646/47780 [01:56<01:07, 269.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28691/47780 [01:56<01:27, 216.94 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29729/47780 [01:56<01:07, 265.84 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30827/47780 [01:56<00:58, 290.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29844/47780 [01:56<01:15, 237.47 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28091/47780 [01:56<00:55, 357.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31827/47780 [01:56<01:07, 237.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29681/47780 [01:56<01:01, 292.94 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34671/47780 [01:56<00:40, 322.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28714/47780 [01:56<01:26, 219.25 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29761/47780 [01:56<01:04, 278.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29869/47780 [01:56<01:14, 240.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30858/47780 [01:56<00:59, 283.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31861/47780 [01:56<01:00, 264.84 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34704/47780 [01:56<00:40, 324.33 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29711/47780 [01:56<01:08, 264.01 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28738/47780 [01:56<01:24, 224.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29790/47780 [01:56<01:04, 281.06 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28131/47780 [01:56<01:06, 296.96 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30889/47780 [01:56<00:58, 287.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34740/47780 [01:56<00:39, 331.44 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29894/47780 [01:56<01:19, 223.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31888/47780 [01:56<01:03, 251.92 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29741/47780 [01:56<01:07, 267.98 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29819/47780 [01:56<01:05, 273.97 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28761/47780 [01:56<01:29, 213.55 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29919/47780 [01:56<01:17, 230.82 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30919/47780 [01:56<01:03, 265.67 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31914/47780 [01:56<01:06, 238.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34775/47780 [01:56<00:42, 304.73 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29770/47780 [01:56<01:05, 273.40 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28783/47780 [01:56<01:31, 208.10 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29847/47780 [01:56<01:08, 263.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31950/47780 [01:56<00:58, 268.41 examples/s]
Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28165/47780 [01:56<01:26, 225.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34810/47780 [01:57<00:41, 313.91 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29798/47780 [01:57<01:06, 269.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29943/47780 [01:57<01:29, 199.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30947/47780 [01:57<01:10, 239.92 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29874/47780 [01:57<01:09, 257.38 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28804/47780 [01:57<01:38, 191.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28375/47780 [01:57<00:33, 579.79 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29988/47780 [01:57<01:08, 261.11 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31978/47780 [01:57<01:03, 247.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34842/47780 [01:57<00:44, 289.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29900/47780 [01:57<01:09, 256.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29827/47780 [01:57<01:11, 250.09 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30972/47780 [01:57<01:11, 235.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28826/47780 [01:57<01:36, 197.20 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32008/47780 [01:57<01:01, 258.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30016/47780 [01:57<01:08, 259.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34872/47780 [01:57<00:44, 288.95 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28457/47780 [01:57<00:33, 572.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31000/47780 [01:57<01:10, 236.65 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29853/47780 [01:57<01:14, 239.81 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28846/47780 [01:57<01:42, 185.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29926/47780 [01:57<01:19, 223.23 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30047/47780 [01:57<01:05, 271.34 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32036/47780 [01:57<01:02, 250.45 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29880/47780 [01:57<01:12, 245.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34902/47780 [01:57<00:48, 266.50 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31025/47780 [01:57<01:14, 224.17 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28872/47780 [01:57<01:34, 199.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29953/47780 [01:57<01:16, 233.13 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28530/47780 [01:57<00:37, 515.61 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29912/47780 [01:57<01:08, 260.65 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30076/47780 [01:57<01:10, 249.92 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32062/47780 [01:57<01:06, 237.97 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34931/47780 [01:57<00:47, 269.37 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28894/47780 [01:57<01:32, 204.90 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29978/47780 [01:57<01:15, 235.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31052/47780 [01:57<01:13, 226.76 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30102/47780 [01:57<01:11, 247.34 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29943/47780 [01:57<01:07, 262.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32096/47780 [01:57<01:01, 256.71 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28594/47780 [01:57<00:40, 478.10 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28915/47780 [01:57<01:32, 204.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30008/47780 [01:57<01:10, 250.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34960/47780 [01:57<00:49, 258.34 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31075/47780 [01:57<01:18, 213.97 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30128/47780 [01:57<01:11, 246.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32124/47780 [01:57<01:00, 260.21 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 28662/47780 [01:57<00:37, 511.73 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29970/47780 [01:57<01:09, 255.26 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34991/47780 [01:57<00:47, 269.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30034/47780 [01:57<01:11, 247.61 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28937/47780 [01:57<01:37, 193.24 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31103/47780 [01:57<01:12, 228.95 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32153/47780 [01:57<00:59, 262.66 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28721/47780 [01:57<00:36, 517.86 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35019/47780 [01:57<00:47, 266.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29996/47780 [01:57<01:13, 240.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30154/47780 [01:57<01:17, 228.11 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30060/47780 [01:57<01:15, 233.73 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28962/47780 [01:57<01:32, 204.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31127/47780 [01:57<01:15, 221.41 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32180/47780 [01:57<00:59, 264.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35046/47780 [01:57<00:47, 267.15 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30178/47780 [01:57<01:18, 224.82 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28778/47780 [01:57<00:38, 498.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30029/47780 [01:57<01:09, 255.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31154/47780 [01:57<01:11, 232.99 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28983/47780 [01:57<01:36, 195.11 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30084/47780 [01:58<01:18, 224.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35079/47780 [01:58<00:45, 281.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32207/47780 [01:58<01:04, 241.24 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30059/47780 [01:58<01:06, 266.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31179/47780 [01:58<01:09, 237.46 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30201/47780 [01:58<01:21, 216.32 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28832/47780 [01:57<00:38, 486.57 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30110/47780 [01:58<01:17, 226.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29003/47780 [01:58<01:39, 188.82 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32236/47780 [01:58<01:01, 251.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35110/47780 [01:58<00:47, 265.58 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30086/47780 [01:58<01:08, 258.53 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30223/47780 [01:58<01:20, 217.10 examples/s]
Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28892/47780 [01:58<00:36, 514.11 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31205/47780 [01:58<01:10, 235.96 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30133/47780 [01:58<01:19, 222.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29023/47780 [01:58<01:44, 178.71 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30114/47780 [01:58<01:06, 264.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35140/47780 [01:58<00:46, 269.02 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32262/47780 [01:58<01:03, 243.54 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30253/47780 [01:58<01:14, 236.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31229/47780 [01:58<01:12, 229.53 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28946/47780 [01:58<00:40, 469.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29042/47780 [01:58<01:53, 165.01 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30141/47780 [01:58<01:07, 260.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30278/47780 [01:58<01:13, 238.89 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32289/47780 [01:58<01:03, 245.42 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31259/47780 [01:58<01:06, 249.20 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30156/47780 [01:58<01:40, 175.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35168/47780 [01:58<00:49, 253.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29010/47780 [01:58<00:36, 509.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29065/47780 [01:58<01:45, 177.99 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30304/47780 [01:58<01:11, 244.81 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32314/47780 [01:58<01:04, 241.45 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30206/47780 [01:58<01:10, 248.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30168/47780 [01:58<01:11, 245.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35194/47780 [01:58<00:50, 251.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31285/47780 [01:58<01:10, 235.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29063/47780 [01:58<00:39, 474.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29091/47780 [01:58<01:34, 197.61 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30330/47780 [01:58<01:11, 243.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32352/47780 [01:58<00:55, 279.66 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30234/47780 [01:58<01:08, 256.04 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30201/47780 [01:58<01:06, 263.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31309/47780 [01:58<01:10, 232.10 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29151/47780 [01:58<00:32, 579.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35220/47780 [01:58<00:55, 224.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29113/47780 [01:58<01:31, 203.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30262/47780 [01:58<01:07, 259.55 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30355/47780 [01:58<01:17, 224.47 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30228/47780 [01:58<01:07, 258.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32381/47780 [01:58<01:00, 253.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31333/47780 [01:58<01:15, 217.51 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35246/47780 [01:58<00:54, 228.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29217/47780 [01:58<00:31, 581.16 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29134/47780 [01:58<01:34, 196.49 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30255/47780 [01:58<01:08, 256.98 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30290/47780 [01:58<01:11, 245.29 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30378/47780 [01:58<01:21, 212.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31360/47780 [01:58<01:10, 231.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32408/47780 [01:58<01:02, 245.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35270/47780 [01:58<00:55, 224.52 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29278/47780 [01:58<00:35, 526.94 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29155/47780 [01:58<01:40, 184.43 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30281/47780 [01:58<01:08, 255.15 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30412/47780 [01:58<01:10, 245.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31389/47780 [01:58<01:06, 247.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32434/47780 [01:58<01:03, 243.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30316/47780 [01:59<01:14, 233.18 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35294/47780 [01:58<00:57, 216.84 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29334/47780 [01:58<00:35, 524.66 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29174/47780 [01:59<01:43, 179.80 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30307/47780 [01:59<01:09, 250.66 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31415/47780 [01:59<01:05, 248.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30444/47780 [01:59<01:07, 255.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32467/47780 [01:59<00:59, 256.57 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35316/47780 [01:59<00:57, 215.87 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30341/47780 [01:59<01:23, 209.36 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30333/47780 [01:59<01:09, 250.59 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29193/47780 [01:59<01:48, 171.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29388/47780 [01:59<00:38, 478.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30470/47780 [01:59<01:10, 245.51 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31441/47780 [01:59<01:10, 230.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35341/47780 [01:59<00:55, 222.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30370/47780 [01:59<01:15, 229.23 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32493/47780 [01:59<01:07, 225.49 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29439/47780 [01:59<00:38, 473.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30359/47780 [01:59<01:13, 236.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29211/47780 [01:59<01:53, 163.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30496/47780 [01:59<01:13, 234.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35368/47780 [01:59<00:52, 235.25 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31465/47780 [01:59<01:16, 214.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30402/47780 [01:59<01:10, 245.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32522/47780 [01:59<01:03, 239.64 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29502/47780 [01:59<00:35, 512.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30383/47780 [01:59<01:13, 235.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29228/47780 [01:59<01:57, 158.34 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30526/47780 [01:59<01:09, 247.15 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35392/47780 [01:59<00:55, 221.90 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30428/47780 [01:59<01:14, 234.14 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32547/47780 [01:59<01:05, 231.26 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31487/47780 [01:59<01:23, 195.37 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29556/47780 [01:59<00:36, 503.67 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30415/47780 [01:59<01:08, 252.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29247/47780 [01:59<01:52, 164.28 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30560/47780 [01:59<01:04, 267.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35416/47780 [01:59<00:55, 223.70 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30460/47780 [01:59<01:08, 252.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32576/47780 [01:59<01:04, 235.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31508/47780 [01:59<01:24, 193.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29610/47780 [01:59<00:35, 513.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30441/47780 [01:59<01:11, 244.10 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29271/47780 [01:59<01:46, 174.14 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35439/47780 [01:59<00:57, 215.12 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30492/47780 [01:59<01:04, 269.54 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32600/47780 [01:59<01:04, 234.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31528/47780 [01:59<01:28, 183.21 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30473/47780 [01:59<01:05, 262.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30588/47780 [01:59<01:18, 219.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29663/47780 [01:59<00:37, 478.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29295/47780 [01:59<01:37, 189.79 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35462/47780 [01:59<00:56, 218.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32628/47780 [01:59<01:01, 246.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31552/47780 [01:59<01:22, 196.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30618/47780 [01:59<01:11, 238.78 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30500/47780 [01:59<01:06, 261.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30521/47780 [01:59<01:11, 242.04 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29315/47780 [01:59<01:35, 192.56 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35491/47780 [01:59<00:51, 238.59 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29712/47780 [01:59<00:42, 423.00 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32654/47780 [01:59<01:01, 247.77 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30647/47780 [01:59<01:08, 251.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30530/47780 [01:59<01:03, 269.60 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31574/47780 [01:59<01:21, 198.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30553/47780 [01:59<01:06, 260.39 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29335/47780 [01:59<01:40, 184.14 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29769/47780 [01:59<00:39, 456.69 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32683/47780 [01:59<00:58, 259.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35517/47780 [01:59<00:53, 227.72 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30582/47780 [02:00<01:05, 263.25 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31597/47780 [02:00<01:19, 202.63 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30560/47780 [02:00<01:06, 260.38 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30674/47780 [02:00<01:14, 229.84 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29354/47780 [02:00<01:44, 175.71 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29817/47780 [01:59<00:39, 449.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35541/47780 [02:00<00:53, 229.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32710/47780 [02:00<00:59, 254.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30613/47780 [02:00<01:03, 272.48 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30587/47780 [02:00<01:06, 257.33 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30701/47780 [02:00<01:11, 238.80 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31618/47780 [02:00<01:26, 186.13 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29864/47780 [02:00<00:39, 449.13 examples/s]
Tokenizing train dataset (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29382/47780 [02:00<01:34, 193.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35565/47780 [02:00<00:53, 227.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32736/47780 [02:00<01:00, 250.04 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30641/47780 [02:00<01:05, 261.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30727/47780 [02:00<01:10, 240.57 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30613/47780 [02:00<01:09, 247.66 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29404/47780 [02:00<01:31, 200.55 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29925/47780 [02:00<00:36, 487.69 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31637/47780 [02:00<01:34, 170.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35592/47780 [02:00<00:52, 234.29 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32766/47780 [02:00<01:03, 237.26 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30668/47780 [02:00<01:08, 251.53 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30643/47780 [02:00<01:06, 255.79 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30752/47780 [02:00<01:12, 235.20 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29426/47780 [02:00<01:30, 202.01 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31655/47780 [02:00<01:33, 171.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35619/47780 [02:00<00:50, 242.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29975/47780 [02:00<00:37, 469.60 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32791/47780 [02:00<01:02, 240.09 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30694/47780 [02:00<01:09, 245.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30670/47780 [02:00<01:07, 254.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30777/47780 [02:00<01:14, 229.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35645/47780 [02:00<00:49, 246.56 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29447/47780 [02:00<01:33, 195.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31673/47780 [02:00<01:39, 161.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30023/47780 [02:00<00:40, 440.18 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32816/47780 [02:00<01:04, 230.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30696/47780 [02:00<01:07, 252.97 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30804/47780 [02:00<01:11, 238.74 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30719/47780 [02:00<01:14, 230.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35671/47780 [02:00<00:49, 244.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29467/47780 [02:00<01:39, 183.30 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30068/47780 [02:00<00:41, 427.94 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31690/47780 [02:00<01:46, 151.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32840/47780 [02:00<01:08, 219.03 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30722/47780 [02:00<01:07, 251.83 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30745/47780 [02:00<01:12, 234.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35696/47780 [02:00<00:50, 240.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30829/47780 [02:00<01:17, 219.17 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29492/47780 [02:00<01:32, 198.42 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30113/47780 [02:00<00:40, 433.42 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31706/47780 [02:00<01:51, 144.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30748/47780 [02:00<01:08, 248.76 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32863/47780 [02:00<01:10, 212.42 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30770/47780 [02:00<01:12, 233.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35723/47780 [02:00<00:48, 248.52 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29513/47780 [02:00<01:34, 193.10 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30157/47780 [02:00<00:41, 420.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30852/47780 [02:00<01:27, 192.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31723/47780 [02:00<01:51, 143.71 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32885/47780 [02:00<01:10, 212.56 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30774/47780 [02:00<01:10, 240.87 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35750/47780 [02:00<00:47, 254.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30794/47780 [02:00<01:16, 223.24 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29535/47780 [02:00<01:33, 196.12 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30201/47780 [02:00<00:43, 406.23 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30876/47780 [02:01<01:23, 203.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31744/47780 [02:00<01:40, 159.35 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32907/47780 [02:00<01:09, 214.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30799/47780 [02:01<01:09, 243.28 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30818/47780 [02:01<01:15, 226.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35777/47780 [02:01<00:48, 247.88 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29561/47780 [02:01<01:26, 211.48 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30247/47780 [02:00<00:41, 419.13 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32931/47780 [02:01<01:07, 221.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30833/47780 [02:01<01:04, 262.13 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30898/47780 [02:01<01:29, 189.41 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31762/47780 [02:01<01:43, 154.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30841/47780 [02:01<01:15, 223.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35803/47780 [02:01<00:49, 241.36 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29583/47780 [02:01<01:30, 200.38 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32960/47780 [02:01<01:02, 236.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30860/47780 [02:01<01:06, 255.39 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30918/47780 [02:01<01:30, 186.58 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30866/47780 [02:01<01:13, 231.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31778/47780 [02:01<01:46, 149.88 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30290/47780 [02:01<00:52, 335.58 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35829/47780 [02:01<00:52, 225.75 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29604/47780 [02:01<01:31, 199.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30890/47780 [02:01<01:12, 233.62 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31797/47780 [02:01<01:39, 160.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32984/47780 [02:01<01:08, 217.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30887/47780 [02:01<01:09, 243.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30363/47780 [02:01<00:40, 430.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30938/47780 [02:01<01:37, 173.07 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35859/47780 [02:01<00:48, 245.62 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29628/47780 [02:01<01:26, 209.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31816/47780 [02:01<01:35, 166.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30915/47780 [02:01<01:15, 223.43 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30912/47780 [02:01<01:11, 235.06 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33007/47780 [02:01<01:13, 201.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35885/47780 [02:01<00:48, 246.86 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30411/47780 [02:01<00:42, 410.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30956/47780 [02:01<01:44, 161.04 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29653/47780 [02:01<01:24, 215.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31836/47780 [02:01<01:32, 172.18 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33028/47780 [02:01<01:12, 203.04 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30938/47780 [02:01<01:19, 213.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30938/47780 [02:01<01:12, 231.71 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30463/47780 [02:01<00:39, 437.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30978/47780 [02:01<01:36, 173.94 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29675/47780 [02:01<01:26, 209.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35915/47780 [02:01<00:50, 235.41 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31857/47780 [02:01<01:30, 176.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30966/47780 [02:01<01:12, 231.41 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33056/47780 [02:01<01:07, 219.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30963/47780 [02:01<01:11, 234.27 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29702/47780 [02:01<01:20, 225.20 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35947/47780 [02:01<00:45, 257.58 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30511/47780 [02:01<00:42, 401.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30996/47780 [02:01<01:44, 160.37 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31875/47780 [02:01<01:34, 168.33 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30990/47780 [02:01<01:14, 225.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33087/47780 [02:01<01:02, 236.68 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30987/47780 [02:01<01:16, 220.21 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29727/47780 [02:01<01:18, 229.65 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30554/47780 [02:01<00:42, 405.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31016/47780 [02:01<01:41, 165.45 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35974/47780 [02:01<00:51, 230.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31894/47780 [02:01<01:31, 174.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33123/47780 [02:01<00:54, 267.79 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31013/47780 [02:01<01:16, 220.00 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31032/47780 [02:01<00:59, 280.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29751/47780 [02:01<01:26, 208.41 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30597/47780 [02:01<00:44, 382.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35999/47780 [02:01<00:50, 233.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31033/47780 [02:02<01:47, 155.14 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31919/47780 [02:01<01:24, 187.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31037/47780 [02:02<01:15, 220.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33152/47780 [02:01<00:56, 259.18 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31072/47780 [02:02<00:54, 306.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29777/47780 [02:02<01:22, 218.83 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36025/47780 [02:02<00:48, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30652/47780 [02:01<00:40, 419.78 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31054/47780 [02:02<01:41, 164.42 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31939/47780 [02:02<01:23, 188.64 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31060/47780 [02:02<01:16, 217.88 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33179/47780 [02:02<00:57, 255.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31104/47780 [02:02<00:57, 288.01 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36050/47780 [02:02<00:50, 232.51 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30696/47780 [02:02<00:42, 401.76 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31961/47780 [02:02<01:21, 195.29 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29800/47780 [02:02<01:33, 191.61 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31072/47780 [02:02<01:48, 153.71 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33210/47780 [02:02<00:54, 265.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31082/47780 [02:02<01:20, 206.58 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36074/47780 [02:02<00:51, 227.27 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31134/47780 [02:02<01:06, 250.30 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31982/47780 [02:02<01:25, 184.71 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31088/47780 [02:02<01:52, 147.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33238/47780 [02:02<00:55, 260.73 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31103/47780 [02:02<01:22, 201.28 examples/s]
Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29820/47780 [02:02<01:41, 176.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30738/47780 [02:02<00:50, 337.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36097/47780 [02:02<00:51, 227.91 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31161/47780 [02:02<01:05, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32005/47780 [02:02<01:21, 194.75 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31107/47780 [02:02<01:45, 158.73 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33280/47780 [02:02<00:49, 295.64 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31127/47780 [02:02<01:20, 207.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29842/47780 [02:02<01:38, 182.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30792/47780 [02:02<00:44, 383.37 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36121/47780 [02:02<00:52, 221.53 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31188/47780 [02:02<01:06, 248.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33313/47780 [02:02<00:47, 305.03 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31149/47780 [02:02<01:19, 208.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32025/47780 [02:02<01:27, 181.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29861/47780 [02:02<01:37, 182.90 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31125/47780 [02:02<01:53, 147.12 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30834/47780 [02:02<00:48, 352.15 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31214/47780 [02:02<01:10, 234.81 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31170/47780 [02:02<01:20, 206.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36149/47780 [02:02<00:57, 201.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32044/47780 [02:02<01:29, 175.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33344/47780 [02:02<00:53, 269.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31148/47780 [02:02<01:42, 161.73 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29882/47780 [02:02<01:43, 173.52 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30872/47780 [02:02<00:47, 353.16 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31198/47780 [02:02<01:12, 227.60 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31238/47780 [02:02<01:12, 227.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36172/47780 [02:02<00:56, 206.94 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32066/47780 [02:02<01:26, 181.37 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31165/47780 [02:02<01:43, 160.54 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29900/47780 [02:02<01:45, 169.74 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33373/47780 [02:02<00:55, 258.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30909/47780 [02:02<00:49, 339.80 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31273/47780 [02:02<01:04, 256.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31221/47780 [02:02<01:14, 223.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36195/47780 [02:02<00:56, 206.42 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32085/47780 [02:02<01:27, 179.95 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31184/47780 [02:02<01:42, 161.50 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29922/47780 [02:02<01:39, 178.67 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33400/47780 [02:02<00:56, 253.86 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30944/47780 [02:02<00:50, 332.55 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31244/47780 [02:03<01:16, 217.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31300/47780 [02:02<01:05, 249.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36225/47780 [02:02<00:50, 226.61 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32108/47780 [02:02<01:20, 193.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31211/47780 [02:03<01:28, 186.51 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29943/47780 [02:03<01:37, 183.85 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33426/47780 [02:03<00:58, 247.30 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30986/47780 [02:02<00:48, 348.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31269/47780 [02:03<01:13, 224.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31326/47780 [02:03<01:09, 236.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32128/47780 [02:03<01:26, 180.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36250/47780 [02:03<00:56, 205.06 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33451/47780 [02:03<00:59, 240.23 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31230/47780 [02:03<01:36, 170.75 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29962/47780 [02:03<01:46, 167.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31292/47780 [02:03<01:12, 225.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31350/47780 [02:03<01:10, 234.57 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32150/47780 [02:03<01:22, 189.60 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31022/47780 [02:03<00:59, 283.75 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36273/47780 [02:03<00:56, 202.17 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31249/47780 [02:03<01:34, 174.07 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29983/47780 [02:03<01:39, 178.20 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33476/47780 [02:03<01:03, 225.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31320/47780 [02:03<01:10, 233.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31380/47780 [02:03<01:05, 250.36 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31087/47780 [02:03<00:45, 367.50 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32170/47780 [02:03<01:28, 177.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36301/47780 [02:03<00:52, 220.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31344/47780 [02:03<01:09, 235.42 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31267/47780 [02:03<01:42, 161.57 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33499/47780 [02:03<01:06, 213.21 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30002/47780 [02:03<01:48, 163.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31406/47780 [02:03<01:07, 243.54 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31129/47780 [02:03<00:45, 365.76 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36327/47780 [02:03<00:50, 228.32 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32189/47780 [02:03<01:31, 169.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31368/47780 [02:03<01:09, 236.47 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31289/47780 [02:03<01:36, 171.33 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30024/47780 [02:03<01:42, 172.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33521/47780 [02:03<01:11, 198.71 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31431/47780 [02:03<01:12, 225.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36360/47780 [02:03<00:44, 256.07 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32209/47780 [02:03<01:30, 172.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31398/47780 [02:03<01:05, 250.83 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31169/47780 [02:03<00:49, 333.75 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31307/47780 [02:03<01:38, 166.68 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30045/47780 [02:03<01:40, 177.04 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33545/47780 [02:03<01:08, 209.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31463/47780 [02:03<01:06, 246.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36390/47780 [02:03<00:44, 256.91 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31430/47780 [02:03<01:00, 269.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32227/47780 [02:03<01:30, 172.26 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31227/47780 [02:03<00:42, 390.40 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31325/47780 [02:03<01:38, 166.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33574/47780 [02:03<01:01, 230.84 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30063/47780 [02:03<01:45, 167.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31489/47780 [02:03<01:07, 241.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31458/47780 [02:03<01:01, 266.55 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32245/47780 [02:03<01:33, 167.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31270/47780 [02:03<00:41, 396.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36417/47780 [02:03<00:47, 236.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31342/47780 [02:03<01:38, 167.42 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33598/47780 [02:03<01:01, 230.94 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30084/47780 [02:03<01:40, 176.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31530/47780 [02:03<00:56, 285.16 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31487/47780 [02:03<01:01, 263.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32262/47780 [02:03<01:34, 164.50 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36456/47780 [02:03<00:41, 275.30 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31313/47780 [02:03<00:41, 392.94 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33622/47780 [02:03<01:01, 230.61 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31359/47780 [02:04<01:42, 160.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30105/47780 [02:03<01:35, 185.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31559/47780 [02:04<01:02, 260.15 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31517/47780 [02:04<00:59, 271.64 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36488/47780 [02:04<00:39, 286.74 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32279/47780 [02:04<01:34, 164.03 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31354/47780 [02:03<00:41, 397.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33646/47780 [02:04<01:03, 221.13 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31377/47780 [02:04<01:44, 157.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30131/47780 [02:04<01:31, 193.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31592/47780 [02:04<00:59, 273.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31546/47780 [02:04<00:59, 273.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36532/47780 [02:04<00:34, 326.14 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32296/47780 [02:04<01:34, 163.96 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31401/47780 [02:04<00:39, 413.85 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31396/47780 [02:04<01:39, 164.76 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33669/47780 [02:04<01:05, 214.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30151/47780 [02:04<01:34, 187.13 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32315/47780 [02:04<01:31, 168.69 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36566/47780 [02:04<00:34, 322.64 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31446/47780 [02:04<00:39, 416.65 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31574/47780 [02:04<01:05, 246.64 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31418/47780 [02:04<01:31, 178.09 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33691/47780 [02:04<01:05, 215.17 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31620/47780 [02:04<01:12, 222.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30170/47780 [02:04<01:37, 179.95 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36606/47780 [02:04<00:32, 344.59 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31509/47780 [02:04<00:34, 468.84 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31603/47780 [02:04<01:02, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32332/47780 [02:04<01:41, 152.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33716/47780 [02:04<01:03, 222.74 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31437/47780 [02:04<01:32, 176.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30199/47780 [02:04<01:24, 207.72 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31557/47780 [02:04<00:35, 462.36 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31645/47780 [02:04<01:19, 203.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36641/47780 [02:04<00:36, 304.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31630/47780 [02:04<01:05, 247.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32351/47780 [02:04<01:38, 157.41 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33741/47780 [02:04<01:01, 227.97 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31468/47780 [02:04<01:17, 210.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30224/47780 [02:04<01:20, 219.07 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31700/47780 [02:04<00:57, 281.17 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32367/47780 [02:04<01:37, 157.95 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31604/47780 [02:04<00:38, 424.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33768/47780 [02:04<01:01, 229.44 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31490/47780 [02:04<01:19, 203.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31656/47780 [02:04<01:09, 233.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30252/47780 [02:04<01:14, 234.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36673/47780 [02:04<00:41, 268.22 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32391/47780 [02:04<01:25, 179.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31732/47780 [02:04<00:58, 274.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33797/47780 [02:04<00:57, 243.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31511/47780 [02:04<01:20, 201.76 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31648/47780 [02:04<00:40, 398.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31680/47780 [02:04<01:10, 227.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30279/47780 [02:04<01:14, 236.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36702/47780 [02:04<00:44, 248.96 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31765/47780 [02:04<00:55, 288.13 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32420/47780 [02:04<01:13, 208.66 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33826/47780 [02:04<00:54, 254.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31532/47780 [02:04<01:20, 201.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31689/47780 [02:04<00:41, 385.37 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31704/47780 [02:04<01:14, 217.09 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30303/47780 [02:04<01:18, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31798/47780 [02:04<00:53, 296.24 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36728/47780 [02:04<00:46, 235.57 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32442/47780 [02:04<01:18, 195.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31734/47780 [02:04<00:40, 398.35 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33852/47780 [02:04<01:00, 231.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31559/47780 [02:05<01:19, 203.05 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31726/47780 [02:05<01:14, 215.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31829/47780 [02:05<00:54, 290.60 examples/s]
Tokenizing train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30326/47780 [02:05<01:28, 198.11 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36755/47780 [02:05<00:46, 239.14 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32470/47780 [02:05<01:13, 207.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31786/47780 [02:04<00:37, 423.08 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31750/47780 [02:05<01:12, 222.23 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31585/47780 [02:05<01:14, 217.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33880/47780 [02:05<00:57, 239.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31859/47780 [02:05<00:55, 286.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36785/47780 [02:05<00:43, 253.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31830/47780 [02:05<00:37, 422.33 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32492/47780 [02:05<01:14, 206.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30347/47780 [02:05<01:35, 182.68 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31609/47780 [02:05<01:13, 219.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31780/47780 [02:05<01:07, 238.75 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33905/47780 [02:05<00:58, 236.71 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31889/47780 [02:05<00:54, 290.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36812/47780 [02:05<00:45, 243.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30367/47780 [02:05<01:34, 184.93 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32513/47780 [02:05<01:15, 202.93 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31807/47780 [02:05<01:04, 247.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33929/47780 [02:05<01:01, 225.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31873/47780 [02:05<00:41, 383.63 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31632/47780 [02:05<01:20, 199.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31927/47780 [02:05<00:53, 293.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36838/47780 [02:05<00:44, 245.58 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32539/47780 [02:05<01:10, 216.35 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31838/47780 [02:05<01:00, 265.30 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30391/47780 [02:05<01:29, 193.26 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33957/47780 [02:05<00:58, 237.84 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31913/47780 [02:05<00:41, 385.56 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31653/47780 [02:05<01:22, 194.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36874/47780 [02:05<00:39, 273.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31957/47780 [02:05<00:55, 284.61 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32561/47780 [02:05<01:10, 215.43 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30412/47780 [02:05<01:28, 195.49 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31865/47780 [02:05<01:04, 246.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33983/47780 [02:05<00:57, 238.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31954/47780 [02:05<00:43, 364.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31687/47780 [02:05<01:09, 232.49 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32596/47780 [02:05<01:02, 244.84 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36902/47780 [02:05<00:43, 252.68 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30442/47780 [02:05<01:20, 214.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31986/47780 [02:05<01:00, 263.00 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31891/47780 [02:05<01:07, 234.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31711/47780 [02:05<01:09, 232.24 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34008/47780 [02:05<01:01, 222.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32000/47780 [02:05<00:41, 377.92 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32623/47780 [02:05<01:00, 248.99 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30464/47780 [02:05<01:23, 207.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36928/47780 [02:05<00:45, 237.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32013/47780 [02:05<01:03, 249.20 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31927/47780 [02:05<01:00, 263.88 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31735/47780 [02:05<01:09, 231.88 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32042/47780 [02:05<00:40, 385.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34031/47780 [02:05<01:04, 212.53 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32649/47780 [02:05<01:02, 243.93 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30486/47780 [02:05<01:22, 210.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36960/47780 [02:05<00:42, 257.17 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32042/47780 [02:05<01:02, 252.15 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31954/47780 [02:05<01:01, 255.74 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32082/47780 [02:05<00:41, 380.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31759/47780 [02:05<01:14, 214.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34053/47780 [02:05<01:06, 207.49 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32674/47780 [02:05<01:01, 245.64 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30508/47780 [02:05<01:22, 208.63 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36988/47780 [02:05<00:42, 256.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31984/47780 [02:06<01:00, 262.85 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32122/47780 [02:05<00:41, 381.80 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31787/47780 [02:06<01:09, 229.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34081/47780 [02:05<01:00, 225.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32068/47780 [02:05<01:09, 225.39 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32699/47780 [02:06<01:05, 230.99 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30529/47780 [02:06<01:24, 204.01 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37017/47780 [02:06<00:42, 252.14 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32011/47780 [02:06<01:00, 261.87 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32165/47780 [02:05<00:39, 395.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31814/47780 [02:06<01:06, 241.05 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34107/47780 [02:06<00:58, 234.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32092/47780 [02:06<01:08, 228.82 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32723/47780 [02:06<01:04, 233.01 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30553/47780 [02:06<01:21, 211.16 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37043/47780 [02:06<00:42, 251.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32212/47780 [02:06<00:38, 409.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32044/47780 [02:06<00:57, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31845/47780 [02:06<01:01, 260.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34134/47780 [02:06<00:55, 244.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32121/47780 [02:06<01:04, 242.81 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30576/47780 [02:06<01:20, 212.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32752/47780 [02:06<01:02, 238.79 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37069/47780 [02:06<00:42, 251.67 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32254/47780 [02:06<00:37, 410.99 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32072/47780 [02:06<00:58, 266.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31872/47780 [02:06<01:01, 257.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34159/47780 [02:06<00:57, 235.17 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32146/47780 [02:06<01:08, 227.50 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32787/47780 [02:06<00:55, 269.69 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30600/47780 [02:06<01:20, 213.24 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37095/47780 [02:06<00:42, 250.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32296/47780 [02:06<00:37, 407.55 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32099/47780 [02:06<01:00, 259.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34183/47780 [02:06<00:58, 233.91 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31899/47780 [02:06<01:05, 242.73 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32184/47780 [02:06<01:00, 259.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32820/47780 [02:06<00:53, 280.78 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30622/47780 [02:06<01:25, 201.51 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37121/47780 [02:06<00:44, 242.19 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32337/47780 [02:06<00:40, 382.81 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32128/47780 [02:06<00:59, 265.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34215/47780 [02:06<00:53, 255.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31930/47780 [02:06<01:01, 258.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32224/47780 [02:06<00:52, 297.10 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30643/47780 [02:06<01:27, 196.64 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32385/47780 [02:06<00:37, 405.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37146/47780 [02:06<00:45, 233.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32156/47780 [02:06<00:58, 266.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34241/47780 [02:06<00:53, 253.83 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32850/47780 [02:06<01:01, 241.01 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31957/47780 [02:06<01:04, 246.24 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32256/47780 [02:06<00:56, 273.40 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30668/47780 [02:06<01:21, 209.74 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32196/47780 [02:06<00:51, 301.21 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37170/47780 [02:06<00:46, 230.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32432/47780 [02:06<00:37, 414.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34270/47780 [02:06<00:51, 261.53 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31982/47780 [02:06<01:05, 239.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32876/47780 [02:06<01:05, 226.11 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32291/47780 [02:06<00:53, 290.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32227/47780 [02:06<00:51, 303.66 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37214/47780 [02:06<00:36, 288.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30690/47780 [02:06<01:23, 203.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34299/47780 [02:06<00:50, 266.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32474/47780 [02:06<00:38, 401.03 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32008/47780 [02:06<01:04, 243.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32321/47780 [02:06<00:56, 273.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32900/47780 [02:06<01:12, 204.35 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32517/47780 [02:06<00:37, 406.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34326/47780 [02:06<00:52, 254.39 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32258/47780 [02:06<00:55, 279.46 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30711/47780 [02:06<01:30, 188.54 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37244/47780 [02:06<00:39, 264.60 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32035/47780 [02:06<01:03, 247.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32923/47780 [02:06<01:10, 210.07 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32559/47780 [02:06<00:37, 405.02 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32350/47780 [02:07<01:00, 255.11 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32292/47780 [02:07<00:52, 292.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34352/47780 [02:07<00:54, 247.00 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30732/47780 [02:07<01:29, 190.23 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32062/47780 [02:07<01:02, 250.84 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37272/47780 [02:07<00:44, 238.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32945/47780 [02:07<01:11, 207.38 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32600/47780 [02:07<00:37, 401.21 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32322/47780 [02:07<00:52, 292.37 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34377/47780 [02:07<00:54, 247.08 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32089/47780 [02:07<01:01, 255.55 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32378/47780 [02:07<01:03, 241.61 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30752/47780 [02:07<01:31, 186.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37299/47780 [02:07<00:44, 236.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32969/47780 [02:07<01:11, 207.24 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32642/47780 [02:07<00:37, 401.54 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34403/47780 [02:07<00:54, 245.15 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32352/47780 [02:07<00:54, 284.13 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32404/47780 [02:07<01:02, 246.20 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32117/47780 [02:07<01:02, 251.74 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30776/47780 [02:07<01:28, 192.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37329/47780 [02:07<00:42, 247.96 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32997/47780 [02:07<01:06, 221.94 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32686/47780 [02:07<00:37, 404.15 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32384/47780 [02:07<00:52, 290.96 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34429/47780 [02:07<00:54, 243.83 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32143/47780 [02:07<01:03, 247.87 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32431/47780 [02:07<01:07, 228.36 examples/s]
Tokenizing train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30800/47780 [02:07<01:27, 193.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37357/47780 [02:07<00:41, 251.14 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33026/47780 [02:07<01:01, 240.26 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32728/47780 [02:07<00:37, 404.32 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34464/47780 [02:07<00:49, 271.01 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30823/47780 [02:07<01:23, 202.88 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32414/47780 [02:07<00:59, 258.43 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32470/47780 [02:07<00:57, 266.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32168/47780 [02:07<01:09, 225.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37386/47780 [02:07<00:41, 253.29 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33052/47780 [02:07<01:01, 238.49 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32769/47780 [02:07<00:39, 375.53 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34492/47780 [02:07<00:50, 264.58 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32461/47780 [02:07<00:48, 314.02 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30844/47780 [02:07<01:23, 202.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32499/47780 [02:07<00:58, 261.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37427/47780 [02:07<00:35, 290.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33079/47780 [02:07<00:59, 246.51 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32191/47780 [02:07<01:16, 204.51 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32807/47780 [02:07<00:41, 364.66 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34520/47780 [02:07<00:52, 254.70 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30865/47780 [02:07<01:24, 200.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32531/47780 [02:07<00:56, 269.98 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37462/47780 [02:07<00:33, 306.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33105/47780 [02:07<00:59, 247.56 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32496/47780 [02:07<00:53, 286.22 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32216/47780 [02:07<01:12, 214.95 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32850/47780 [02:07<00:39, 374.45 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34548/47780 [02:07<00:52, 253.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30888/47780 [02:07<01:25, 197.60 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32559/47780 [02:07<00:59, 257.40 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32532/47780 [02:07<00:50, 304.90 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32241/47780 [02:07<01:09, 224.15 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37495/47780 [02:07<00:35, 293.23 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33130/47780 [02:07<01:03, 229.59 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32898/47780 [02:07<00:36, 403.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34575/47780 [02:07<00:51, 255.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30913/47780 [02:07<01:20, 209.65 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32587/47780 [02:07<00:58, 260.90 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32567/47780 [02:08<00:48, 313.86 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32267/47780 [02:08<01:06, 233.91 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37527/47780 [02:07<00:34, 293.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32939/47780 [02:07<00:37, 392.66 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34601/47780 [02:07<00:52, 253.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33154/47780 [02:08<01:12, 201.74 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30942/47780 [02:08<01:14, 224.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32600/47780 [02:08<00:48, 316.02 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32292/47780 [02:08<01:05, 235.91 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32614/47780 [02:08<01:00, 251.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37557/47780 [02:08<00:35, 289.62 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32980/47780 [02:08<00:37, 392.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34627/47780 [02:08<00:53, 243.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33177/47780 [02:08<01:09, 208.78 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30965/47780 [02:08<01:16, 219.05 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32633/47780 [02:08<00:49, 307.87 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32646/47780 [02:08<00:57, 265.36 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32318/47780 [02:08<01:10, 219.99 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33026/47780 [02:08<00:36, 407.14 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37587/47780 [02:08<00:39, 260.55 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34657/47780 [02:08<00:51, 256.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33204/47780 [02:08<01:06, 220.40 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30992/47780 [02:08<01:12, 230.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32675/47780 [02:08<00:55, 271.68 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32666/47780 [02:08<00:50, 301.05 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32345/47780 [02:08<01:07, 228.97 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33068/47780 [02:08<00:36, 401.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34683/47780 [02:08<00:53, 244.47 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37614/47780 [02:08<00:42, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31016/47780 [02:08<01:14, 225.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33227/47780 [02:08<01:11, 203.46 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32703/47780 [02:08<00:59, 251.69 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32376/47780 [02:08<01:02, 248.17 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33124/47780 [02:08<00:33, 442.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32697/47780 [02:08<00:55, 273.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34711/47780 [02:08<00:52, 248.43 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37640/47780 [02:08<00:42, 238.56 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31039/47780 [02:08<01:16, 219.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33248/47780 [02:08<01:14, 194.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32734/47780 [02:08<00:58, 259.04 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33172/47780 [02:08<00:32, 452.70 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32725/47780 [02:08<00:55, 272.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32402/47780 [02:08<01:06, 230.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34736/47780 [02:08<00:53, 243.65 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37671/47780 [02:08<00:40, 251.95 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31065/47780 [02:08<01:13, 228.75 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33281/47780 [02:08<01:04, 225.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32759/47780 [02:08<00:51, 290.58 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32764/47780 [02:08<00:57, 261.66 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32427/47780 [02:08<01:05, 235.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33218/47780 [02:08<00:34, 416.44 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34767/47780 [02:08<00:49, 262.04 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31088/47780 [02:08<01:12, 228.98 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37702/47780 [02:08<00:38, 259.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33306/47780 [02:08<01:03, 229.62 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32793/47780 [02:08<00:56, 266.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32458/47780 [02:08<01:00, 253.89 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32790/47780 [02:08<00:56, 266.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34796/47780 [02:08<00:50, 257.97 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31112/47780 [02:08<01:11, 231.72 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37729/47780 [02:08<00:38, 259.28 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33334/47780 [02:08<01:00, 238.26 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33261/47780 [02:08<00:42, 344.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32820/47780 [02:08<00:57, 261.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32484/47780 [02:08<01:02, 244.27 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32818/47780 [02:08<00:59, 251.27 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37756/47780 [02:08<00:38, 259.13 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34822/47780 [02:08<00:52, 247.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33360/47780 [02:08<01:00, 239.06 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31137/47780 [02:08<01:17, 214.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33319/47780 [02:08<00:35, 401.81 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32849/47780 [02:08<00:55, 269.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32514/47780 [02:09<00:59, 257.85 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34850/47780 [02:08<00:50, 253.99 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37783/47780 [02:08<00:39, 256.19 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32844/47780 [02:09<01:00, 245.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33385/47780 [02:08<00:30, 468.46 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33386/47780 [02:09<01:00, 239.23 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31165/47780 [02:09<01:13, 227.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32541/47780 [02:09<00:59, 254.88 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32877/47780 [02:09<01:03, 234.98 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34877/47780 [02:09<00:49, 258.39 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37815/47780 [02:09<00:37, 268.71 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32870/47780 [02:09<01:01, 242.86 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33436/47780 [02:09<00:30, 474.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31189/47780 [02:09<01:15, 219.95 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33415/47780 [02:09<01:06, 217.10 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32567/47780 [02:09<01:02, 245.26 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32902/47780 [02:09<01:02, 238.05 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34913/47780 [02:09<00:46, 276.10 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32896/47780 [02:09<01:00, 246.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37843/47780 [02:09<00:37, 262.66 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33486/47780 [02:09<00:30, 467.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31212/47780 [02:09<01:15, 219.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33439/47780 [02:09<01:04, 220.72 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32592/47780 [02:09<01:03, 238.27 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32943/47780 [02:09<00:53, 276.49 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34941/47780 [02:09<00:46, 276.00 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32922/47780 [02:09<01:00, 245.25 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37870/47780 [02:09<00:39, 250.71 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33537/47780 [02:09<00:29, 477.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31235/47780 [02:09<01:15, 218.99 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32620/47780 [02:09<01:01, 247.49 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33462/47780 [02:09<01:08, 209.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32972/47780 [02:09<00:54, 273.76 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32951/47780 [02:09<00:58, 254.78 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34969/47780 [02:09<00:52, 245.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37896/47780 [02:09<00:41, 237.79 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33587/47780 [02:09<00:31, 457.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31258/47780 [02:09<01:17, 213.96 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32645/47780 [02:09<01:04, 235.04 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33485/47780 [02:09<01:09, 206.43 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32977/47780 [02:09<00:59, 250.70 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33000/47780 [02:09<00:58, 253.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34998/47780 [02:09<00:50, 252.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33636/47780 [02:09<00:32, 441.87 examples/s]
Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31280/47780 [02:09<01:23, 197.49 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32673/47780 [02:09<01:01, 247.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37920/47780 [02:09<00:48, 203.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33005/47780 [02:09<00:57, 258.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33506/47780 [02:09<01:11, 199.62 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33027/47780 [02:09<00:57, 257.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35034/47780 [02:09<00:46, 277.07 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33681/47780 [02:09<00:32, 430.07 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32698/47780 [02:09<01:01, 245.31 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31302/47780 [02:09<01:25, 192.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37943/47780 [02:09<00:46, 209.86 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33032/47780 [02:09<00:56, 259.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33054/47780 [02:09<00:57, 255.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33529/47780 [02:09<01:12, 197.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33728/47780 [02:09<00:32, 436.84 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35063/47780 [02:09<00:49, 257.16 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37966/47780 [02:09<00:45, 214.78 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31355/47780 [02:09<00:59, 277.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33063/47780 [02:09<00:53, 273.09 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32723/47780 [02:09<01:04, 235.02 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33081/47780 [02:09<00:57, 256.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33553/47780 [02:09<01:08, 208.65 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35091/47780 [02:09<00:48, 259.86 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33773/47780 [02:09<00:33, 413.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37994/47780 [02:09<00:43, 225.48 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33093/47780 [02:10<00:52, 278.46 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32760/47780 [02:10<00:56, 267.67 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31384/47780 [02:09<01:01, 266.16 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33107/47780 [02:09<00:58, 251.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33575/47780 [02:09<01:09, 204.08 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35124/47780 [02:09<00:46, 273.06 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33815/47780 [02:09<00:34, 405.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38017/47780 [02:10<00:44, 221.87 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33121/47780 [02:10<00:53, 274.88 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31412/47780 [02:10<01:02, 263.65 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33599/47780 [02:10<01:06, 213.77 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32787/47780 [02:10<01:00, 246.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33133/47780 [02:10<01:02, 235.63 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35153/47780 [02:10<00:45, 275.63 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33860/47780 [02:10<00:33, 413.59 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38044/47780 [02:10<00:41, 232.63 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33149/47780 [02:10<00:57, 255.98 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31439/47780 [02:10<01:07, 243.85 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33627/47780 [02:10<01:03, 223.37 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33157/47780 [02:10<01:01, 236.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32813/47780 [02:10<01:03, 236.25 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35181/47780 [02:10<00:45, 275.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33907/47780 [02:10<00:32, 424.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38070/47780 [02:10<00:41, 232.49 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31464/47780 [02:10<01:08, 238.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33175/47780 [02:10<01:01, 237.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32838/47780 [02:10<01:03, 235.55 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33650/47780 [02:10<01:06, 213.74 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33181/47780 [02:10<01:07, 215.80 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35215/47780 [02:10<00:44, 284.56 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33951/47780 [02:10<00:34, 403.56 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38094/47780 [02:10<00:43, 222.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33211/47780 [02:10<00:53, 270.70 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31495/47780 [02:10<01:05, 249.80 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32862/47780 [02:10<01:04, 230.66 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33673/47780 [02:10<01:06, 212.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33213/47780 [02:10<01:00, 240.15 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34012/47780 [02:10<00:30, 453.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35244/47780 [02:10<00:47, 262.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38118/47780 [02:10<00:43, 224.39 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33242/47780 [02:10<00:53, 273.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32891/47780 [02:10<01:00, 246.79 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31521/47780 [02:10<01:07, 241.67 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33698/47780 [02:10<01:05, 215.47 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33240/47780 [02:10<00:58, 246.73 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35273/47780 [02:10<00:46, 266.93 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34059/47780 [02:10<00:30, 451.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38141/47780 [02:10<00:46, 208.20 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32916/47780 [02:10<01:01, 243.60 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33271/47780 [02:10<00:53, 269.29 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31546/47780 [02:10<01:08, 236.69 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33721/47780 [02:10<01:06, 212.53 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33266/47780 [02:10<01:01, 234.76 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34111/47780 [02:10<00:29, 466.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35300/47780 [02:10<00:48, 256.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38164/47780 [02:10<00:45, 211.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33303/47780 [02:10<00:51, 280.11 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32941/47780 [02:10<01:01, 242.45 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33747/47780 [02:10<01:02, 225.57 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31570/47780 [02:10<01:10, 230.01 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33294/47780 [02:10<00:59, 244.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34158/47780 [02:10<00:29, 456.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35326/47780 [02:10<00:48, 254.30 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32970/47780 [02:10<00:58, 253.60 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33332/47780 [02:10<00:54, 265.21 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38186/47780 [02:10<00:48, 196.32 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33770/47780 [02:10<01:03, 219.50 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31594/47780 [02:10<01:12, 223.36 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33322/47780 [02:10<00:58, 248.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34204/47780 [02:10<00:30, 448.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35352/47780 [02:10<00:52, 237.61 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33367/47780 [02:11<00:51, 282.28 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33797/47780 [02:10<01:00, 231.22 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32996/47780 [02:11<01:03, 234.01 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38211/47780 [02:10<00:46, 204.04 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31617/47780 [02:10<01:11, 224.83 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34263/47780 [02:10<00:27, 483.03 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33348/47780 [02:11<01:00, 238.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35380/47780 [02:10<00:50, 246.42 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33024/47780 [02:11<01:00, 243.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38238/47780 [02:11<00:43, 221.53 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 31644/47780 [02:11<01:07, 237.46 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33396/47780 [02:11<00:53, 266.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33373/47780 [02:11<00:59, 241.50 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34312/47780 [02:11<00:28, 473.59 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33821/47780 [02:11<01:06, 208.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35405/47780 [02:11<00:50, 244.17 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33050/47780 [02:11<00:59, 248.32 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31668/47780 [02:11<01:08, 235.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38261/47780 [02:11<00:44, 214.58 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33423/47780 [02:11<00:54, 262.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33405/47780 [02:11<00:55, 261.04 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33846/47780 [02:11<01:03, 218.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34361/47780 [02:11<00:28, 467.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35430/47780 [02:11<00:52, 235.38 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33076/47780 [02:11<01:00, 243.06 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31693/47780 [02:11<01:08, 234.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38283/47780 [02:11<00:44, 213.76 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33452/47780 [02:11<00:54, 262.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34415/47780 [02:11<00:27, 487.11 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33432/47780 [02:11<00:57, 249.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33873/47780 [02:11<01:01, 225.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35458/47780 [02:11<00:50, 245.47 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38307/47780 [02:11<00:42, 221.06 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33101/47780 [02:11<01:02, 234.64 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31717/47780 [02:11<01:12, 222.89 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33480/47780 [02:11<00:53, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34476/47780 [02:11<00:25, 518.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33906/47780 [02:11<00:58, 238.77 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33458/47780 [02:11<01:01, 234.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35485/47780 [02:11<00:49, 246.77 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38331/47780 [02:11<00:42, 221.45 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33131/47780 [02:11<00:58, 250.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31745/47780 [02:11<01:07, 236.40 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34532/47780 [02:11<00:24, 530.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33507/47780 [02:11<00:57, 246.42 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33932/47780 [02:11<00:57, 241.43 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33483/47780 [02:11<01:01, 233.27 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35512/47780 [02:11<00:48, 251.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38357/47780 [02:11<00:40, 232.32 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33157/47780 [02:11<00:58, 249.18 examples/s]
Tokenizing train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31769/47780 [02:11<01:10, 227.11 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34586/47780 [02:11<00:26, 497.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33960/47780 [02:11<00:55, 249.34 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33509/47780 [02:11<00:59, 240.48 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33532/47780 [02:11<01:01, 233.10 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35540/47780 [02:11<00:48, 252.69 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38387/47780 [02:11<00:38, 246.16 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33183/47780 [02:11<01:02, 231.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34637/47780 [02:11<00:26, 490.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33988/47780 [02:11<00:54, 255.40 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31792/47780 [02:11<01:17, 205.14 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33556/47780 [02:11<01:01, 232.31 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35568/47780 [02:11<00:46, 260.44 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33534/47780 [02:11<01:01, 232.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38412/47780 [02:11<00:40, 234.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33209/47780 [02:11<01:00, 239.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34689/47780 [02:11<00:26, 490.64 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33580/47780 [02:11<01:01, 232.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34019/47780 [02:11<00:52, 261.63 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31813/47780 [02:11<01:18, 202.16 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33558/47780 [02:11<01:06, 213.46 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38436/47780 [02:11<00:40, 233.29 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35595/47780 [02:11<00:55, 218.00 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33238/47780 [02:11<00:58, 248.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34740/47780 [02:11<00:26, 493.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34046/47780 [02:11<00:53, 255.35 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33604/47780 [02:12<01:03, 224.18 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31834/47780 [02:12<01:24, 187.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33581/47780 [02:12<01:06, 213.33 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33265/47780 [02:12<00:57, 251.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38460/47780 [02:12<00:43, 215.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33630/47780 [02:12<01:01, 231.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34790/47780 [02:12<00:28, 448.91 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34073/47780 [02:12<00:54, 251.08 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35619/47780 [02:12<01:02, 195.68 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31865/47780 [02:12<01:13, 215.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33603/47780 [02:12<01:08, 206.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38484/47780 [02:12<00:42, 217.29 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33291/47780 [02:12<01:01, 235.18 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33656/47780 [02:12<00:59, 239.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34837/47780 [02:12<00:28, 451.13 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35640/47780 [02:12<01:02, 195.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34099/47780 [02:12<00:59, 229.16 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31888/47780 [02:12<01:16, 208.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33629/47780 [02:12<01:05, 216.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38512/47780 [02:12<00:40, 227.03 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33323/47780 [02:12<00:58, 247.77 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33682/47780 [02:12<00:58, 240.69 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34897/47780 [02:12<00:26, 490.91 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35684/47780 [02:12<00:47, 252.54 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31910/47780 [02:12<01:17, 204.80 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34124/47780 [02:12<01:00, 226.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33652/47780 [02:12<01:10, 201.82 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33349/47780 [02:12<00:58, 245.61 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34952/47780 [02:12<00:25, 496.44 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38535/47780 [02:12<00:44, 209.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35711/47780 [02:12<00:48, 248.27 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34152/47780 [02:12<00:57, 238.29 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33708/47780 [02:12<01:07, 209.66 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31931/47780 [02:12<01:21, 193.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33673/47780 [02:12<01:09, 202.14 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33375/47780 [02:12<00:57, 249.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35004/47780 [02:12<00:25, 502.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38557/47780 [02:12<00:43, 209.99 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35737/47780 [02:12<00:48, 246.69 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34177/47780 [02:12<00:56, 238.85 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33732/47780 [02:12<01:05, 215.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33702/47780 [02:12<01:02, 223.75 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31951/47780 [02:12<01:24, 187.32 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33404/47780 [02:12<00:55, 258.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35057/47780 [02:12<00:25, 505.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38579/47780 [02:12<00:44, 206.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35765/47780 [02:12<00:48, 247.64 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34205/47780 [02:12<00:55, 244.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33757/47780 [02:12<01:05, 212.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33725/47780 [02:12<01:03, 220.58 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31970/47780 [02:12<01:29, 176.75 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33441/47780 [02:12<00:50, 285.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35109/47780 [02:12<00:25, 490.54 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38600/47780 [02:12<00:46, 197.20 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35791/47780 [02:12<00:50, 237.92 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34231/47780 [02:12<00:55, 243.40 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33749/47780 [02:12<01:02, 225.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33785/47780 [02:12<01:01, 226.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31988/47780 [02:12<01:29, 175.81 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33475/47780 [02:12<00:48, 295.70 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35159/47780 [02:12<00:25, 489.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38625/47780 [02:12<00:43, 210.51 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34262/47780 [02:12<00:52, 259.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35816/47780 [02:12<00:51, 233.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33809/47780 [02:12<01:00, 229.59 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33772/47780 [02:12<01:03, 219.62 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33505/47780 [02:12<00:48, 296.92 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32006/47780 [02:12<01:31, 173.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38658/47780 [02:12<00:37, 241.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35209/47780 [02:12<00:27, 451.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34289/47780 [02:12<00:54, 245.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33796/47780 [02:13<01:02, 225.35 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33833/47780 [02:13<01:03, 221.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35840/47780 [02:12<00:55, 216.44 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32028/47780 [02:13<01:24, 186.02 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33535/47780 [02:13<00:48, 294.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38685/47780 [02:13<00:37, 245.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35255/47780 [02:12<00:28, 443.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33858/47780 [02:13<01:00, 228.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33822/47780 [02:13<01:01, 227.46 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34314/47780 [02:13<00:57, 233.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35862/47780 [02:13<00:57, 208.72 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32047/47780 [02:13<01:29, 176.21 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33565/47780 [02:13<00:51, 273.48 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35309/47780 [02:13<00:26, 469.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38710/47780 [02:13<00:39, 226.96 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33888/47780 [02:13<00:56, 245.73 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34343/47780 [02:13<00:53, 249.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33848/47780 [02:13<01:00, 231.36 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32071/47780 [02:13<01:22, 190.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35357/47780 [02:13<00:26, 467.34 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35884/47780 [02:13<01:05, 182.72 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38734/47780 [02:13<00:40, 223.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33593/47780 [02:13<00:59, 237.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33913/47780 [02:13<00:56, 246.95 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33877/47780 [02:13<00:57, 239.97 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34370/47780 [02:13<00:57, 234.24 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32095/47780 [02:13<01:17, 202.18 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35409/47780 [02:13<00:25, 477.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35903/47780 [02:13<01:06, 179.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33619/47780 [02:13<00:58, 241.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38757/47780 [02:13<00:41, 215.30 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33943/47780 [02:13<00:54, 252.90 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33902/47780 [02:13<00:59, 231.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34398/47780 [02:13<00:54, 243.77 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32121/47780 [02:13<01:12, 216.04 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35473/47780 [02:13<00:24, 506.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35926/47780 [02:13<01:02, 190.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33644/47780 [02:13<00:59, 238.63 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38782/47780 [02:13<00:40, 219.96 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33979/47780 [02:13<00:49, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34424/47780 [02:13<00:54, 244.10 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33932/47780 [02:13<00:56, 243.96 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32150/47780 [02:13<01:07, 231.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35527/47780 [02:13<00:23, 513.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35949/47780 [02:13<00:59, 200.30 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33669/47780 [02:13<01:00, 234.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38805/47780 [02:13<00:40, 220.17 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34018/47780 [02:13<00:44, 308.82 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33960/47780 [02:13<00:54, 253.13 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32174/47780 [02:13<01:09, 223.99 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35580/47780 [02:13<00:24, 502.15 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34450/47780 [02:13<00:59, 223.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35971/47780 [02:13<00:58, 201.74 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34053/47780 [02:13<00:42, 320.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33694/47780 [02:13<01:00, 233.48 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33987/47780 [02:13<00:54, 255.27 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38828/47780 [02:13<00:45, 196.78 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32202/47780 [02:13<01:05, 237.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34473/47780 [02:13<00:59, 224.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35632/47780 [02:13<00:24, 491.97 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34086/47780 [02:13<00:42, 323.21 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35992/47780 [02:13<01:01, 191.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33721/47780 [02:13<00:57, 243.50 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34015/47780 [02:13<00:54, 250.79 examples/s]
Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32226/47780 [02:13<01:07, 229.72 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38849/47780 [02:13<00:47, 188.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35690/47780 [02:13<00:23, 516.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34496/47780 [02:13<01:00, 218.54 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33751/47780 [02:13<00:54, 256.68 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36014/47780 [02:13<01:02, 187.05 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34120/47780 [02:14<00:46, 296.04 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34052/47780 [02:13<00:49, 278.15 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38869/47780 [02:14<00:47, 189.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35742/47780 [02:13<00:23, 516.90 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34520/47780 [02:14<01:00, 220.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32251/47780 [02:14<01:12, 214.58 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33783/47780 [02:14<00:52, 268.53 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36038/47780 [02:14<00:58, 201.16 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34080/47780 [02:14<00:49, 275.49 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38889/47780 [02:14<00:46, 190.20 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34151/47780 [02:14<00:51, 265.56 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34543/47780 [02:14<00:59, 222.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35802/47780 [02:14<00:22, 523.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32274/47780 [02:14<01:11, 215.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33812/47780 [02:14<00:50, 274.28 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36059/47780 [02:14<00:59, 197.09 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34111/47780 [02:14<00:48, 284.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38909/47780 [02:14<00:46, 192.33 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35863/47780 [02:14<00:21, 547.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34572/47780 [02:14<00:55, 236.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34180/47780 [02:14<00:51, 263.45 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33845/47780 [02:14<00:48, 290.29 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32296/47780 [02:14<01:16, 203.42 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36082/47780 [02:14<00:56, 206.12 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35937/47780 [02:14<00:20, 590.52 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34140/47780 [02:14<00:53, 257.23 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34207/47780 [02:14<00:51, 261.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38934/47780 [02:14<00:45, 193.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34596/47780 [02:14<00:57, 230.13 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33875/47780 [02:14<00:49, 280.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36105/47780 [02:14<00:57, 203.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32317/47780 [02:14<01:24, 183.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35997/47780 [02:14<00:20, 573.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34625/47780 [02:14<00:54, 243.36 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34167/47780 [02:14<00:55, 247.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33907/47780 [02:14<00:48, 288.51 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38954/47780 [02:14<00:49, 178.24 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34234/47780 [02:14<00:57, 237.25 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36131/47780 [02:14<00:54, 214.85 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32339/47780 [02:14<01:20, 192.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36056/47780 [02:14<00:20, 577.98 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34659/47780 [02:14<00:50, 259.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34193/47780 [02:14<00:56, 242.15 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38978/47780 [02:14<00:45, 193.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34261/47780 [02:14<00:55, 245.11 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33936/47780 [02:14<00:49, 278.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36154/47780 [02:14<00:53, 217.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32363/47780 [02:14<01:15, 203.50 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34691/47780 [02:14<00:48, 270.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34218/47780 [02:14<00:58, 232.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39000/47780 [02:14<00:45, 191.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36116/47780 [02:14<00:22, 507.43 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36182/47780 [02:14<00:50, 231.36 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33965/47780 [02:14<00:54, 255.75 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34287/47780 [02:14<01:00, 222.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32385/47780 [02:14<01:18, 196.62 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34720/47780 [02:14<00:49, 261.30 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34242/47780 [02:14<00:58, 229.54 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36181/47780 [02:14<00:21, 534.55 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36215/47780 [02:14<00:46, 248.17 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39020/47780 [02:14<00:50, 174.73 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32412/47780 [02:14<01:12, 211.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34310/47780 [02:14<01:04, 207.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33992/47780 [02:14<00:58, 234.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34751/47780 [02:14<00:49, 262.80 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34266/47780 [02:14<01:00, 223.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36241/47780 [02:14<00:46, 245.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39040/47780 [02:14<00:48, 179.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36236/47780 [02:14<00:23, 481.03 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32434/47780 [02:14<01:13, 208.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34339/47780 [02:15<00:59, 225.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34017/47780 [02:15<00:58, 237.28 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34780/47780 [02:15<00:48, 269.98 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34291/47780 [02:15<00:59, 225.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36266/47780 [02:15<00:47, 241.76 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32459/47780 [02:15<01:09, 219.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36318/47780 [02:14<00:20, 557.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34043/47780 [02:15<00:57, 239.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34364/47780 [02:15<01:01, 218.26 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39059/47780 [02:15<00:55, 157.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34812/47780 [02:15<00:46, 281.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34317/47780 [02:15<00:57, 232.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36294/47780 [02:15<00:45, 252.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32489/47780 [02:15<01:03, 240.64 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34070/47780 [02:15<00:55, 245.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36376/47780 [02:15<00:21, 534.91 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34388/47780 [02:15<01:00, 222.33 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39079/47780 [02:15<00:52, 166.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34841/47780 [02:15<00:48, 268.43 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36323/47780 [02:15<00:43, 263.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34341/47780 [02:15<01:03, 212.67 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36431/47780 [02:15<00:21, 538.21 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32514/47780 [02:15<01:07, 224.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34095/47780 [02:15<00:57, 238.70 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34411/47780 [02:15<00:59, 224.05 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39101/47780 [02:15<00:48, 180.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34869/47780 [02:15<00:50, 257.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36350/47780 [02:15<00:45, 253.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34367/47780 [02:15<01:00, 223.01 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36487/47780 [02:15<00:21, 533.17 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34126/47780 [02:15<00:53, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32537/47780 [02:15<01:09, 218.58 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34438/47780 [02:15<00:57, 230.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39125/47780 [02:15<00:45, 192.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36377/47780 [02:15<00:44, 255.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34897/47780 [02:15<00:50, 255.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34391/47780 [02:15<01:01, 217.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36542/47780 [02:15<00:21, 531.99 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34152/47780 [02:15<00:54, 249.78 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32567/47780 [02:15<01:03, 239.13 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34465/47780 [02:15<00:56, 235.36 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34925/47780 [02:15<00:49, 259.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36403/47780 [02:15<00:46, 244.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39145/47780 [02:15<00:52, 163.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36596/47780 [02:15<00:20, 533.73 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34183/47780 [02:15<00:51, 265.34 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34415/47780 [02:15<01:03, 209.76 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34489/47780 [02:15<00:57, 232.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32592/47780 [02:15<01:12, 208.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36428/47780 [02:15<00:48, 236.08 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36652/47780 [02:15<00:20, 535.55 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39163/47780 [02:15<00:52, 162.67 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34953/47780 [02:15<00:52, 245.77 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34219/47780 [02:15<00:46, 292.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34437/47780 [02:15<01:05, 202.20 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34516/47780 [02:15<00:56, 236.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32625/47780 [02:15<01:03, 239.93 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39182/47780 [02:15<00:51, 168.27 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36707/47780 [02:15<00:20, 534.19 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36453/47780 [02:15<00:49, 230.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34978/47780 [02:15<00:52, 241.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34249/47780 [02:15<00:48, 277.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34460/47780 [02:15<01:03, 209.52 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34541/47780 [02:15<00:55, 237.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32651/47780 [02:15<01:03, 239.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36769/47780 [02:15<00:19, 558.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36479/47780 [02:15<00:47, 235.70 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35008/47780 [02:15<00:50, 252.19 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39200/47780 [02:15<00:53, 160.81 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34568/47780 [02:15<00:54, 243.82 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34278/47780 [02:15<00:49, 270.06 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34482/47780 [02:15<01:09, 191.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32677/47780 [02:15<01:02, 240.25 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35034/47780 [02:16<00:50, 251.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36503/47780 [02:15<00:49, 228.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39217/47780 [02:16<00:54, 158.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36826/47780 [02:15<00:21, 507.08 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34306/47780 [02:16<00:50, 266.84 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34593/47780 [02:16<00:55, 237.36 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34506/47780 [02:16<01:05, 202.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32702/47780 [02:16<01:05, 229.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35064/47780 [02:16<00:48, 262.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36529/47780 [02:16<00:47, 235.26 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36891/47780 [02:16<00:20, 541.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34333/47780 [02:16<00:50, 264.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39238/47780 [02:16<00:52, 163.59 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34621/47780 [02:16<00:54, 241.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34530/47780 [02:16<01:03, 208.28 examples/s]
Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32728/47780 [02:16<01:04, 233.71 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35099/47780 [02:16<00:44, 283.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36555/47780 [02:16<00:47, 238.16 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36947/47780 [02:16<00:19, 546.71 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39255/47780 [02:16<00:51, 165.29 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34365/47780 [02:16<00:48, 277.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34646/47780 [02:16<00:56, 232.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34552/47780 [02:16<01:04, 204.28 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32752/47780 [02:16<01:07, 222.87 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37003/47780 [02:16<00:20, 526.49 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36579/47780 [02:16<00:49, 224.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39272/47780 [02:16<00:51, 164.84 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34394/47780 [02:16<00:48, 277.12 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35128/47780 [02:16<00:50, 251.16 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34675/47780 [02:16<00:54, 238.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34576/47780 [02:16<01:02, 211.90 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32775/47780 [02:16<01:10, 211.40 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34428/47780 [02:16<00:45, 294.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39298/47780 [02:16<00:44, 189.31 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36603/47780 [02:16<00:50, 221.60 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34700/47780 [02:16<00:54, 241.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34598/47780 [02:16<01:02, 212.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35154/47780 [02:16<00:54, 230.44 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32799/47780 [02:16<01:08, 218.96 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37060/47780 [02:16<00:25, 424.57 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39322/47780 [02:16<00:41, 201.42 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34459/47780 [02:16<00:45, 290.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36626/47780 [02:16<00:51, 216.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34629/47780 [02:16<00:54, 239.34 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35182/47780 [02:16<00:52, 241.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34725/47780 [02:16<00:57, 226.18 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32822/47780 [02:16<01:09, 214.86 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34492/47780 [02:16<00:44, 301.35 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36655/47780 [02:16<00:46, 236.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37108/47780 [02:16<00:26, 409.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39344/47780 [02:16<00:45, 187.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35208/47780 [02:16<00:51, 244.09 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34654/47780 [02:16<00:57, 229.22 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34748/47780 [02:16<00:57, 226.67 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32850/47780 [02:16<01:05, 228.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37265/47780 [02:16<00:15, 691.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36679/47780 [02:16<00:50, 217.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35242/47780 [02:16<00:46, 270.23 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34690/47780 [02:16<00:49, 263.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39364/47780 [02:16<00:46, 181.16 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34523/47780 [02:16<00:50, 263.88 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34771/47780 [02:16<00:59, 219.31 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32877/47780 [02:16<01:03, 234.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36704/47780 [02:16<00:49, 223.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35272/47780 [02:16<00:44, 278.33 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34719/47780 [02:16<00:48, 270.51 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39384/47780 [02:16<00:47, 176.68 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34552/47780 [02:16<00:51, 254.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34794/47780 [02:17<01:01, 212.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32901/47780 [02:16<01:04, 230.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35305/47780 [02:17<00:43, 286.82 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36727/47780 [02:17<00:52, 212.13 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34818/47780 [02:17<00:59, 217.35 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34579/47780 [02:17<00:52, 253.19 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37343/47780 [02:16<00:21, 488.48 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34747/47780 [02:17<00:52, 247.58 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39402/47780 [02:17<00:52, 160.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32940/47780 [02:17<00:53, 275.21 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35339/47780 [02:17<00:42, 295.31 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34774/47780 [02:17<00:51, 253.65 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34605/47780 [02:17<00:52, 249.79 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34848/47780 [02:17<00:55, 232.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37406/47780 [02:17<00:20, 502.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36749/47780 [02:17<00:58, 189.71 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39420/47780 [02:17<00:51, 163.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32969/47780 [02:17<00:55, 267.52 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35369/47780 [02:17<00:42, 290.00 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34631/47780 [02:17<00:53, 247.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37514/47780 [02:17<00:16, 626.03 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34800/47780 [02:17<00:53, 244.08 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34874/47780 [02:17<00:56, 227.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39444/47780 [02:17<00:46, 180.34 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32997/47780 [02:17<00:55, 265.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36769/47780 [02:17<01:03, 174.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34660/47780 [02:17<00:50, 259.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34903/47780 [02:17<00:53, 241.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35399/47780 [02:17<00:48, 255.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39468/47780 [02:17<00:42, 196.50 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34825/47780 [02:17<00:57, 225.51 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37589/47780 [02:17<00:16, 603.91 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33024/47780 [02:17<00:57, 254.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36801/47780 [02:17<00:52, 210.68 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34687/47780 [02:17<00:52, 248.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34928/47780 [02:17<00:54, 236.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34851/47780 [02:17<00:55, 232.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39489/47780 [02:17<00:44, 185.82 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33051/47780 [02:17<00:57, 256.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35426/47780 [02:17<00:51, 239.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37659/47780 [02:17<00:17, 584.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36824/47780 [02:17<00:54, 201.01 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34718/47780 [02:17<00:49, 265.11 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34954/47780 [02:17<00:53, 237.71 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34877/47780 [02:17<00:54, 235.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39508/47780 [02:17<00:45, 181.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33077/47780 [02:17<00:59, 246.07 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37724/47780 [02:17<00:17, 575.47 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36845/47780 [02:17<00:56, 195.25 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35451/47780 [02:17<00:57, 215.34 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34984/47780 [02:17<00:50, 252.30 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34745/47780 [02:17<00:52, 249.38 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34906/47780 [02:17<00:51, 250.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39539/47780 [02:17<00:38, 215.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33102/47780 [02:17<01:00, 244.44 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37787/47780 [02:17<00:17, 583.87 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36866/47780 [02:17<00:57, 190.84 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35474/47780 [02:17<01:02, 197.56 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35011/47780 [02:17<00:53, 238.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34771/47780 [02:17<00:55, 234.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34932/47780 [02:17<00:55, 232.03 examples/s]
Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33128/47780 [02:17<01:00, 243.38 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39565/47780 [02:17<00:37, 216.36 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37853/47780 [02:17<00:16, 591.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36909/47780 [02:17<00:44, 246.39 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35536/47780 [02:17<00:40, 299.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34799/47780 [02:17<00:53, 241.62 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34959/47780 [02:17<00:53, 239.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33156/47780 [02:17<00:57, 253.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39588/47780 [02:17<00:37, 217.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37916/47780 [02:17<00:16, 601.54 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35036/47780 [02:18<00:57, 222.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36935/47780 [02:17<00:47, 230.28 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35569/47780 [02:18<00:42, 288.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33183/47780 [02:18<00:56, 258.35 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39622/47780 [02:18<00:33, 244.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34984/47780 [02:18<00:55, 229.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37989/47780 [02:18<00:15, 623.15 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34824/47780 [02:18<00:57, 226.77 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35059/47780 [02:18<00:59, 212.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36964/47780 [02:18<00:44, 243.37 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33210/47780 [02:18<00:57, 252.91 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35014/47780 [02:18<00:51, 248.72 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35600/47780 [02:18<00:45, 269.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34848/47780 [02:18<00:56, 230.08 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38067/47780 [02:18<00:14, 659.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39647/47780 [02:18<00:35, 230.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35081/47780 [02:18<01:04, 198.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36994/47780 [02:18<00:42, 255.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33241/47780 [02:18<00:53, 269.26 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34878/47780 [02:18<00:51, 248.97 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35629/47780 [02:18<00:45, 266.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38134/47780 [02:18<00:14, 647.02 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35040/47780 [02:18<00:55, 231.15 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39671/47780 [02:18<00:37, 216.29 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35102/47780 [02:18<01:04, 196.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37022/47780 [02:18<00:43, 248.78 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33269/47780 [02:18<00:55, 261.46 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35657/47780 [02:18<00:45, 266.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34906/47780 [02:18<00:53, 241.49 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38200/47780 [02:18<00:15, 615.84 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35070/47780 [02:18<00:51, 247.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39697/47780 [02:18<00:35, 225.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35122/47780 [02:18<01:07, 187.01 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37048/47780 [02:18<00:44, 243.69 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33296/47780 [02:18<00:57, 253.07 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35097/47780 [02:18<00:50, 253.49 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35685/47780 [02:18<00:48, 247.46 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39721/47780 [02:18<00:36, 219.84 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38263/47780 [02:18<00:16, 563.71 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34931/47780 [02:18<01:01, 209.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35141/47780 [02:18<01:09, 181.31 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37075/47780 [02:18<00:43, 248.36 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33325/47780 [02:18<00:55, 258.64 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35125/47780 [02:18<00:49, 258.08 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39746/47780 [02:18<00:35, 228.02 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35712/47780 [02:18<00:51, 233.51 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34953/47780 [02:18<01:01, 209.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35161/47780 [02:18<01:08, 184.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37101/47780 [02:18<00:44, 241.10 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33365/47780 [02:18<00:48, 295.34 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38321/47780 [02:18<00:20, 469.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35152/47780 [02:18<00:51, 245.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39770/47780 [02:18<00:35, 223.89 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35752/47780 [02:18<00:44, 270.73 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35189/47780 [02:18<00:59, 210.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35021/47780 [02:18<00:39, 327.13 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37128/47780 [02:18<00:44, 240.83 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38386/47780 [02:18<00:18, 512.41 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33395/47780 [02:18<00:51, 277.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35178/47780 [02:18<00:51, 246.24 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39793/47780 [02:18<00:35, 225.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35212/47780 [02:18<00:58, 213.52 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35780/47780 [02:18<00:46, 257.02 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35056/47780 [02:18<00:41, 309.93 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37158/47780 [02:18<00:43, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38456/47780 [02:18<00:16, 559.85 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33424/47780 [02:18<00:52, 272.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35203/47780 [02:18<00:50, 246.91 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39816/47780 [02:18<00:35, 224.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35243/47780 [02:19<00:52, 240.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35809/47780 [02:18<00:45, 262.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35092/47780 [02:19<00:39, 319.71 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37185/47780 [02:19<00:43, 244.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38516/47780 [02:18<00:17, 536.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35229/47780 [02:19<00:51, 242.61 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39847/47780 [02:19<00:32, 246.12 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33452/47780 [02:19<00:55, 257.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35273/47780 [02:19<00:48, 257.79 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35836/47780 [02:19<00:45, 260.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35126/47780 [02:19<00:39, 318.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37210/47780 [02:19<00:44, 239.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38573/47780 [02:19<00:17, 533.97 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33478/47780 [02:19<00:55, 255.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39872/47780 [02:19<00:33, 236.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35254/47780 [02:19<00:54, 228.29 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35863/47780 [02:19<00:48, 243.23 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35300/47780 [02:19<00:56, 222.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37234/47780 [02:19<00:45, 234.35 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35159/47780 [02:19<00:44, 281.25 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33504/47780 [02:19<00:55, 256.40 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35279/47780 [02:19<00:53, 232.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38629/47780 [02:19<00:18, 497.99 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39896/47780 [02:19<00:34, 226.92 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35888/47780 [02:19<00:49, 242.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35330/47780 [02:19<00:52, 235.78 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37262/47780 [02:19<00:43, 242.98 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33533/47780 [02:19<00:53, 265.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35189/47780 [02:19<00:46, 273.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38681/47780 [02:19<00:18, 487.94 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35303/47780 [02:19<00:56, 221.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39920/47780 [02:19<00:37, 208.71 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35355/47780 [02:19<00:53, 233.85 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35913/47780 [02:19<00:52, 227.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37287/47780 [02:19<00:45, 228.27 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33560/47780 [02:19<00:55, 255.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35218/47780 [02:19<00:45, 273.10 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38739/47780 [02:19<00:17, 507.61 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35326/47780 [02:19<00:56, 222.25 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39942/47780 [02:19<00:38, 203.90 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37310/47780 [02:19<00:45, 228.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35937/47780 [02:19<00:54, 218.77 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33586/47780 [02:19<00:56, 250.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35379/47780 [02:19<00:58, 212.70 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38791/47780 [02:19<00:17, 500.09 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35350/47780 [02:19<00:57, 215.17 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35246/47780 [02:19<00:50, 248.77 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39963/47780 [02:19<00:40, 193.30 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35960/47780 [02:19<00:54, 217.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33614/47780 [02:19<00:55, 256.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37333/47780 [02:19<00:49, 212.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35401/47780 [02:19<01:01, 202.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38842/47780 [02:19<00:18, 482.77 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35374/47780 [02:19<00:57, 217.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35272/47780 [02:19<00:50, 246.62 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39985/47780 [02:19<00:38, 200.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35983/47780 [02:19<00:53, 219.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37358/47780 [02:19<00:46, 222.49 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33641/47780 [02:19<00:56, 248.46 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35403/47780 [02:19<00:52, 234.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35422/47780 [02:19<01:03, 194.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38893/47780 [02:19<00:18, 472.59 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35299/47780 [02:19<00:50, 247.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40007/47780 [02:19<00:37, 205.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36006/47780 [02:19<00:53, 218.55 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37382/47780 [02:19<00:46, 222.68 examples/s]
Tokenizing train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33668/47780 [02:19<00:57, 246.57 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35432/47780 [02:19<00:49, 247.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38959/47780 [02:19<00:16, 519.17 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35442/47780 [02:20<01:04, 191.70 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35326/47780 [02:20<00:50, 247.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40029/47780 [02:19<00:38, 200.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37407/47780 [02:19<00:45, 228.70 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36029/47780 [02:20<00:57, 203.78 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33698/47780 [02:20<00:55, 255.79 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39022/47780 [02:19<00:16, 544.17 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35459/47780 [02:20<00:50, 245.58 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35462/47780 [02:20<01:04, 191.76 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35352/47780 [02:20<00:49, 248.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40056/47780 [02:20<00:35, 215.40 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37433/47780 [02:20<00:45, 228.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36052/47780 [02:20<00:56, 208.57 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33724/47780 [02:20<00:55, 253.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39079/47780 [02:20<00:15, 545.34 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35490/47780 [02:20<00:57, 213.87 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35490/47780 [02:20<00:48, 251.57 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35378/47780 [02:20<00:53, 233.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40086/47780 [02:20<00:32, 239.07 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33764/47780 [02:20<00:47, 292.42 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37456/47780 [02:20<00:48, 214.84 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36074/47780 [02:20<01:01, 190.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39134/47780 [02:20<00:17, 505.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35405/47780 [02:20<00:51, 241.05 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35516/47780 [02:20<00:51, 236.57 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35513/47780 [02:20<01:03, 194.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40111/47780 [02:20<00:33, 229.13 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33794/47780 [02:20<00:50, 278.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37478/47780 [02:20<00:49, 209.57 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36094/47780 [02:20<01:03, 182.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39186/47780 [02:20<00:18, 473.30 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35540/47780 [02:20<00:53, 227.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35430/47780 [02:20<00:54, 228.39 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40135/47780 [02:20<00:35, 214.92 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35533/47780 [02:20<01:10, 174.74 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33823/47780 [02:20<00:52, 263.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37503/47780 [02:20<00:50, 202.44 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36113/47780 [02:20<01:04, 181.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35564/47780 [02:20<00:53, 228.33 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35456/47780 [02:20<00:54, 224.78 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39237/47780 [02:20<00:19, 445.46 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40158/47780 [02:20<00:35, 215.19 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35555/47780 [02:20<01:06, 183.39 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33851/47780 [02:20<00:54, 257.32 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37524/47780 [02:20<00:51, 200.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36145/47780 [02:20<00:54, 214.22 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35489/47780 [02:20<00:49, 250.21 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39291/47780 [02:20<00:18, 468.93 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40180/47780 [02:20<00:35, 216.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35576/47780 [02:20<01:04, 190.31 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35587/47780 [02:20<00:58, 207.95 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33878/47780 [02:20<00:53, 257.63 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36170/47780 [02:20<00:51, 223.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37550/47780 [02:20<00:48, 211.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35519/47780 [02:20<00:46, 261.13 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40209/47780 [02:20<00:32, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39352/47780 [02:20<00:17, 491.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35609/47780 [02:20<00:58, 206.94 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35599/47780 [02:20<01:02, 194.65 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33911/47780 [02:20<00:50, 271.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37572/47780 [02:20<00:47, 214.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36193/47780 [02:20<00:55, 207.03 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35549/47780 [02:20<00:46, 263.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40233/47780 [02:20<00:32, 233.02 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35635/47780 [02:20<00:54, 221.23 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35622/47780 [02:20<00:59, 204.22 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39402/47780 [02:20<00:17, 469.46 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33943/47780 [02:20<00:50, 276.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37594/47780 [02:20<00:49, 204.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36217/47780 [02:20<00:53, 215.06 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35581/47780 [02:21<00:44, 276.51 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35660/47780 [02:20<00:53, 226.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35643/47780 [02:21<00:59, 203.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40257/47780 [02:20<00:34, 220.31 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39450/47780 [02:20<00:18, 459.05 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33978/47780 [02:21<00:46, 296.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37617/47780 [02:21<00:48, 210.85 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36239/47780 [02:21<00:54, 212.47 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35609/47780 [02:21<00:44, 273.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35685/47780 [02:21<00:51, 233.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39497/47780 [02:21<00:18, 454.93 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35665/47780 [02:21<01:01, 197.14 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40280/47780 [02:21<00:39, 191.12 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34008/47780 [02:21<00:48, 281.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37639/47780 [02:21<00:48, 209.11 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35712/47780 [02:21<00:50, 238.31 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36261/47780 [02:21<00:57, 199.05 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35637/47780 [02:21<00:47, 258.05 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39547/47780 [02:21<00:17, 467.31 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35685/47780 [02:21<01:04, 186.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40301/47780 [02:21<00:38, 194.40 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37661/47780 [02:21<00:50, 199.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35736/47780 [02:21<00:51, 233.34 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36282/47780 [02:21<00:57, 200.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35664/47780 [02:21<00:46, 260.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39602/47780 [02:21<00:16, 490.37 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34037/47780 [02:21<00:54, 250.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35706/47780 [02:21<01:03, 189.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40324/47780 [02:21<00:37, 199.00 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37682/47780 [02:21<00:50, 199.63 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39654/47780 [02:21<00:16, 498.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36309/47780 [02:21<00:52, 216.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35691/47780 [02:21<00:47, 252.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35760/47780 [02:21<00:53, 222.73 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34063/47780 [02:21<00:55, 247.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35728/47780 [02:21<01:01, 197.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40345/47780 [02:21<00:37, 198.14 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36344/47780 [02:21<00:45, 248.74 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35785/47780 [02:21<00:52, 230.31 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34094/47780 [02:21<00:52, 263.17 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35718/47780 [02:21<00:47, 254.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37703/47780 [02:21<00:55, 180.13 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39705/47780 [02:21<00:17, 449.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35749/47780 [02:21<01:02, 192.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40366/47780 [02:21<00:38, 194.57 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36371/47780 [02:21<00:45, 251.56 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35817/47780 [02:21<00:47, 250.03 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34126/47780 [02:21<00:50, 268.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35744/47780 [02:21<00:49, 242.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37722/47780 [02:21<00:57, 173.85 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39752/47780 [02:21<00:19, 410.98 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35769/47780 [02:21<01:08, 175.24 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40388/47780 [02:21<00:38, 193.09 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36398/47780 [02:21<00:44, 253.51 examples/s]
Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34154/47780 [02:21<00:50, 268.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35846/47780 [02:21<00:47, 250.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35769/47780 [02:21<00:50, 238.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37740/47780 [02:21<01:00, 166.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39806/47780 [02:21<00:18, 442.67 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35792/47780 [02:21<01:03, 189.65 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40413/47780 [02:21<00:35, 206.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36425/47780 [02:21<00:44, 254.04 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35875/47780 [02:21<00:47, 252.73 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35793/47780 [02:21<00:51, 234.37 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34182/47780 [02:21<00:53, 254.76 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37761/47780 [02:21<00:57, 175.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39863/47780 [02:21<00:16, 473.96 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35812/47780 [02:21<01:02, 191.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40434/47780 [02:21<00:37, 195.78 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36451/47780 [02:21<00:46, 246.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35823/47780 [02:21<00:47, 252.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35901/47780 [02:21<00:49, 238.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37780/47780 [02:21<00:55, 179.20 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35837/47780 [02:22<00:57, 207.02 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34208/47780 [02:21<00:57, 234.35 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39912/47780 [02:21<00:16, 467.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36479/47780 [02:22<00:44, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40458/47780 [02:22<00:37, 197.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37808/47780 [02:22<00:48, 206.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35859/47780 [02:22<00:56, 210.35 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39960/47780 [02:22<00:16, 469.18 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35926/47780 [02:22<00:52, 227.03 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34233/47780 [02:22<00:59, 227.80 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35849/47780 [02:22<00:54, 217.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36507/47780 [02:22<00:44, 255.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40478/47780 [02:22<00:39, 184.39 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40008/47780 [02:22<00:16, 471.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37829/47780 [02:22<00:51, 192.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35882/47780 [02:22<00:57, 206.71 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35950/47780 [02:22<00:53, 223.09 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34268/47780 [02:22<00:52, 257.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35872/47780 [02:22<00:54, 217.03 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36539/47780 [02:22<00:41, 267.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40497/47780 [02:22<00:39, 183.57 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40056/47780 [02:22<00:16, 460.93 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37849/47780 [02:22<00:51, 192.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35973/47780 [02:22<00:52, 223.18 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35910/47780 [02:22<00:53, 222.48 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34296/47780 [02:22<00:52, 257.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35901/47780 [02:22<00:50, 234.56 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36566/47780 [02:22<00:47, 236.71 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37873/47780 [02:22<00:48, 203.40 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35999/47780 [02:22<00:50, 232.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40516/47780 [02:22<00:43, 168.03 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40103/47780 [02:22<00:17, 438.44 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35933/47780 [02:22<00:55, 213.95 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34332/47780 [02:22<00:48, 277.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35928/47780 [02:22<00:55, 213.94 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36591/47780 [02:22<00:48, 231.96 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40535/47780 [02:22<00:41, 173.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40149/47780 [02:22<00:17, 439.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37894/47780 [02:22<00:50, 194.55 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36023/47780 [02:22<00:53, 221.19 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34360/47780 [02:22<00:50, 267.00 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35955/47780 [02:22<00:57, 205.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35951/47780 [02:22<00:54, 216.52 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36621/47780 [02:22<00:44, 249.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40195/47780 [02:22<00:17, 445.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40559/47780 [02:22<00:39, 183.29 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37915/47780 [02:22<00:52, 189.38 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34387/47780 [02:22<00:51, 261.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36046/47780 [02:22<00:56, 206.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35977/47780 [02:22<00:58, 200.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35974/47780 [02:22<00:57, 204.07 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40248/47780 [02:22<00:16, 462.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36647/47780 [02:22<00:48, 230.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37935/47780 [02:22<00:52, 185.95 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40579/47780 [02:22<00:41, 173.03 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36069/47780 [02:22<00:55, 210.64 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34414/47780 [02:22<00:53, 248.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36008/47780 [02:22<00:53, 218.38 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35995/47780 [02:22<00:59, 197.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36672/47780 [02:22<00:48, 230.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37957/47780 [02:22<00:50, 193.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40597/47780 [02:22<00:42, 170.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36091/47780 [02:22<00:56, 208.72 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34446/47780 [02:22<00:50, 263.78 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36033/47780 [02:22<00:52, 224.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40296/47780 [02:22<00:19, 384.22 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36022/47780 [02:22<00:54, 215.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36699/47780 [02:22<00:46, 239.64 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37982/47780 [02:22<00:47, 205.09 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36056/47780 [02:23<00:51, 225.61 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36113/47780 [02:22<00:58, 200.61 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34473/47780 [02:22<00:52, 254.33 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40617/47780 [02:22<00:43, 163.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40365/47780 [02:22<00:16, 457.86 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36044/47780 [02:23<00:54, 214.05 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36729/47780 [02:23<00:44, 247.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38003/47780 [02:23<00:49, 198.05 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36141/47780 [02:23<00:52, 219.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34499/47780 [02:23<00:53, 250.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40634/47780 [02:23<00:44, 161.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40414/47780 [02:23<00:15, 461.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36079/47780 [02:23<00:56, 208.25 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36068/47780 [02:23<00:57, 205.37 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36754/47780 [02:23<00:45, 239.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38028/47780 [02:23<00:47, 203.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36168/47780 [02:23<00:50, 231.18 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34530/47780 [02:23<00:49, 266.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40464/47780 [02:23<00:15, 467.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40651/47780 [02:23<00:45, 158.10 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36102/47780 [02:23<00:56, 207.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36089/47780 [02:23<00:56, 206.57 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34562/47780 [02:23<00:46, 281.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38049/47780 [02:23<00:48, 202.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36196/47780 [02:23<00:48, 238.65 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36779/47780 [02:23<00:49, 220.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40513/47780 [02:23<00:15, 467.76 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40669/47780 [02:23<00:43, 163.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36127/47780 [02:23<00:54, 215.72 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36114/47780 [02:23<00:54, 216.03 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38073/47780 [02:23<00:46, 210.56 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36811/47780 [02:23<00:44, 246.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36221/47780 [02:23<00:49, 234.42 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34591/47780 [02:23<00:50, 260.23 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40564/47780 [02:23<00:15, 458.89 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36149/47780 [02:23<00:54, 213.58 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40686/47780 [02:23<00:46, 152.77 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36138/47780 [02:23<00:52, 220.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38096/47780 [02:23<00:45, 213.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36247/47780 [02:23<00:48, 239.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36838/47780 [02:23<00:43, 248.73 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36173/47780 [02:23<00:53, 216.62 examples/s]
Tokenizing train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34618/47780 [02:23<00:52, 252.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40621/47780 [02:23<00:16, 445.58 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40704/47780 [02:23<00:46, 153.16 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36162/47780 [02:23<00:53, 215.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38118/47780 [02:23<00:44, 215.36 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36864/47780 [02:23<00:44, 242.98 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36272/47780 [02:23<00:49, 231.51 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36201/47780 [02:23<00:50, 230.95 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34644/47780 [02:23<00:51, 253.23 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36184/47780 [02:23<00:53, 214.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40686/47780 [02:23<00:14, 478.52 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40720/47780 [02:23<00:49, 143.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38141/47780 [02:23<00:45, 211.90 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36890/47780 [02:23<00:43, 247.63 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36299/47780 [02:23<00:48, 237.35 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34670/47780 [02:23<00:53, 247.17 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36225/47780 [02:23<00:52, 220.07 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36208/47780 [02:23<00:52, 221.48 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40744/47780 [02:23<00:14, 496.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40740/47780 [02:23<00:45, 154.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36917/47780 [02:23<00:42, 253.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38166/47780 [02:23<00:45, 211.10 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34701/47780 [02:23<00:50, 259.32 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36233/47780 [02:23<00:51, 224.52 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36323/47780 [02:23<00:54, 211.47 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36248/47780 [02:23<00:55, 207.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40796/47780 [02:23<00:14, 477.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38191/47780 [02:23<00:43, 221.08 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36943/47780 [02:23<00:43, 247.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40756/47780 [02:23<00:50, 140.06 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34729/47780 [02:23<00:50, 256.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36347/47780 [02:23<00:52, 217.11 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36257/47780 [02:24<00:51, 224.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36269/47780 [02:24<00:57, 201.46 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40845/47780 [02:23<00:15, 449.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38214/47780 [02:24<00:43, 219.36 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40771/47780 [02:24<00:51, 135.29 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36968/47780 [02:24<00:47, 229.80 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36370/47780 [02:24<00:52, 218.19 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34755/47780 [02:24<00:55, 236.30 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36295/47780 [02:24<00:53, 213.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36280/47780 [02:24<00:56, 202.97 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40904/47780 [02:24<00:14, 478.25 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36992/47780 [02:24<00:47, 226.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38237/47780 [02:24<00:47, 201.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40785/47780 [02:24<00:53, 130.96 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36402/47780 [02:24<00:46, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34780/47780 [02:24<00:55, 232.48 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36318/47780 [02:24<00:54, 210.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36303/47780 [02:24<00:55, 207.83 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40954/47780 [02:24<00:14, 468.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38260/47780 [02:24<00:45, 207.41 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37015/47780 [02:24<00:48, 221.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40799/47780 [02:24<00:53, 129.45 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36427/47780 [02:24<00:47, 239.20 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36328/47780 [02:24<00:52, 219.43 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34804/47780 [02:24<00:57, 224.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36340/47780 [02:24<00:55, 204.90 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41009/47780 [02:24<00:14, 483.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38282/47780 [02:24<00:46, 204.11 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37043/47780 [02:24<00:47, 227.66 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36458/47780 [02:24<00:44, 254.39 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40813/47780 [02:24<00:55, 126.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36353/47780 [02:24<00:50, 228.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36363/47780 [02:24<00:54, 207.90 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34827/47780 [02:24<00:59, 216.81 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41058/47780 [02:24<00:13, 483.23 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38303/47780 [02:24<00:46, 203.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37078/47780 [02:24<00:40, 261.04 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40826/47780 [02:24<00:55, 125.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36484/47780 [02:24<00:45, 247.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36380/47780 [02:24<00:47, 239.04 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34849/47780 [02:24<00:59, 217.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36384/47780 [02:24<00:58, 193.97 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41108/47780 [02:24<00:15, 441.98 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38324/47780 [02:24<00:47, 200.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40840/47780 [02:24<00:53, 129.17 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34872/47780 [02:24<00:58, 219.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36405/47780 [02:24<00:49, 227.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37105/47780 [02:24<00:46, 227.81 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36509/47780 [02:24<00:50, 222.26 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36404/47780 [02:24<00:58, 194.34 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41158/47780 [02:24<00:14, 455.52 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38347/47780 [02:24<00:45, 208.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40853/47780 [02:24<00:57, 120.02 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34899/47780 [02:24<00:56, 229.99 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36429/47780 [02:24<00:49, 227.82 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37131/47780 [02:24<00:45, 236.00 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36533/47780 [02:24<00:50, 221.56 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36427/47780 [02:24<00:57, 197.79 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38371/47780 [02:24<00:44, 210.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41205/47780 [02:24<00:15, 428.34 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40868/47780 [02:24<00:55, 124.68 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36456/47780 [02:24<00:48, 234.74 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34923/47780 [02:24<00:57, 222.81 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37156/47780 [02:24<00:46, 227.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36556/47780 [02:24<00:51, 216.27 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36447/47780 [02:24<00:57, 195.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38398/47780 [02:24<00:41, 225.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41250/47780 [02:24<00:16, 385.26 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40881/47780 [02:24<00:57, 119.68 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36587/47780 [02:24<00:46, 239.12 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34946/47780 [02:24<01:00, 213.15 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36467/47780 [02:25<00:58, 194.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36481/47780 [02:25<00:50, 221.56 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37180/47780 [02:25<00:48, 217.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38422/47780 [02:25<00:42, 221.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41307/47780 [02:24<00:14, 432.08 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40894/47780 [02:25<00:58, 116.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36613/47780 [02:25<00:46, 242.18 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34970/47780 [02:25<00:58, 220.12 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36508/47780 [02:25<00:48, 232.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37203/47780 [02:25<00:48, 220.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36488/47780 [02:25<00:59, 191.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38445/47780 [02:25<00:45, 203.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36535/47780 [02:25<00:46, 240.27 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34994/47780 [02:25<00:57, 221.16 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36650/47780 [02:25<00:40, 272.03 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37227/47780 [02:25<00:46, 225.38 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36510/47780 [02:25<00:56, 198.59 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40910/47780 [02:25<00:56, 121.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41352/47780 [02:25<00:16, 386.98 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36680/47780 [02:25<00:39, 279.61 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36564/47780 [02:25<00:44, 251.20 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37251/47780 [02:25<00:45, 229.30 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35017/47780 [02:25<00:58, 218.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41403/47780 [02:25<00:15, 417.75 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40925/47780 [02:25<00:53, 127.62 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38466/47780 [02:25<00:51, 181.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36539/47780 [02:25<00:52, 212.62 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36591/47780 [02:25<00:44, 253.80 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35040/47780 [02:25<00:58, 219.39 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36709/47780 [02:25<00:41, 269.69 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37275/47780 [02:25<00:47, 222.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40938/47780 [02:25<00:54, 124.56 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41447/47780 [02:25<00:15, 410.61 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38488/47780 [02:25<00:50, 185.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36568/47780 [02:25<00:48, 231.45 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35065/47780 [02:25<00:56, 225.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37308/47780 [02:25<00:41, 252.57 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41495/47780 [02:25<00:14, 423.51 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38509/47780 [02:25<00:49, 186.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36737/47780 [02:25<00:44, 250.77 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36592/47780 [02:25<00:49, 223.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36617/47780 [02:25<00:49, 224.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40951/47780 [02:25<00:59, 114.68 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37336/47780 [02:25<00:40, 257.64 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35088/47780 [02:25<00:58, 217.64 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41542/47780 [02:25<00:14, 428.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36763/47780 [02:25<00:44, 247.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36615/47780 [02:25<00:51, 218.26 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36641/47780 [02:25<00:50, 221.72 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38528/47780 [02:25<00:53, 172.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40966/47780 [02:25<00:56, 120.62 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37362/47780 [02:25<00:40, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35113/47780 [02:25<00:56, 226.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41588/47780 [02:25<00:14, 427.44 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36792/47780 [02:25<00:42, 256.91 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36637/47780 [02:25<00:51, 218.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36671/47780 [02:25<00:46, 240.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38546/47780 [02:25<00:53, 172.44 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40981/47780 [02:25<00:53, 126.62 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35140/47780 [02:25<00:54, 233.84 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37396/47780 [02:25<00:39, 264.50 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41634/47780 [02:25<00:14, 431.88 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36659/47780 [02:25<00:51, 216.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36696/47780 [02:25<00:45, 242.67 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38566/47780 [02:25<00:52, 176.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36819/47780 [02:25<00:44, 244.10 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40994/47780 [02:25<00:54, 124.83 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35164/47780 [02:25<00:54, 232.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37425/47780 [02:25<00:38, 271.65 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41678/47780 [02:25<00:14, 428.67 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36681/47780 [02:26<00:51, 214.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36724/47780 [02:26<00:43, 252.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41010/47780 [02:25<00:51, 131.66 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36844/47780 [02:26<00:46, 234.61 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38588/47780 [02:25<00:52, 176.67 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37456/47780 [02:26<00:36, 282.49 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35188/47780 [02:26<00:54, 229.14 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41722/47780 [02:25<00:14, 427.55 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36704/47780 [02:26<00:51, 215.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36750/47780 [02:26<00:43, 252.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38618/47780 [02:26<00:43, 209.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41031/47780 [02:26<00:46, 144.34 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36868/47780 [02:26<00:49, 221.86 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35211/47780 [02:26<00:55, 225.97 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37485/47780 [02:26<00:37, 275.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36778/47780 [02:26<00:42, 257.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36734/47780 [02:26<00:47, 233.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41765/47780 [02:26<00:15, 384.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38641/47780 [02:26<00:43, 208.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41054/47780 [02:26<00:41, 160.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36891/47780 [02:26<00:52, 206.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37516/47780 [02:26<00:35, 285.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35234/47780 [02:26<00:55, 225.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36760/47780 [02:26<00:46, 234.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36804/47780 [02:26<00:44, 244.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41805/47780 [02:26<00:16, 372.25 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41071/47780 [02:26<00:41, 161.91 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38663/47780 [02:26<00:46, 194.23 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36913/47780 [02:26<00:53, 204.98 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35257/47780 [02:26<00:56, 221.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37545/47780 [02:26<00:37, 274.32 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36829/47780 [02:26<00:44, 243.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36790/47780 [02:26<00:44, 246.19 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41848/47780 [02:26<00:15, 387.77 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38685/47780 [02:26<00:45, 199.22 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36939/47780 [02:26<00:49, 218.56 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37578/47780 [02:26<00:35, 286.32 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35280/47780 [02:26<00:58, 214.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41088/47780 [02:26<00:46, 142.80 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36824/47780 [02:26<00:41, 263.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41888/47780 [02:26<00:15, 382.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36854/47780 [02:26<00:48, 226.35 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38711/47780 [02:26<00:43, 208.92 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36963/47780 [02:26<00:48, 222.14 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37615/47780 [02:26<00:33, 306.85 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35304/47780 [02:26<00:56, 221.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41103/47780 [02:26<00:47, 141.57 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36851/47780 [02:26<00:41, 263.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41927/47780 [02:26<00:16, 364.51 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36877/47780 [02:26<00:50, 214.98 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36994/47780 [02:26<00:44, 241.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38733/47780 [02:26<00:44, 202.82 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37647/47780 [02:26<00:33, 306.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35328/47780 [02:26<00:57, 217.09 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36878/47780 [02:26<00:41, 265.40 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41119/47780 [02:26<00:49, 135.18 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36906/47780 [02:26<00:46, 234.08 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41964/47780 [02:26<00:16, 353.76 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37020/47780 [02:26<00:43, 246.21 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38757/47780 [02:26<00:42, 211.81 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37678/47780 [02:26<00:33, 297.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35350/47780 [02:26<00:57, 215.53 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36905/47780 [02:26<00:42, 256.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41136/47780 [02:26<00:47, 139.82 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42001/47780 [02:26<00:16, 358.20 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36930/47780 [02:26<00:49, 220.63 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37047/47780 [02:26<00:43, 246.06 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37711/47780 [02:26<00:32, 305.40 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38780/47780 [02:26<00:43, 207.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35378/47780 [02:26<00:53, 231.16 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36932/47780 [02:26<00:42, 254.92 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41151/47780 [02:26<00:47, 140.74 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42046/47780 [02:26<00:14, 383.86 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36953/47780 [02:27<00:49, 220.80 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37073/47780 [02:27<00:42, 249.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37742/47780 [02:27<00:33, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38803/47780 [02:26<00:43, 207.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35403/47780 [02:27<00:54, 229.07 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36960/47780 [02:27<00:42, 256.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42087/47780 [02:26<00:14, 387.29 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36976/47780 [02:27<00:50, 215.71 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37100/47780 [02:27<00:42, 249.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37777/47780 [02:27<00:31, 315.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41166/47780 [02:27<00:55, 118.45 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35432/47780 [02:27<00:51, 240.54 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36986/47780 [02:27<00:42, 254.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38824/47780 [02:27<00:48, 185.67 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42132/47780 [02:27<00:14, 387.84 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36998/47780 [02:27<00:50, 211.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37126/47780 [02:27<00:43, 245.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37810/47780 [02:27<00:31, 315.65 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35457/47780 [02:27<00:51, 237.17 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41179/47780 [02:27<00:57, 115.04 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37013/47780 [02:27<00:42, 255.92 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38843/47780 [02:27<00:49, 179.18 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42180/47780 [02:27<00:13, 409.42 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37025/47780 [02:27<00:47, 226.48 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37151/47780 [02:27<00:44, 239.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37842/47780 [02:27<00:32, 304.88 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35482/47780 [02:27<00:52, 236.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37046/47780 [02:27<00:39, 270.95 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41191/47780 [02:27<00:59, 110.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42227/47780 [02:27<00:13, 422.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38862/47780 [02:27<00:53, 166.73 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37049/47780 [02:27<00:47, 227.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37874/47780 [02:27<00:32, 307.02 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35506/47780 [02:27<00:51, 236.10 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37175/47780 [02:27<00:48, 216.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37082/47780 [02:27<00:36, 296.30 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41204/47780 [02:27<00:59, 110.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38883/47780 [02:27<00:50, 177.80 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37072/47780 [02:27<00:47, 226.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37907/47780 [02:27<00:32, 307.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42272/47780 [02:27<00:15, 358.91 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35531/47780 [02:27<00:55, 222.47 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37113/47780 [02:27<00:37, 287.18 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37198/47780 [02:27<00:51, 205.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41217/47780 [02:27<00:58, 111.58 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37096/47780 [02:27<00:48, 219.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37941/47780 [02:27<00:31, 316.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38902/47780 [02:27<00:52, 168.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42322/47780 [02:27<00:13, 393.77 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35556/47780 [02:27<00:54, 226.36 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37219/47780 [02:27<00:52, 199.84 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41230/47780 [02:27<00:56, 115.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37142/47780 [02:27<00:39, 266.54 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37119/47780 [02:27<00:47, 222.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37973/47780 [02:27<00:30, 316.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38923/47780 [02:27<00:50, 176.89 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42364/47780 [02:27<00:13, 389.97 examples/s]
Tokenizing train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35582/47780 [02:27<00:52, 234.07 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41242/47780 [02:27<00:57, 114.22 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37246/47780 [02:27<00:50, 207.99 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37175/47780 [02:27<00:39, 271.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37145/47780 [02:27<00:46, 227.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38942/47780 [02:27<00:50, 175.47 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38005/47780 [02:27<00:32, 296.40 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42405/47780 [02:27<00:13, 386.15 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35608/47780 [02:27<00:51, 237.25 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41254/47780 [02:27<00:56, 115.75 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37267/47780 [02:27<00:52, 202.13 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37204/47780 [02:27<00:38, 274.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37170/47780 [02:27<00:45, 231.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38961/47780 [02:27<00:49, 179.39 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38035/47780 [02:27<00:33, 291.98 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42445/47780 [02:27<00:14, 359.63 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41269/47780 [02:28<00:52, 124.05 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37290/47780 [02:28<00:51, 205.29 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35633/47780 [02:28<00:57, 211.15 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37194/47780 [02:28<00:45, 231.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38980/47780 [02:28<00:48, 180.39 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37232/47780 [02:28<00:42, 249.54 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38069/47780 [02:28<00:32, 299.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42482/47780 [02:28<00:14, 358.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41286/47780 [02:28<00:47, 135.60 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37311/47780 [02:28<00:51, 201.95 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35655/47780 [02:28<00:58, 207.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37225/47780 [02:28<00:42, 251.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38999/47780 [02:28<00:50, 175.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38101/47780 [02:28<00:32, 294.64 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37258/47780 [02:28<00:46, 226.88 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42519/47780 [02:28<00:15, 348.22 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41300/47780 [02:28<00:48, 134.09 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37340/47780 [02:28<00:46, 225.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37260/47780 [02:28<00:38, 276.62 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35677/47780 [02:28<00:59, 201.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39018/47780 [02:28<00:49, 177.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38131/47780 [02:28<00:35, 271.49 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37282/47780 [02:28<00:46, 223.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41316/47780 [02:28<00:45, 141.18 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42555/47780 [02:28<00:15, 338.07 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37363/47780 [02:28<00:46, 225.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37297/47780 [02:28<00:34, 300.24 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35699/47780 [02:28<00:58, 205.24 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39036/47780 [02:28<00:50, 172.23 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37307/47780 [02:28<00:45, 230.44 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38162/47780 [02:28<00:35, 270.24 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42592/47780 [02:28<00:15, 344.13 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41332/47780 [02:28<00:46, 140.15 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37388/47780 [02:28<00:45, 229.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37328/47780 [02:28<00:34, 302.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35722/47780 [02:28<00:57, 209.80 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39054/47780 [02:28<00:50, 172.50 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37331/47780 [02:28<00:45, 230.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42635/47780 [02:28<00:14, 363.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37416/47780 [02:28<00:43, 238.47 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38190/47780 [02:28<00:38, 248.55 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37359/47780 [02:28<00:35, 294.81 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41350/47780 [02:28<00:46, 138.69 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35746/47780 [02:28<00:58, 206.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39075/47780 [02:28<00:48, 180.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37358/47780 [02:28<00:45, 228.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42672/47780 [02:28<00:14, 353.54 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37393/47780 [02:28<00:34, 304.32 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37440/47780 [02:28<00:45, 226.05 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38217/47780 [02:28<00:38, 248.48 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35767/47780 [02:28<00:57, 207.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41364/47780 [02:28<00:48, 132.05 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39096/47780 [02:28<00:47, 181.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37387/47780 [02:28<00:42, 245.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42708/47780 [02:28<00:14, 355.17 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37463/47780 [02:28<00:45, 227.05 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37428/47780 [02:28<00:33, 312.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38246/47780 [02:28<00:37, 257.50 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41379/47780 [02:28<00:46, 136.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35793/47780 [02:28<00:56, 212.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39118/47780 [02:28<00:45, 190.16 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37416/47780 [02:28<00:40, 255.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42744/47780 [02:28<00:14, 344.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37486/47780 [02:28<00:45, 225.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38275/47780 [02:28<00:36, 263.54 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35821/47780 [02:28<00:52, 228.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41393/47780 [02:28<00:50, 126.60 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39139/47780 [02:28<00:48, 179.52 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37449/47780 [02:29<00:37, 276.26 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37460/47780 [02:29<00:40, 256.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42779/47780 [02:28<00:14, 335.02 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37522/47780 [02:28<00:39, 260.66 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38303/47780 [02:29<00:37, 253.90 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35845/47780 [02:29<00:56, 212.92 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41409/47780 [02:29<00:49, 128.57 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39159/47780 [02:29<00:48, 179.08 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37499/47780 [02:29<00:36, 285.53 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37477/47780 [02:29<00:39, 263.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42813/47780 [02:29<00:14, 334.41 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37549/47780 [02:29<00:41, 249.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38329/47780 [02:29<00:39, 239.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41426/47780 [02:29<00:45, 138.20 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39182/47780 [02:29<00:44, 192.50 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35867/47780 [02:29<00:58, 204.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37505/47780 [02:29<00:39, 263.14 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42847/47780 [02:29<00:14, 329.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37575/47780 [02:29<00:44, 231.63 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38354/47780 [02:29<00:40, 234.93 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37530/47780 [02:29<00:42, 240.59 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41440/47780 [02:29<00:47, 134.30 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39203/47780 [02:29<00:44, 193.57 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35901/47780 [02:29<00:50, 234.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37533/47780 [02:29<00:38, 265.83 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42881/47780 [02:29<00:15, 314.99 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37557/47780 [02:29<00:41, 245.20 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38378/47780 [02:29<00:40, 230.98 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37599/47780 [02:29<00:46, 217.22 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41456/47780 [02:29<00:45, 138.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37561/47780 [02:29<00:38, 262.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35925/47780 [02:29<00:52, 224.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39223/47780 [02:29<00:50, 168.67 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42914/47780 [02:29<00:16, 302.73 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37624/47780 [02:29<00:44, 225.79 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41480/47780 [02:29<00:38, 164.72 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38402/47780 [02:29<00:44, 208.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37588/47780 [02:29<00:39, 258.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37584/47780 [02:29<00:45, 221.66 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35948/47780 [02:29<00:56, 208.45 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39243/47780 [02:29<00:48, 175.69 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42947/47780 [02:29<00:15, 310.12 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37651/47780 [02:29<00:42, 237.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41501/47780 [02:29<00:36, 171.63 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37624/47780 [02:29<00:35, 282.73 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37608/47780 [02:29<00:46, 220.27 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35970/47780 [02:29<00:56, 208.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38424/47780 [02:29<00:47, 195.29 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39262/47780 [02:29<00:50, 168.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42982/47780 [02:29<00:16, 296.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37676/47780 [02:29<00:44, 228.67 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37662/47780 [02:29<00:33, 305.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41519/47780 [02:29<00:39, 157.90 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37634/47780 [02:29<00:44, 226.10 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35992/47780 [02:29<00:57, 204.91 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39284/47780 [02:29<00:47, 179.96 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38444/47780 [02:29<00:51, 181.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43012/47780 [02:29<00:17, 280.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37700/47780 [02:29<00:44, 226.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37696/47780 [02:29<00:32, 310.30 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41540/47780 [02:29<00:37, 168.61 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37659/47780 [02:29<00:43, 230.26 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36017/47780 [02:29<00:54, 214.80 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38466/47780 [02:29<00:49, 189.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39303/47780 [02:29<00:47, 178.35 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43042/47780 [02:29<00:16, 279.84 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37726/47780 [02:29<00:43, 231.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37729/47780 [02:29<00:31, 314.84 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41563/47780 [02:29<00:33, 183.04 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37689/47780 [02:29<00:42, 238.88 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36043/47780 [02:29<00:52, 224.82 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38488/47780 [02:29<00:47, 195.39 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43079/47780 [02:29<00:15, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39322/47780 [02:29<00:50, 168.16 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37750/47780 [02:30<00:43, 231.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37761/47780 [02:30<00:32, 312.97 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37716/47780 [02:30<00:41, 244.07 examples/s]
Tokenizing train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36069/47780 [02:30<00:52, 222.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38508/47780 [02:30<00:48, 192.46 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41582/47780 [02:30<00:37, 165.44 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43112/47780 [02:30<00:15, 302.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39340/47780 [02:30<00:50, 166.84 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37793/47780 [02:30<00:33, 298.75 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37775/47780 [02:30<00:46, 216.58 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37746/47780 [02:30<00:39, 256.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38528/47780 [02:30<00:48, 190.41 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36097/47780 [02:30<00:52, 223.97 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43153/47780 [02:30<00:14, 326.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41600/47780 [02:30<00:40, 154.17 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39358/47780 [02:30<00:53, 158.37 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37830/47780 [02:30<00:31, 317.83 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37802/47780 [02:30<00:44, 226.15 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37772/47780 [02:30<00:39, 252.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38549/47780 [02:30<00:47, 193.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36122/47780 [02:30<00:51, 227.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43192/47780 [02:30<00:13, 342.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41617/47780 [02:30<00:39, 155.05 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39376/47780 [02:30<00:52, 160.27 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37862/47780 [02:30<00:32, 303.17 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37803/47780 [02:30<00:37, 265.33 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37825/47780 [02:30<00:47, 210.98 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38569/47780 [02:30<00:48, 189.82 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36145/47780 [02:30<00:52, 220.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43239/47780 [02:30<00:12, 375.21 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41633/47780 [02:30<00:40, 150.37 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39394/47780 [02:30<00:51, 162.49 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37893/47780 [02:30<00:33, 294.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37836/47780 [02:30<00:36, 274.25 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37847/47780 [02:30<00:48, 204.65 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38589/47780 [02:30<00:48, 189.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43282/47780 [02:30<00:11, 388.02 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41655/47780 [02:30<00:37, 164.92 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36168/47780 [02:30<00:57, 201.43 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39412/47780 [02:30<00:50, 167.04 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37924/47780 [02:30<00:33, 297.69 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37870/47780 [02:30<00:33, 292.75 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38615/47780 [02:30<00:44, 207.05 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37868/47780 [02:30<00:50, 195.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43321/47780 [02:30<00:12, 370.63 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41674/47780 [02:30<00:35, 169.90 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39431/47780 [02:30<00:48, 171.87 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37965/47780 [02:30<00:29, 329.49 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36189/47780 [02:30<01:00, 193.10 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37892/47780 [02:30<00:47, 207.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38640/47780 [02:30<00:42, 216.64 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37900/47780 [02:30<00:36, 267.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43359/47780 [02:30<00:12, 367.82 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41693/47780 [02:30<00:35, 173.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39450/47780 [02:30<00:47, 174.92 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37999/47780 [02:30<00:29, 328.70 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36210/47780 [02:30<01:00, 192.66 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38665/47780 [02:30<00:40, 224.29 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37915/47780 [02:30<00:47, 209.13 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37929/47780 [02:30<00:36, 267.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43400/47780 [02:30<00:11, 371.80 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39468/47780 [02:30<00:47, 174.83 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41713/47780 [02:30<00:35, 173.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38041/47780 [02:30<00:27, 350.90 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36230/47780 [02:30<01:01, 187.71 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38694/47780 [02:30<00:37, 243.26 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37937/47780 [02:30<00:46, 211.64 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37957/47780 [02:30<00:37, 259.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43441/47780 [02:30<00:11, 378.41 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39486/47780 [02:30<00:47, 173.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41731/47780 [02:30<00:34, 173.13 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38079/47780 [02:31<00:27, 359.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36249/47780 [02:31<01:07, 172.04 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38719/47780 [02:31<00:39, 231.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37985/47780 [02:31<00:37, 262.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37959/47780 [02:31<00:49, 198.96 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43479/47780 [02:30<00:11, 365.72 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41751/47780 [02:31<00:33, 179.90 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38121/47780 [02:31<00:26, 368.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39504/47780 [02:31<00:53, 153.94 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36272/47780 [02:31<01:02, 184.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37983/47780 [02:31<00:47, 206.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38013/47780 [02:31<00:38, 252.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38743/47780 [02:31<00:42, 212.44 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41770/47780 [02:31<00:33, 179.67 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43516/47780 [02:31<00:12, 340.46 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38160/47780 [02:31<00:26, 366.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39523/47780 [02:31<00:53, 155.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36292/47780 [02:31<01:02, 183.14 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38042/47780 [02:31<00:37, 258.22 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38769/47780 [02:31<00:40, 222.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38199/47780 [02:31<00:25, 373.29 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38004/47780 [02:31<00:52, 185.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41789/47780 [02:31<00:34, 174.22 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43554/47780 [02:31<00:12, 336.91 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39540/47780 [02:31<00:51, 159.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36319/47780 [02:31<00:55, 206.35 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38078/47780 [02:31<00:34, 282.77 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38792/47780 [02:31<00:41, 216.88 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38245/47780 [02:31<00:23, 398.50 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38025/47780 [02:31<00:51, 188.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41807/47780 [02:31<00:35, 168.37 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43588/47780 [02:31<00:13, 314.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36341/47780 [02:31<00:56, 203.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39557/47780 [02:31<00:55, 147.75 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38108/47780 [02:31<00:35, 275.38 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38287/47780 [02:31<00:24, 394.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38814/47780 [02:31<00:42, 209.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38049/47780 [02:31<00:48, 200.09 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43622/47780 [02:31<00:12, 320.39 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41824/47780 [02:31<00:37, 158.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36365/47780 [02:31<00:55, 206.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39576/47780 [02:31<00:52, 155.31 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38139/47780 [02:31<00:35, 272.89 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38327/47780 [02:31<00:24, 389.33 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38071/47780 [02:31<00:48, 201.00 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38837/47780 [02:31<00:43, 203.76 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43656/47780 [02:31<00:12, 322.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41848/47780 [02:31<00:32, 180.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38167/47780 [02:31<00:34, 274.74 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38368/47780 [02:31<00:24, 389.21 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36386/47780 [02:31<01:02, 183.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39592/47780 [02:31<00:59, 137.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38099/47780 [02:31<00:44, 216.56 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41868/47780 [02:31<00:33, 176.01 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43689/47780 [02:31<00:13, 303.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38858/47780 [02:31<00:49, 181.67 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38195/47780 [02:31<00:35, 267.29 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36405/47780 [02:31<01:02, 180.90 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38121/47780 [02:31<00:44, 216.84 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39607/47780 [02:31<00:59, 136.32 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38407/47780 [02:31<00:27, 346.33 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41889/47780 [02:31<00:32, 181.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43720/47780 [02:31<00:13, 291.52 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38884/47780 [02:31<00:46, 193.04 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38222/47780 [02:31<00:35, 267.88 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36425/47780 [02:31<01:01, 185.48 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38143/47780 [02:31<00:44, 215.03 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39621/47780 [02:31<01:00, 134.87 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38458/47780 [02:32<00:23, 389.71 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41909/47780 [02:31<00:32, 182.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43758/47780 [02:31<00:12, 313.61 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38904/47780 [02:32<00:46, 189.91 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38252/47780 [02:32<00:34, 277.06 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36446/47780 [02:32<00:59, 191.15 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38171/47780 [02:32<00:41, 233.45 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39635/47780 [02:32<01:04, 126.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43790/47780 [02:32<00:12, 312.12 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38499/47780 [02:32<00:26, 352.07 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41928/47780 [02:32<00:35, 166.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38924/47780 [02:32<00:49, 179.28 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38281/47780 [02:32<00:35, 266.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38195/47780 [02:32<00:41, 230.33 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36466/47780 [02:32<01:01, 183.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39651/47780 [02:32<01:01, 132.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43822/47780 [02:32<00:13, 303.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38542/47780 [02:32<00:25, 365.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41946/47780 [02:32<00:35, 164.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38944/47780 [02:32<00:48, 180.85 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38308/47780 [02:32<00:35, 267.43 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38219/47780 [02:32<00:41, 228.40 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36485/47780 [02:32<01:05, 173.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39677/47780 [02:32<00:48, 166.83 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38580/47780 [02:32<00:25, 364.04 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43854/47780 [02:32<00:13, 286.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41964/47780 [02:32<00:36, 157.86 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38250/47780 [02:32<00:38, 246.86 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38963/47780 [02:32<00:52, 167.25 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38335/47780 [02:32<00:39, 241.86 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36509/47780 [02:32<01:01, 184.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39715/47780 [02:32<00:36, 223.51 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43883/47780 [02:32<00:13, 285.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38621/47780 [02:32<00:25, 357.88 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41983/47780 [02:32<00:35, 164.45 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38275/47780 [02:32<00:41, 230.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39740/47780 [02:32<00:35, 228.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38980/47780 [02:32<00:55, 158.18 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36528/47780 [02:32<01:03, 177.53 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38360/47780 [02:32<00:41, 224.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38662/47780 [02:32<00:24, 368.80 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42001/47780 [02:32<00:34, 166.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43912/47780 [02:32<00:14, 258.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39767/47780 [02:32<00:33, 240.04 examples/s]
Tokenizing train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36547/47780 [02:32<01:02, 178.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38300/47780 [02:32<00:44, 215.40 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38997/47780 [02:32<00:57, 153.67 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38384/47780 [02:32<00:42, 219.86 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38704/47780 [02:32<00:23, 382.20 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43947/47780 [02:32<00:13, 278.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42019/47780 [02:32<00:37, 154.50 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36566/47780 [02:32<01:02, 180.01 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39020/47780 [02:32<00:50, 173.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38323/47780 [02:32<00:43, 217.78 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39792/47780 [02:32<00:35, 224.79 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38743/47780 [02:32<00:23, 384.41 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38407/47780 [02:32<00:45, 205.01 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42039/47780 [02:32<00:34, 166.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43976/47780 [02:32<00:14, 258.06 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38346/47780 [02:32<00:43, 217.26 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36585/47780 [02:32<01:03, 174.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39038/47780 [02:32<00:51, 168.75 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39816/47780 [02:32<00:37, 209.81 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38428/47780 [02:32<00:46, 202.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38782/47780 [02:32<00:26, 342.96 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38368/47780 [02:32<00:45, 208.64 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39057/47780 [02:32<00:51, 169.61 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44003/47780 [02:32<00:15, 238.45 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36609/47780 [02:32<01:02, 179.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42056/47780 [02:32<00:39, 143.56 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39838/47780 [02:32<00:39, 202.32 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38824/47780 [02:33<00:24, 361.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38449/47780 [02:33<00:49, 188.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39075/47780 [02:33<00:51, 170.37 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44035/47780 [02:32<00:14, 254.42 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38390/47780 [02:33<00:45, 207.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36634/47780 [02:33<00:56, 197.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42076/47780 [02:33<00:37, 151.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39859/47780 [02:33<00:39, 200.20 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38474/47780 [02:33<00:45, 202.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38862/47780 [02:33<00:26, 342.00 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38412/47780 [02:33<00:45, 206.14 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39094/47780 [02:33<00:51, 168.56 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44062/47780 [02:33<00:14, 248.13 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36654/47780 [02:33<00:57, 194.55 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39887/47780 [02:33<00:36, 217.05 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42092/47780 [02:33<00:38, 146.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38898/47780 [02:33<00:26, 335.97 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38495/47780 [02:33<00:50, 182.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39117/47780 [02:33<00:46, 185.43 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36676/47780 [02:33<00:55, 199.49 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38439/47780 [02:33<00:43, 216.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44088/47780 [02:33<00:14, 248.32 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39914/47780 [02:33<00:34, 226.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42109/47780 [02:33<00:37, 152.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38934/47780 [02:33<00:26, 329.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38516/47780 [02:33<00:50, 184.16 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39141/47780 [02:33<00:43, 198.63 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44119/47780 [02:33<00:13, 262.54 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38465/47780 [02:33<00:41, 224.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39938/47780 [02:33<00:34, 230.21 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36697/47780 [02:33<01:00, 183.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42125/47780 [02:33<00:37, 149.69 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38970/47780 [02:33<00:26, 336.50 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38535/47780 [02:33<00:50, 181.54 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39163/47780 [02:33<00:42, 202.85 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44153/47780 [02:33<00:12, 281.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38494/47780 [02:33<00:38, 242.14 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36730/47780 [02:33<00:49, 222.92 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42141/47780 [02:33<00:37, 149.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39962/47780 [02:33<00:36, 215.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39004/47780 [02:33<00:27, 322.43 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38574/47780 [02:33<00:39, 235.15 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39184/47780 [02:33<00:44, 191.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44182/47780 [02:33<00:13, 268.30 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38521/47780 [02:33<00:39, 236.48 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36758/47780 [02:33<00:47, 233.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42162/47780 [02:33<00:34, 163.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39984/47780 [02:33<00:39, 197.13 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39037/47780 [02:33<00:28, 308.24 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38600/47780 [02:33<00:40, 224.53 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39206/47780 [02:33<00:43, 197.09 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38551/47780 [02:33<00:36, 250.47 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44211/47780 [02:33<00:13, 266.84 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36800/47780 [02:33<00:39, 280.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42179/47780 [02:33<00:35, 159.96 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40005/47780 [02:33<00:39, 198.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39072/47780 [02:33<00:27, 312.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44238/47780 [02:33<00:13, 265.68 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38577/47780 [02:33<00:37, 242.74 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39227/47780 [02:33<00:45, 188.93 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36829/47780 [02:33<00:38, 281.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42198/47780 [02:33<00:33, 166.94 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38624/47780 [02:33<00:48, 190.65 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40027/47780 [02:33<00:39, 197.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39118/47780 [02:33<00:24, 353.14 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38602/47780 [02:33<00:37, 244.12 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39248/47780 [02:33<00:45, 187.64 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42216/47780 [02:33<00:32, 170.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44266/47780 [02:33<00:14, 248.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36858/47780 [02:33<00:40, 266.85 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38652/47780 [02:34<00:43, 211.67 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40047/47780 [02:33<00:39, 194.50 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38627/47780 [02:34<00:38, 236.23 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39278/47780 [02:34<00:38, 218.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44293/47780 [02:33<00:13, 253.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39154/47780 [02:34<00:28, 299.86 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36887/47780 [02:34<00:40, 270.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42234/47780 [02:34<00:33, 167.59 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38675/47780 [02:34<00:42, 214.56 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40067/47780 [02:34<00:39, 194.19 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38655/47780 [02:34<00:36, 248.40 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39303/47780 [02:34<00:38, 222.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44321/47780 [02:34<00:13, 255.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42251/47780 [02:34<00:33, 164.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39203/47780 [02:34<00:25, 335.81 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36915/47780 [02:34<00:43, 248.64 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38698/47780 [02:34<00:43, 207.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40088/47780 [02:34<00:40, 191.23 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38682/47780 [02:34<00:36, 248.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39329/47780 [02:34<00:36, 232.97 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39238/47780 [02:34<00:25, 338.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44347/47780 [02:34<00:13, 247.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42271/47780 [02:34<00:32, 170.73 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36941/47780 [02:34<00:45, 238.41 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38720/47780 [02:34<00:44, 202.68 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40110/47780 [02:34<00:40, 187.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39356/47780 [02:34<00:35, 235.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38710/47780 [02:34<00:36, 249.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42289/47780 [02:34<00:32, 167.24 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44372/47780 [02:34<00:14, 233.75 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39273/47780 [02:34<00:26, 315.96 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36967/47780 [02:34<00:45, 237.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38744/47780 [02:34<00:44, 203.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40129/47780 [02:34<00:42, 179.82 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38737/47780 [02:34<00:35, 251.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39382/47780 [02:34<00:35, 237.04 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42306/47780 [02:34<00:33, 161.15 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44396/47780 [02:34<00:14, 227.71 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39306/47780 [02:34<00:27, 302.98 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 36992/47780 [02:34<00:45, 238.55 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38772/47780 [02:34<00:40, 221.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40155/47780 [02:34<00:39, 192.34 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38763/47780 [02:34<00:37, 238.98 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39406/47780 [02:34<00:37, 222.42 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44423/47780 [02:34<00:14, 231.61 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39337/47780 [02:34<00:28, 301.06 examples/s]
Tokenizing train dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37017/47780 [02:34<00:44, 239.66 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38796/47780 [02:34<00:40, 223.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42324/47780 [02:34<00:36, 147.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40178/47780 [02:34<00:38, 195.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39430/47780 [02:34<00:38, 217.91 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44450/47780 [02:34<00:13, 239.57 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37045/47780 [02:34<00:42, 250.76 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39379/47780 [02:34<00:25, 330.35 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38788/47780 [02:34<00:42, 210.79 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42341/47780 [02:34<00:35, 152.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38819/47780 [02:34<00:41, 216.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40201/47780 [02:34<00:37, 200.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39461/47780 [02:34<00:34, 242.88 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37073/47780 [02:34<00:41, 259.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39414/47780 [02:34<00:24, 335.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44477/47780 [02:34<00:13, 242.28 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38810/47780 [02:34<00:42, 209.96 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42360/47780 [02:34<00:34, 159.08 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38844/47780 [02:34<00:40, 219.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40223/47780 [02:34<00:36, 205.88 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39486/47780 [02:34<00:35, 231.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39451/47780 [02:34<00:24, 343.20 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44502/47780 [02:34<00:13, 236.41 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37101/47780 [02:34<00:41, 255.02 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38835/47780 [02:34<00:40, 219.80 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38867/47780 [02:35<00:41, 214.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42379/47780 [02:34<00:35, 154.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40248/47780 [02:34<00:34, 215.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39493/47780 [02:35<00:22, 363.16 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39510/47780 [02:35<00:35, 231.29 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37127/47780 [02:35<00:42, 249.05 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38858/47780 [02:35<00:40, 217.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44526/47780 [02:35<00:15, 211.84 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38889/47780 [02:35<00:42, 211.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42404/47780 [02:35<00:30, 177.83 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40280/47780 [02:35<00:31, 240.24 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39535/47780 [02:35<00:35, 231.28 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37156/47780 [02:35<00:41, 257.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39531/47780 [02:35<00:23, 344.49 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38881/47780 [02:35<00:40, 221.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44549/47780 [02:35<00:14, 216.50 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38911/47780 [02:35<00:44, 199.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40306/47780 [02:35<00:32, 232.37 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42423/47780 [02:35<00:32, 167.20 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39561/47780 [02:35<00:34, 234.87 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38910/47780 [02:35<00:37, 237.96 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37183/47780 [02:35<00:41, 258.19 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39567/47780 [02:35<00:24, 341.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44573/47780 [02:35<00:14, 215.89 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38932/47780 [02:35<00:44, 200.82 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40330/47780 [02:35<00:33, 219.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42441/47780 [02:35<00:33, 159.49 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39593/47780 [02:35<00:31, 255.90 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38935/47780 [02:35<00:37, 236.45 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37211/47780 [02:35<00:40, 258.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39611/47780 [02:35<00:22, 364.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44596/47780 [02:35<00:14, 217.35 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38953/47780 [02:35<00:45, 194.75 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40360/47780 [02:35<00:32, 231.72 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42458/47780 [02:35<00:33, 156.87 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39662/47780 [02:35<00:20, 405.42 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39619/47780 [02:35<00:33, 242.76 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37239/47780 [02:35<00:40, 258.82 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38959/47780 [02:35<00:38, 228.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44620/47780 [02:35<00:14, 218.88 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38981/47780 [02:35<00:41, 213.51 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42478/47780 [02:35<00:31, 167.42 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37266/47780 [02:35<00:40, 261.98 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39646/47780 [02:35<00:32, 248.14 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39703/47780 [02:35<00:20, 393.66 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38986/47780 [02:35<00:38, 230.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44648/47780 [02:35<00:13, 235.99 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40384/47780 [02:35<00:36, 205.19 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39004/47780 [02:35<00:43, 202.33 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39672/47780 [02:35<00:32, 251.26 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42495/47780 [02:35<00:34, 154.58 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39743/47780 [02:35<00:21, 378.27 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37293/47780 [02:35<00:42, 247.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39013/47780 [02:35<00:36, 238.85 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44672/47780 [02:35<00:13, 229.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40406/47780 [02:35<00:37, 199.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39025/47780 [02:35<00:43, 202.11 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39698/47780 [02:35<00:32, 248.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42516/47780 [02:35<00:31, 165.68 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39786/47780 [02:35<00:20, 384.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37322/47780 [02:35<00:40, 255.18 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39037/47780 [02:35<00:38, 226.30 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44699/47780 [02:35<00:12, 238.10 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40428/47780 [02:35<00:36, 200.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39046/47780 [02:35<00:43, 201.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39727/47780 [02:35<00:31, 257.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42533/47780 [02:35<00:32, 161.57 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39066/47780 [02:35<00:35, 242.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37348/47780 [02:35<00:42, 244.88 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44723/47780 [02:35<00:13, 228.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40451/47780 [02:35<00:35, 205.81 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39825/47780 [02:36<00:23, 338.79 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39755/47780 [02:35<00:30, 263.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39071/47780 [02:36<00:41, 208.62 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37376/47780 [02:36<00:41, 253.42 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39096/47780 [02:36<00:34, 254.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42555/47780 [02:36<00:30, 170.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44752/47780 [02:35<00:12, 245.07 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39867/47780 [02:36<00:22, 357.41 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40473/47780 [02:36<00:36, 200.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39796/47780 [02:36<00:26, 299.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39092/47780 [02:36<00:45, 191.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37405/47780 [02:36<00:39, 260.77 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39125/47780 [02:36<00:33, 259.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40502/47780 [02:36<00:32, 224.87 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44777/47780 [02:36<00:13, 228.65 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39904/47780 [02:36<00:22, 348.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42574/47780 [02:36<00:32, 158.26 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39840/47780 [02:36<00:23, 332.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37439/47780 [02:36<00:36, 283.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39113/47780 [02:36<00:45, 191.18 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39155/47780 [02:36<00:31, 270.16 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40527/47780 [02:36<00:31, 227.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42592/47780 [02:36<00:32, 161.72 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39940/47780 [02:36<00:22, 342.92 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44801/47780 [02:36<00:13, 224.35 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39874/47780 [02:36<00:24, 327.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39136/47780 [02:36<00:43, 200.59 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37468/47780 [02:36<00:37, 272.72 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39184/47780 [02:36<00:34, 251.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40550/47780 [02:36<00:32, 224.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42610/47780 [02:36<00:31, 165.24 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39975/47780 [02:36<00:22, 341.89 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44825/47780 [02:36<00:14, 209.93 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39907/47780 [02:36<00:25, 305.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39159/47780 [02:36<00:42, 204.92 examples/s]
Tokenizing train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37501/47780 [02:36<00:36, 279.35 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40575/47780 [02:36<00:31, 227.83 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39213/47780 [02:36<00:33, 254.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42627/47780 [02:36<00:31, 163.09 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40010/47780 [02:36<00:23, 334.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44858/47780 [02:36<00:12, 240.87 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39939/47780 [02:36<00:26, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37530/47780 [02:36<00:36, 281.93 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39181/47780 [02:36<00:43, 196.89 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40598/47780 [02:36<00:31, 225.48 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39242/47780 [02:36<00:33, 257.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42645/47780 [02:36<00:32, 158.90 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40045/47780 [02:36<00:23, 324.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44886/47780 [02:36<00:11, 247.43 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39971/47780 [02:36<00:25, 303.18 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37561/47780 [02:36<00:35, 289.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39201/47780 [02:36<00:46, 186.20 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40622/47780 [02:36<00:32, 219.52 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39268/47780 [02:36<00:34, 248.02 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40088/47780 [02:36<00:21, 349.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44912/47780 [02:36<00:11, 248.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42661/47780 [02:36<00:33, 150.85 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37593/47780 [02:36<00:35, 289.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40002/47780 [02:36<00:27, 287.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39224/47780 [02:36<00:44, 192.06 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39294/47780 [02:36<00:33, 251.27 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40645/47780 [02:36<00:33, 210.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42682/47780 [02:36<00:30, 165.15 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40125/47780 [02:36<00:22, 336.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44938/47780 [02:36<00:12, 235.35 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 37623/47780 [02:36<00:36, 281.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39248/47780 [02:36<00:42, 202.82 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40031/47780 [02:36<00:30, 256.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40670/47780 [02:36<00:32, 218.87 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42703/47780 [02:36<00:29, 173.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44962/47780 [02:36<00:12, 232.09 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39320/47780 [02:36<00:39, 215.66 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40159/47780 [02:37<00:25, 304.08 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37665/47780 [02:36<00:32, 315.44 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39278/47780 [02:37<00:38, 223.33 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40693/47780 [02:36<00:32, 217.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40060/47780 [02:37<00:30, 252.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42722/47780 [02:37<00:28, 176.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44986/47780 [02:36<00:12, 231.38 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39347/47780 [02:37<00:36, 228.37 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40191/47780 [02:37<00:24, 304.89 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37702/47780 [02:37<00:30, 326.56 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40087/47780 [02:37<00:30, 255.45 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39302/47780 [02:37<00:40, 210.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40715/47780 [02:37<00:33, 212.85 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39373/47780 [02:37<00:35, 236.63 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40226/47780 [02:37<00:24, 313.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45010/47780 [02:37<00:13, 212.08 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42740/47780 [02:37<00:33, 150.08 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37736/47780 [02:37<00:33, 299.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40122/47780 [02:37<00:27, 279.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40739/47780 [02:37<00:32, 219.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39324/47780 [02:37<00:41, 202.38 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40269/47780 [02:37<00:21, 342.63 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39399/47780 [02:37<00:37, 226.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45032/47780 [02:37<00:13, 205.46 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42758/47780 [02:37<00:32, 153.12 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40761/47780 [02:37<00:32, 218.75 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37767/47780 [02:37<00:34, 289.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40152/47780 [02:37<00:27, 277.45 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40304/47780 [02:37<00:22, 336.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39424/47780 [02:37<00:36, 230.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39345/47780 [02:37<00:45, 185.14 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45053/47780 [02:37<00:13, 202.13 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40795/47780 [02:37<00:27, 253.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42774/47780 [02:37<00:34, 145.80 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37799/47780 [02:37<00:34, 292.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40181/47780 [02:37<00:27, 271.71 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40341/47780 [02:37<00:21, 346.03 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39366/47780 [02:37<00:44, 191.01 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39452/47780 [02:37<00:34, 241.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45075/47780 [02:37<00:13, 204.99 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37829/47780 [02:37<00:33, 293.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42791/47780 [02:37<00:33, 148.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40821/47780 [02:37<00:28, 247.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40211/47780 [02:37<00:27, 276.64 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40376/47780 [02:37<00:21, 342.09 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39477/47780 [02:37<00:35, 236.65 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39388/47780 [02:37<00:44, 190.52 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37863/47780 [02:37<00:32, 306.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45097/47780 [02:37<00:13, 192.05 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42809/47780 [02:37<00:32, 155.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40846/47780 [02:37<00:29, 237.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40239/47780 [02:37<00:29, 259.72 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40420/47780 [02:37<00:20, 363.03 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39508/47780 [02:37<00:32, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39409/47780 [02:37<00:43, 193.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42826/47780 [02:37<00:31, 159.00 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45122/47780 [02:37<00:13, 201.19 examples/s]
Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37894/47780 [02:37<00:33, 291.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40870/47780 [02:37<00:29, 237.57 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40272/47780 [02:37<00:27, 276.22 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40465/47780 [02:37<00:18, 385.55 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39433/47780 [02:37<00:41, 202.27 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39534/47780 [02:37<00:33, 248.86 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42843/47780 [02:37<00:31, 158.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37924/47780 [02:37<00:33, 291.86 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40894/47780 [02:37<00:30, 225.57 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40310/47780 [02:37<00:24, 305.14 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40504/47780 [02:37<00:19, 382.04 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45144/47780 [02:37<00:14, 184.30 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39470/47780 [02:37<00:33, 245.95 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39571/47780 [02:37<00:29, 273.68 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42860/47780 [02:37<00:31, 154.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37960/47780 [02:37<00:32, 302.06 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40344/47780 [02:37<00:23, 311.71 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45166/47780 [02:37<00:13, 191.65 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40917/47780 [02:37<00:32, 212.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40545/47780 [02:38<00:19, 363.66 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39600/47780 [02:38<00:29, 277.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39496/47780 [02:38<00:34, 240.47 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 37996/47780 [02:38<00:31, 314.48 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40377/47780 [02:38<00:24, 305.78 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45186/47780 [02:38<00:13, 191.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40944/47780 [02:38<00:31, 219.80 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42876/47780 [02:38<00:35, 137.73 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40588/47780 [02:38<00:19, 377.52 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39628/47780 [02:38<00:30, 266.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39521/47780 [02:38<00:34, 236.16 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38033/47780 [02:38<00:30, 320.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40411/47780 [02:38<00:23, 312.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42891/47780 [02:38<00:35, 138.76 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40972/47780 [02:38<00:29, 230.64 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39548/47780 [02:38<00:34, 241.69 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39655/47780 [02:38<00:31, 258.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40628/47780 [02:38<00:20, 355.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45208/47780 [02:38<00:15, 171.34 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38075/47780 [02:38<00:27, 348.49 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40443/47780 [02:38<00:23, 314.55 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42906/47780 [02:38<00:34, 140.42 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41002/47780 [02:38<00:27, 248.46 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40664/47780 [02:38<00:20, 348.28 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39573/47780 [02:38<00:35, 228.96 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45227/47780 [02:38<00:14, 172.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39681/47780 [02:38<00:32, 245.55 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38113/47780 [02:38<00:27, 350.90 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40475/47780 [02:38<00:24, 302.62 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42922/47780 [02:38<00:33, 144.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41029/47780 [02:38<00:27, 242.03 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40703/47780 [02:38<00:19, 357.29 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45250/47780 [02:38<00:13, 185.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39706/47780 [02:38<00:33, 243.11 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39597/47780 [02:38<00:36, 223.24 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38149/47780 [02:38<00:27, 353.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40520/47780 [02:38<00:21, 340.11 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42940/47780 [02:38<00:31, 152.34 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41054/47780 [02:38<00:28, 232.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45271/47780 [02:38<00:13, 189.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39736/47780 [02:38<00:31, 253.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39620/47780 [02:38<00:37, 217.95 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38185/47780 [02:38<00:28, 334.62 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40739/47780 [02:38<00:22, 311.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40557/47780 [02:38<00:20, 346.97 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42958/47780 [02:38<00:32, 150.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41083/47780 [02:38<00:27, 244.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45291/47780 [02:38<00:13, 191.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39768/47780 [02:38<00:29, 270.18 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39644/47780 [02:38<00:37, 219.09 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40790/47780 [02:38<00:19, 360.37 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38219/47780 [02:38<00:29, 328.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42988/47780 [02:38<00:25, 189.15 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40593/47780 [02:38<00:22, 312.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41113/47780 [02:38<00:26, 252.98 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45312/47780 [02:38<00:12, 192.10 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39803/47780 [02:38<00:27, 289.53 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39680/47780 [02:38<00:31, 255.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40830/47780 [02:38<00:18, 367.11 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38253/47780 [02:38<00:30, 314.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43009/47780 [02:38<00:25, 188.71 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40626/47780 [02:38<00:23, 304.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41141/47780 [02:38<00:25, 255.93 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45332/47780 [02:38<00:13, 187.97 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39833/47780 [02:38<00:28, 282.17 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39708/47780 [02:38<00:31, 256.52 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40868/47780 [02:39<00:19, 353.15 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38286/47780 [02:38<00:30, 316.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41180/47780 [02:38<00:22, 290.25 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40658/47780 [02:38<00:23, 301.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43029/47780 [02:38<00:26, 181.62 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39862/47780 [02:39<00:28, 276.47 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39739/47780 [02:39<00:29, 271.57 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40919/47780 [02:39<00:17, 390.17 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45351/47780 [02:38<00:14, 167.83 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38319/47780 [02:39<00:30, 312.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40689/47780 [02:39<00:23, 298.74 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41212/47780 [02:39<00:23, 276.76 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39781/47780 [02:39<00:25, 310.50 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39909/47780 [02:39<00:24, 316.03 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45369/47780 [02:39<00:14, 169.29 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40959/47780 [02:39<00:17, 387.93 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38351/47780 [02:39<00:32, 292.75 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43048/47780 [02:39<00:32, 146.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40727/47780 [02:39<00:22, 320.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41246/47780 [02:39<00:22, 287.59 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39813/47780 [02:39<00:25, 309.16 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39946/47780 [02:39<00:23, 327.20 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40999/47780 [02:39<00:18, 371.71 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38381/47780 [02:39<00:32, 289.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45388/47780 [02:39<00:15, 157.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40765/47780 [02:39<00:21, 329.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43064/47780 [02:39<00:33, 138.93 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39851/47780 [02:39<00:24, 319.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41276/47780 [02:39<00:23, 278.23 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39979/47780 [02:39<00:24, 317.27 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41038/47780 [02:39<00:18, 374.26 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38417/47780 [02:39<00:30, 306.96 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45406/47780 [02:39<00:14, 163.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40802/47780 [02:39<00:20, 337.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43079/47780 [02:39<00:33, 140.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39884/47780 [02:39<00:24, 318.71 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40014/47780 [02:39<00:24, 319.31 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41305/47780 [02:39<00:25, 251.67 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41080/47780 [02:39<00:17, 375.67 examples/s]
Tokenizing train dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38448/47780 [02:39<00:31, 300.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40839/47780 [02:39<00:20, 342.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43094/47780 [02:39<00:33, 140.82 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45424/47780 [02:39<00:15, 153.10 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39916/47780 [02:39<00:27, 289.28 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40046/47780 [02:39<00:25, 297.52 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41332/47780 [02:39<00:25, 254.63 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38481/47780 [02:39<00:30, 305.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41118/47780 [02:39<00:19, 349.35 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40874/47780 [02:39<00:20, 333.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45441/47780 [02:39<00:14, 157.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43124/47780 [02:39<00:26, 178.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39947/47780 [02:39<00:27, 288.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40076/47780 [02:39<00:26, 293.74 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41359/47780 [02:39<00:25, 254.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38517/47780 [02:39<00:29, 317.94 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41154/47780 [02:39<00:19, 337.02 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40908/47780 [02:39<00:21, 319.29 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43148/47780 [02:39<00:24, 192.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45458/47780 [02:39<00:15, 153.89 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40110/47780 [02:39<00:25, 306.55 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39977/47780 [02:39<00:27, 282.34 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41385/47780 [02:39<00:26, 243.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38549/47780 [02:39<00:30, 307.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40941/47780 [02:39<00:21, 316.48 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41190/47780 [02:39<00:20, 323.04 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43168/47780 [02:39<00:24, 188.91 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45474/47780 [02:39<00:16, 136.66 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40013/47780 [02:39<00:26, 296.12 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40141/47780 [02:39<00:26, 286.26 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38581/47780 [02:39<00:29, 309.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41414/47780 [02:39<00:25, 250.42 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40974/47780 [02:39<00:21, 320.16 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41223/47780 [02:40<00:20, 324.85 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43188/47780 [02:39<00:24, 187.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45491/47780 [02:39<00:15, 144.98 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40176/47780 [02:40<00:25, 301.29 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38619/47780 [02:40<00:28, 323.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40044/47780 [02:40<00:27, 285.09 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41256/47780 [02:40<00:20, 319.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41440/47780 [02:40<00:28, 223.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43207/47780 [02:40<00:26, 174.51 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41007/47780 [02:40<00:24, 280.27 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45506/47780 [02:40<00:16, 138.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40211/47780 [02:40<00:24, 314.42 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40085/47780 [02:40<00:24, 319.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38660/47780 [02:40<00:26, 344.56 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41297/47780 [02:40<00:18, 344.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41469/47780 [02:40<00:26, 240.37 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43225/47780 [02:40<00:26, 169.16 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41042/47780 [02:40<00:23, 290.49 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40249/47780 [02:40<00:22, 330.86 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40120/47780 [02:40<00:23, 325.59 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38697/47780 [02:40<00:25, 351.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45521/47780 [02:40<00:16, 136.66 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41335/47780 [02:40<00:18, 354.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41495/47780 [02:40<00:26, 237.10 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43248/47780 [02:40<00:24, 182.33 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41076/47780 [02:40<00:22, 298.11 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40156/47780 [02:40<00:22, 334.03 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38733/47780 [02:40<00:25, 348.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45538/47780 [02:40<00:15, 144.53 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40284/47780 [02:40<00:23, 317.92 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41373/47780 [02:40<00:17, 358.10 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41521/47780 [02:40<00:27, 225.94 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43267/47780 [02:40<00:25, 177.91 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41117/47780 [02:40<00:20, 320.76 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38769/47780 [02:40<00:25, 349.03 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40191/47780 [02:40<00:22, 331.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40319/47780 [02:40<00:22, 324.55 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45561/47780 [02:40<00:14, 156.53 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41417/47780 [02:40<00:16, 381.77 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41545/47780 [02:40<00:27, 226.45 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43286/47780 [02:40<00:24, 180.56 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38810/47780 [02:40<00:24, 366.54 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40225/47780 [02:40<00:22, 331.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41151/47780 [02:40<00:20, 315.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40352/47780 [02:40<00:23, 321.36 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41456/47780 [02:40<00:16, 383.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45578/47780 [02:40<00:14, 150.26 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41568/47780 [02:40<00:27, 227.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38847/47780 [02:40<00:24, 357.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40261/47780 [02:40<00:23, 326.32 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41183/47780 [02:40<00:22, 296.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40385/47780 [02:40<00:23, 309.53 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43305/47780 [02:40<00:27, 161.81 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41495/47780 [02:40<00:17, 356.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45596/47780 [02:40<00:14, 148.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41595/47780 [02:40<00:26, 231.48 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38884/47780 [02:40<00:25, 346.95 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40294/47780 [02:40<00:22, 327.14 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40417/47780 [02:40<00:24, 305.82 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41214/47780 [02:40<00:22, 288.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43322/47780 [02:40<00:30, 148.58 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41532/47780 [02:40<00:18, 341.18 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45611/47780 [02:40<00:15, 138.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41638/47780 [02:40<00:22, 271.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40328/47780 [02:40<00:22, 327.11 examples/s]
Tokenizing train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38923/47780 [02:40<00:25, 351.26 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40448/47780 [02:40<00:24, 296.49 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41244/47780 [02:40<00:24, 267.39 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41567/47780 [02:41<00:19, 319.44 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43338/47780 [02:40<00:31, 139.60 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40366/47780 [02:41<00:21, 341.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41668/47780 [02:40<00:22, 270.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38962/47780 [02:40<00:24, 362.10 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40479/47780 [02:41<00:24, 293.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45626/47780 [02:40<00:17, 122.99 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41273/47780 [02:41<00:24, 270.16 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41604/47780 [02:41<00:18, 332.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43354/47780 [02:41<00:31, 142.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41695/47780 [02:41<00:23, 264.32 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39003/47780 [02:41<00:23, 371.87 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40401/47780 [02:41<00:23, 318.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40509/47780 [02:41<00:25, 282.99 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45640/47780 [02:41<00:17, 120.46 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41645/47780 [02:41<00:17, 353.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41301/47780 [02:41<00:25, 255.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43375/47780 [02:41<00:28, 153.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41723/47780 [02:41<00:22, 264.49 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39041/47780 [02:41<00:23, 369.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40434/47780 [02:41<00:23, 310.38 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40541/47780 [02:41<00:24, 290.07 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45653/47780 [02:41<00:18, 117.72 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41337/47780 [02:41<00:23, 276.33 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41683/47780 [02:41<00:17, 348.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43400/47780 [02:41<00:24, 175.94 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39081/47780 [02:41<00:23, 376.80 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41750/47780 [02:41<00:23, 253.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40466/47780 [02:41<00:23, 311.25 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40572/47780 [02:41<00:24, 295.68 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41378/47780 [02:41<00:20, 312.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45667/47780 [02:41<00:18, 112.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41722/47780 [02:41<00:17, 340.57 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41781/47780 [02:41<00:23, 259.99 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39123/47780 [02:41<00:24, 357.83 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43419/47780 [02:41<00:26, 164.94 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40498/47780 [02:41<00:24, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40602/47780 [02:41<00:25, 286.82 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41411/47780 [02:41<00:20, 310.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41766/47780 [02:41<00:16, 365.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45679/47780 [02:41<00:18, 111.52 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43445/47780 [02:41<00:23, 188.35 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41815/47780 [02:41<00:21, 276.29 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40529/47780 [02:41<00:23, 303.50 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40631/47780 [02:41<00:25, 284.27 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39160/47780 [02:41<00:26, 331.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41444/47780 [02:41<00:20, 309.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41810/47780 [02:41<00:15, 377.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45691/47780 [02:41<00:19, 109.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43469/47780 [02:41<00:21, 201.68 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41850/47780 [02:41<00:20, 293.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40660/47780 [02:41<00:25, 276.57 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40561/47780 [02:41<00:25, 287.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39194/47780 [02:41<00:27, 314.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41481/47780 [02:41<00:19, 326.36 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41849/47780 [02:41<00:15, 376.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45704/47780 [02:41<00:18, 112.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43492/47780 [02:41<00:20, 205.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40692/47780 [02:41<00:24, 288.79 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40594/47780 [02:41<00:24, 295.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41880/47780 [02:41<00:22, 268.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39228/47780 [02:41<00:26, 318.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41522/47780 [02:41<00:18, 346.43 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41887/47780 [02:41<00:15, 369.57 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45716/47780 [02:41<00:18, 109.81 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43514/47780 [02:41<00:21, 202.44 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40626/47780 [02:41<00:23, 300.74 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40721/47780 [02:41<00:25, 279.65 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41908/47780 [02:41<00:22, 266.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41567/47780 [02:41<00:16, 367.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41930/47780 [02:41<00:15, 384.08 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39261/47780 [02:41<00:28, 294.64 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43535/47780 [02:41<00:21, 193.74 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40661/47780 [02:42<00:23, 309.46 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40750/47780 [02:41<00:25, 270.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45728/47780 [02:41<00:20, 100.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41937/47780 [02:41<00:22, 254.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41606/47780 [02:41<00:16, 365.68 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39291/47780 [02:42<00:28, 293.31 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41974/47780 [02:42<00:14, 393.76 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43556/47780 [02:42<00:21, 198.18 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40694/47780 [02:42<00:23, 304.55 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40783/47780 [02:42<00:24, 280.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45740/47780 [02:42<00:19, 102.41 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41968/47780 [02:42<00:21, 269.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41651/47780 [02:42<00:15, 383.28 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39323/47780 [02:42<00:28, 297.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42014/47780 [02:42<00:15, 377.49 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40741/47780 [02:42<00:20, 351.29 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43577/47780 [02:42<00:22, 185.90 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41997/47780 [02:42<00:21, 272.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40814/47780 [02:42<00:24, 279.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45752/47780 [02:42<00:20, 100.95 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41690/47780 [02:42<00:16, 370.02 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39357/47780 [02:42<00:27, 305.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42055/47780 [02:42<00:14, 383.18 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43596/47780 [02:42<00:22, 184.99 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40849/47780 [02:42<00:23, 293.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42034/47780 [02:42<00:19, 293.54 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40778/47780 [02:42<00:21, 320.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45764/47780 [02:42<00:19, 105.10 examples/s]
Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39399/47780 [02:42<00:25, 325.56 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41730/47780 [02:42<00:17, 351.13 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42095/47780 [02:42<00:15, 374.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43621/47780 [02:42<00:21, 197.41 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40888/47780 [02:42<00:21, 316.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42064/47780 [02:42<00:19, 290.48 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45776/47780 [02:42<00:19, 104.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39433/47780 [02:42<00:25, 327.28 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42137/47780 [02:42<00:14, 383.59 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40811/47780 [02:42<00:23, 293.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41766/47780 [02:42<00:17, 349.11 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40920/47780 [02:42<00:22, 300.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43641/47780 [02:42<00:22, 185.61 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42094/47780 [02:42<00:20, 275.80 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39481/47780 [02:42<00:22, 370.51 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41804/47780 [02:42<00:16, 357.56 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42179/47780 [02:42<00:14, 392.81 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45788/47780 [02:42<00:19, 100.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40843/47780 [02:42<00:25, 276.66 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43670/47780 [02:42<00:19, 211.78 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42125/47780 [02:42<00:20, 282.24 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40952/47780 [02:42<00:23, 289.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42222/47780 [02:42<00:13, 400.82 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41840/47780 [02:42<00:17, 347.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39519/47780 [02:42<00:24, 341.36 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40888/47780 [02:42<00:21, 315.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45803/47780 [02:42<00:18, 104.94 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43693/47780 [02:42<00:18, 216.27 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42154/47780 [02:42<00:20, 274.14 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40982/47780 [02:42<00:23, 290.70 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39556/47780 [02:42<00:23, 345.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42263/47780 [02:42<00:14, 376.72 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41875/47780 [02:42<00:17, 331.76 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40926/47780 [02:42<00:20, 332.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45816/47780 [02:42<00:17, 111.15 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43715/47780 [02:42<00:19, 210.54 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42191/47780 [02:42<00:18, 298.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41012/47780 [02:42<00:23, 282.23 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39600/47780 [02:42<00:22, 365.28 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40962/47780 [02:42<00:20, 339.69 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42309/47780 [02:42<00:14, 381.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41909/47780 [02:42<00:18, 311.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45828/47780 [02:42<00:18, 106.68 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42222/47780 [02:42<00:18, 301.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43737/47780 [02:42<00:19, 204.73 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41044/47780 [02:42<00:23, 290.31 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39638/47780 [02:42<00:22, 360.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40999/47780 [02:43<00:19, 345.87 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42354/47780 [02:43<00:13, 400.50 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41942/47780 [02:43<00:18, 316.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45840/47780 [02:42<00:17, 109.27 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41076/47780 [02:43<00:22, 298.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43762/47780 [02:43<00:19, 207.53 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39675/47780 [02:43<00:23, 351.49 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42253/47780 [02:43<00:20, 267.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41035/47780 [02:43<00:20, 330.32 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42395/47780 [02:43<00:14, 379.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41974/47780 [02:43<00:19, 304.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45852/47780 [02:43<00:18, 103.70 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41106/47780 [02:43<00:22, 298.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43784/47780 [02:43<00:19, 209.34 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39711/47780 [02:43<00:22, 353.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42286/47780 [02:43<00:19, 281.07 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41077/47780 [02:43<00:19, 348.93 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42006/47780 [02:43<00:18, 306.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42435/47780 [02:43<00:14, 375.23 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41136/47780 [02:43<00:23, 285.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45863/47780 [02:43<00:20, 95.75 examples/s] 
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43806/47780 [02:43<00:19, 204.77 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39749/47780 [02:43<00:23, 341.66 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41113/47780 [02:43<00:18, 351.29 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42039/47780 [02:43<00:18, 307.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42474/47780 [02:43<00:14, 367.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42315/47780 [02:43<00:21, 249.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41170/47780 [02:43<00:22, 298.80 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45874/47780 [02:43<00:19, 98.39 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43829/47780 [02:43<00:19, 197.77 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41149/47780 [02:43<00:18, 353.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42511/47780 [02:43<00:14, 367.35 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39784/47780 [02:43<00:25, 308.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42070/47780 [02:43<00:20, 279.02 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42341/47780 [02:43<00:22, 236.55 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41202/47780 [02:43<00:21, 304.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45885/47780 [02:43<00:18, 100.41 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43855/47780 [02:43<00:18, 213.14 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41185/47780 [02:43<00:19, 344.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42548/47780 [02:43<00:14, 365.25 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39822/47780 [02:43<00:24, 324.87 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42110/47780 [02:43<00:18, 305.89 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42374/47780 [02:43<00:20, 257.76 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41233/47780 [02:43<00:22, 297.40 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43878/47780 [02:43<00:18, 215.45 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41220/47780 [02:43<00:19, 340.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45899/47780 [02:43<00:18, 100.03 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42586/47780 [02:43<00:15, 341.63 examples/s]
Tokenizing train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39864/47780 [02:43<00:22, 346.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42142/47780 [02:43<00:19, 290.83 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42401/47780 [02:43<00:21, 250.41 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41263/47780 [02:43<00:22, 295.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41258/47780 [02:43<00:18, 351.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43900/47780 [02:43<00:18, 208.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42629/47780 [02:43<00:14, 365.26 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45913/47780 [02:43<00:18, 101.79 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39904/47780 [02:43<00:22, 357.20 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42172/47780 [02:43<00:19, 290.25 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41293/47780 [02:43<00:21, 296.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42428/47780 [02:43<00:22, 237.61 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41294/47780 [02:43<00:18, 351.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43921/47780 [02:43<00:18, 205.13 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42666/47780 [02:43<00:14, 359.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45924/47780 [02:43<00:18, 101.37 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39941/47780 [02:43<00:22, 344.11 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42204/47780 [02:43<00:18, 295.05 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41328/47780 [02:43<00:21, 303.20 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41330/47780 [02:43<00:18, 353.61 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42453/47780 [02:43<00:23, 229.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43948/47780 [02:43<00:17, 216.46 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39976/47780 [02:43<00:22, 343.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42704/47780 [02:44<00:14, 341.92 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42235/47780 [02:44<00:18, 295.37 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41360/47780 [02:44<00:21, 301.33 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45936/47780 [02:43<00:19, 93.37 examples/s] 
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41370/47780 [02:44<00:17, 357.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42482/47780 [02:44<00:21, 243.88 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43970/47780 [02:44<00:19, 198.65 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40017/47780 [02:44<00:21, 362.47 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42745/47780 [02:44<00:13, 360.59 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42268/47780 [02:44<00:18, 300.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41392/47780 [02:44<00:21, 298.65 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42516/47780 [02:44<00:19, 268.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41407/47780 [02:44<00:18, 353.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45947/47780 [02:44<00:20, 88.69 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40054/47780 [02:44<00:21, 360.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42784/47780 [02:44<00:13, 364.93 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42299/47780 [02:44<00:19, 280.25 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43991/47780 [02:44<00:21, 173.99 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41423/47780 [02:44<00:22, 283.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42549/47780 [02:44<00:18, 282.14 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41443/47780 [02:44<00:19, 333.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45956/47780 [02:44<00:21, 83.18 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40091/47780 [02:44<00:21, 355.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42832/47780 [02:44<00:12, 393.24 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42331/47780 [02:44<00:18, 287.26 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41462/47780 [02:44<00:20, 305.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42578/47780 [02:44<00:19, 271.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44010/47780 [02:44<00:22, 166.05 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41481/47780 [02:44<00:18, 345.20 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40128/47780 [02:44<00:21, 358.35 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42876/47780 [02:44<00:12, 402.08 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45966/47780 [02:44<00:22, 80.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42364/47780 [02:44<00:18, 298.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41495/47780 [02:44<00:20, 301.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44030/47780 [02:44<00:22, 170.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41516/47780 [02:44<00:18, 338.12 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42606/47780 [02:44<00:19, 260.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42918/47780 [02:44<00:12, 393.64 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40165/47780 [02:44<00:22, 342.71 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42397/47780 [02:44<00:17, 303.73 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45975/47780 [02:44<00:24, 74.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41527/47780 [02:44<00:20, 301.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44050/47780 [02:44<00:21, 176.49 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41550/47780 [02:44<00:19, 324.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42633/47780 [02:44<00:20, 248.26 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40212/47780 [02:44<00:20, 374.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42958/47780 [02:44<00:12, 377.35 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42428/47780 [02:44<00:17, 301.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41565/47780 [02:44<00:19, 319.10 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45985/47780 [02:44<00:22, 78.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44070/47780 [02:44<00:20, 182.32 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41590/47780 [02:44<00:18, 341.59 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42663/47780 [02:44<00:20, 255.08 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43000/47780 [02:44<00:12, 385.80 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40250/47780 [02:44<00:21, 351.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42460/47780 [02:44<00:17, 304.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44089/47780 [02:44<00:21, 174.84 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41625/47780 [02:44<00:18, 340.57 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41598/47780 [02:44<00:20, 297.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45998/47780 [02:44<00:21, 84.59 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42689/47780 [02:44<00:20, 253.14 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43039/47780 [02:44<00:12, 377.99 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40295/47780 [02:44<00:20, 374.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42491/47780 [02:44<00:18, 283.68 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41661/47780 [02:44<00:17, 346.09 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44110/47780 [02:44<00:19, 184.25 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41631/47780 [02:44<00:20, 304.20 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43079/47780 [02:45<00:12, 380.05 examples/s]
Tokenizing train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40344/47780 [02:44<00:18, 402.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42715/47780 [02:44<00:22, 230.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42522/47780 [02:44<00:18, 284.31 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41699/47780 [02:45<00:17, 351.59 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46008/47780 [02:44<00:24, 71.24 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44130/47780 [02:45<00:19, 184.48 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41662/47780 [02:45<00:20, 299.16 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43124/47780 [02:45<00:11, 395.90 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42746/47780 [02:45<00:20, 248.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40385/47780 [02:45<00:19, 386.92 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42551/47780 [02:45<00:18, 276.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44151/47780 [02:45<00:18, 191.17 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41695/47780 [02:45<00:20, 304.07 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41735/47780 [02:45<00:17, 339.91 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46017/47780 [02:45<00:24, 72.10 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43172/47780 [02:45<00:10, 420.05 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40426/47780 [02:45<00:18, 389.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42774/47780 [02:45<00:20, 246.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42579/47780 [02:45<00:19, 271.33 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44172/47780 [02:45<00:18, 193.35 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41772/47780 [02:45<00:17, 346.87 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41728/47780 [02:45<00:20, 291.38 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46025/47780 [02:45<00:25, 69.72 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43215/47780 [02:45<00:11, 405.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42807/47780 [02:45<00:18, 269.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40475/47780 [02:45<00:17, 408.73 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42622/47780 [02:45<00:16, 305.56 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44192/47780 [02:45<00:18, 192.40 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41807/47780 [02:45<00:17, 332.77 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41763/47780 [02:45<00:19, 306.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42840/47780 [02:45<00:17, 284.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43256/47780 [02:45<00:12, 367.93 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40517/47780 [02:45<00:19, 379.69 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46033/47780 [02:45<00:27, 62.91 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42666/47780 [02:45<00:15, 339.26 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44216/47780 [02:45<00:17, 203.95 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41846/47780 [02:45<00:17, 347.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41794/47780 [02:45<00:20, 297.20 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42871/47780 [02:45<00:17, 286.55 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43294/47780 [02:45<00:12, 362.69 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40557/47780 [02:45<00:19, 379.05 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42701/47780 [02:45<00:14, 341.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44237/47780 [02:45<00:17, 202.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41884/47780 [02:45<00:16, 352.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46040/47780 [02:45<00:29, 59.36 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41824/47780 [02:45<00:20, 286.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42907/47780 [02:45<00:16, 304.11 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40600/47780 [02:45<00:18, 392.22 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43334/47780 [02:45<00:12, 365.34 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42736/47780 [02:45<00:14, 340.25 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41932/47780 [02:45<00:15, 388.28 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44258/47780 [02:45<00:18, 185.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41853/47780 [02:45<00:20, 286.76 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46047/47780 [02:45<00:29, 58.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42938/47780 [02:45<00:16, 286.00 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40648/47780 [02:45<00:17, 414.59 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43381/47780 [02:45<00:11, 386.23 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42771/47780 [02:45<00:14, 334.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41972/47780 [02:45<00:15, 365.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41886/47780 [02:45<00:20, 294.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44281/47780 [02:45<00:18, 187.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46056/47780 [02:45<00:27, 63.06 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43420/47780 [02:45<00:11, 382.51 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40690/47780 [02:45<00:17, 400.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42979/47780 [02:45<00:15, 306.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42806/47780 [02:45<00:16, 310.84 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42009/47780 [02:45<00:15, 361.45 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41924/47780 [02:45<00:18, 310.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44300/47780 [02:45<00:18, 187.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46063/47780 [02:45<00:28, 60.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43014/47780 [02:45<00:14, 318.34 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40731/47780 [02:45<00:18, 390.50 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43460/47780 [02:46<00:11, 366.72 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42047/47780 [02:46<00:15, 362.76 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42838/47780 [02:45<00:16, 300.83 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44320/47780 [02:45<00:18, 191.17 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41972/47780 [02:46<00:16, 355.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46072/47780 [02:45<00:25, 66.21 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43047/47780 [02:46<00:15, 313.89 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43518/47780 [02:46<00:10, 424.64 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40771/47780 [02:46<00:19, 353.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42880/47780 [02:46<00:14, 328.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42085/47780 [02:46<00:15, 358.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44344/47780 [02:46<00:17, 201.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42008/47780 [02:46<00:16, 347.96 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43082/47780 [02:46<00:14, 316.85 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43563/47780 [02:46<00:09, 428.94 examples/s]
Tokenizing train dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40826/47780 [02:46<00:17, 402.58 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42923/47780 [02:46<00:13, 352.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46079/47780 [02:46<00:29, 58.22 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42047/47780 [02:46<00:16, 357.00 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44367/47780 [02:46<00:17, 195.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42123/47780 [02:46<00:17, 319.89 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43114/47780 [02:46<00:15, 307.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43607/47780 [02:46<00:10, 391.08 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40877/47780 [02:46<00:16, 425.79 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42960/47780 [02:46<00:13, 355.15 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46088/47780 [02:46<00:26, 63.42 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42085/47780 [02:46<00:16, 346.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44388/47780 [02:46<00:17, 198.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42156/47780 [02:46<00:18, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43145/47780 [02:46<00:16, 289.54 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42998/47780 [02:46<00:13, 358.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43648/47780 [02:46<00:11, 368.55 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40921/47780 [02:46<00:17, 390.61 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44412/47780 [02:46<00:16, 207.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42126/47780 [02:46<00:16, 352.89 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42189/47780 [02:46<00:18, 298.77 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43175/47780 [02:46<00:16, 273.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46096/47780 [02:46<00:30, 54.76 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40965/47780 [02:46<00:16, 403.54 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44444/47780 [02:46<00:14, 236.38 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42168/47780 [02:46<00:15, 368.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43035/47780 [02:46<00:14, 326.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43686/47780 [02:46<00:11, 353.77 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42223/47780 [02:46<00:18, 301.00 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41015/47780 [02:46<00:15, 425.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43203/47780 [02:46<00:17, 257.47 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44469/47780 [02:46<00:14, 232.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43725/47780 [02:46<00:11, 357.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42205/47780 [02:46<00:15, 355.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46102/47780 [02:46<00:33, 49.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43069/47780 [02:46<00:15, 307.76 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42255/47780 [02:46<00:18, 302.78 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41069/47780 [02:46<00:14, 456.86 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43234/47780 [02:46<00:16, 268.89 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43776/47780 [02:46<00:10, 393.04 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42244/47780 [02:46<00:15, 363.12 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44493/47780 [02:46<00:14, 224.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43103/47780 [02:46<00:15, 311.43 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42293/47780 [02:46<00:16, 323.37 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46109/47780 [02:46<00:33, 49.89 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41116/47780 [02:46<00:14, 446.00 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43816/47780 [02:46<00:10, 388.63 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42281/47780 [02:46<00:15, 351.61 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43262/47780 [02:46<00:17, 252.51 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43149/47780 [02:46<00:13, 345.04 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42335/47780 [02:46<00:15, 346.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44521/47780 [02:46<00:15, 213.35 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46119/47780 [02:46<00:29, 56.60 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41162/47780 [02:46<00:14, 444.69 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43857/47780 [02:47<00:09, 393.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42317/47780 [02:46<00:15, 349.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43184/47780 [02:46<00:13, 340.57 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42378/47780 [02:47<00:14, 369.51 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43288/47780 [02:46<00:19, 226.86 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44547/47780 [02:47<00:14, 216.77 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41207/47780 [02:47<00:14, 444.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46129/47780 [02:46<00:25, 64.77 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43897/47780 [02:47<00:10, 388.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42357/47780 [02:47<00:15, 352.39 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42421/47780 [02:47<00:13, 385.28 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43219/47780 [02:47<00:14, 321.42 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43317/47780 [02:47<00:18, 242.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44569/47780 [02:47<00:14, 215.15 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41258/47780 [02:47<00:14, 460.49 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43943/47780 [02:47<00:09, 398.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42395/47780 [02:47<00:15, 352.29 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42460/47780 [02:47<00:14, 375.54 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43347/47780 [02:47<00:17, 256.06 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46145/47780 [02:47<00:21, 75.40 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43254/47780 [02:47<00:14, 317.54 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44596/47780 [02:47<00:13, 227.96 examples/s]
Tokenizing train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41312/47780 [02:47<00:13, 478.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43989/47780 [02:47<00:09, 398.84 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42435/47780 [02:47<00:15, 341.86 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42499/47780 [02:47<00:14, 375.99 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43381/47780 [02:47<00:16, 271.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44623/47780 [02:47<00:13, 236.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43287/47780 [02:47<00:15, 299.30 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41362/47780 [02:47<00:14, 455.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44030/47780 [02:47<00:09, 398.30 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46153/47780 [02:47<00:26, 62.41 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42470/47780 [02:47<00:15, 338.77 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43412/47780 [02:47<00:15, 277.28 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42537/47780 [02:47<00:14, 356.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43325/47780 [02:47<00:14, 317.36 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44647/47780 [02:47<00:14, 220.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41408/47780 [02:47<00:14, 448.37 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44071/47780 [02:47<00:09, 386.01 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42513/47780 [02:47<00:14, 359.87 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43446/47780 [02:47<00:14, 294.68 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43367/47780 [02:47<00:12, 344.98 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42573/47780 [02:47<00:16, 318.03 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44670/47780 [02:47<00:14, 208.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41454/47780 [02:47<00:14, 433.46 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44113/47780 [02:47<00:09, 392.45 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42550/47780 [02:47<00:15, 345.94 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43409/47780 [02:47<00:12, 354.57 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43476/47780 [02:47<00:16, 266.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46161/47780 [02:47<00:32, 49.68 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44695/47780 [02:47<00:14, 213.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42607/47780 [02:47<00:16, 307.67 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41498/47780 [02:47<00:15, 415.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44153/47780 [02:47<00:09, 377.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42590/47780 [02:47<00:14, 360.88 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43445/47780 [02:47<00:12, 349.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43504/47780 [02:47<00:16, 253.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46167/47780 [02:47<00:32, 49.30 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42642/47780 [02:47<00:16, 305.89 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44717/47780 [02:47<00:15, 202.33 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44191/47780 [02:47<00:09, 362.38 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41541/47780 [02:47<00:16, 385.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42627/47780 [02:47<00:14, 348.59 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43481/47780 [02:47<00:12, 340.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43530/47780 [02:47<00:17, 245.81 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46177/47780 [02:47<00:27, 57.48 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42677/47780 [02:47<00:16, 314.42 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44741/47780 [02:47<00:14, 209.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44228/47780 [02:48<00:10, 348.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41581/47780 [02:47<00:16, 379.50 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42664/47780 [02:48<00:15, 330.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43518/47780 [02:47<00:12, 343.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42712/47780 [02:48<00:15, 324.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43555/47780 [02:48<00:18, 234.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46185/47780 [02:47<00:26, 60.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44763/47780 [02:48<00:14, 206.23 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41621/47780 [02:48<00:16, 384.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44269/47780 [02:48<00:09, 362.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42698/47780 [02:48<00:15, 327.43 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43553/47780 [02:48<00:13, 322.36 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42755/47780 [02:48<00:14, 349.52 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44787/47780 [02:48<00:14, 211.17 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43579/47780 [02:48<00:18, 226.97 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41665/47780 [02:48<00:15, 398.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44308/47780 [02:48<00:09, 369.40 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43588/47780 [02:48<00:12, 328.85 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42734/47780 [02:48<00:16, 311.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46192/47780 [02:48<00:30, 52.49 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42792/47780 [02:48<00:14, 355.13 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43609/47780 [02:48<00:17, 236.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44361/47780 [02:48<00:08, 414.86 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41716/47780 [02:48<00:14, 411.64 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44809/47780 [02:48<00:15, 193.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43624/47780 [02:48<00:12, 333.10 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42766/47780 [02:48<00:16, 304.15 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42828/47780 [02:48<00:15, 329.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43642/47780 [02:48<00:15, 259.24 examples/s]
Tokenizing train dataset (num_proc=32):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 41764/47780 [02:48<00:13, 430.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44403/47780 [02:48<00:08, 396.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44833/47780 [02:48<00:14, 205.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46199/47780 [02:48<00:32, 49.26 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42799/47780 [02:48<00:16, 310.95 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43662/47780 [02:48<00:12, 337.57 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42863/47780 [02:48<00:15, 325.21 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43672/47780 [02:48<00:15, 270.18 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44448/47780 [02:48<00:08, 404.93 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44857/47780 [02:48<00:13, 210.73 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41808/47780 [02:48<00:14, 409.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46207/47780 [02:48<00:30, 51.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43696/47780 [02:48<00:12, 335.63 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42831/47780 [02:48<00:17, 288.22 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42901/47780 [02:48<00:14, 339.93 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43702/47780 [02:48<00:14, 275.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44490/47780 [02:48<00:08, 408.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41850/47780 [02:48<00:14, 400.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43730/47780 [02:48<00:12, 330.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46214/47780 [02:48<00:29, 53.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44879/47780 [02:48<00:15, 182.64 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42861/47780 [02:48<00:17, 282.19 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42938/47780 [02:48<00:14, 339.42 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43731/47780 [02:48<00:14, 272.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44538/47780 [02:48<00:07, 422.32 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41891/47780 [02:48<00:16, 354.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43764/47780 [02:48<00:12, 310.03 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42890/47780 [02:48<00:17, 281.33 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42986/47780 [02:48<00:12, 372.50 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44899/47780 [02:48<00:16, 172.34 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43759/47780 [02:48<00:15, 262.11 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44581/47780 [02:48<00:07, 411.11 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46221/47780 [02:48<00:32, 47.83 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41947/47780 [02:48<00:14, 405.90 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43797/47780 [02:48<00:12, 314.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42926/47780 [02:48<00:16, 302.84 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43025/47780 [02:48<00:13, 364.95 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44917/47780 [02:48<00:16, 168.43 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44624/47780 [02:48<00:07, 413.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43786/47780 [02:48<00:15, 255.47 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46227/47780 [02:48<00:32, 48.10 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41990/47780 [02:48<00:14, 410.88 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42957/47780 [02:49<00:16, 293.47 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43829/47780 [02:49<00:13, 291.70 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44940/47780 [02:49<00:15, 181.71 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43062/47780 [02:49<00:13, 338.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44666/47780 [02:49<00:07, 390.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43812/47780 [02:49<00:16, 241.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46232/47780 [02:48<00:32, 47.97 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42033/47780 [02:49<00:14, 401.16 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43864/47780 [02:49<00:12, 306.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44962/47780 [02:49<00:14, 190.81 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42987/47780 [02:49<00:17, 267.38 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43097/47780 [02:49<00:14, 332.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43839/47780 [02:49<00:16, 242.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44707/47780 [02:49<00:08, 365.30 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42074/47780 [02:49<00:14, 391.62 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46238/47780 [02:49<00:32, 46.98 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43897/47780 [02:49<00:12, 310.78 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44982/47780 [02:49<00:14, 193.12 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43020/47780 [02:49<00:16, 283.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43137/47780 [02:49<00:13, 346.36 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43865/47780 [02:49<00:16, 235.73 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44744/47780 [02:49<00:08, 361.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45012/47780 [02:49<00:12, 220.41 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46243/47780 [02:49<00:34, 44.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43938/47780 [02:49<00:11, 321.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42114/47780 [02:49<00:16, 339.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43049/47780 [02:49<00:17, 267.64 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43174/47780 [02:49<00:13, 335.64 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43889/47780 [02:49<00:16, 230.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44786/47780 [02:49<00:08, 351.66 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45035/47780 [02:49<00:12, 221.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43979/47780 [02:49<00:11, 344.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46248/47780 [02:49<00:34, 43.94 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42150/47780 [02:49<00:16, 332.59 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43088/47780 [02:49<00:15, 294.42 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43208/47780 [02:49<00:13, 331.61 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43916/47780 [02:49<00:16, 233.60 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45062/47780 [02:49<00:11, 228.71 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44822/47780 [02:49<00:09, 320.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46254/47780 [02:49<00:31, 47.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44014/47780 [02:49<00:11, 317.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42186/47780 [02:49<00:16, 334.89 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43118/47780 [02:49<00:16, 289.13 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43953/47780 [02:49<00:14, 266.80 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43242/47780 [02:49<00:15, 297.43 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44856/47780 [02:49<00:09, 318.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46261/47780 [02:49<00:29, 51.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44047/47780 [02:49<00:11, 311.75 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45087/47780 [02:49<00:12, 207.67 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43149/47780 [02:49<00:15, 294.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42224/47780 [02:49<00:16, 337.53 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43986/47780 [02:49<00:13, 279.45 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43273/47780 [02:49<00:14, 300.60 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44896/47780 [02:49<00:08, 339.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46271/47780 [02:49<00:23, 63.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44079/47780 [02:49<00:12, 307.39 examples/s]
Tokenizing train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42260/47780 [02:49<00:16, 336.41 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45109/47780 [02:49<00:13, 197.73 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43180/47780 [02:49<00:16, 279.86 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44015/47780 [02:49<00:13, 273.41 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43304/47780 [02:49<00:16, 276.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44112/47780 [02:49<00:11, 312.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44932/47780 [02:49<00:09, 314.00 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42294/47780 [02:49<00:16, 330.71 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46286/47780 [02:49<00:18, 79.01 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45130/47780 [02:49<00:13, 194.90 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43220/47780 [02:49<00:15, 303.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44043/47780 [02:49<00:14, 263.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43339/47780 [02:50<00:15, 293.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44965/47780 [02:50<00:09, 311.25 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44144/47780 [02:49<00:12, 300.21 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42328/47780 [02:50<00:16, 324.40 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46294/47780 [02:49<00:19, 75.05 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45150/47780 [02:50<00:13, 188.23 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43267/47780 [02:50<00:13, 334.19 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44070/47780 [02:50<00:14, 263.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43369/47780 [02:50<00:15, 290.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44997/47780 [02:50<00:09, 309.19 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42367/47780 [02:50<00:15, 339.99 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44175/47780 [02:50<00:12, 288.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43305/47780 [02:50<00:12, 344.47 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45172/47780 [02:50<00:13, 194.56 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44103/47780 [02:50<00:13, 280.94 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46303/47780 [02:50<00:21, 68.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43400/47780 [02:50<00:16, 272.58 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45029/47780 [02:50<00:09, 299.62 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42402/47780 [02:50<00:15, 337.56 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44209/47780 [02:50<00:11, 301.96 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45199/47780 [02:50<00:12, 214.34 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43340/47780 [02:50<00:13, 331.82 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44132/47780 [02:50<00:13, 268.60 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43430/47780 [02:50<00:15, 277.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46313/47780 [02:50<00:20, 72.85 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44252/47780 [02:50<00:10, 337.70 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42440/47780 [02:50<00:15, 346.36 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45060/47780 [02:50<00:09, 284.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45226/47780 [02:50<00:11, 225.87 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43374/47780 [02:50<00:13, 330.52 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44161/47780 [02:50<00:13, 271.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43463/47780 [02:50<00:14, 289.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44292/47780 [02:50<00:09, 353.95 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42487/47780 [02:50<00:13, 378.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46324/47780 [02:50<00:19, 75.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45089/47780 [02:50<00:09, 278.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45253/47780 [02:50<00:10, 232.12 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44189/47780 [02:50<00:13, 272.27 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43408/47780 [02:50<00:13, 313.96 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44331/47780 [02:50<00:09, 364.03 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42525/47780 [02:50<00:14, 374.11 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43493/47780 [02:50<00:16, 260.13 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45279/47780 [02:50<00:10, 239.96 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45119/47780 [02:50<00:09, 277.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46332/47780 [02:50<00:20, 70.48 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44217/47780 [02:50<00:13, 266.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43443/47780 [02:50<00:13, 316.97 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42569/47780 [02:50<00:13, 384.08 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43520/47780 [02:50<00:16, 261.70 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45152/47780 [02:50<00:09, 288.55 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44369/47780 [02:50<00:10, 328.48 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45304/47780 [02:50<00:10, 233.17 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46343/47780 [02:50<00:17, 80.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44248/47780 [02:50<00:12, 274.97 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43475/47780 [02:50<00:15, 285.88 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43547/47780 [02:50<00:16, 259.64 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42609/47780 [02:50<00:14, 361.77 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45328/47780 [02:50<00:10, 232.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45184/47780 [02:50<00:09, 285.64 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44404/47780 [02:50<00:10, 323.30 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44276/47780 [02:50<00:13, 266.50 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46352/47780 [02:50<00:18, 78.56 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43505/47780 [02:50<00:16, 266.75 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43574/47780 [02:50<00:17, 245.77 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45215/47780 [02:50<00:08, 291.20 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42648/47780 [02:50<00:14, 356.04 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44443/47780 [02:50<00:09, 338.19 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45354/47780 [02:50<00:10, 234.74 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44304/47780 [02:50<00:13, 258.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46365/47780 [02:50<00:16, 86.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43534/47780 [02:50<00:16, 261.69 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45247/47780 [02:51<00:08, 295.32 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44478/47780 [02:50<00:09, 340.14 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42684/47780 [02:50<00:14, 349.05 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43608/47780 [02:51<00:16, 260.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45379/47780 [02:51<00:11, 212.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46381/47780 [02:50<00:14, 98.06 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44331/47780 [02:51<00:15, 221.39 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43571/47780 [02:51<00:14, 283.37 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44514/47780 [02:51<00:09, 340.53 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42721/47780 [02:51<00:14, 351.63 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45279/47780 [02:51<00:08, 295.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43647/47780 [02:51<00:14, 287.90 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45408/47780 [02:51<00:10, 219.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46391/47780 [02:51<00:14, 98.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43602/47780 [02:51<00:14, 286.09 examples/s]
Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42758/47780 [02:51<00:14, 352.99 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44558/47780 [02:51<00:08, 363.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45316/47780 [02:51<00:07, 309.59 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44359/47780 [02:51<00:15, 220.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43677/47780 [02:51<00:15, 273.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45431/47780 [02:51<00:11, 200.56 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42799/47780 [02:51<00:13, 365.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46401/47780 [02:51<00:15, 87.37 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43631/47780 [02:51<00:14, 280.65 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44595/47780 [02:51<00:08, 358.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45351/47780 [02:51<00:07, 319.27 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44385/47780 [02:51<00:14, 228.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43711/47780 [02:51<00:14, 286.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45455/47780 [02:51<00:11, 209.88 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42836/47780 [02:51<00:13, 366.44 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43662/47780 [02:51<00:14, 286.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45383/47780 [02:51<00:07, 312.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44632/47780 [02:51<00:09, 344.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44421/47780 [02:51<00:13, 248.29 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43740/47780 [02:51<00:14, 274.09 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45480/47780 [02:51<00:10, 220.07 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42875/47780 [02:51<00:13, 367.17 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43694/47780 [02:51<00:14, 282.39 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44668/47780 [02:51<00:09, 341.74 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46410/47780 [02:51<00:20, 66.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44447/47780 [02:51<00:13, 246.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45415/47780 [02:51<00:08, 284.31 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43768/47780 [02:51<00:15, 259.09 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45504/47780 [02:51<00:10, 219.70 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42914/47780 [02:51<00:13, 373.11 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43724/47780 [02:51<00:14, 285.99 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44703/47780 [02:51<00:08, 342.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44473/47780 [02:51<00:13, 248.48 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45444/47780 [02:51<00:08, 284.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46418/47780 [02:51<00:21, 62.95 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43813/47780 [02:51<00:12, 306.62 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42955/47780 [02:51<00:12, 379.03 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45528/47780 [02:51<00:10, 220.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43753/47780 [02:51<00:14, 275.90 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44501/47780 [02:51<00:13, 251.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44739/47780 [02:51<00:09, 329.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45478/47780 [02:51<00:07, 299.56 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43845/47780 [02:51<00:12, 303.45 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46426/47780 [02:51<00:21, 62.54 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45551/47780 [02:51<00:10, 220.73 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43783/47780 [02:51<00:14, 281.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42993/47780 [02:51<00:13, 348.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44528/47780 [02:51<00:13, 241.93 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44773/47780 [02:51<00:09, 310.05 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45510/47780 [02:51<00:08, 278.91 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43876/47780 [02:51<00:12, 301.61 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45587/47780 [02:51<00:08, 248.66 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43818/47780 [02:51<00:13, 298.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43039/47780 [02:51<00:12, 374.73 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44809/47780 [02:51<00:09, 322.11 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44553/47780 [02:51<00:13, 232.60 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43907/47780 [02:52<00:12, 300.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45539/47780 [02:52<00:08, 266.95 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45621/47780 [02:52<00:07, 270.55 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46433/47780 [02:51<00:27, 49.38 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43854/47780 [02:52<00:12, 311.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43080/47780 [02:52<00:12, 380.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44853/47780 [02:52<00:08, 354.87 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44580/47780 [02:52<00:13, 241.25 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43943/47780 [02:52<00:12, 314.23 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43886/47780 [02:52<00:12, 308.42 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45567/47780 [02:52<00:09, 237.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45649/47780 [02:52<00:08, 256.25 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43119/47780 [02:52<00:13, 349.95 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44889/47780 [02:52<00:08, 347.57 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44607/47780 [02:52<00:12, 247.88 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43981/47780 [02:52<00:11, 332.86 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46439/47780 [02:52<00:30, 43.35 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43918/47780 [02:52<00:12, 309.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45592/47780 [02:52<00:09, 238.08 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45675/47780 [02:52<00:08, 245.84 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44926/47780 [02:52<00:08, 352.74 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43158/47780 [02:52<00:12, 356.23 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44632/47780 [02:52<00:12, 248.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44015/47780 [02:52<00:11, 328.53 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43951/47780 [02:52<00:12, 295.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44962/47780 [02:52<00:08, 343.79 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44657/47780 [02:52<00:12, 244.22 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45617/47780 [02:52<00:10, 215.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46444/47780 [02:52<00:34, 39.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45700/47780 [02:52<00:09, 225.39 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43195/47780 [02:52<00:14, 324.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44049/47780 [02:52<00:11, 311.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43985/47780 [02:52<00:12, 304.53 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44998/47780 [02:52<00:08, 339.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44682/47780 [02:52<00:12, 239.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45641/47780 [02:52<00:09, 215.26 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45732/47780 [02:52<00:08, 243.47 examples/s]
Tokenizing train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43232/47780 [02:52<00:13, 334.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44081/47780 [02:52<00:12, 290.53 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44016/47780 [02:52<00:12, 290.47 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44707/47780 [02:52<00:13, 235.30 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45034/47780 [02:52<00:08, 332.80 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45669/47780 [02:52<00:09, 229.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46449/47780 [02:52<00:40, 33.11 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43267/47780 [02:52<00:13, 324.78 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45757/47780 [02:52<00:08, 225.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44111/47780 [02:52<00:12, 291.70 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44055/47780 [02:52<00:11, 311.93 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45700/47780 [02:52<00:08, 250.12 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44731/47780 [02:52<00:13, 232.02 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43301/47780 [02:52<00:13, 326.40 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45068/47780 [02:52<00:09, 298.53 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44142/47780 [02:52<00:12, 293.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45780/47780 [02:52<00:09, 220.81 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44088/47780 [02:52<00:11, 316.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46453/47780 [02:52<00:44, 29.67 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44755/47780 [02:52<00:13, 231.74 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45731/47780 [02:52<00:07, 256.19 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43347/47780 [02:52<00:12, 361.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45804/47780 [02:52<00:08, 225.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45099/47780 [02:52<00:08, 298.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44172/47780 [02:52<00:12, 281.52 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44120/47780 [02:52<00:12, 302.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44779/47780 [02:52<00:12, 231.32 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45758/47780 [02:52<00:07, 252.78 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43384/47780 [02:52<00:12, 360.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45132/47780 [02:52<00:08, 303.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45833/47780 [02:52<00:08, 230.77 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44202/47780 [02:53<00:13, 274.86 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44806/47780 [02:53<00:12, 242.44 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44151/47780 [02:53<00:12, 292.98 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43433/47780 [02:53<00:10, 396.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46458/47780 [02:52<00:49, 26.59 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45164/47780 [02:53<00:08, 306.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45784/47780 [02:53<00:08, 233.34 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45870/47780 [02:53<00:07, 260.38 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44230/47780 [02:53<00:13, 263.52 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44837/47780 [02:53<00:11, 261.68 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44181/47780 [02:53<00:12, 277.04 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43475/47780 [02:53<00:11, 387.05 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46464/47780 [02:53<00:41, 31.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45195/47780 [02:53<00:08, 300.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45811/47780 [02:53<00:08, 238.62 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45898/47780 [02:53<00:07, 264.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44266/47780 [02:53<00:12, 287.75 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44864/47780 [02:53<00:11, 259.71 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44209/47780 [02:53<00:13, 272.35 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43521/47780 [02:53<00:10, 399.12 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46471/47780 [02:53<00:33, 38.54 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45226/47780 [02:53<00:08, 302.66 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45836/47780 [02:53<00:08, 234.42 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45925/47780 [02:53<00:07, 251.84 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44301/47780 [02:53<00:11, 302.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44891/47780 [02:53<00:11, 241.50 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44237/47780 [02:53<00:13, 267.32 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43562/47780 [02:53<00:10, 389.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45257/47780 [02:53<00:08, 296.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46478/47780 [02:53<00:29, 43.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45861/47780 [02:53<00:08, 237.41 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44332/47780 [02:53<00:11, 301.37 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45954/47780 [02:53<00:07, 249.80 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44925/47780 [02:53<00:10, 268.67 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44264/47780 [02:53<00:13, 262.12 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45288/47780 [02:53<00:08, 299.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43602/47780 [02:53<00:10, 383.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45897/47780 [02:53<00:06, 271.09 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44364/47780 [02:53<00:11, 296.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46483/47780 [02:53<00:32, 40.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44959/47780 [02:53<00:10, 281.61 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45982/47780 [02:53<00:07, 230.83 examples/s]
Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43642/47780 [02:53<00:10, 381.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45930/47780 [02:53<00:06, 286.80 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44291/47780 [02:53<00:14, 249.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45319/47780 [02:53<00:08, 285.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44394/47780 [02:53<00:12, 276.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44988/47780 [02:53<00:10, 270.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46006/47780 [02:53<00:07, 222.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43688/47780 [02:53<00:10, 403.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44317/47780 [02:53<00:13, 251.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45348/47780 [02:53<00:08, 285.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46488/47780 [02:53<00:35, 36.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45959/47780 [02:53<00:07, 256.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44435/47780 [02:53<00:10, 308.66 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46030/47780 [02:53<00:07, 225.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43735/47780 [02:53<00:09, 421.15 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44356/47780 [02:53<00:11, 285.76 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45016/47780 [02:53<00:11, 249.76 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45377/47780 [02:53<00:09, 265.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46492/47780 [02:53<00:38, 33.84 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44473/47780 [02:53<00:10, 327.36 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45987/47780 [02:53<00:07, 231.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43779/47780 [02:53<00:09, 421.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44395/47780 [02:53<00:10, 314.69 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46054/47780 [02:53<00:07, 215.95 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45409/47780 [02:53<00:08, 275.65 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45042/47780 [02:53<00:11, 235.00 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44517/47780 [02:54<00:09, 351.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46496/47780 [02:53<00:37, 33.86 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46012/47780 [02:54<00:07, 232.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43829/47780 [02:53<00:08, 442.92 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46078/47780 [02:54<00:07, 217.63 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44427/47780 [02:54<00:11, 298.46 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45452/47780 [02:54<00:07, 315.05 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45066/47780 [02:54<00:12, 224.11 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44561/47780 [02:54<00:08, 373.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46045/47780 [02:54<00:06, 256.63 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43874/47780 [02:54<00:09, 422.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46501/47780 [02:54<00:37, 33.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44465/47780 [02:54<00:10, 311.81 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45488/47780 [02:54<00:06, 327.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46104/47780 [02:54<00:07, 216.72 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45092/47780 [02:54<00:11, 229.43 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44599/47780 [02:54<00:08, 364.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46072/47780 [02:54<00:06, 249.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43923/47780 [02:54<00:08, 439.90 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46133/47780 [02:54<00:07, 231.95 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44497/47780 [02:54<00:10, 299.30 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45523/47780 [02:54<00:07, 316.94 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45121/47780 [02:54<00:10, 245.29 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44638/47780 [02:54<00:08, 370.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46506/47780 [02:54<00:38, 33.09 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46098/47780 [02:54<00:07, 234.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46157/47780 [02:54<00:07, 230.62 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43968/47780 [02:54<00:09, 391.24 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45557/47780 [02:54<00:06, 319.73 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45151/47780 [02:54<00:10, 260.27 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44676/47780 [02:54<00:08, 372.83 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44529/47780 [02:54<00:11, 281.75 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46510/47780 [02:54<00:41, 30.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46122/47780 [02:54<00:07, 217.00 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45600/47780 [02:54<00:06, 340.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46181/47780 [02:54<00:07, 220.08 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44009/47780 [02:54<00:09, 380.57 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45178/47780 [02:54<00:10, 259.63 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44715/47780 [02:54<00:08, 374.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44563/47780 [02:54<00:11, 291.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46514/47780 [02:54<00:40, 31.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46146/47780 [02:54<00:07, 215.06 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45637/47780 [02:54<00:06, 339.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45207/47780 [02:54<00:09, 264.43 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44610/47780 [02:54<00:09, 335.15 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44050/47780 [02:54<00:10, 361.32 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44755/47780 [02:54<00:08, 357.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46205/47780 [02:54<00:07, 208.94 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45234/47780 [02:54<00:09, 256.82 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44647/47780 [02:54<00:09, 342.65 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45677/47780 [02:54<00:06, 341.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46172/47780 [02:54<00:07, 216.08 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44794/47780 [02:54<00:08, 366.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44087/47780 [02:54<00:10, 348.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46227/47780 [02:54<00:07, 196.21 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46519/47780 [02:54<00:42, 29.70 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45712/47780 [02:54<00:06, 342.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44691/47780 [02:54<00:08, 362.13 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44838/47780 [02:54<00:07, 383.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45262/47780 [02:54<00:09, 251.89 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46194/47780 [02:54<00:07, 200.32 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44124/47780 [02:54<00:10, 341.78 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46248/47780 [02:54<00:07, 193.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45747/47780 [02:54<00:05, 342.57 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44730/47780 [02:54<00:08, 369.84 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46523/47780 [02:54<00:44, 28.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45289/47780 [02:54<00:09, 249.90 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44877/47780 [02:54<00:08, 356.61 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46223/47780 [02:55<00:07, 220.27 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44159/47780 [02:54<00:11, 327.00 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46268/47780 [02:54<00:08, 188.19 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44774/47780 [02:55<00:07, 385.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45782/47780 [02:55<00:06, 326.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45315/47780 [02:55<00:10, 243.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46526/47780 [02:54<00:47, 26.45 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46247/47780 [02:55<00:06, 221.02 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44915/47780 [02:55<00:08, 350.05 examples/s]
Tokenizing train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44192/47780 [02:55<00:11, 319.33 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46291/47780 [02:55<00:07, 197.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45817/47780 [02:55<00:05, 332.55 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44814/47780 [02:55<00:07, 372.41 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46271/47780 [02:55<00:06, 225.40 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45340/47780 [02:55<00:10, 232.46 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44226/47780 [02:55<00:10, 323.51 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44951/47780 [02:55<00:08, 331.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46316/47780 [02:55<00:07, 206.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46529/47780 [02:55<00:50, 24.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45853/47780 [02:55<00:05, 337.13 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44852/47780 [02:55<00:08, 348.59 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46294/47780 [02:55<00:06, 221.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45375/47780 [02:55<00:09, 264.31 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44272/47780 [02:55<00:10, 345.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46339/47780 [02:55<00:06, 206.15 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44985/47780 [02:55<00:08, 315.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46532/47780 [02:55<00:52, 23.89 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45402/47780 [02:55<00:09, 260.58 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45887/47780 [02:55<00:06, 298.53 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46321/47780 [02:55<00:06, 223.21 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44892/47780 [02:55<00:08, 339.82 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44314/47780 [02:55<00:09, 362.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46360/47780 [02:55<00:07, 198.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45019/47780 [02:55<00:09, 306.45 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45434/47780 [02:55<00:08, 275.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46536/47780 [02:55<00:49, 25.21 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44931/47780 [02:55<00:08, 352.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46344/47780 [02:55<00:06, 220.94 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44357/47780 [02:55<00:09, 379.83 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45918/47780 [02:55<00:06, 284.26 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45050/47780 [02:55<00:08, 306.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46380/47780 [02:55<00:07, 179.75 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46545/47780 [02:55<00:31, 39.33 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45463/47780 [02:55<00:08, 268.49 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44401/47780 [02:55<00:08, 394.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46367/47780 [02:55<00:06, 216.77 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45948/47780 [02:55<00:06, 285.70 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44969/47780 [02:55<00:08, 338.35 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45081/47780 [02:55<00:08, 301.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46399/47780 [02:55<00:07, 176.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45491/47780 [02:55<00:08, 271.72 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44442/47780 [02:55<00:08, 395.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46559/47780 [02:55<00:19, 61.18 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46389/47780 [02:55<00:06, 212.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45978/47780 [02:55<00:06, 286.42 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45006/47780 [02:55<00:08, 336.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45112/47780 [02:55<00:09, 290.52 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46568/47780 [02:55<00:18, 67.09 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46414/47780 [02:55<00:06, 221.44 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44486/47780 [02:55<00:08, 390.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46418/47780 [02:55<00:08, 157.36 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45040/47780 [02:55<00:08, 336.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45519/47780 [02:55<00:09, 248.45 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46009/47780 [02:55<00:06, 277.59 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45144/47780 [02:55<00:09, 292.58 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46438/47780 [02:55<00:08, 164.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46438/47780 [02:55<00:06, 216.45 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45077/47780 [02:55<00:07, 338.33 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44527/47780 [02:55<00:08, 378.64 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46044/47780 [02:55<00:05, 292.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45176/47780 [02:56<00:08, 300.14 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45545/47780 [02:55<00:10, 213.03 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45115/47780 [02:56<00:07, 347.70 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46462/47780 [02:56<00:06, 217.93 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46462/47780 [02:56<00:07, 178.31 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44581/47780 [02:56<00:07, 413.29 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46576/47780 [02:55<00:23, 52.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46075/47780 [02:56<00:06, 282.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45216/47780 [02:56<00:07, 326.92 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45571/47780 [02:56<00:09, 222.99 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45150/47780 [02:56<00:07, 344.88 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46485/47780 [02:56<00:06, 189.98 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46484/47780 [02:56<00:06, 210.85 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45251/47780 [02:56<00:07, 329.66 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44623/47780 [02:56<00:08, 391.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46104/47780 [02:56<00:06, 271.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46586/47780 [02:56<00:20, 57.70 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45595/47780 [02:56<00:10, 213.50 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45188/47780 [02:56<00:07, 352.54 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46506/47780 [02:56<00:06, 194.83 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45286/47780 [02:56<00:07, 329.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46506/47780 [02:56<00:06, 203.01 examples/s]
Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44663/47780 [02:56<00:08, 384.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46139/47780 [02:56<00:05, 287.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46593/47780 [02:56<00:21, 55.49 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45621/47780 [02:56<00:10, 214.74 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45224/47780 [02:56<00:07, 347.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46526/47780 [02:56<00:06, 189.60 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46529/47780 [02:56<00:05, 209.96 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45320/47780 [02:56<00:07, 328.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46168/47780 [02:56<00:05, 286.23 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44702/47780 [02:56<00:08, 365.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45643/47780 [02:56<00:09, 214.69 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46600/47780 [02:56<00:21, 55.35 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45259/47780 [02:56<00:07, 338.79 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45354/47780 [02:56<00:07, 326.72 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46547/47780 [02:56<00:06, 183.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46551/47780 [02:56<00:06, 204.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46197/47780 [02:56<00:05, 280.31 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44739/47780 [02:56<00:08, 358.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45293/47780 [02:56<00:07, 336.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46606/47780 [02:56<00:22, 53.26 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45388/47780 [02:56<00:07, 322.14 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46572/47780 [02:56<00:05, 204.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46566/47780 [02:56<00:06, 178.54 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45665/47780 [02:56<00:11, 187.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46226/47780 [02:56<00:05, 276.73 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 44776/47780 [02:56<00:08, 342.52 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45329/47780 [02:56<00:07, 326.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46596/47780 [02:56<00:05, 212.86 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45432/47780 [02:56<00:06, 349.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46585/47780 [02:56<00:06, 179.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45685/47780 [02:56<00:11, 186.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46256/47780 [02:56<00:05, 274.76 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46613/47780 [02:56<00:22, 52.13 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44815/47780 [02:56<00:08, 345.36 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45362/47780 [02:56<00:07, 313.31 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45469/47780 [02:56<00:06, 353.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46619/47780 [02:56<00:05, 215.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45705/47780 [02:56<00:11, 185.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46604/47780 [02:56<00:06, 172.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46619/47780 [02:56<00:21, 53.29 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46284/47780 [02:56<00:05, 262.10 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44853/47780 [02:56<00:08, 351.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45411/47780 [02:56<00:06, 361.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45511/47780 [02:56<00:06, 364.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46641/47780 [02:56<00:05, 209.11 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45728/47780 [02:56<00:10, 195.72 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46628/47780 [02:56<00:06, 188.51 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46312/47780 [02:56<00:05, 261.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46626/47780 [02:56<00:21, 54.07 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44889/47780 [02:56<00:08, 337.66 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45449/47780 [02:57<00:06, 362.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45562/47780 [02:57<00:05, 403.37 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46665/47780 [02:57<00:05, 216.30 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45751/47780 [02:57<00:10, 195.95 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46340/47780 [02:57<00:05, 258.67 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46653/47780 [02:57<00:05, 189.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44928/47780 [02:57<00:08, 347.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46635/47780 [02:57<00:19, 59.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46694/47780 [02:57<00:04, 235.07 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45604/47780 [02:57<00:05, 397.97 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45486/47780 [02:57<00:06, 347.50 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45773/47780 [02:57<00:10, 200.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46366/47780 [02:57<00:05, 256.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46673/47780 [02:57<00:05, 191.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44969/47780 [02:57<00:07, 364.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45644/47780 [02:57<00:05, 390.80 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45522/47780 [02:57<00:06, 338.20 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46720/47780 [02:57<00:04, 231.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46648/47780 [02:57<00:16, 67.47 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45797/47780 [02:57<00:09, 206.61 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45017/47780 [02:57<00:07, 391.86 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46392/47780 [02:57<00:05, 249.47 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46693/47780 [02:57<00:06, 177.65 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45558/47780 [02:57<00:06, 335.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46746/47780 [02:57<00:04, 227.79 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45684/47780 [02:57<00:05, 362.93 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46655/47780 [02:57<00:17, 64.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45818/47780 [02:57<00:09, 200.31 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46418/47780 [02:57<00:05, 248.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45058/47780 [02:57<00:07, 378.70 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46711/47780 [02:57<00:06, 164.41 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45592/47780 [02:57<00:06, 336.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46769/47780 [02:57<00:04, 226.46 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46665/47780 [02:57<00:15, 71.63 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45722/47780 [02:57<00:06, 341.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45840/47780 [02:57<00:10, 192.44 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46444/47780 [02:57<00:05, 236.42 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45101/47780 [02:57<00:07, 378.33 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46728/47780 [02:57<00:06, 163.25 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45634/47780 [02:57<00:06, 354.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46793/47780 [02:57<00:04, 228.40 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45772/47780 [02:57<00:05, 383.97 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45867/47780 [02:57<00:09, 209.82 examples/s]
Tokenizing train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45144/47780 [02:57<00:06, 387.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46472/47780 [02:57<00:05, 241.53 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45673/47780 [02:57<00:05, 363.48 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46674/47780 [02:57<00:17, 63.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46746/47780 [02:57<00:06, 157.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46816/47780 [02:57<00:04, 220.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45816/47780 [02:57<00:04, 398.73 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46500/47780 [02:57<00:05, 244.84 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45183/47780 [02:57<00:07, 366.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45891/47780 [02:57<00:09, 203.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46689/47780 [02:57<00:13, 80.10 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45712/47780 [02:57<00:05, 346.44 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45857/47780 [02:57<00:04, 401.03 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46769/47780 [02:57<00:06, 164.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46839/47780 [02:57<00:04, 215.53 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45913/47780 [02:57<00:09, 207.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46527/47780 [02:57<00:05, 245.91 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45225/47780 [02:57<00:06, 371.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46699/47780 [02:57<00:13, 81.59 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45748/47780 [02:57<00:06, 334.21 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45898/47780 [02:57<00:04, 385.50 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46789/47780 [02:57<00:06, 162.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46861/47780 [02:57<00:04, 198.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46554/47780 [02:57<00:04, 252.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45272/47780 [02:57<00:06, 398.04 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45944/47780 [02:57<00:08, 227.03 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45788/47780 [02:57<00:05, 350.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45938/47780 [02:58<00:04, 381.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46811/47780 [02:58<00:05, 174.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46716/47780 [02:57<00:11, 95.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46580/47780 [02:58<00:04, 250.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46885/47780 [02:58<00:04, 197.99 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45320/47780 [02:58<00:05, 413.05 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45967/47780 [02:58<00:08, 221.88 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45835/47780 [02:58<00:05, 382.74 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45977/47780 [02:58<00:04, 365.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46834/47780 [02:58<00:05, 181.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46730/47780 [02:58<00:10, 102.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46614/47780 [02:58<00:04, 271.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46914/47780 [02:58<00:04, 213.21 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45362/47780 [02:58<00:06, 394.12 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 45991/47780 [02:58<00:08, 214.13 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45875/47780 [02:58<00:05, 369.85 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46015/47780 [02:58<00:04, 366.80 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46854/47780 [02:58<00:05, 184.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46643/47780 [02:58<00:04, 274.45 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45404/47780 [02:58<00:05, 398.22 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46021/47780 [02:58<00:07, 236.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46941/47780 [02:58<00:03, 210.95 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45922/47780 [02:58<00:04, 397.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46741/47780 [02:58<00:12, 82.46 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46679/47780 [02:58<00:03, 297.79 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46873/47780 [02:58<00:05, 179.52 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46052/47780 [02:58<00:05, 343.32 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45446/47780 [02:58<00:05, 392.98 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46046/47780 [02:58<00:07, 235.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46967/47780 [02:58<00:03, 205.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45964/47780 [02:58<00:04, 385.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46709/47780 [02:58<00:03, 288.37 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46090/47780 [02:58<00:04, 348.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46892/47780 [02:58<00:05, 177.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46752/47780 [02:58<00:12, 81.47 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45486/47780 [02:58<00:06, 363.24 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46070/47780 [02:58<00:07, 218.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46989/47780 [02:58<00:03, 207.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46003/47780 [02:58<00:04, 362.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46127/47780 [02:58<00:04, 335.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46738/47780 [02:58<00:04, 258.27 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45542/47780 [02:58<00:05, 414.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46910/47780 [02:58<00:05, 154.82 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46098/47780 [02:58<00:07, 230.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46761/47780 [02:58<00:13, 75.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47010/47780 [02:58<00:03, 202.56 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46044/47780 [02:58<00:05, 344.38 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46163/47780 [02:58<00:04, 330.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46126/47780 [02:58<00:06, 239.16 examples/s]
Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45585/47780 [02:58<00:05, 395.52 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46929/47780 [02:58<00:05, 158.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46765/47780 [02:58<00:04, 230.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47039/47780 [02:58<00:03, 217.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46771/47780 [02:58<00:13, 75.19 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46081/47780 [02:58<00:04, 347.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46198/47780 [02:58<00:04, 325.64 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46154/47780 [02:58<00:06, 246.04 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45633/47780 [02:58<00:05, 414.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46952/47780 [02:58<00:05, 164.06 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47061/47780 [02:58<00:03, 210.42 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46780/47780 [02:58<00:13, 74.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46790/47780 [02:58<00:04, 212.79 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46117/47780 [02:58<00:04, 334.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46234/47780 [02:58<00:04, 324.20 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45677/47780 [02:58<00:05, 403.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46186/47780 [02:58<00:06, 255.06 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46972/47780 [02:58<00:04, 169.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46814/47780 [02:58<00:04, 218.16 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46267/47780 [02:59<00:04, 324.85 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47083/47780 [02:59<00:03, 181.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46788/47780 [02:58<00:14, 67.49 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46157/47780 [02:59<00:05, 322.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46212/47780 [02:59<00:06, 252.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45718/47780 [02:59<00:05, 385.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46837/47780 [02:59<00:04, 220.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46991/47780 [02:59<00:05, 154.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46301/47780 [02:59<00:04, 324.26 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46194/47780 [02:59<00:04, 322.92 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45762/47780 [02:59<00:05, 398.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46795/47780 [02:59<00:15, 63.39 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46238/47780 [02:59<00:06, 243.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47105/47780 [02:59<00:04, 165.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47009/47780 [02:59<00:04, 160.11 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46339/47780 [02:59<00:04, 339.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46862/47780 [02:59<00:04, 205.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46228/47780 [02:59<00:04, 325.91 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46808/47780 [02:59<00:12, 75.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46270/47780 [02:59<00:06, 246.41 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45803/47780 [02:59<00:05, 366.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47123/47780 [02:59<00:04, 152.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47027/47780 [02:59<00:04, 152.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46885/47780 [02:59<00:04, 203.13 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46377/47780 [02:59<00:04, 317.50 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46263/47780 [02:59<00:04, 313.84 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45845/47780 [02:59<00:05, 380.02 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46817/47780 [02:59<00:13, 72.68 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46295/47780 [02:59<00:06, 225.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47054/47780 [02:59<00:04, 176.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47140/47780 [02:59<00:04, 146.03 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46907/47780 [02:59<00:04, 198.42 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46295/47780 [02:59<00:04, 311.60 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45889/47780 [02:59<00:04, 392.66 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46411/47780 [02:59<00:04, 283.63 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46320/47780 [02:59<00:06, 227.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47155/47780 [02:59<00:04, 144.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47078/47780 [02:59<00:03, 187.27 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46825/47780 [02:59<00:14, 65.11 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46928/47780 [02:59<00:04, 186.02 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45929/47780 [02:59<00:04, 393.16 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46441/47780 [02:59<00:04, 274.91 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46343/47780 [02:59<00:06, 226.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46328/47780 [02:59<00:05, 261.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47174/47780 [02:59<00:04, 145.18 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45977/47780 [02:59<00:04, 406.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46832/47780 [02:59<00:15, 61.28 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46947/47780 [02:59<00:04, 177.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47099/47780 [02:59<00:03, 172.45 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46470/47780 [02:59<00:04, 262.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46366/47780 [02:59<00:06, 213.13 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46356/47780 [02:59<00:06, 233.97 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46023/47780 [02:59<00:04, 416.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47193/47780 [02:59<00:03, 147.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46967/47780 [02:59<00:04, 173.94 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46839/47780 [02:59<00:16, 57.23 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46497/47780 [02:59<00:05, 247.91 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47117/47780 [02:59<00:04, 151.22 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46389/47780 [02:59<00:06, 199.96 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46381/47780 [02:59<00:05, 234.37 examples/s]
Tokenizing train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46083/47780 [02:59<00:03, 465.17 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47208/47780 [02:59<00:04, 140.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46539/47780 [03:00<00:04, 285.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46986/47780 [02:59<00:05, 157.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47133/47780 [02:59<00:04, 148.92 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46410/47780 [02:59<00:06, 200.47 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46845/47780 [02:59<00:17, 52.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46406/47780 [03:00<00:06, 227.04 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46130/47780 [03:00<00:03, 419.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47224/47780 [03:00<00:04, 135.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47149/47780 [03:00<00:04, 149.53 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46569/47780 [03:00<00:04, 279.27 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46433/47780 [03:00<00:06, 207.71 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46851/47780 [03:00<00:17, 53.88 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47003/47780 [03:00<00:05, 149.39 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46430/47780 [03:00<00:06, 222.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46173/47780 [03:00<00:04, 395.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47239/47780 [03:00<00:04, 129.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47165/47780 [03:00<00:04, 146.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46599/47780 [03:00<00:04, 268.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46858/47780 [03:00<00:16, 55.44 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47030/47780 [03:00<00:04, 170.67 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46454/47780 [03:00<00:07, 187.26 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46457/47780 [03:00<00:05, 231.01 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46214/47780 [03:00<00:04, 359.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46867/47780 [03:00<00:14, 63.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47253/47780 [03:00<00:04, 117.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47058/47780 [03:00<00:03, 189.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46627/47780 [03:00<00:04, 247.48 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46474/47780 [03:00<00:07, 180.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47185/47780 [03:00<00:04, 134.32 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46482/47780 [03:00<00:06, 208.08 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46251/47780 [03:00<00:04, 352.82 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46874/47780 [03:00<00:14, 62.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47265/47780 [03:00<00:04, 114.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46494/47780 [03:00<00:07, 181.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46654/47780 [03:00<00:04, 237.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47199/47780 [03:00<00:04, 135.24 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46504/47780 [03:00<00:06, 206.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47078/47780 [03:00<00:04, 160.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46287/47780 [03:00<00:04, 352.80 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46513/47780 [03:00<00:06, 183.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46885/47780 [03:00<00:13, 68.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47277/47780 [03:00<00:04, 109.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46681/47780 [03:00<00:04, 237.07 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46526/47780 [03:00<00:06, 204.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47213/47780 [03:00<00:05, 113.25 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46538/47780 [03:00<00:06, 201.57 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46324/47780 [03:00<00:04, 326.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47096/47780 [03:00<00:04, 149.19 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46708/47780 [03:00<00:04, 240.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46894/47780 [03:00<00:12, 68.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47290/47780 [03:00<00:04, 103.76 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46548/47780 [03:00<00:05, 205.77 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46358/47780 [03:00<00:04, 321.87 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46559/47780 [03:00<00:06, 194.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47225/47780 [03:00<00:05, 106.69 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46901/47780 [03:00<00:12, 68.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47112/47780 [03:00<00:05, 133.59 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46733/47780 [03:00<00:04, 222.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47307/47780 [03:00<00:04, 114.28 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46569/47780 [03:00<00:06, 196.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46396/47780 [03:00<00:04, 336.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47238/47780 [03:00<00:04, 110.34 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46583/47780 [03:00<00:06, 195.54 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46756/47780 [03:01<00:04, 219.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47130/47780 [03:00<00:04, 138.99 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46589/47780 [03:00<00:06, 192.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46909/47780 [03:00<00:13, 63.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47320/47780 [03:01<00:04, 113.00 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46432/47780 [03:00<00:03, 337.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46603/47780 [03:01<00:06, 183.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46779/47780 [03:01<00:04, 221.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47145/47780 [03:01<00:04, 139.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46617/47780 [03:01<00:05, 214.94 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47250/47780 [03:01<00:05, 97.89 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47332/47780 [03:01<00:03, 113.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46924/47780 [03:01<00:10, 81.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46470/47780 [03:01<00:03, 347.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46622/47780 [03:01<00:06, 183.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46804/47780 [03:01<00:04, 226.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47161/47780 [03:01<00:04, 143.40 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46642/47780 [03:01<00:05, 219.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47349/47780 [03:01<00:03, 124.01 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46938/47780 [03:01<00:09, 91.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47261/47780 [03:01<00:05, 92.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46506/47780 [03:01<00:03, 334.12 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46831/47780 [03:01<00:03, 237.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46642/47780 [03:01<00:06, 180.21 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46665/47780 [03:01<00:05, 222.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47178/47780 [03:01<00:04, 136.67 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47271/47780 [03:01<00:05, 90.15 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46540/47780 [03:01<00:03, 317.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47365/47780 [03:01<00:03, 119.94 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46859/47780 [03:01<00:03, 242.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46661/47780 [03:01<00:06, 171.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46948/47780 [03:01<00:10, 77.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46689/47780 [03:01<00:05, 215.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47192/47780 [03:01<00:04, 129.56 examples/s]
Tokenizing train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 46572/47780 [03:01<00:04, 301.53 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46884/47780 [03:01<00:03, 238.10 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46957/47780 [03:01<00:10, 79.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47378/47780 [03:01<00:03, 106.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47281/47780 [03:01<00:06, 79.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46683/47780 [03:01<00:06, 177.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46712/47780 [03:01<00:05, 202.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47217/47780 [03:01<00:03, 157.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46911/47780 [03:01<00:03, 244.22 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46703/47780 [03:01<00:05, 183.06 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47393/47780 [03:01<00:03, 112.74 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46605/47780 [03:01<00:04, 267.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47290/47780 [03:01<00:06, 77.61 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46968/47780 [03:01<00:10, 78.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46739/47780 [03:01<00:04, 212.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47235/47780 [03:01<00:03, 158.65 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46722/47780 [03:01<00:05, 177.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46937/47780 [03:01<00:03, 222.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47301/47780 [03:01<00:05, 82.96 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46765/47780 [03:01<00:04, 222.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47253/47780 [03:01<00:03, 163.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47406/47780 [03:01<00:03, 106.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46633/47780 [03:01<00:04, 245.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46977/47780 [03:01<00:10, 75.36 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46740/47780 [03:01<00:06, 163.39 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46791/47780 [03:01<00:04, 230.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47311/47780 [03:01<00:05, 83.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46668/47780 [03:01<00:04, 269.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47270/47780 [03:01<00:03, 157.68 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46961/47780 [03:01<00:04, 204.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46987/47780 [03:01<00:09, 79.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47418/47780 [03:01<00:03, 100.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46758/47780 [03:01<00:06, 165.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47290/47780 [03:01<00:02, 167.30 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46993/47780 [03:02<00:03, 231.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47320/47780 [03:01<00:05, 78.23 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46696/47780 [03:01<00:04, 252.00 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46815/47780 [03:01<00:04, 208.64 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47429/47780 [03:02<00:03, 100.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46999/47780 [03:01<00:09, 84.04 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46779/47780 [03:02<00:05, 168.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47307/47780 [03:02<00:02, 162.58 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47017/47780 [03:02<00:03, 226.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46722/47780 [03:02<00:04, 246.80 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46844/47780 [03:02<00:04, 224.84 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47444/47780 [03:02<00:03, 110.92 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47014/47780 [03:02<00:07, 99.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47328/47780 [03:02<00:06, 71.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47325/47780 [03:02<00:02, 164.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46796/47780 [03:02<00:06, 158.75 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46873/47780 [03:02<00:03, 239.05 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47041/47780 [03:02<00:03, 216.19 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46749/47780 [03:02<00:04, 241.23 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47336/47780 [03:02<00:06, 73.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47457/47780 [03:02<00:02, 108.34 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46813/47780 [03:02<00:06, 160.60 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47071/47780 [03:02<00:03, 233.79 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47343/47780 [03:02<00:02, 157.15 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46776/47780 [03:02<00:04, 248.61 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47026/47780 [03:02<00:09, 81.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47344/47780 [03:02<00:05, 73.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47469/47780 [03:02<00:02, 109.63 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46898/47780 [03:02<00:04, 219.81 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47099/47780 [03:02<00:02, 243.73 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46832/47780 [03:02<00:06, 158.00 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47481/47780 [03:02<00:02, 111.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47036/47780 [03:02<00:09, 81.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47360/47780 [03:02<00:02, 149.87 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46803/47780 [03:02<00:04, 236.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47357/47780 [03:02<00:05, 83.16 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46922/47780 [03:02<00:04, 206.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47126/47780 [03:02<00:02, 244.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46852/47780 [03:02<00:05, 167.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47493/47780 [03:02<00:02, 110.86 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46829/47780 [03:02<00:04, 233.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47376/47780 [03:02<00:02, 146.07 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47047/47780 [03:02<00:08, 81.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47366/47780 [03:02<00:05, 79.57 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46950/47780 [03:02<00:03, 218.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46869/47780 [03:02<00:05, 164.93 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47505/47780 [03:02<00:02, 110.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46853/47780 [03:02<00:03, 232.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47394/47780 [03:02<00:02, 151.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47151/47780 [03:02<00:02, 219.97 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47056/47780 [03:02<00:09, 80.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47374/47780 [03:02<00:05, 75.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46974/47780 [03:02<00:03, 207.38 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46880/47780 [03:02<00:03, 234.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47175/47780 [03:02<00:02, 222.17 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46886/47780 [03:02<00:05, 149.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47519/47780 [03:02<00:02, 107.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47065/47780 [03:02<00:08, 81.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47415/47780 [03:02<00:02, 150.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46997/47780 [03:02<00:03, 204.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47383/47780 [03:02<00:05, 69.83 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46904/47780 [03:02<00:04, 218.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47198/47780 [03:02<00:02, 206.77 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46902/47780 [03:02<00:06, 139.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47432/47780 [03:02<00:02, 152.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47078/47780 [03:02<00:08, 85.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47019/47780 [03:02<00:03, 205.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47531/47780 [03:03<00:02, 94.26 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47392/47780 [03:02<00:05, 73.89 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46920/47780 [03:02<00:05, 149.95 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46927/47780 [03:03<00:04, 207.13 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47040/47780 [03:03<00:03, 205.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47449/47780 [03:03<00:02, 146.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47220/47780 [03:03<00:02, 191.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47088/47780 [03:02<00:08, 83.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47407/47780 [03:03<00:04, 88.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47542/47780 [03:03<00:02, 90.78 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46936/47780 [03:03<00:05, 150.67 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46950/47780 [03:03<00:03, 213.11 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47473/47780 [03:03<00:01, 170.77 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47246/47780 [03:03<00:02, 206.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47064/47780 [03:03<00:03, 209.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47099/47780 [03:03<00:07, 87.96 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47416/47780 [03:03<00:04, 82.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47552/47780 [03:03<00:02, 88.25 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46952/47780 [03:03<00:05, 146.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47492/47780 [03:03<00:01, 175.94 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46972/47780 [03:03<00:03, 204.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47087/47780 [03:03<00:03, 214.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47268/47780 [03:03<00:02, 205.52 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47108/47780 [03:03<00:08, 79.92 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47561/47780 [03:03<00:02, 84.85 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46968/47780 [03:03<00:05, 147.35 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47002/47780 [03:03<00:03, 227.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47427/47780 [03:03<00:04, 80.82 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47110/47780 [03:03<00:03, 211.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47289/47780 [03:03<00:02, 184.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47510/47780 [03:03<00:01, 148.91 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47118/47780 [03:03<00:07, 84.43 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46983/47780 [03:03<00:05, 147.70 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47436/47780 [03:03<00:04, 82.45 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47032/47780 [03:03<00:03, 237.95 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47135/47780 [03:03<00:02, 216.79 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47570/47780 [03:03<00:02, 75.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47313/47780 [03:03<00:02, 196.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47528/47780 [03:03<00:01, 156.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47129/47780 [03:03<00:07, 87.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47002/47780 [03:03<00:05, 154.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47447/47780 [03:03<00:03, 87.74 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47166/47780 [03:03<00:02, 241.26 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47056/47780 [03:03<00:03, 222.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47545/47780 [03:03<00:01, 159.83 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47579/47780 [03:03<00:02, 72.92 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47334/47780 [03:03<00:02, 184.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47140/47780 [03:03<00:07, 89.09 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47019/47780 [03:03<00:05, 148.05 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47457/47780 [03:03<00:03, 87.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47191/47780 [03:03<00:02, 223.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47080/47780 [03:03<00:03, 213.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47563/47780 [03:03<00:01, 160.38 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47588/47780 [03:03<00:02, 72.66 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47035/47780 [03:03<00:04, 150.71 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47468/47780 [03:03<00:03, 89.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47150/47780 [03:03<00:07, 80.34 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47214/47780 [03:03<00:02, 217.79 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47354/47780 [03:03<00:02, 153.65 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47102/47780 [03:03<00:03, 204.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47596/47780 [03:03<00:02, 70.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47580/47780 [03:03<00:01, 142.64 examples/s]
Tokenizing train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47057/47780 [03:03<00:04, 168.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47484/47780 [03:03<00:02, 107.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47163/47780 [03:03<00:07, 86.48 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47237/47780 [03:03<00:02, 209.53 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47128/47780 [03:03<00:03, 215.01 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47372/47780 [03:04<00:02, 145.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47075/47780 [03:03<00:04, 161.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47500/47780 [03:04<00:02, 120.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47595/47780 [03:04<00:01, 127.71 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47607/47780 [03:04<00:02, 69.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47267/47780 [03:04<00:02, 231.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47177/47780 [03:03<00:06, 96.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47151/47780 [03:04<00:02, 215.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47092/47780 [03:04<00:04, 157.42 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47389/47780 [03:04<00:02, 131.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47514/47780 [03:04<00:02, 111.44 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47291/47780 [03:04<00:02, 216.03 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47173/47780 [03:04<00:03, 201.90 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47187/47780 [03:04<00:07, 84.36 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47113/47780 [03:04<00:04, 163.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47403/47780 [03:04<00:03, 123.41 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47195/47780 [03:04<00:02, 199.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47609/47780 [03:04<00:01, 93.10 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47316/47780 [03:04<00:02, 215.26 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47527/47780 [03:04<00:02, 102.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47197/47780 [03:04<00:06, 86.58 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47130/47780 [03:04<00:04, 161.55 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47615/47780 [03:04<00:03, 45.73 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47218/47780 [03:04<00:02, 203.88 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47417/47780 [03:04<00:03, 119.02 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47338/47780 [03:04<00:02, 211.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47542/47780 [03:04<00:02, 108.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47148/47780 [03:04<00:03, 166.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47207/47780 [03:04<00:06, 82.39 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47239/47780 [03:04<00:02, 190.99 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47430/47780 [03:04<00:03, 110.80 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47175/47780 [03:04<00:03, 195.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47360/47780 [03:04<00:02, 188.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47555/47780 [03:04<00:02, 103.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47620/47780 [03:04<00:02, 71.15 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47216/47780 [03:04<00:07, 75.84 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47262/47780 [03:04<00:02, 201.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47621/47780 [03:04<00:04, 38.12 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47445/47780 [03:04<00:02, 115.18 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47196/47780 [03:04<00:03, 193.70 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47381/47780 [03:04<00:02, 189.48 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47573/47780 [03:04<00:01, 110.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47283/47780 [03:04<00:02, 200.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47628/47780 [03:04<00:03, 42.72 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47224/47780 [03:04<00:07, 69.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47629/47780 [03:04<00:02, 65.24 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47402/47780 [03:04<00:01, 190.79 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47457/47780 [03:04<00:02, 110.90 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47233/47780 [03:04<00:02, 228.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47587/47780 [03:04<00:01, 114.59 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47304/47780 [03:04<00:02, 196.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47234/47780 [03:04<00:07, 72.38 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47469/47780 [03:04<00:02, 107.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47256/47780 [03:04<00:02, 213.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47423/47780 [03:04<00:02, 169.60 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47599/47780 [03:04<00:01, 110.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47327/47780 [03:04<00:02, 202.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47638/47780 [03:04<00:02, 56.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47249/47780 [03:04<00:06, 86.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47483/47780 [03:05<00:02, 115.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47634/47780 [03:05<00:04, 34.76 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47280/47780 [03:05<00:02, 203.94 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47612/47780 [03:05<00:01, 111.78 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47350/47780 [03:05<00:02, 207.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47645/47780 [03:05<00:02, 57.49 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47261/47780 [03:05<00:05, 91.66 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47441/47780 [03:05<00:02, 144.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47495/47780 [03:05<00:02, 112.96 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47642/47780 [03:05<00:03, 40.56 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47301/47780 [03:05<00:02, 203.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47625/47780 [03:05<00:01, 112.31 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47372/47780 [03:05<00:02, 198.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47273/47780 [03:05<00:05, 95.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47508/47780 [03:05<00:02, 113.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47652/47780 [03:05<00:02, 55.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47647/47780 [03:05<00:03, 40.21 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47457/47780 [03:05<00:02, 127.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47323/47780 [03:05<00:02, 189.01 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47637/47780 [03:05<00:01, 106.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47392/47780 [03:05<00:02, 186.92 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47520/47780 [03:05<00:02, 113.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47660/47780 [03:05<00:02, 56.55 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47283/47780 [03:05<00:05, 84.06 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47653/47780 [03:05<00:02, 42.57 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47343/47780 [03:05<00:02, 182.02 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47651/47780 [03:05<00:01, 113.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47474/47780 [03:05<00:02, 127.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47411/47780 [03:05<00:02, 169.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47536/47780 [03:05<00:02, 120.14 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47294/47780 [03:05<00:05, 86.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47363/47780 [03:05<00:02, 182.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47668/47780 [03:05<00:02, 54.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47670/47780 [03:05<00:00, 121.50 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47432/47780 [03:05<00:01, 174.98 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47550/47780 [03:05<00:01, 121.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47658/47780 [03:05<00:03, 37.37 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47489/47780 [03:05<00:02, 116.45 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47305/47780 [03:05<00:05, 85.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47383/47780 [03:05<00:02, 174.62 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47452/47780 [03:05<00:01, 170.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47684/47780 [03:05<00:00, 114.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47565/47780 [03:05<00:01, 121.19 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47504/47780 [03:05<00:02, 117.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47675/47780 [03:05<00:02, 50.98 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47316/47780 [03:05<00:05, 88.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47402/47780 [03:05<00:02, 173.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47578/47780 [03:05<00:01, 119.86 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47472/47780 [03:05<00:01, 164.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47697/47780 [03:05<00:00, 106.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47517/47780 [03:05<00:02, 110.63 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47664/47780 [03:05<00:03, 30.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47326/47780 [03:05<00:05, 90.07 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47426/47780 [03:05<00:01, 184.72 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47681/47780 [03:05<00:02, 45.46 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47590/47780 [03:05<00:01, 115.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47491/47780 [03:05<00:01, 160.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47337/47780 [03:05<00:04, 92.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47708/47780 [03:05<00:00, 95.53 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47529/47780 [03:05<00:02, 101.57 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47670/47780 [03:06<00:03, 33.28 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47446/47780 [03:05<00:01, 171.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47686/47780 [03:06<00:02, 41.67 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47607/47780 [03:06<00:01, 117.25 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47510/47780 [03:06<00:01, 160.08 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47357/47780 [03:06<00:03, 113.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47674/47780 [03:06<00:03, 33.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47542/47780 [03:06<00:02, 98.20 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47468/47780 [03:06<00:01, 171.66 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47691/47780 [03:06<00:02, 43.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47718/47780 [03:06<00:00, 81.47 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47530/47780 [03:06<00:01, 159.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47624/47780 [03:06<00:01, 122.25 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47678/47780 [03:06<00:03, 33.54 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47373/47780 [03:06<00:03, 112.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47697/47780 [03:06<00:01, 45.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47487/47780 [03:06<00:01, 163.41 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47554/47780 [03:06<00:02, 94.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47549/47780 [03:06<00:01, 164.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47637/47780 [03:06<00:01, 120.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47727/47780 [03:06<00:00, 73.68 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47707/47780 [03:06<00:01, 53.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47566/47780 [03:06<00:02, 89.15 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47385/47780 [03:06<00:04, 92.80 examples/s] 
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47504/47780 [03:06<00:01, 139.80 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47653/47780 [03:06<00:01, 118.03 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47568/47780 [03:06<00:01, 151.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47683/47780 [03:06<00:03, 28.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47736/47780 [03:06<00:00, 66.30 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47717/47780 [03:06<00:01, 60.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47576/47780 [03:06<00:02, 91.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47400/47780 [03:06<00:03, 105.33 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47519/47780 [03:06<00:01, 140.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47667/47780 [03:06<00:00, 120.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47586/47780 [03:06<00:01, 145.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47688/47780 [03:06<00:02, 31.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47726/47780 [03:06<00:00, 63.99 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47586/47780 [03:06<00:02, 88.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47681/47780 [03:06<00:00, 122.10 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47416/47780 [03:06<00:03, 107.46 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47601/47780 [03:06<00:01, 146.74 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47743/47780 [03:06<00:00, 54.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47693/47780 [03:06<00:02, 33.02 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47534/47780 [03:06<00:02, 117.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47595/47780 [03:06<00:02, 86.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47735/47780 [03:06<00:00, 66.49 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47619/47780 [03:06<00:01, 153.20 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47695/47780 [03:06<00:00, 119.68 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47433/47780 [03:06<00:02, 116.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47702/47780 [03:06<00:01, 42.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47707/47780 [03:06<00:00, 114.69 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47607/47780 [03:06<00:02, 84.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47746/47780 [03:06<00:00, 69.86 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47548/47780 [03:06<00:02, 102.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47749/47780 [03:06<00:00, 45.18 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47635/47780 [03:06<00:01, 135.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47446/47780 [03:06<00:03, 105.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47719/47780 [03:07<00:00, 112.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47754/47780 [03:07<00:00, 44.91 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47618/47780 [03:07<00:01, 83.15 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47649/47780 [03:07<00:00, 132.87 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47560/47780 [03:07<00:02, 97.05 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47461/47780 [03:06<00:02, 111.26 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47708/47780 [03:07<00:02, 35.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47755/47780 [03:07<00:00, 61.42 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47762/47780 [03:07<00:00, 50.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47664/47780 [03:07<00:00, 130.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47633/47780 [03:07<00:01, 91.37 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47577/47780 [03:07<00:01, 105.30 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47476/47780 [03:07<00:02, 111.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47684/47780 [03:07<00:00, 142.61 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47732/47780 [03:07<00:00, 79.25 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47768/47780 [03:07<00:00, 48.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47589/47780 [03:07<00:01, 108.11 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47762/47780 [03:07<00:00, 51.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47643/47780 [03:07<00:01, 87.32 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47495/47780 [03:07<00:02, 123.12 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47701/47780 [03:07<00:00, 148.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47713/47780 [03:07<00:02, 27.75 examples/s]
Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47508/47780 [03:07<00:02, 122.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47654/47780 [03:07<00:01, 87.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [03:07<00:00, 51.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47602/47780 [03:07<00:01, 100.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47742/47780 [03:07<00:00, 70.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47774/47780 [03:07<00:00, 39.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47718/47780 [03:07<00:00, 135.78 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47718/47780 [03:07<00:02, 28.45 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47522/47780 [03:07<00:02, 119.81 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47613/47780 [03:07<00:01, 90.44 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47663/47780 [03:07<00:01, 74.65 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47540/47780 [03:07<00:01, 128.05 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47732/47780 [03:07<00:00, 116.24 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47722/47780 [03:07<00:02, 26.58 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47624/47780 [03:07<00:01, 82.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47671/47780 [03:07<00:01, 66.17 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47752/47780 [03:07<00:00, 54.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47557/47780 [03:07<00:01, 138.17 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47725/47780 [03:07<00:02, 25.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47678/47780 [03:07<00:01, 59.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47633/47780 [03:07<00:01, 74.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47572/47780 [03:07<00:01, 106.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47730/47780 [03:08<00:01, 28.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47641/47780 [03:07<00:01, 74.34 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47760/47780 [03:08<00:00, 45.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47687/47780 [03:08<00:01, 61.01 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47652/47780 [03:08<00:01, 80.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47734/47780 [03:08<00:01, 27.70 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47695/47780 [03:08<00:01, 59.48 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47746/47780 [03:08<00:00, 61.68 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47766/47780 [03:08<00:00, 40.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47662/47780 [03:08<00:01, 77.19 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47738/47780 [03:08<00:01, 27.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47758/47780 [03:08<00:00, 63.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47585/47780 [03:08<00:02, 67.42 examples/s] 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47704/47780 [03:08<00:01, 53.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47670/47780 [03:08<00:01, 67.80 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47742/47780 [03:08<00:01, 26.82 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47746/47780 [03:08<00:01, 26.62 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47598/47780 [03:08<00:02, 62.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47710/47780 [03:08<00:01, 42.54 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47768/47780 [03:08<00:00, 53.66 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47678/47780 [03:08<00:01, 54.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47750/47780 [03:08<00:01, 27.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47716/47780 [03:08<00:01, 42.56 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47609/47780 [03:08<00:02, 63.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47773/47780 [03:08<00:00, 24.49 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47754/47780 [03:08<00:00, 27.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47723/47780 [03:08<00:01, 46.13 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47684/47780 [03:08<00:02, 43.28 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47758/47780 [03:09<00:00, 28.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47728/47780 [03:09<00:01, 43.96 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47764/47780 [03:09<00:00, 35.47 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47618/47780 [03:09<00:03, 49.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47690/47780 [03:09<00:02, 38.01 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47734/47780 [03:09<00:01, 38.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47696/47780 [03:09<00:02, 40.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47770/47780 [03:09<00:00, 36.74 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47701/47780 [03:09<00:01, 40.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47775/47780 [03:09<00:00, 35.71 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47626/47780 [03:09<00:03, 41.65 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47740/47780 [03:09<00:01, 33.16 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47707/47780 [03:09<00:01, 42.40 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47632/47780 [03:09<00:03, 37.31 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47744/47780 [03:09<00:01, 30.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47712/47780 [03:09<00:01, 36.75 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47748/47780 [03:09<00:01, 30.44 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47718/47780 [03:09<00:01, 39.01 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47638/47780 [03:09<00:04, 34.95 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47752/47780 [03:09<00:00, 30.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47725/47780 [03:09<00:01, 44.50 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47775/47780 [03:09<00:00,  8.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47645/47780 [03:09<00:03, 39.43 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47756/47780 [03:10<00:00, 31.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47730/47780 [03:10<00:01, 43.73 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47654/47780 [03:10<00:02, 44.95 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47761/47780 [03:10<00:00, 33.39 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47735/47780 [03:10<00:01, 40.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47765/47780 [03:10<00:00, 33.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47661/47780 [03:10<00:02, 43.53 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [03:10<00:00, 33.59 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47668/47780 [03:10<00:02, 46.67 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47741/47780 [03:10<00:01, 34.41 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47745/47780 [03:10<00:01, 31.43 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47674/47780 [03:10<00:02, 40.22 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47749/47780 [03:10<00:01, 30.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47679/47780 [03:10<00:02, 39.21 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47753/47780 [03:10<00:00, 31.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47684/47780 [03:10<00:02, 39.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47757/47780 [03:10<00:00, 31.35 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47691/47780 [03:10<00:02, 39.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47761/47780 [03:11<00:00, 32.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47697/47780 [03:11<00:02, 41.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47765/47780 [03:11<00:00, 32.36 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47702/47780 [03:11<00:01, 41.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47769/47780 [03:11<00:00, 33.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47710/47780 [03:11<00:01, 46.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47715/47780 [03:11<00:01, 38.97 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47721/47780 [03:11<00:01, 37.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47729/47780 [03:11<00:01, 45.32 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47734/47780 [03:11<00:01, 44.78 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47743/47780 [03:12<00:00, 45.56 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47749/47780 [03:12<00:00, 39.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47754/47780 [03:12<00:00, 39.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47762/47780 [03:12<00:00, 45.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47771/47780 [03:12<00:00, 53.58 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47774/47780 [03:14<00:01,  3.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47774/47780 [03:14<00:01,  3.85 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47777/47780 [03:15<00:00,  3.52 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47777/47780 [03:15<00:00,  7.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47776/47780 [03:15<00:00,  4.98 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47779/47780 [03:15<00:00,  2.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47778/47780 [03:16<00:00,  3.45 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47778/47780 [03:16<00:00,  2.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47779/47780 [03:16<00:00,  2.52 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47779/47780 [03:16<00:00,  2.88 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:16<00:00,  2.23 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:16<00:00, 242.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:16<00:00,  3.49 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:17<00:00, 241.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:17<00:00, 241.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:17<00:00, 241.35 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:17<00:00, 241.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:17<00:00, 241.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:18<00:00, 241.30 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<00:57, 810.63 examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   8%|â–Š         | 4000/47780 [00:01<00:11, 3826.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22480/47780 [00:01<00:00, 27040.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33370/47780 [00:01<00:00, 39665.76 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44822/47780 [00:01<00:00, 50708.68 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<00:55, 847.12 examples/s]
Truncating train dataset (num_proc=32):  15%|â–ˆâ–        | 7000/47780 [00:01<00:05, 7054.29 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<01:00, 775.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 13000/47780 [00:01<00:02, 13702.30 examples/s]
Truncating train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18000/47780 [00:01<00:01, 19132.05 examples/s]
Truncating train dataset (num_proc=32):   6%|â–‹         | 3000/47780 [00:01<00:17, 2557.31 examples/s]
Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<01:05, 710.40 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<01:09, 673.12 examples/s]
Truncating train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22494/47780 [00:01<00:01, 22984.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   8%|â–Š         | 4000/47780 [00:01<00:12, 3410.10 examples/s]
Truncating train dataset (num_proc=32):   4%|â–         | 2000/47780 [00:01<00:32, 1389.69 examples/s]
Truncating train dataset (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27481/47780 [00:01<00:00, 25895.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6000/47780 [00:01<00:07, 5359.16 examples/s]
Truncating train dataset (num_proc=32):   4%|â–         | 2000/47780 [00:01<00:35, 1300.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11988/47780 [00:01<00:02, 14072.00 examples/s]
Truncating train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32453/47780 [00:01<00:00, 28501.84 examples/s]
Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:01<01:24, 554.63 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  11%|â–ˆâ–        | 5494/47780 [00:01<00:09, 4481.07 examples/s]
Truncating train dataset (num_proc=32):   6%|â–‹         | 3000/47780 [00:01<00:22, 1974.05 examples/s]
Truncating train dataset (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36413/47780 [00:02<00:00, 28172.41 examples/s]
Truncating train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 7494/47780 [00:01<00:06, 6279.82 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14988/47780 [00:02<00:02, 14192.12 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  10%|â–ˆ         | 4988/47780 [00:02<00:11, 3652.17 examples/s]
Truncating train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19482/47780 [00:02<00:01, 18812.95 examples/s]
Truncating train dataset (num_proc=32):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 39864/47780 [00:02<00:00, 24615.44 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  21%|â–ˆâ–ˆ        | 9988/47780 [00:02<00:05, 7476.60 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   4%|â–         | 2000/47780 [00:02<00:46, 984.82 examples/s]
Truncating train dataset (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 42836/47780 [00:02<00:00, 21965.42 examples/s]
Truncating train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 22455/47780 [00:02<00:01, 17056.03 examples/s]
Truncating train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11988/47780 [00:02<00:04, 8755.10 examples/s]
Truncating train dataset (num_proc=32):  15%|â–ˆâ–        | 6988/47780 [00:02<00:08, 4641.53 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   6%|â–‹         | 3000/47780 [00:02<00:26, 1668.62 examples/s]
Truncating train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 26427/47780 [00:02<00:01, 20867.29 examples/s]
Truncating train dataset (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 13467/47780 [00:02<00:03, 9380.10 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:02<01:59, 391.19 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10481/47780 [00:02<00:04, 8175.83 examples/s]
Truncating train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 6000/47780 [00:02<00:09, 4217.93 examples/s]
Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [03:20<00:00, 238.04 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15454/47780 [00:02<00:02, 11150.39 examples/s]
Truncating train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45808/47780 [00:02<00:00, 16458.61 examples/s]
Truncating train dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20440/47780 [00:02<00:01, 19005.31 examples/s]
Truncating train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 12975/47780 [00:02<00:03, 9651.05 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29399/47780 [00:02<00:01, 17234.57 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   4%|â–         | 2000/47780 [00:02<00:54, 844.41 examples/s]
Truncating train dataset (num_proc=32):  17%|â–ˆâ–‹        | 8000/47780 [00:02<00:07, 5525.98 examples/s]
Truncating train dataset (num_proc=32):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25934/47780 [00:02<00:00, 27124.90 examples/s]
Truncating train dataset (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 14975/47780 [00:02<00:03, 10770.06 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31892/47780 [00:02<00:00, 17698.28 examples/s]
Truncating train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 11986/47780 [00:02<00:03, 9913.41 examples/s]
Truncating train dataset (num_proc=32):  15%|â–ˆâ–        | 7000/47780 [00:02<00:10, 3951.47 examples/s]
Truncating train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29934/47780 [00:02<00:00, 27822.23 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 19454/47780 [00:02<00:01, 16610.69 examples/s]
Truncating train dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35371/47780 [00:02<00:00, 20518.80 examples/s]
Truncating train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 15467/47780 [00:02<00:02, 13670.36 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 10494/47780 [00:03<00:05, 6407.10 examples/s]
Truncating train dataset (num_proc=32):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24440/47780 [00:03<00:01, 21284.89 examples/s]
Truncating train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38864/47780 [00:03<00:00, 21415.48 examples/s]
Truncating train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19960/47780 [00:03<00:01, 18055.28 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33920/47780 [00:03<00:00, 24696.24 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15987/47780 [00:03<00:02, 11068.84 examples/s]
Truncating train dataset (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31919/47780 [00:03<00:00, 31959.38 examples/s]
Truncating train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43836/47780 [00:03<00:00, 27308.33 examples/s]
Truncating train dataset (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30440/47780 [00:03<00:00, 34340.20 examples/s]
Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42357/47780 [00:03<00:00, 36646.41 examples/s]
Truncating train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21468/47780 [00:03<00:01, 16460.00 examples/s]
Truncating train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35920/47780 [00:03<00:00, 38243.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38906/47780 [00:03<00:00, 37315.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 33934/47780 [00:03<00:00, 32860.62 examples/s]
Truncating train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40878/47780 [00:03<00:00, 38963.99 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 43343/47780 [00:03<00:00, 36593.58 examples/s]
Truncating train dataset (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 46794/47780 [00:03<00:00, 28635.79 examples/s]
Truncating train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47287/47780 [00:03<00:00, 19972.73 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 40878/47780 [00:03<00:00, 36425.08 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 45808/47780 [00:04<00:00, 13076.92 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:04<00:00, 12287.14 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 47287/47780 [00:06<00:00, 7194.33 examples/s] 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:16<00:00, 50708.68 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:15<00:00, 13076.92 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:15<00:00, 19972.73 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:15<00:00, 16458.61 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:15<00:00, 28635.79 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:17<00:00, 12287.14 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:17<00:00, 7194.33 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:19<00:00, 1289.81 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   2%|â–         | 1000/47780 [00:20<16:20, 47.72 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   5%|â–Œ         | 2494/47780 [00:22<05:27, 138.09 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):   8%|â–Š         | 3987/47780 [00:23<03:00, 243.18 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:28<00:00, 646.99 examples/s] 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:28<00:00, 558.13 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  15%|â–ˆâ–        | 6973/47780 [00:25<01:28, 458.74 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:29<00:00, 469.71 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 10960/47780 [00:27<00:44, 835.90 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:30<00:00, 330.35 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:31<00:00, 348.29 examples/s]  
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15946/47780 [00:28<00:23, 1352.37 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 17932/47780 [00:28<00:17, 1691.88 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 18932/47780 [00:29<00:19, 1509.98 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:36<00:00, 1289.81 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19918/47780 [00:32<00:26, 1044.69 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26891/47780 [00:32<00:07, 2645.93 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29877/47780 [00:33<00:06, 2709.77 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Truncating train dataset (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43835/47780 [00:33<00:00, 7403.25 examples/s]
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:38<00:00, 1254.34 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:09,156] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:43<00:00, 1104.38 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:43<00:00, 1091.07 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:43<00:00, 1088.62 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:44<00:00, 1082.33 examples/s] 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:44<00:00, 1075.18 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:11,814] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:44<00:00, 1066.94 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:12,419] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:12,617] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:12,787] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:12,912] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:13,332] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,660] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,660] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,660] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,661] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,661] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,661] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:15,661] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Truncating train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47780/47780 [00:45<00:00, 1042.22 examples/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:17,575] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 07:48:18,816] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m  10%|â–ˆ         | 1/10 [00:46<07:00, 46.76s/it]Chrome trace exported to: /tmp/trace_10_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_6.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_5.json
[36m(head, rank=0, pid=3864)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:31<06:05, 45.64s/it]Chrome trace exported to: /tmp/trace_18_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_7.json
[36m(head, rank=0, pid=3864)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [02:15<05:15, 45.00s/it]Chrome trace exported to: /tmp/trace_26_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [03:00<04:29, 44.93s/it]Chrome trace exported to: /tmp/trace_34_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_6.json
[36m(head, rank=0, pid=3864)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:46<03:45, 45.13s/it]Chrome trace exported to: /tmp/trace_42_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [04:30<02:59, 44.79s/it]Chrome trace exported to: /tmp/trace_50_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_6.json
[36m(head, rank=0, pid=3864)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [05:16<02:15, 45.10s/it]Chrome trace exported to: /tmp/trace_58_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_5.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [06:02<01:30, 45.46s/it]Chrome trace exported to: /tmp/trace_66_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_4.json
[36m(head, rank=0, pid=3864)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [06:47<00:45, 45.25s/it]Chrome trace exported to: /tmp/trace_74_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [07:30<00:00, 44.67s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [07:30<00:00, 44.67s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 185.74 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 185.74s (Total: 185.74s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 185.75 secondsCompleted Save checkpoint in 185.75 secondsCompleted Save checkpoint in 185.75 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)Checkpoint save time: 185.75s (Total: 185.75s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 185.75 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 185.75 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 185.75 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 185.75 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 185.75 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 185.75s (Total: 185.75s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 326.84 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 326.84s (Total: 326.84s)
[36m(head, rank=0, pid=3864)[0m 
                                               
{'train_runtime': 777.2569, 'train_samples_per_second': 1.647, 'train_steps_per_second': 0.013, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [12:57<00:00, 44.67s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [12:57<00:00, 77.73s/it]
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_0.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1163.02 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 326.84s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 326.84s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 326.84s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 326.84s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.37s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 363.32s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.54s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.82s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 8.39s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.13s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 22.33s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 22.33s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 22.33s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 22.33s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1163.02s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1163.02s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1163.02s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1163.02s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.54s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.82s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 8.39s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 363.32s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.37s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 326.84s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 326.84s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 326.84s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 326.84s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1187.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1187.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1187.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1187.49s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(head, rank=0, pid=3864)[0m {
[36m(head, rank=0, pid=3864)[0m   "run_id": 1,
[36m(head, rank=0, pid=3864)[0m   "timestamp": "2025-08-03T07:41:59.784827",
[36m(head, rank=0, pid=3864)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3864)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3864)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3864)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3864)[0m   "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3864)[0m   "dataset_load_time": 2.1340391635894775,
[36m(head, rank=0, pid=3864)[0m   "model_load_time": 22.326956510543823,
[36m(head, rank=0, pid=3864)[0m   "training_time": 1163.0245580673218,
[36m(head, rank=0, pid=3864)[0m   "total_time": 1187.485553741455,
[36m(head, rank=0, pid=3864)[0m   "error": null,
[36m(head, rank=0, pid=3864)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m   "total_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m   "average_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m   "min_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m   "max_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3864)[0m     326.8372061252594
[36m(head, rank=0, pid=3864)[0m   ],
[36m(head, rank=0, pid=3864)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m   "total_batch_sample_time": 0.3676140308380127,
[36m(head, rank=0, pid=3864)[0m   "average_batch_sample_time": 0.03676140308380127,
[36m(head, rank=0, pid=3864)[0m   "min_batch_sample_time": 0.030091285705566406,
[36m(head, rank=0, pid=3864)[0m   "max_batch_sample_time": 0.0730123519897461,
[36m(head, rank=0, pid=3864)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3864)[0m     0.0730123519897461,
[36m(head, rank=0, pid=3864)[0m     0.033022403717041016,
[36m(head, rank=0, pid=3864)[0m     0.032224416732788086,
[36m(head, rank=0, pid=3864)[0m     0.03136324882507324,
[36m(head, rank=0, pid=3864)[0m     0.03369593620300293,
[36m(head, rank=0, pid=3864)[0m     0.03087592124938965,
[36m(head, rank=0, pid=3864)[0m     0.034124135971069336,
[36m(head, rank=0, pid=3864)[0m     0.03486132621765137,
[36m(head, rank=0, pid=3864)[0m     0.030091285705566406,
[36m(head, rank=0, pid=3864)[0m     0.03434300422668457
[36m(head, rank=0, pid=3864)[0m   ],
[36m(head, rank=0, pid=3864)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m   "total_training_step_time": 363.319561958313,
[36m(head, rank=0, pid=3864)[0m   "average_training_step_time": 4.541494524478912,
[36m(head, rank=0, pid=3864)[0m   "min_training_step_time": 3.8242111206054688,
[36m(head, rank=0, pid=3864)[0m   "max_training_step_time": 8.39288878440857,
[36m(head, rank=0, pid=3864)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3864)[0m     8.39288878440857,
[36m(head, rank=0, pid=3864)[0m     4.837349891662598,
[36m(head, rank=0, pid=3864)[0m     5.27648401260376,
[36m(head, rank=0, pid=3864)[0m     4.287578105926514,
[36m(head, rank=0, pid=3864)[0m     5.2485191822052,
[36m(head, rank=0, pid=3864)[0m     4.016190767288208,
[36m(head, rank=0, pid=3864)[0m     4.426859378814697,
[36m(head, rank=0, pid=3864)[0m     4.219585418701172,
[36m(head, rank=0, pid=3864)[0m     4.307659149169922,
[36m(head, rank=0, pid=3864)[0m     5.18176794052124,
[36m(head, rank=0, pid=3864)[0m     4.3233888149261475,
[36m(head, rank=0, pid=3864)[0m     4.180347681045532,
[36m(head, rank=0, pid=3864)[0m     4.037775993347168,
[36m(head, rank=0, pid=3864)[0m     5.449738502502441,
[36m(head, rank=0, pid=3864)[0m     4.254331588745117,
[36m(head, rank=0, pid=3864)[0m     4.785634756088257,
[36m(head, rank=0, pid=3864)[0m     4.92850136756897,
[36m(head, rank=0, pid=3864)[0m     4.365365266799927,
[36m(head, rank=0, pid=3864)[0m     4.202784061431885,
[36m(head, rank=0, pid=3864)[0m     4.1940693855285645,
[36m(head, rank=0, pid=3864)[0m     4.778977632522583,
[36m(head, rank=0, pid=3864)[0m     4.155876159667969,
[36m(head, rank=0, pid=3864)[0m     5.1685380935668945,
[36m(head, rank=0, pid=3864)[0m     4.222829818725586,
[36m(head, rank=0, pid=3864)[0m     5.45882773399353,
[36m(head, rank=0, pid=3864)[0m     4.4573235511779785,
[36m(head, rank=0, pid=3864)[0m     4.460582256317139,
[36m(head, rank=0, pid=3864)[0m     4.211920738220215,
[36m(head, rank=0, pid=3864)[0m     4.110219717025757,
[36m(head, rank=0, pid=3864)[0m     4.19789981842041,
[36m(head, rank=0, pid=3864)[0m     4.4385857582092285,
[36m(head, rank=0, pid=3864)[0m     4.846711874008179,
[36m(head, rank=0, pid=3864)[0m     5.365627288818359,
[36m(head, rank=0, pid=3864)[0m     4.365147829055786,
[36m(head, rank=0, pid=3864)[0m     4.554199695587158,
[36m(head, rank=0, pid=3864)[0m     4.586117744445801,
[36m(head, rank=0, pid=3864)[0m     4.765818119049072,
[36m(head, rank=0, pid=3864)[0m     4.649993896484375,
[36m(head, rank=0, pid=3864)[0m     3.8242111206054688,
[36m(head, rank=0, pid=3864)[0m     4.221147060394287,
[36m(head, rank=0, pid=3864)[0m     3.9619927406311035,
[36m(head, rank=0, pid=3864)[0m     4.015509366989136,
[36m(head, rank=0, pid=3864)[0m     5.658488035202026,
[36m(head, rank=0, pid=3864)[0m     4.523710489273071,
[36m(head, rank=0, pid=3864)[0m     4.395962238311768,
[36m(head, rank=0, pid=3864)[0m     4.1561315059661865,
[36m(head, rank=0, pid=3864)[0m     4.215657472610474,
[36m(head, rank=0, pid=3864)[0m     4.306119441986084,
[36m(head, rank=0, pid=3864)[0m     5.2034690380096436,
[36m(head, rank=0, pid=3864)[0m     5.133680582046509,
[36m(head, rank=0, pid=3864)[0m     4.191375732421875,
[36m(head, rank=0, pid=3864)[0m     4.165024042129517,
[36m(head, rank=0, pid=3864)[0m     4.4788665771484375,
[36m(head, rank=0, pid=3864)[0m     4.381201982498169,
[36m(head, rank=0, pid=3864)[0m     4.817064046859741,
[36m(head, rank=0, pid=3864)[0m     3.995034694671631,
[36m(head, rank=0, pid=3864)[0m     5.444278955459595,
[36m(head, rank=0, pid=3864)[0m     4.503037929534912,
[36m(head, rank=0, pid=3864)[0m     4.472434759140015,
[36m(head, rank=0, pid=3864)[0m     4.6967573165893555,
[36m(head, rank=0, pid=3864)[0m     4.35838508605957,
[36m(head, rank=0, pid=3864)[0m     4.187142610549927,
[36m(head, rank=0, pid=3864)[0m     4.162023544311523,
[36m(head, rank=0, pid=3864)[0m     4.911708354949951,
[36m(head, rank=0, pid=3864)[0m     4.082312107086182,
[36m(head, rank=0, pid=3864)[0m     4.009612321853638,
[36m(head, rank=0, pid=3864)[0m     4.228375196456909,
[36m(head, rank=0, pid=3864)[0m     3.950972557067871,
[36m(head, rank=0, pid=3864)[0m     4.625889301300049,
[36m(head, rank=0, pid=3864)[0m     5.4769606590271,
[36m(head, rank=0, pid=3864)[0m     4.399389266967773,
[36m(head, rank=0, pid=3864)[0m     4.405238389968872,
[36m(head, rank=0, pid=3864)[0m     3.9021244049072266,
[36m(head, rank=0, pid=3864)[0m     4.5431969165802,
[36m(head, rank=0, pid=3864)[0m     4.2728354930877686,
[36m(head, rank=0, pid=3864)[0m     4.222481727600098,
[36m(head, rank=0, pid=3864)[0m     4.467930793762207,
[36m(head, rank=0, pid=3864)[0m     4.190685510635376,
[36m(head, rank=0, pid=3864)[0m     4.195856094360352,
[36m(head, rank=0, pid=3864)[0m     4.253268718719482
[36m(head, rank=0, pid=3864)[0m   ]
[36m(head, rank=0, pid=3864)[0m }
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3864)[0m [
[36m(head, rank=0, pid=3864)[0m   {
[36m(head, rank=0, pid=3864)[0m     "run_id": 1,
[36m(head, rank=0, pid=3864)[0m     "timestamp": "2025-08-03T07:41:59.784827",
[36m(head, rank=0, pid=3864)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3864)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3864)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3864)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3864)[0m     "output_dir": "/tmp/checkpoint",
[36m(head, rank=0, pid=3864)[0m     "dataset_load_time": 2.1340391635894775,
[36m(head, rank=0, pid=3864)[0m     "model_load_time": 22.326956510543823,
[36m(head, rank=0, pid=3864)[0m     "training_time": 1163.0245580673218,
[36m(head, rank=0, pid=3864)[0m     "total_time": 1187.485553741455,
[36m(head, rank=0, pid=3864)[0m     "error": null,
[36m(head, rank=0, pid=3864)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m     "total_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "average_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "min_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "max_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3864)[0m       326.8372061252594
[36m(head, rank=0, pid=3864)[0m     ],
[36m(head, rank=0, pid=3864)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m     "total_batch_sample_time": 0.3676140308380127,
[36m(head, rank=0, pid=3864)[0m     "average_batch_sample_time": 0.03676140308380127,
[36m(head, rank=0, pid=3864)[0m     "min_batch_sample_time": 0.030091285705566406,
[36m(head, rank=0, pid=3864)[0m     "max_batch_sample_time": 0.0730123519897461,
[36m(head, rank=0, pid=3864)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3864)[0m       0.0730123519897461,
[36m(head, rank=0, pid=3864)[0m       0.033022403717041016,
[36m(head, rank=0, pid=3864)[0m       0.032224416732788086,
[36m(head, rank=0, pid=3864)[0m       0.03136324882507324,
[36m(head, rank=0, pid=3864)[0m       0.03369593620300293,
[36m(head, rank=0, pid=3864)[0m       0.03087592124938965,
[36m(head, rank=0, pid=3864)[0m       0.034124135971069336,
[36m(head, rank=0, pid=3864)[0m       0.03486132621765137,
[36m(head, rank=0, pid=3864)[0m       0.030091285705566406,
[36m(head, rank=0, pid=3864)[0m       0.03434300422668457
[36m(head, rank=0, pid=3864)[0m     ],
[36m(head, rank=0, pid=3864)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m     "total_training_step_time": 363.319561958313,
[36m(head, rank=0, pid=3864)[0m     "average_training_step_time": 4.541494524478912,
[36m(head, rank=0, pid=3864)[0m     "min_training_step_time": 3.8242111206054688,
[36m(head, rank=0, pid=3864)[0m     "max_training_step_time": 8.39288878440857,
[36m(head, rank=0, pid=3864)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3864)[0m       8.39288878440857,
[36m(head, rank=0, pid=3864)[0m       4.837349891662598,
[36m(head, rank=0, pid=3864)[0m       5.27648401260376,
[36m(head, rank=0, pid=3864)[0m       4.287578105926514,
[36m(head, rank=0, pid=3864)[0m       5.2485191822052,
[36m(head, rank=0, pid=3864)[0m       4.016190767288208,
[36m(head, rank=0, pid=3864)[0m       4.426859378814697,
[36m(head, rank=0, pid=3864)[0m       4.219585418701172,
[36m(head, rank=0, pid=3864)[0m       4.307659149169922,
[36m(head, rank=0, pid=3864)[0m       5.18176794052124,
[36m(head, rank=0, pid=3864)[0m       4.3233888149261475,
[36m(head, rank=0, pid=3864)[0m       4.180347681045532,
[36m(head, rank=0, pid=3864)[0m       4.037775993347168,
[36m(head, rank=0, pid=3864)[0m       5.449738502502441,
[36m(head, rank=0, pid=3864)[0m       4.254331588745117,
[36m(head, rank=0, pid=3864)[0m       4.785634756088257,
[36m(head, rank=0, pid=3864)[0m       4.92850136756897,
[36m(head, rank=0, pid=3864)[0m       4.365365266799927,
[36m(head, rank=0, pid=3864)[0m       4.202784061431885,
[36m(head, rank=0, pid=3864)[0m       4.1940693855285645,
[36m(head, rank=0, pid=3864)[0m       4.778977632522583,
[36m(head, rank=0, pid=3864)[0m       4.155876159667969,
[36m(head, rank=0, pid=3864)[0m       5.1685380935668945,
[36m(head, rank=0, pid=3864)[0m       4.222829818725586,
[36m(head, rank=0, pid=3864)[0m       5.45882773399353,
[36m(head, rank=0, pid=3864)[0m       4.4573235511779785,
[36m(head, rank=0, pid=3864)[0m       4.460582256317139,
[36m(head, rank=0, pid=3864)[0m       4.211920738220215,
[36m(head, rank=0, pid=3864)[0m       4.110219717025757,
[36m(head, rank=0, pid=3864)[0m       4.19789981842041,
[36m(head, rank=0, pid=3864)[0m       4.4385857582092285,
[36m(head, rank=0, pid=3864)[0m       4.846711874008179,
[36m(head, rank=0, pid=3864)[0m       5.365627288818359,
[36m(head, rank=0, pid=3864)[0m       4.365147829055786,
[36m(head, rank=0, pid=3864)[0m       4.554199695587158,
[36m(head, rank=0, pid=3864)[0m       4.586117744445801,
[36m(head, rank=0, pid=3864)[0m       4.765818119049072,
[36m(head, rank=0, pid=3864)[0m       4.649993896484375,
[36m(head, rank=0, pid=3864)[0m       3.8242111206054688,
[36m(head, rank=0, pid=3864)[0m       4.221147060394287,
[36m(head, rank=0, pid=3864)[0m       3.9619927406311035,
[36m(head, rank=0, pid=3864)[0m       4.015509366989136,
[36m(head, rank=0, pid=3864)[0m       5.658488035202026,
[36m(head, rank=0, pid=3864)[0m       4.523710489273071,
[36m(head, rank=0, pid=3864)[0m       4.395962238311768,
[36m(head, rank=0, pid=3864)[0m       4.1561315059661865,
[36m(head, rank=0, pid=3864)[0m       4.215657472610474,
[36m(head, rank=0, pid=3864)[0m       4.306119441986084,
[36m(head, rank=0, pid=3864)[0m       5.2034690380096436,
[36m(head, rank=0, pid=3864)[0m       5.133680582046509,
[36m(head, rank=0, pid=3864)[0m       4.191375732421875,
[36m(head, rank=0, pid=3864)[0m       4.165024042129517,
[36m(head, rank=0, pid=3864)[0m       4.4788665771484375,
[36m(head, rank=0, pid=3864)[0m       4.381201982498169,
[36m(head, rank=0, pid=3864)[0m       4.817064046859741,
[36m(head, rank=0, pid=3864)[0m       3.995034694671631,
[36m(head, rank=0, pid=3864)[0m       5.444278955459595,
[36m(head, rank=0, pid=3864)[0m       4.503037929534912,
[36m(head, rank=0, pid=3864)[0m       4.472434759140015,
[36m(head, rank=0, pid=3864)[0m       4.6967573165893555,
[36m(head, rank=0, pid=3864)[0m       4.35838508605957,
[36m(head, rank=0, pid=3864)[0m       4.187142610549927,
[36m(head, rank=0, pid=3864)[0m       4.162023544311523,
[36m(head, rank=0, pid=3864)[0m       4.911708354949951,
[36m(head, rank=0, pid=3864)[0m       4.082312107086182,
[36m(head, rank=0, pid=3864)[0m       4.009612321853638,
[36m(head, rank=0, pid=3864)[0m       4.228375196456909,
[36m(head, rank=0, pid=3864)[0m       3.950972557067871,
[36m(head, rank=0, pid=3864)[0m       4.625889301300049,
[36m(head, rank=0, pid=3864)[0m       5.4769606590271,
[36m(head, rank=0, pid=3864)[0m       4.399389266967773,
[36m(head, rank=0, pid=3864)[0m       4.405238389968872,
[36m(head, rank=0, pid=3864)[0m       3.9021244049072266,
[36m(head, rank=0, pid=3864)[0m       4.5431969165802,
[36m(head, rank=0, pid=3864)[0m       4.2728354930877686,
[36m(head, rank=0, pid=3864)[0m       4.222481727600098,
[36m(head, rank=0, pid=3864)[0m       4.467930793762207,
[36m(head, rank=0, pid=3864)[0m       4.190685510635376,
[36m(head, rank=0, pid=3864)[0m       4.195856094360352,
[36m(head, rank=0, pid=3864)[0m       4.253268718719482
[36m(head, rank=0, pid=3864)[0m     ]
[36m(head, rank=0, pid=3864)[0m   }
[36m(head, rank=0, pid=3864)[0m ]
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3864)[0m {
[36m(head, rank=0, pid=3864)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3864)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3864)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_average": 2.1340391635894775,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_min": 2.1340391635894775,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_max": 2.1340391635894775,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_total": 2.1340391635894775
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "model_loading": {
[36m(head, rank=0, pid=3864)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3864)[0m     "model_load_average": 22.326956510543823,
[36m(head, rank=0, pid=3864)[0m     "model_load_min": 22.326956510543823,
[36m(head, rank=0, pid=3864)[0m     "model_load_max": 22.326956510543823,
[36m(head, rank=0, pid=3864)[0m     "model_load_total": 22.326956510543823
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "training": {
[36m(head, rank=0, pid=3864)[0m     "training_count": 1,
[36m(head, rank=0, pid=3864)[0m     "training_average": 1163.0245580673218,
[36m(head, rank=0, pid=3864)[0m     "training_min": 1163.0245580673218,
[36m(head, rank=0, pid=3864)[0m     "training_max": 1163.0245580673218,
[36m(head, rank=0, pid=3864)[0m     "training_total": 1163.0245580673218
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "total_run_time": {
[36m(head, rank=0, pid=3864)[0m     "total_count": 1,
[36m(head, rank=0, pid=3864)[0m     "total_average": 1187.485553741455,
[36m(head, rank=0, pid=3864)[0m     "total_min": 1187.485553741455,
[36m(head, rank=0, pid=3864)[0m     "total_max": 1187.485553741455,
[36m(head, rank=0, pid=3864)[0m     "total_total": 1187.485553741455
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3864)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m     "total_checkpoint_save_time": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "average_save_time_per_checkpoint": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_min": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_max": 326.8372061252594,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_average": 326.8372061252594
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3864)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m     "total_batch_sample_time": 0.3676140308380127,
[36m(head, rank=0, pid=3864)[0m     "average_sample_time_per_batch": 0.03676140308380127,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_min": 0.030091285705566406,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_max": 0.0730123519897461,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_average": 0.03676140308380127
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "training_steps": {
[36m(head, rank=0, pid=3864)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m     "total_training_step_time": 363.319561958313,
[36m(head, rank=0, pid=3864)[0m     "average_step_time_per_step": 4.541494524478912,
[36m(head, rank=0, pid=3864)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3864)[0m     "training_step_min": 3.8242111206054688,
[36m(head, rank=0, pid=3864)[0m     "training_step_max": 8.39288878440857,
[36m(head, rank=0, pid=3864)[0m     "training_step_average": 4.541494524478912
[36m(head, rank=0, pid=3864)[0m   }
[36m(head, rank=0, pid=3864)[0m }
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1208.58 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 367.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.83s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1209.51 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 367.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.86s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.18s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_3.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1209.28 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 367.10s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.59s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.95s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.20s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1208.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1208.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1208.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1208.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.83s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 367.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1211.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1211.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1211.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1211.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_4.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1209.37 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 366.66s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.58s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.87s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.20s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.44s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.44s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.44s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.44s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.06s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1209.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1209.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1209.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1209.28s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.59s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.95s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.20s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 367.10s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.36s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1212.78s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1212.78s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1212.78s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1212.78s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.14s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.14s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.14s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.14s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.07s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1209.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1209.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1209.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1209.37s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.87s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.20s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 366.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1212.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1212.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1212.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1212.58s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_1.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1209.55 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 366.30s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.58s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.85s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.26s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.15s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.15s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.15s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.15s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.14s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.14s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.14s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.14s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1209.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1209.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1209.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1209.55s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.85s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 366.30s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1212.84s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1212.84s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1212.84s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1212.84s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.92s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.92s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.92s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.92s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1209.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1209.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1209.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1209.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.86s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.18s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 367.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1212.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1212.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1212.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1212.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1189.45 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 362.78s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 8.27s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 22.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 22.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 22.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 22.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1189.45s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1189.45s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1189.45s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1189.45s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 8.27s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 362.78s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- Training Run 1 Info (Directory: /tmp/checkpoint) ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "timestamp": "2025-08-03T07:41:59.784906",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_load_time": 2.131533622741699,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_load_time": 22.06537699699402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_time": 1189.4533994197845,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_time": 1213.6503100395203,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "error": null,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     185.74557971954346
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_batch_sample_time": 0.3782999515533447,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_batch_sample_time": 0.03782999515533447,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_batch_sample_time": 0.027328014373779297,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_batch_sample_time": 0.09129071235656738,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.09129071235656738,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.027328014373779297,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.033164262771606445,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.033576250076293945,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03298830986022949,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03368067741394043,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.033550262451171875,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.028804779052734375,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03402972221374512,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.029886960983276367
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_training_step_time": 362.7846875190735,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_training_step_time": 4.534808593988418,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_training_step_time": 3.7861807346343994,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_training_step_time": 8.269468545913696,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     8.269468545913696,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.444729328155518,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.277886629104614,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.288489103317261,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.278280735015869,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.017553329467773,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.285006284713745,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.21777606010437,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.261953353881836,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.154100179672241,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.267120599746704,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.1817755699157715,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.038748264312744,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.450480222702026,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.19293737411499,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.293026685714722,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.877745151519775,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.366795778274536,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.319214820861816,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.192818880081177,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.798383712768555,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.15544867515564,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.229400634765625,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.223617076873779,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.461918354034424,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.555965423583984,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.548910856246948,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.211530685424805,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.962031602859497,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.196866512298584,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.377803564071655,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.847040414810181,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.41030478477478,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.365460395812988,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.6470701694488525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.5849289894104,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.763830661773682,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.606563329696655,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7861807346343994,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.220665216445923,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.867497205734253,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.164196252822876,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.593490839004517,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.525241136550903,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.4218056201934814,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.151883125305176,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.117833852767944,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.307265281677246,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.204134464263916,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.1340954303741455,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.169450044631958,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.166085958480835,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.476494073867798,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.290079355239868,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.793471097946167,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.996131181716919,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.458806276321411,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.506389856338501,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.420628547668457,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.675766468048096,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.210689544677734,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.190542936325073,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.19067645072937,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.811284780502319,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.086835145950317,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.921872138977051,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.3063063621521,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.035970449447632,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.625538349151611,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.478317737579346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.411034345626831,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.411690950393677,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.045399904251099,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.586410284042358,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.181753396987915,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.226308107376099,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.388538599014282,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.167248249053955,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.182418346405029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.255276679992676
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "timestamp": "2025-08-03T07:41:59.784906",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "output_dir": "/tmp/checkpoint",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_time": 2.131533622741699,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_time": 22.06537699699402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_time": 1189.4533994197845,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_time": 1213.6503100395203,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "error": null,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       185.74557971954346
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_sample_time": 0.3782999515533447,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_batch_sample_time": 0.03782999515533447,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_batch_sample_time": 0.027328014373779297,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_batch_sample_time": 0.09129071235656738,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.09129071235656738,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.027328014373779297,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.033164262771606445,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.033576250076293945,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03298830986022949,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03368067741394043,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.033550262451171875,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.028804779052734375,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03402972221374512,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.029886960983276367
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_step_time": 362.7846875190735,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_training_step_time": 4.534808593988418,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_training_step_time": 3.7861807346343994,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_training_step_time": 8.269468545913696,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       8.269468545913696,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.444729328155518,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.277886629104614,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.288489103317261,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.278280735015869,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.017553329467773,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.285006284713745,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.21777606010437,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.261953353881836,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.154100179672241,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.267120599746704,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.1817755699157715,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.038748264312744,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.450480222702026,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.19293737411499,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.293026685714722,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.877745151519775,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.366795778274536,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.319214820861816,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.192818880081177,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.798383712768555,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.15544867515564,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.229400634765625,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.223617076873779,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.461918354034424,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.555965423583984,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.548910856246948,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.211530685424805,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.962031602859497,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.196866512298584,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.377803564071655,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.847040414810181,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.41030478477478,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.365460395812988,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.6470701694488525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.5849289894104,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.763830661773682,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.606563329696655,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7861807346343994,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.220665216445923,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.867497205734253,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.164196252822876,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.593490839004517,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.525241136550903,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.4218056201934814,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.151883125305176,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.117833852767944,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.307265281677246,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.204134464263916,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.1340954303741455,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.169450044631958,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.166085958480835,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.476494073867798,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.290079355239868,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.793471097946167,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.996131181716919,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.458806276321411,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.506389856338501,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.420628547668457,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.675766468048096,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.210689544677734,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.190542936325073,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.19067645072937,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.811284780502319,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.086835145950317,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.921872138977051,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.3063063621521,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.035970449447632,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.625538349151611,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.478317737579346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.411034345626831,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.411690950393677,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.045399904251099,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.586410284042358,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.181753396987915,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.226308107376099,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.388538599014282,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.167248249053955,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.182418346405029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.255276679992676
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_average": 2.131533622741699,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_min": 2.131533622741699,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_max": 2.131533622741699,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_total": 2.131533622741699
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_average": 22.06537699699402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_min": 22.06537699699402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_max": 22.06537699699402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_total": 22.06537699699402
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_average": 1189.4533994197845,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_min": 1189.4533994197845,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_max": 1189.4533994197845,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_total": 1189.4533994197845
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_average": 1213.6503100395203,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_min": 1213.6503100395203,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_max": 1213.6503100395203,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_total": 1213.6503100395203
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoint_save_time": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_save_time_per_checkpoint": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_min": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_max": 185.74557971954346,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_average": 185.74557971954346
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_sample_time": 0.3782999515533447,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_sample_time_per_batch": 0.03782999515533447,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_min": 0.027328014373779297,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_max": 0.09129071235656738,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_average": 0.03782999515533447
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_step_time": 362.7846875190735,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_step_time_per_step": 4.534808593988418,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_min": 3.7861807346343994,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_max": 8.269468545913696,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_average": 4.534808593988418
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1210.04 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 365.76s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.88s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1210.24 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 365.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1210.27 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 365.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.86s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.18s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_2.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1210.40 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 364.90s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.56s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.83s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.26s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1210.30 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 365.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1210.72 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 365.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.13s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 0.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 0.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 0.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 0.94s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1210.40s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1210.40s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1210.40s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1210.40s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.83s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 364.90s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1213.46s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1213.46s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1213.46s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1213.46s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_5.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1210.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.36s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 366.08s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.58s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.79s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.20s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_7.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1210.81 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 364.73s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.56s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.80s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.37s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.15s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.15s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.15s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.15s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.08s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1210.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1210.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1210.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1210.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.79s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.20s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 366.08s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.36s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1213.88s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1213.88s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1213.88s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1213.88s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.18s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.18s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.18s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.18s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 0.93s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 0.93s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 0.93s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 0.93s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1210.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1210.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1210.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1210.81s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 364.73s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1213.92s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1213.92s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1213.92s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1213.92s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_6.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1210.99 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 364.75s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.56s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.83s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 10.21s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1210.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1210.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1210.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1210.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.88s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 365.76s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1213.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1213.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1213.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1213.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1210.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1210.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1210.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1210.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 365.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1213.48s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1213.48s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1213.48s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1213.48s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.13s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 0.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 0.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 0.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 0.94s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1210.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1210.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1210.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1210.99s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.83s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 10.21s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 364.75s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.35s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 185.74s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 185.74s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1214.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1214.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1214.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1214.06s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1210.27s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1210.27s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1210.27s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1210.27s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.86s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.18s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 365.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1213.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.50s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.50s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.50s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.50s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1210.30s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1210.30s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1210.30s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1210.30s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 365.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1213.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1213.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1213.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1213.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1210.72s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1210.72s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1210.72s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1210.72s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.79s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 10.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 365.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 185.75s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1213.81s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1213.81s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1213.81s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1213.81s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3864)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: 'pytorch_model-00001-of-00012.bin'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.21 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.22 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.23 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.25 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.28 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.32 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.32 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.38 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.05 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.05 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.24 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.24 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.26 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.30 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.47 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 67.39it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 70.70it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 72.40it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 64.48it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 57.40it/s]
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.65it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 70.27it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.98 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.09 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.03 seconds
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 67.90it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.86it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.49it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 62.56it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 61.44it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 58.51it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.02 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.06 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 66.87it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.11 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.17 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.03 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:21,  5.45s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:22,  5.60s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:15,  5.24s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:16,  5.40s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:15<00:10,  5.14s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:10,  5.33s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:20<00:05,  5.05s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  4.89s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.02s/it]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 26.05 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:21<00:05,  5.24s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.02s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:25<00:00,  5.17s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 26.64 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:05,400] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,764] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,766] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,769] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,770] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,774] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,777] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,781] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:06,839] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,217] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,232] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,232] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,232] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,233] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,233] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,235] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:07,237] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:07,952] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:07,956] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:08,041] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:08,064] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:08,067] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:08,070] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:04:08,091] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,271] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,474] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,489] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,490] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,491] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,498] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,506] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:04:08,516] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_5.json
[36m(head, rank=0, pid=3864)[0m  10%|â–ˆ         | 1/10 [00:39<05:53, 39.25s/it]Chrome trace exported to: /tmp/trace_10_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:20<05:22, 40.36s/it]Chrome trace exported to: /tmp/trace_18_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [02:00<04:42, 40.39s/it]Chrome trace exported to: /tmp/trace_26_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:41<04:02, 40.49s/it]Chrome trace exported to: /tmp/trace_34_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_0.json
[36m(head, rank=0, pid=3864)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:23<03:25, 41.17s/it]Chrome trace exported to: /tmp/trace_42_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_5.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [04:04<02:43, 40.95s/it]Chrome trace exported to: /tmp/trace_50_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_2.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:46<02:04, 41.38s/it]Chrome trace exported to: /tmp/trace_58_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [05:29<01:23, 41.84s/it]Chrome trace exported to: /tmp/trace_66_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_6.json
[36m(head, rank=0, pid=3864)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [06:10<00:41, 41.66s/it]Chrome trace exported to: /tmp/trace_74_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:50<00:00, 41.20s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:50<00:00, 41.20s/it]Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.51 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.51 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.51 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.51 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.52 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.52 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.52 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 378.52 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.51 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.51 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.51 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.51 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.51s (Total: 378.51s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.52 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.52 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 378.52 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 378.52s (Total: 378.52s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 679.96 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 679.96s (Total: 679.96s)
[36m(head, rank=0, pid=3864)[0m 
                                               
{'train_runtime': 1090.8574, 'train_samples_per_second': 1.173, 'train_steps_per_second': 0.009, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [18:10<00:00, 41.20s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [18:10<00:00, 109.09s/it]
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_0.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1129.57 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 679.96s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 679.96s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 679.96s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 679.96s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.53s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 325.89s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.07s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 5.22s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.32s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.32s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.32s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.32s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 26.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 26.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 26.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 26.05s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1129.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1129.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1129.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1129.57s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 5.22s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 325.89s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.53s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 679.96s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 679.96s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 679.96s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 679.96s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1157.95s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1157.95s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1157.95s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1157.95s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(head, rank=0, pid=3864)[0m {
[36m(head, rank=0, pid=3864)[0m   "run_id": 1,
[36m(head, rank=0, pid=3864)[0m   "timestamp": "2025-08-03T08:03:33.505187",
[36m(head, rank=0, pid=3864)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3864)[0m   "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3864)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3864)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3864)[0m   "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3864)[0m   "dataset_load_time": 2.324483633041382,
[36m(head, rank=0, pid=3864)[0m   "model_load_time": 26.052084922790527,
[36m(head, rank=0, pid=3864)[0m   "training_time": 1129.5736055374146,
[36m(head, rank=0, pid=3864)[0m   "total_time": 1157.9501740932465,
[36m(head, rank=0, pid=3864)[0m   "error": null,
[36m(head, rank=0, pid=3864)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m   "total_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m   "average_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m   "min_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m   "max_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3864)[0m     679.9598314762115
[36m(head, rank=0, pid=3864)[0m   ],
[36m(head, rank=0, pid=3864)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m   "total_batch_sample_time": 0.526160717010498,
[36m(head, rank=0, pid=3864)[0m   "average_batch_sample_time": 0.0526160717010498,
[36m(head, rank=0, pid=3864)[0m   "min_batch_sample_time": 0.03436684608459473,
[36m(head, rank=0, pid=3864)[0m   "max_batch_sample_time": 0.1237635612487793,
[36m(head, rank=0, pid=3864)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3864)[0m     0.1237635612487793,
[36m(head, rank=0, pid=3864)[0m     0.06051135063171387,
[36m(head, rank=0, pid=3864)[0m     0.06859803199768066,
[36m(head, rank=0, pid=3864)[0m     0.03970026969909668,
[36m(head, rank=0, pid=3864)[0m     0.04870343208312988,
[36m(head, rank=0, pid=3864)[0m     0.036530494689941406,
[36m(head, rank=0, pid=3864)[0m     0.04076981544494629,
[36m(head, rank=0, pid=3864)[0m     0.03837323188781738,
[36m(head, rank=0, pid=3864)[0m     0.03484368324279785,
[36m(head, rank=0, pid=3864)[0m     0.03436684608459473
[36m(head, rank=0, pid=3864)[0m   ],
[36m(head, rank=0, pid=3864)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m   "total_training_step_time": 325.88842964172363,
[36m(head, rank=0, pid=3864)[0m   "average_training_step_time": 4.073605370521546,
[36m(head, rank=0, pid=3864)[0m   "min_training_step_time": 3.563748598098755,
[36m(head, rank=0, pid=3864)[0m   "max_training_step_time": 5.220434665679932,
[36m(head, rank=0, pid=3864)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3864)[0m     5.220434665679932,
[36m(head, rank=0, pid=3864)[0m     4.132154226303101,
[36m(head, rank=0, pid=3864)[0m     4.385087490081787,
[36m(head, rank=0, pid=3864)[0m     3.6746861934661865,
[36m(head, rank=0, pid=3864)[0m     4.695443391799927,
[36m(head, rank=0, pid=3864)[0m     3.8757264614105225,
[36m(head, rank=0, pid=3864)[0m     3.5658762454986572,
[36m(head, rank=0, pid=3864)[0m     3.709458112716675,
[36m(head, rank=0, pid=3864)[0m     4.029959440231323,
[36m(head, rank=0, pid=3864)[0m     4.684859991073608,
[36m(head, rank=0, pid=3864)[0m     3.8487844467163086,
[36m(head, rank=0, pid=3864)[0m     3.7031421661376953,
[36m(head, rank=0, pid=3864)[0m     3.698620080947876,
[36m(head, rank=0, pid=3864)[0m     4.965776681900024,
[36m(head, rank=0, pid=3864)[0m     3.7431766986846924,
[36m(head, rank=0, pid=3864)[0m     4.108020782470703,
[36m(head, rank=0, pid=3864)[0m     4.160543441772461,
[36m(head, rank=0, pid=3864)[0m     3.7379605770111084,
[36m(head, rank=0, pid=3864)[0m     4.06437873840332,
[36m(head, rank=0, pid=3864)[0m     3.710864543914795,
[36m(head, rank=0, pid=3864)[0m     4.3051440715789795,
[36m(head, rank=0, pid=3864)[0m     3.7046587467193604,
[36m(head, rank=0, pid=3864)[0m     4.974995851516724,
[36m(head, rank=0, pid=3864)[0m     3.731910228729248,
[36m(head, rank=0, pid=3864)[0m     5.013312578201294,
[36m(head, rank=0, pid=3864)[0m     3.614307403564453,
[36m(head, rank=0, pid=3864)[0m     4.009869813919067,
[36m(head, rank=0, pid=3864)[0m     3.754817008972168,
[36m(head, rank=0, pid=3864)[0m     3.714132308959961,
[36m(head, rank=0, pid=3864)[0m     3.7119081020355225,
[36m(head, rank=0, pid=3864)[0m     4.045522689819336,
[36m(head, rank=0, pid=3864)[0m     4.3730103969573975,
[36m(head, rank=0, pid=3864)[0m     4.696900129318237,
[36m(head, rank=0, pid=3864)[0m     3.890624523162842,
[36m(head, rank=0, pid=3864)[0m     4.002564430236816,
[36m(head, rank=0, pid=3864)[0m     4.165008544921875,
[36m(head, rank=0, pid=3864)[0m     4.527897119522095,
[36m(head, rank=0, pid=3864)[0m     4.450897455215454,
[36m(head, rank=0, pid=3864)[0m     3.8721580505371094,
[36m(head, rank=0, pid=3864)[0m     3.877652168273926,
[36m(head, rank=0, pid=3864)[0m     3.7192416191101074,
[36m(head, rank=0, pid=3864)[0m     3.563748598098755,
[36m(head, rank=0, pid=3864)[0m     5.103281021118164,
[36m(head, rank=0, pid=3864)[0m     3.740351915359497,
[36m(head, rank=0, pid=3864)[0m     3.935568332672119,
[36m(head, rank=0, pid=3864)[0m     3.9275808334350586,
[36m(head, rank=0, pid=3864)[0m     3.9577853679656982,
[36m(head, rank=0, pid=3864)[0m     3.8977224826812744,
[36m(head, rank=0, pid=3864)[0m     4.805358409881592,
[36m(head, rank=0, pid=3864)[0m     4.809439659118652,
[36m(head, rank=0, pid=3864)[0m     3.8234024047851562,
[36m(head, rank=0, pid=3864)[0m     3.7072861194610596,
[36m(head, rank=0, pid=3864)[0m     3.975581169128418,
[36m(head, rank=0, pid=3864)[0m     3.7096261978149414,
[36m(head, rank=0, pid=3864)[0m     4.68545937538147,
[36m(head, rank=0, pid=3864)[0m     3.7241406440734863,
[36m(head, rank=0, pid=3864)[0m     5.061465263366699,
[36m(head, rank=0, pid=3864)[0m     4.345308542251587,
[36m(head, rank=0, pid=3864)[0m     4.12170934677124,
[36m(head, rank=0, pid=3864)[0m     4.178555011749268,
[36m(head, rank=0, pid=3864)[0m     3.712604284286499,
[36m(head, rank=0, pid=3864)[0m     3.7555394172668457,
[36m(head, rank=0, pid=3864)[0m     4.002589702606201,
[36m(head, rank=0, pid=3864)[0m     4.494260549545288,
[36m(head, rank=0, pid=3864)[0m     3.6973116397857666,
[36m(head, rank=0, pid=3864)[0m     3.697910785675049,
[36m(head, rank=0, pid=3864)[0m     3.850140333175659,
[36m(head, rank=0, pid=3864)[0m     3.589247941970825,
[36m(head, rank=0, pid=3864)[0m     4.277975797653198,
[36m(head, rank=0, pid=3864)[0m     4.845205783843994,
[36m(head, rank=0, pid=3864)[0m     4.043187379837036,
[36m(head, rank=0, pid=3864)[0m     3.952653169631958,
[36m(head, rank=0, pid=3864)[0m     3.590833902359009,
[36m(head, rank=0, pid=3864)[0m     4.186796188354492,
[36m(head, rank=0, pid=3864)[0m     3.9784963130950928,
[36m(head, rank=0, pid=3864)[0m     4.05401086807251,
[36m(head, rank=0, pid=3864)[0m     3.9549965858459473,
[36m(head, rank=0, pid=3864)[0m     3.717609405517578,
[36m(head, rank=0, pid=3864)[0m     3.8235855102539062,
[36m(head, rank=0, pid=3864)[0m     3.718615770339966
[36m(head, rank=0, pid=3864)[0m   ]
[36m(head, rank=0, pid=3864)[0m }
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3864)[0m [
[36m(head, rank=0, pid=3864)[0m   {
[36m(head, rank=0, pid=3864)[0m     "run_id": 1,
[36m(head, rank=0, pid=3864)[0m     "timestamp": "2025-08-03T08:03:33.505187",
[36m(head, rank=0, pid=3864)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3864)[0m     "checkpoint_dir": "/mnt/data",
[36m(head, rank=0, pid=3864)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3864)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3864)[0m     "output_dir": "/mnt/data",
[36m(head, rank=0, pid=3864)[0m     "dataset_load_time": 2.324483633041382,
[36m(head, rank=0, pid=3864)[0m     "model_load_time": 26.052084922790527,
[36m(head, rank=0, pid=3864)[0m     "training_time": 1129.5736055374146,
[36m(head, rank=0, pid=3864)[0m     "total_time": 1157.9501740932465,
[36m(head, rank=0, pid=3864)[0m     "error": null,
[36m(head, rank=0, pid=3864)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m     "total_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "average_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "min_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "max_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3864)[0m       679.9598314762115
[36m(head, rank=0, pid=3864)[0m     ],
[36m(head, rank=0, pid=3864)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m     "total_batch_sample_time": 0.526160717010498,
[36m(head, rank=0, pid=3864)[0m     "average_batch_sample_time": 0.0526160717010498,
[36m(head, rank=0, pid=3864)[0m     "min_batch_sample_time": 0.03436684608459473,
[36m(head, rank=0, pid=3864)[0m     "max_batch_sample_time": 0.1237635612487793,
[36m(head, rank=0, pid=3864)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3864)[0m       0.1237635612487793,
[36m(head, rank=0, pid=3864)[0m       0.06051135063171387,
[36m(head, rank=0, pid=3864)[0m       0.06859803199768066,
[36m(head, rank=0, pid=3864)[0m       0.03970026969909668,
[36m(head, rank=0, pid=3864)[0m       0.04870343208312988,
[36m(head, rank=0, pid=3864)[0m       0.036530494689941406,
[36m(head, rank=0, pid=3864)[0m       0.04076981544494629,
[36m(head, rank=0, pid=3864)[0m       0.03837323188781738,
[36m(head, rank=0, pid=3864)[0m       0.03484368324279785,
[36m(head, rank=0, pid=3864)[0m       0.03436684608459473
[36m(head, rank=0, pid=3864)[0m     ],
[36m(head, rank=0, pid=3864)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m     "total_training_step_time": 325.88842964172363,
[36m(head, rank=0, pid=3864)[0m     "average_training_step_time": 4.073605370521546,
[36m(head, rank=0, pid=3864)[0m     "min_training_step_time": 3.563748598098755,
[36m(head, rank=0, pid=3864)[0m     "max_training_step_time": 5.220434665679932,
[36m(head, rank=0, pid=3864)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3864)[0m       5.220434665679932,
[36m(head, rank=0, pid=3864)[0m       4.132154226303101,
[36m(head, rank=0, pid=3864)[0m       4.385087490081787,
[36m(head, rank=0, pid=3864)[0m       3.6746861934661865,
[36m(head, rank=0, pid=3864)[0m       4.695443391799927,
[36m(head, rank=0, pid=3864)[0m       3.8757264614105225,
[36m(head, rank=0, pid=3864)[0m       3.5658762454986572,
[36m(head, rank=0, pid=3864)[0m       3.709458112716675,
[36m(head, rank=0, pid=3864)[0m       4.029959440231323,
[36m(head, rank=0, pid=3864)[0m       4.684859991073608,
[36m(head, rank=0, pid=3864)[0m       3.8487844467163086,
[36m(head, rank=0, pid=3864)[0m       3.7031421661376953,
[36m(head, rank=0, pid=3864)[0m       3.698620080947876,
[36m(head, rank=0, pid=3864)[0m       4.965776681900024,
[36m(head, rank=0, pid=3864)[0m       3.7431766986846924,
[36m(head, rank=0, pid=3864)[0m       4.108020782470703,
[36m(head, rank=0, pid=3864)[0m       4.160543441772461,
[36m(head, rank=0, pid=3864)[0m       3.7379605770111084,
[36m(head, rank=0, pid=3864)[0m       4.06437873840332,
[36m(head, rank=0, pid=3864)[0m       3.710864543914795,
[36m(head, rank=0, pid=3864)[0m       4.3051440715789795,
[36m(head, rank=0, pid=3864)[0m       3.7046587467193604,
[36m(head, rank=0, pid=3864)[0m       4.974995851516724,
[36m(head, rank=0, pid=3864)[0m       3.731910228729248,
[36m(head, rank=0, pid=3864)[0m       5.013312578201294,
[36m(head, rank=0, pid=3864)[0m       3.614307403564453,
[36m(head, rank=0, pid=3864)[0m       4.009869813919067,
[36m(head, rank=0, pid=3864)[0m       3.754817008972168,
[36m(head, rank=0, pid=3864)[0m       3.714132308959961,
[36m(head, rank=0, pid=3864)[0m       3.7119081020355225,
[36m(head, rank=0, pid=3864)[0m       4.045522689819336,
[36m(head, rank=0, pid=3864)[0m       4.3730103969573975,
[36m(head, rank=0, pid=3864)[0m       4.696900129318237,
[36m(head, rank=0, pid=3864)[0m       3.890624523162842,
[36m(head, rank=0, pid=3864)[0m       4.002564430236816,
[36m(head, rank=0, pid=3864)[0m       4.165008544921875,
[36m(head, rank=0, pid=3864)[0m       4.527897119522095,
[36m(head, rank=0, pid=3864)[0m       4.450897455215454,
[36m(head, rank=0, pid=3864)[0m       3.8721580505371094,
[36m(head, rank=0, pid=3864)[0m       3.877652168273926,
[36m(head, rank=0, pid=3864)[0m       3.7192416191101074,
[36m(head, rank=0, pid=3864)[0m       3.563748598098755,
[36m(head, rank=0, pid=3864)[0m       5.103281021118164,
[36m(head, rank=0, pid=3864)[0m       3.740351915359497,
[36m(head, rank=0, pid=3864)[0m       3.935568332672119,
[36m(head, rank=0, pid=3864)[0m       3.9275808334350586,
[36m(head, rank=0, pid=3864)[0m       3.9577853679656982,
[36m(head, rank=0, pid=3864)[0m       3.8977224826812744,
[36m(head, rank=0, pid=3864)[0m       4.805358409881592,
[36m(head, rank=0, pid=3864)[0m       4.809439659118652,
[36m(head, rank=0, pid=3864)[0m       3.8234024047851562,
[36m(head, rank=0, pid=3864)[0m       3.7072861194610596,
[36m(head, rank=0, pid=3864)[0m       3.975581169128418,
[36m(head, rank=0, pid=3864)[0m       3.7096261978149414,
[36m(head, rank=0, pid=3864)[0m       4.68545937538147,
[36m(head, rank=0, pid=3864)[0m       3.7241406440734863,
[36m(head, rank=0, pid=3864)[0m       5.061465263366699,
[36m(head, rank=0, pid=3864)[0m       4.345308542251587,
[36m(head, rank=0, pid=3864)[0m       4.12170934677124,
[36m(head, rank=0, pid=3864)[0m       4.178555011749268,
[36m(head, rank=0, pid=3864)[0m       3.712604284286499,
[36m(head, rank=0, pid=3864)[0m       3.7555394172668457,
[36m(head, rank=0, pid=3864)[0m       4.002589702606201,
[36m(head, rank=0, pid=3864)[0m       4.494260549545288,
[36m(head, rank=0, pid=3864)[0m       3.6973116397857666,
[36m(head, rank=0, pid=3864)[0m       3.697910785675049,
[36m(head, rank=0, pid=3864)[0m       3.850140333175659,
[36m(head, rank=0, pid=3864)[0m       3.589247941970825,
[36m(head, rank=0, pid=3864)[0m       4.277975797653198,
[36m(head, rank=0, pid=3864)[0m       4.845205783843994,
[36m(head, rank=0, pid=3864)[0m       4.043187379837036,
[36m(head, rank=0, pid=3864)[0m       3.952653169631958,
[36m(head, rank=0, pid=3864)[0m       3.590833902359009,
[36m(head, rank=0, pid=3864)[0m       4.186796188354492,
[36m(head, rank=0, pid=3864)[0m       3.9784963130950928,
[36m(head, rank=0, pid=3864)[0m       4.05401086807251,
[36m(head, rank=0, pid=3864)[0m       3.9549965858459473,
[36m(head, rank=0, pid=3864)[0m       3.717609405517578,
[36m(head, rank=0, pid=3864)[0m       3.8235855102539062,
[36m(head, rank=0, pid=3864)[0m       3.718615770339966
[36m(head, rank=0, pid=3864)[0m     ]
[36m(head, rank=0, pid=3864)[0m   }
[36m(head, rank=0, pid=3864)[0m ]
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3864)[0m {
[36m(head, rank=0, pid=3864)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3864)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3864)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_average": 2.324483633041382,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_min": 2.324483633041382,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_max": 2.324483633041382,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_total": 2.324483633041382
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "model_loading": {
[36m(head, rank=0, pid=3864)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3864)[0m     "model_load_average": 26.052084922790527,
[36m(head, rank=0, pid=3864)[0m     "model_load_min": 26.052084922790527,
[36m(head, rank=0, pid=3864)[0m     "model_load_max": 26.052084922790527,
[36m(head, rank=0, pid=3864)[0m     "model_load_total": 26.052084922790527
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "training": {
[36m(head, rank=0, pid=3864)[0m     "training_count": 1,
[36m(head, rank=0, pid=3864)[0m     "training_average": 1129.5736055374146,
[36m(head, rank=0, pid=3864)[0m     "training_min": 1129.5736055374146,
[36m(head, rank=0, pid=3864)[0m     "training_max": 1129.5736055374146,
[36m(head, rank=0, pid=3864)[0m     "training_total": 1129.5736055374146
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "total_run_time": {
[36m(head, rank=0, pid=3864)[0m     "total_count": 1,
[36m(head, rank=0, pid=3864)[0m     "total_average": 1157.9501740932465,
[36m(head, rank=0, pid=3864)[0m     "total_min": 1157.9501740932465,
[36m(head, rank=0, pid=3864)[0m     "total_max": 1157.9501740932465,
[36m(head, rank=0, pid=3864)[0m     "total_total": 1157.9501740932465
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3864)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m     "total_checkpoint_save_time": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "average_save_time_per_checkpoint": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_min": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_max": 679.9598314762115,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_average": 679.9598314762115
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3864)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m     "total_batch_sample_time": 0.526160717010498,
[36m(head, rank=0, pid=3864)[0m     "average_sample_time_per_batch": 0.0526160717010498,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_min": 0.03436684608459473,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_max": 0.1237635612487793,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_average": 0.0526160717010498
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "training_steps": {
[36m(head, rank=0, pid=3864)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m     "total_training_step_time": 325.88842964172363,
[36m(head, rank=0, pid=3864)[0m     "average_step_time_per_step": 4.073605370521546,
[36m(head, rank=0, pid=3864)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3864)[0m     "training_step_min": 3.563748598098755,
[36m(head, rank=0, pid=3864)[0m     "training_step_max": 5.220434665679932,
[36m(head, rank=0, pid=3864)[0m     "training_step_average": 4.073605370521546
[36m(head, rank=0, pid=3864)[0m   }
[36m(head, rank=0, pid=3864)[0m }
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_2.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1203.98 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.52s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.54s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.34s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.64s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_1.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1204.10 seconds
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.52s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.48s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.43s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.58s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.69s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.47s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.47s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.47s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.47s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.03s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1203.98s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1203.98s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1203.98s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1203.98s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.64s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.34s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.54s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1207.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1207.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1207.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1207.49s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.24s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.24s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.24s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.24s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.17s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.17s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.17s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.17s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1204.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1204.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1204.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1204.10s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.58s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.69s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.43s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.48s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1207.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1207.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1207.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1207.51s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_4.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1204.48 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.56s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.06s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.38s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.64s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_5.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1204.49 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.58s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.06s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.17s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.53s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.64s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.30s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.30s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.30s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.30s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.02s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.02s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.02s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.02s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1204.48s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1204.48s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1204.48s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1204.48s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.64s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.38s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.56s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1207.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1207.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1207.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1207.80s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.26s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.06s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1204.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1204.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1204.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1204.49s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.64s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.53s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.17s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.58s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1207.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1207.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1207.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1207.81s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_7.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1205.54 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.52s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.52s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.20s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.69s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1205.43 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.48s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 325.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1205.54 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.60s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 326.66s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.32s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.32s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.32s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.32s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1205.43s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1205.43s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1205.43s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1205.43s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 325.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.48s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1208.78s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1208.78s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1208.78s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1208.78s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.05s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 0.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 0.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 0.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 0.99s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1205.54s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1205.54s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1205.54s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1205.54s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.69s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.20s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.52s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1208.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1208.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1208.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1208.57s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.21s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.21s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.21s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.21s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1205.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1205.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1205.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1205.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 326.66s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.60s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1208.74s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1208.74s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1208.74s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1208.74s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_6.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1205.72 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.55s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.66s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.59s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.66s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.05s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 0.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 0.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 0.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 0.99s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1205.72s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1205.72s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1205.72s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1205.72s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.59s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.55s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1208.76s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1208.76s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1208.76s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1208.76s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_3.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1205.28 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.57s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.06s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 325.82s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.07s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.60s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 6.65s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.24s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.24s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.24s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.24s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.11s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.11s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.11s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.11s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1205.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1205.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1205.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1205.28s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.60s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 6.65s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 325.82s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.16s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.57s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 378.51s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1208.63s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1208.63s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1208.63s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1208.63s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1206.10 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 325.49s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.22s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.22s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.22s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.22s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1206.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1206.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1206.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1206.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 325.49s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1209.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1209.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1209.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1209.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1206.62 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 325.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1206.62s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1206.62s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1206.62s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1206.62s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.57s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 325.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1209.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1209.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1209.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1209.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1181.70 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 325.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 5.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 26.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 26.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 26.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 26.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1181.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1181.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1181.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1181.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 5.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 325.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1210.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1210.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1210.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1210.70s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- Training Run 1 Info (Directory: /mnt/data/) ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "timestamp": "2025-08-03T08:03:33.505392",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_load_time": 2.3644649982452393,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_load_time": 26.637884616851807,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_time": 1181.7016401290894,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_time": 1210.7039897441864,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "error": null,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     378.51496863365173
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_batch_sample_time": 0.456423282623291,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_batch_sample_time": 0.0456423282623291,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_batch_sample_time": 0.02778005599975586,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_batch_sample_time": 0.07552695274353027,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.07552695274353027,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.06272387504577637,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.04115581512451172,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.05218076705932617,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.04748797416687012,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03432798385620117,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03879976272583008,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.034918785095214844,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.041521310806274414,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.02778005599975586
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_training_step_time": 325.1510362625122,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_training_step_time": 4.064387953281402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_training_step_time": 3.5625975131988525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_training_step_time": 5.1037962436676025,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.1037962436676025,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.744900703430176,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.383908748626709,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.675520420074463,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.728468418121338,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8795652389526367,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8078486919403076,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.71362042427063,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.34084939956665,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.6676836013793945,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.878915309906006,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.708319902420044,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.699605941772461,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.9619460105896,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7155580520629883,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.61784291267395,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.131792783737183,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7394962310791016,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.968195676803589,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.712448835372925,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.321528434753418,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.705815553665161,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.621937990188599,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7345588207244873,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.998399496078491,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7048065662384033,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9177982807159424,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.75479793548584,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.5662612915039062,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7124969959259033,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.999793291091919,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.375513315200806,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.7409186363220215,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8901243209838867,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8044629096984863,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.165894508361816,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.52592396736145,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.406204462051392,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.857362985610962,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8820912837982178,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6305482387542725,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7119297981262207,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.080322742462158,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7406601905822754,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.961414098739624,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9306960105895996,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9480879306793213,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.895150661468506,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.800691604614258,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.8089423179626465,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7119672298431396,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7076468467712402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.980090379714966,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6195006370544434,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.5718958377838135,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7263383865356445,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.059360980987549,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.343163967132568,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.0575056076049805,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.1570143699646,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.5625975131988525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7527568340301514,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.958911180496216,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.394587993621826,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.698829412460327,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.61391282081604,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.936371088027954,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6739161014556885,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.274337530136108,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.842252016067505,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.018158435821533,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9533112049102783,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7391998767852783,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.229308366775513,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8113818168640137,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.058670282363892,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.867950439453125,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6901803016662598,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.045876741409302,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7186238765716553
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "timestamp": "2025-08-03T08:03:33.505392",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "output_dir": "/mnt/data",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_time": 2.3644649982452393,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_time": 26.637884616851807,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_time": 1181.7016401290894,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_time": 1210.7039897441864,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "error": null,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       378.51496863365173
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_sample_time": 0.456423282623291,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_batch_sample_time": 0.0456423282623291,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_batch_sample_time": 0.02778005599975586,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_batch_sample_time": 0.07552695274353027,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.07552695274353027,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.06272387504577637,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.04115581512451172,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.05218076705932617,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.04748797416687012,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03432798385620117,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03879976272583008,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.034918785095214844,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.041521310806274414,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.02778005599975586
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_step_time": 325.1510362625122,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_training_step_time": 4.064387953281402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_training_step_time": 3.5625975131988525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_training_step_time": 5.1037962436676025,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.1037962436676025,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.744900703430176,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.383908748626709,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.675520420074463,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.728468418121338,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8795652389526367,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8078486919403076,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.71362042427063,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.34084939956665,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.6676836013793945,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.878915309906006,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.708319902420044,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.699605941772461,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.9619460105896,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7155580520629883,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.61784291267395,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.131792783737183,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7394962310791016,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.968195676803589,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.712448835372925,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.321528434753418,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.705815553665161,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.621937990188599,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7345588207244873,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.998399496078491,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7048065662384033,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9177982807159424,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.75479793548584,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.5662612915039062,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7124969959259033,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.999793291091919,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.375513315200806,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.7409186363220215,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8901243209838867,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8044629096984863,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.165894508361816,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.52592396736145,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.406204462051392,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.857362985610962,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8820912837982178,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6305482387542725,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7119297981262207,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.080322742462158,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7406601905822754,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.961414098739624,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9306960105895996,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9480879306793213,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.895150661468506,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.800691604614258,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.8089423179626465,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7119672298431396,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7076468467712402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.980090379714966,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6195006370544434,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.5718958377838135,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7263383865356445,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.059360980987549,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.343163967132568,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.0575056076049805,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.1570143699646,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.5625975131988525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7527568340301514,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.958911180496216,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.394587993621826,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.698829412460327,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.61391282081604,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.936371088027954,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6739161014556885,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.274337530136108,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.842252016067505,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.018158435821533,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9533112049102783,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7391998767852783,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.229308366775513,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8113818168640137,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.058670282363892,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.867950439453125,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6901803016662598,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.045876741409302,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7186238765716553
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_average": 2.3644649982452393,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_min": 2.3644649982452393,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_max": 2.3644649982452393,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_total": 2.3644649982452393
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_average": 26.637884616851807,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_min": 26.637884616851807,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_max": 26.637884616851807,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_total": 26.637884616851807
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_average": 1181.7016401290894,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_min": 1181.7016401290894,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_max": 1181.7016401290894,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_total": 1181.7016401290894
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_average": 1210.7039897441864,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_min": 1210.7039897441864,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_max": 1210.7039897441864,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_total": 1210.7039897441864
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoint_save_time": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_save_time_per_checkpoint": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_min": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_max": 378.51496863365173,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_average": 378.51496863365173
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_sample_time": 0.456423282623291,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_sample_time_per_batch": 0.0456423282623291,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_min": 0.02778005599975586,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_max": 0.07552695274353027,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_average": 0.0456423282623291
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_step_time": 325.1510362625122,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_step_time_per_step": 4.064387953281402,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_min": 3.5625975131988525,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_max": 5.1037962436676025,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_average": 4.064387953281402
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1209.14 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 326.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.60s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.63s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.96s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1209.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1209.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1209.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1209.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.60s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.63s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 326.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1212.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1212.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1212.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1212.33s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1209.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 325.87s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1209.34 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 327.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.55s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.63s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /mnt/data/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.28s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 0.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 0.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 0.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 0.99s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1209.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1209.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1209.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1209.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.65s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 325.87s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1212.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1212.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1212.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1212.64s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.25s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.25s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.25s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.25s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1209.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1209.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1209.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1209.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.55s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.63s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 327.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.17s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 378.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1212.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1212.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1212.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1212.67s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m cp: target '/mnt/data/checkpoint/checkpoints' is not a directory
[36m(head, rank=0, pid=3864)[0m cp: target '/mnt/data/checkpoint/checkpoints' is not a directory
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3864)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.95 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.93 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.89 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.90 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.87 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.98 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.88 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.88 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.97 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.91 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.92 secondsCompleted Load dataset in 2.91 seconds
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.94 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.95 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.91 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.88 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  9.30it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.72it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.88it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.73it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.67it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  9.45it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  6.35it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.46it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 12.83it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.11it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  8.81it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 10.57it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 10.19it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 10.90it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  8.16it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.69it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.13it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  8.03it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.41it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.34it/s]
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.32it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00,  9.32it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  9.27it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  9.42it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  9.57it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  9.38it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  9.37it/s]
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  9.37it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:00, 12.65it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 11.52it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 10.06it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 10.67it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 11.45it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00,  9.92it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 10.80it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00,  8.95it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 11.29it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 11.34it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.92it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.74it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.67it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.54it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.38it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  8.61it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.24it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.24it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.92it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.25it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.33it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.91it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.95it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.82it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.10it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.14it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.21it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.89it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.14it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  9.76it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.61 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.62 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.62 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.63 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.63 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.63 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.62 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.64 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:40, 10.20s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:42, 10.64s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:19<00:29,  9.83s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:20<00:29,  9.98s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29<00:19,  9.63s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:29<00:19,  9.77s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:38<00:09,  9.65s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:47<00:00,  9.38s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:47<00:00,  9.55s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 48.86 seconds
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:39<00:09,  9.62s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48<00:00,  9.40s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:48<00:00,  9.62s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Completed Load model in 49.23 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Completed Training in 9.74 seconds
[36m(head, rank=0, pid=3864)[0m [rank0]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank0]:     main()
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank0]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank0]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank0]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 810, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank0]:     dataset = dataset.map(
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank0]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3266, in map
[36m(head, rank=0, pid=3864)[0m [rank0]:     transformed_shards[rank] = load_processed_shard_from_cache(job_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3153, in load_processed_shard_from_cache
[36m(head, rank=0, pid=3864)[0m [rank0]:     return Dataset.from_file(shard_kwargs["cache_file_name"], info=info, split=shard.split)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 800, in from_file
[36m(head, rank=0, pid=3864)[0m [rank0]:     table = ArrowReader.read_table(filename, in_memory=in_memory)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_reader.py", line 329, in read_table
[36m(head, rank=0, pid=3864)[0m [rank0]:     return table_cls.from_file(filename)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 1017, in from_file
[36m(head, rank=0, pid=3864)[0m [rank0]:     table = _memory_mapped_arrow_table_from_file(filename)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 63, in _memory_mapped_arrow_table_from_file
[36m(head, rank=0, pid=3864)[0m [rank0]:     opened_stream = _memory_mapped_record_batch_reader_from_file(filename)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 49, in _memory_mapped_record_batch_reader_from_file
[36m(head, rank=0, pid=3864)[0m [rank0]:     return pa.ipc.open_stream(memory_mapped_stream)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 187, in open_stream
[36m(head, rank=0, pid=3864)[0m [rank0]:     return RecordBatchStreamReader(source, options=options,
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 52, in __init__
[36m(head, rank=0, pid=3864)[0m [rank0]:     self._open(source, options=options, memory_pool=memory_pool)
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "pyarrow/ipc.pxi", line 1038, in pyarrow.lib._RecordBatchStreamReader._open
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
[36m(head, rank=0, pid=3864)[0m [rank0]:   File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
[36m(head, rank=0, pid=3864)[0m [rank0]: pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0
[36m(head, rank=0, pid=3864)[0m Completed Training in 58.54 seconds
[36m(head, rank=0, pid=3864)[0m Completed Training in 58.59 seconds
[36m(head, rank=0, pid=3864)[0m [rank1]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank1]:     main()
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank1]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank1]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank1]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank1]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3864)[0m [rank1]:     return next(self.gen)
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3864)[0m [rank1]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3864)[0m [rank1]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3864)[0m [rank1]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank1]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3864)[0m [rank1]:     work.wait()
[36m(head, rank=0, pid=3864)[0m [rank1]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:51863
[36m(head, rank=0, pid=3864)[0m [rank2]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank2]:     main()
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank2]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank2]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank2]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank2]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3864)[0m [rank2]:     return next(self.gen)
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3864)[0m [rank2]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3864)[0m [rank2]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3864)[0m [rank2]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank2]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3864)[0m [rank2]:     work.wait()
[36m(head, rank=0, pid=3864)[0m [rank2]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:37039
[36m(head, rank=0, pid=3864)[0m Completed Training in 58.58 seconds
[36m(head, rank=0, pid=3864)[0m [rank4]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank4]:     main()
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank4]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank4]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank4]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank4]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3864)[0m [rank4]:     return next(self.gen)
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3864)[0m [rank4]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3864)[0m [rank4]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3864)[0m [rank4]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank4]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3864)[0m [rank4]:     work.wait()
[36m(head, rank=0, pid=3864)[0m [rank4]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:61588
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 12.05 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank8]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:26798
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 58.99 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank12]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:52868
[36m(head, rank=0, pid=3864)[0m [rank0]:[W803 08:25:28.445035403 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 58.97 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank14]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:42728
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 58.98 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank15]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:3716
[36m(head, rank=0, pid=3864)[0m Completed Training in 58.93 seconds
[36m(head, rank=0, pid=3864)[0m [rank3]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank3]:     main()
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank3]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank3]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank3]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank3]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3864)[0m [rank3]:     return next(self.gen)
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3864)[0m [rank3]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3864)[0m [rank3]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3864)[0m [rank3]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank3]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3864)[0m [rank3]:     work.wait()
[36m(head, rank=0, pid=3864)[0m [rank3]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:30637
[36m(head, rank=0, pid=3864)[0m Completed Training in 58.98 seconds
[36m(head, rank=0, pid=3864)[0m [rank5]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank5]:     main()
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank5]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank5]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank5]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank5]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3864)[0m [rank5]:     return next(self.gen)
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3864)[0m [rank5]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3864)[0m [rank5]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3864)[0m [rank5]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank5]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3864)[0m [rank5]:     work.wait()
[36m(head, rank=0, pid=3864)[0m [rank5]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:30915
[36m(head, rank=0, pid=3864)[0m Completed Training in 59.03 seconds
[36m(head, rank=0, pid=3864)[0m [rank6]: Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/e2e/train.py", line 744, in <module>
[36m(head, rank=0, pid=3864)[0m [rank6]:     main()
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/e2e/train.py", line 613, in main
[36m(head, rank=0, pid=3864)[0m [rank6]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/e2e/train.py", line 105, in __init__
[36m(head, rank=0, pid=3864)[0m [rank6]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3864)[0m [rank6]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3864)[0m [rank6]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3864)[0m [rank6]:     return next(self.gen)
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3864)[0m [rank6]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3864)[0m [rank6]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3864)[0m [rank6]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3864)[0m [rank6]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3864)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3864)[0m [rank6]:     work.wait()
[36m(head, rank=0, pid=3864)[0m [rank6]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.159]:44765
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 59.47 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank10]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.141]:4531
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 59.56 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank11]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.141]:2774
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 59.52 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank13]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.141]:2440
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.199000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165735 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.200000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165736 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.200000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165738 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.200000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165740 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.201000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165741 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.201000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165743 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m W0803 08:25:29.201000 2165028 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 2165744 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 59.93 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/e2e/train.py", line 744, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     main()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/e2e/train.py", line 613, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/e2e/train.py", line 105, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     return next(self.gen)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]:     work.wait()
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [rank9]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.141]:38809
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.712000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887443 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.713000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887444 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.713000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887445 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.713000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887446 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.714000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887447 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.714000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887448 closing signal SIGTERM
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m W0803 08:25:29.714000 1886866 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1887450 closing signal SIGTERM
[36m(head, rank=0, pid=3864)[0m E0803 08:25:30.613000 2165028 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 2165733) of binary: /root/training/bin/python3
[36m(head, rank=0, pid=3864)[0m Traceback (most recent call last):
[36m(head, rank=0, pid=3864)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(head, rank=0, pid=3864)[0m     sys.exit(main())
[36m(head, rank=0, pid=3864)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(head, rank=0, pid=3864)[0m     args.func(args)
[36m(head, rank=0, pid=3864)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(head, rank=0, pid=3864)[0m     multi_gpu_launcher(args)
[36m(head, rank=0, pid=3864)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(head, rank=0, pid=3864)[0m     distrib_run.run(args)
[36m(head, rank=0, pid=3864)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(head, rank=0, pid=3864)[0m     elastic_launch(
[36m(head, rank=0, pid=3864)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(head, rank=0, pid=3864)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(head, rank=0, pid=3864)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(head, rank=0, pid=3864)[0m     raise ChildFailedError(
[36m(head, rank=0, pid=3864)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(head, rank=0, pid=3864)[0m ============================================================
[36m(head, rank=0, pid=3864)[0m /e2e/train.py FAILED
[36m(head, rank=0, pid=3864)[0m ------------------------------------------------------------
[36m(head, rank=0, pid=3864)[0m Failures:
[36m(head, rank=0, pid=3864)[0m   <NO_OTHER_FAILURES>
[36m(head, rank=0, pid=3864)[0m ------------------------------------------------------------
[36m(head, rank=0, pid=3864)[0m Root Cause (first observed failure):
[36m(head, rank=0, pid=3864)[0m [0]:
[36m(head, rank=0, pid=3864)[0m   time      : 2025-08-03_08:25:29
[36m(head, rank=0, pid=3864)[0m   host      : dd-3c0a52b3-head
[36m(head, rank=0, pid=3864)[0m   rank      : 0 (local_rank: 0)
[36m(head, rank=0, pid=3864)[0m   exitcode  : 1 (pid: 2165733)
[36m(head, rank=0, pid=3864)[0m   error_file: <N/A>
[36m(head, rank=0, pid=3864)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(head, rank=0, pid=3864)[0m ============================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m E0803 08:25:30.735000 1886866 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 6 (pid: 1887449) of binary: /root/training/bin/python3
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Traceback (most recent call last):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     sys.exit(main())
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     args.func(args)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     multi_gpu_launcher(args)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     distrib_run.run(args)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     elastic_launch(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     raise ChildFailedError(
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ============================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m /e2e/train.py FAILED
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Failures:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   <NO_OTHER_FAILURES>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Root Cause (first observed failure):
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [0]:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   time      : 2025-08-03_08:25:29
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   host      : dd-3c0a52b3-worker1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   rank      : 14 (local_rank: 6)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   exitcode  : 1 (pid: 1887449)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   error_file: <N/A>
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ============================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m cp: cannot create regular file '/checkpoints_s3/checkpoints/trace_58_0.json': File exists
[36m(head, rank=0, pid=3864)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3864)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3864)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3864)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Starting Load dataset...
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.37 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.37 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.37 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load dataset in 2.40 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Load model...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.42 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 2.45 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 35.80it/s]
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 36.45it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 35.05it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 35.59it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 53.49it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 72.10it/s]
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 108.12it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3864)[0m Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 94.61it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 52.78it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 51.88it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 52.28it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 53.88it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 56.13it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.23 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.23 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.23 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.23 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.20 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 1.23 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 57.43it/s]
[36m(head, rank=0, pid=3864)[0m Completed Load dataset in 5.50 seconds
[36m(head, rank=0, pid=3864)[0m Starting Load model...
[36m(head, rank=0, pid=3864)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3864)[0m Completed Load model in 3.25 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  6.79it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 31.04it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 3.87 seconds
[36m(head, rank=0, pid=3864)[0m 
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 84.16it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m Completed Load model in 0.96 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:15<01:01, 15.32s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:21<01:24, 21.22s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:36<00:53, 17.82s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:36<00:56, 18.76s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:58<00:40, 20.28s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:58<00:39, 19.78s/it]
[36m(head, rank=0, pid=3864)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:21<00:21, 21.04s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 20.91s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 20.48s/it]
[36m(head, rank=0, pid=3864)[0m Completed Load model in 103.41 seconds
[36m(head, rank=0, pid=3864)[0m Starting Training...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:21<00:21, 21.34s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 21.27s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:42<00:00, 20.54s/it]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Load model in 103.85 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Training...
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:30,961] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,892] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,894] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,894] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,905] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,916] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,921] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:31,982] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:32,426] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,143] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,162] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,175] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,189] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,235] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,242] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m [2025-08-03 08:29:33,314] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,674] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,677] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,678] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,680] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,684] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,684] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,691] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:36,694] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,892] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,902] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,903] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,904] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,908] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,914] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:37,924] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [2025-08-03 08:29:38,044] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_0.json
[36m(head, rank=0, pid=3864)[0m  10%|â–ˆ         | 1/10 [00:39<05:56, 39.60s/it]Chrome trace exported to: /tmp/trace_10_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_10_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_10_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_14_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_14_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  20%|â–ˆâ–ˆ        | 2/10 [01:20<05:23, 40.45s/it]Chrome trace exported to: /tmp/trace_18_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_18_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_18_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_22_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_22_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [02:00<04:42, 40.40s/it]Chrome trace exported to: /tmp/trace_26_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_26_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_26_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_30_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_30_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_2.json
[36m(head, rank=0, pid=3864)[0m  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:41<04:03, 40.55s/it]Chrome trace exported to: /tmp/trace_34_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_34_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_34_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_38_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_38_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_5.json
[36m(head, rank=0, pid=3864)[0m  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:24<03:26, 41.29s/it]Chrome trace exported to: /tmp/trace_42_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_42_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_42_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_46_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_46_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_7.json
[36m(head, rank=0, pid=3864)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [04:04<02:44, 41.02s/it]Chrome trace exported to: /tmp/trace_50_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_50_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_50_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_54_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_54_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_0.json
[36m(head, rank=0, pid=3864)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:47<02:04, 41.52s/it]Chrome trace exported to: /tmp/trace_58_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_58_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_58_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_62_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_62_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_0.json
[36m(head, rank=0, pid=3864)[0m  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [05:30<01:23, 41.96s/it]Chrome trace exported to: /tmp/trace_66_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_66_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_66_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_70_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_70_6.json
[36m(head, rank=0, pid=3864)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_5.json
[36m(head, rank=0, pid=3864)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [06:11<00:41, 41.78s/it]Chrome trace exported to: /tmp/trace_74_0.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_74_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_74_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_2.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_5.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_78_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_78_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:52<00:00, 41.34s/it]Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m 
                                               
{'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:52<00:00, 41.34s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.66s (Total: 345.66s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.66s (Total: 345.66s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.66s (Total: 345.66s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.66s (Total: 345.66s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.66s (Total: 345.66s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.67 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.67s (Total: 345.67s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 345.67 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 345.67s (Total: 345.67s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Save checkpoint in 345.69 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint save time: 345.69s (Total: 345.69s)
[36m(head, rank=0, pid=3864)[0m Completed Save checkpoint in 608.57 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint save time: 608.57s (Total: 608.57s)
[36m(head, rank=0, pid=3864)[0m 
                                               
{'train_runtime': 1020.6311, 'train_samples_per_second': 1.254, 'train_steps_per_second': 0.01, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3864)[0m 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [17:00<00:00, 41.34s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [17:00<00:00, 102.06s/it]
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_0.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1067.49 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 608.57s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 608.57s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 608.57s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 608.57s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.96s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.38s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.08s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 5.39s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.37s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 103.41s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 103.41s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 103.41s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 103.41s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1067.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1067.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1067.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1067.49s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 5.39s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.08s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.38s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.96s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 608.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 608.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 608.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 608.57s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1173.27s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1173.27s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1173.27s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1173.27s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(head, rank=0, pid=3864)[0m {
[36m(head, rank=0, pid=3864)[0m   "run_id": 1,
[36m(head, rank=0, pid=3864)[0m   "timestamp": "2025-08-03T08:27:34.936349",
[36m(head, rank=0, pid=3864)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3864)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3864)[0m   "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3864)[0m   "training_status": "completed",
[36m(head, rank=0, pid=3864)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3864)[0m   "dataset_load_time": 2.369500160217285,
[36m(head, rank=0, pid=3864)[0m   "model_load_time": 103.40977954864502,
[36m(head, rank=0, pid=3864)[0m   "training_time": 1067.486756324768,
[36m(head, rank=0, pid=3864)[0m   "total_time": 1173.2660360336304,
[36m(head, rank=0, pid=3864)[0m   "error": null,
[36m(head, rank=0, pid=3864)[0m   "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m   "total_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m   "average_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m   "min_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m   "max_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m   "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3864)[0m     608.5705771446228
[36m(head, rank=0, pid=3864)[0m   ],
[36m(head, rank=0, pid=3864)[0m   "num_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m   "total_batch_sample_time": 0.959824800491333,
[36m(head, rank=0, pid=3864)[0m   "average_batch_sample_time": 0.0959824800491333,
[36m(head, rank=0, pid=3864)[0m   "min_batch_sample_time": 0.03329658508300781,
[36m(head, rank=0, pid=3864)[0m   "max_batch_sample_time": 0.38349366188049316,
[36m(head, rank=0, pid=3864)[0m   "individual_batch_sample_times": [
[36m(head, rank=0, pid=3864)[0m     0.38349366188049316,
[36m(head, rank=0, pid=3864)[0m     0.09346771240234375,
[36m(head, rank=0, pid=3864)[0m     0.15529751777648926,
[36m(head, rank=0, pid=3864)[0m     0.07649517059326172,
[36m(head, rank=0, pid=3864)[0m     0.0690927505493164,
[36m(head, rank=0, pid=3864)[0m     0.03329658508300781,
[36m(head, rank=0, pid=3864)[0m     0.0377354621887207,
[36m(head, rank=0, pid=3864)[0m     0.03791618347167969,
[36m(head, rank=0, pid=3864)[0m     0.03465390205383301,
[36m(head, rank=0, pid=3864)[0m     0.0383758544921875
[36m(head, rank=0, pid=3864)[0m   ],
[36m(head, rank=0, pid=3864)[0m   "num_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m   "total_training_step_time": 326.08466506004333,
[36m(head, rank=0, pid=3864)[0m   "average_training_step_time": 4.076058313250542,
[36m(head, rank=0, pid=3864)[0m   "min_training_step_time": 3.5643906593322754,
[36m(head, rank=0, pid=3864)[0m   "max_training_step_time": 5.390280485153198,
[36m(head, rank=0, pid=3864)[0m   "individual_training_step_times": [
[36m(head, rank=0, pid=3864)[0m     5.390280485153198,
[36m(head, rank=0, pid=3864)[0m     4.06302547454834,
[36m(head, rank=0, pid=3864)[0m     4.382202386856079,
[36m(head, rank=0, pid=3864)[0m     3.6672203540802,
[36m(head, rank=0, pid=3864)[0m     4.705383777618408,
[36m(head, rank=0, pid=3864)[0m     3.8715248107910156,
[36m(head, rank=0, pid=3864)[0m     3.5746030807495117,
[36m(head, rank=0, pid=3864)[0m     3.7102699279785156,
[36m(head, rank=0, pid=3864)[0m     3.943657636642456,
[36m(head, rank=0, pid=3864)[0m     4.688997745513916,
[36m(head, rank=0, pid=3864)[0m     3.9856886863708496,
[36m(head, rank=0, pid=3864)[0m     3.7131998538970947,
[36m(head, rank=0, pid=3864)[0m     3.6947662830352783,
[36m(head, rank=0, pid=3864)[0m     4.99575662612915,
[36m(head, rank=0, pid=3864)[0m     3.807065725326538,
[36m(head, rank=0, pid=3864)[0m     4.077108860015869,
[36m(head, rank=0, pid=3864)[0m     4.203912258148193,
[36m(head, rank=0, pid=3864)[0m     3.735280990600586,
[36m(head, rank=0, pid=3864)[0m     3.95292592048645,
[36m(head, rank=0, pid=3864)[0m     3.7022318840026855,
[36m(head, rank=0, pid=3864)[0m     4.304328441619873,
[36m(head, rank=0, pid=3864)[0m     3.7044484615325928,
[36m(head, rank=0, pid=3864)[0m     4.750295400619507,
[36m(head, rank=0, pid=3864)[0m     3.7217466831207275,
[36m(head, rank=0, pid=3864)[0m     5.039169549942017,
[36m(head, rank=0, pid=3864)[0m     3.6128056049346924,
[36m(head, rank=0, pid=3864)[0m     3.8883819580078125,
[36m(head, rank=0, pid=3864)[0m     3.7290217876434326,
[36m(head, rank=0, pid=3864)[0m     3.793549060821533,
[36m(head, rank=0, pid=3864)[0m     3.7327404022216797,
[36m(head, rank=0, pid=3864)[0m     3.9666316509246826,
[36m(head, rank=0, pid=3864)[0m     4.37441086769104,
[36m(head, rank=0, pid=3864)[0m     4.812607526779175,
[36m(head, rank=0, pid=3864)[0m     3.8874430656433105,
[36m(head, rank=0, pid=3864)[0m     4.024206161499023,
[36m(head, rank=0, pid=3864)[0m     4.084951877593994,
[36m(head, rank=0, pid=3864)[0m     4.515872478485107,
[36m(head, rank=0, pid=3864)[0m     4.446397542953491,
[36m(head, rank=0, pid=3864)[0m     3.9583230018615723,
[36m(head, rank=0, pid=3864)[0m     3.876560926437378,
[36m(head, rank=0, pid=3864)[0m     3.77428936958313,
[36m(head, rank=0, pid=3864)[0m     3.5643906593322754,
[36m(head, rank=0, pid=3864)[0m     4.959347724914551,
[36m(head, rank=0, pid=3864)[0m     3.709028720855713,
[36m(head, rank=0, pid=3864)[0m     3.8909270763397217,
[36m(head, rank=0, pid=3864)[0m     3.9193708896636963,
[36m(head, rank=0, pid=3864)[0m     3.764206886291504,
[36m(head, rank=0, pid=3864)[0m     3.9062976837158203,
[36m(head, rank=0, pid=3864)[0m     4.933987855911255,
[36m(head, rank=0, pid=3864)[0m     4.857526779174805,
[36m(head, rank=0, pid=3864)[0m     3.9013965129852295,
[36m(head, rank=0, pid=3864)[0m     3.7955074310302734,
[36m(head, rank=0, pid=3864)[0m     3.977159261703491,
[36m(head, rank=0, pid=3864)[0m     3.7123513221740723,
[36m(head, rank=0, pid=3864)[0m     4.54076075553894,
[36m(head, rank=0, pid=3864)[0m     3.718093156814575,
[36m(head, rank=0, pid=3864)[0m     5.1283957958221436,
[36m(head, rank=0, pid=3864)[0m     4.330104827880859,
[36m(head, rank=0, pid=3864)[0m     4.081711530685425,
[36m(head, rank=0, pid=3864)[0m     4.141639232635498,
[36m(head, rank=0, pid=3864)[0m     3.7392711639404297,
[36m(head, rank=0, pid=3864)[0m     3.753538131713867,
[36m(head, rank=0, pid=3864)[0m     3.9990527629852295,
[36m(head, rank=0, pid=3864)[0m     4.5087761878967285,
[36m(head, rank=0, pid=3864)[0m     3.767033100128174,
[36m(head, rank=0, pid=3864)[0m     3.706449508666992,
[36m(head, rank=0, pid=3864)[0m     3.9668922424316406,
[36m(head, rank=0, pid=3864)[0m     3.5761165618896484,
[36m(head, rank=0, pid=3864)[0m     4.281715154647827,
[36m(head, rank=0, pid=3864)[0m     4.847369432449341,
[36m(head, rank=0, pid=3864)[0m     3.9940643310546875,
[36m(head, rank=0, pid=3864)[0m     3.906306743621826,
[36m(head, rank=0, pid=3864)[0m     3.716576337814331,
[36m(head, rank=0, pid=3864)[0m     4.178035259246826,
[36m(head, rank=0, pid=3864)[0m     4.095031976699829,
[36m(head, rank=0, pid=3864)[0m     4.029332637786865,
[36m(head, rank=0, pid=3864)[0m     3.9625585079193115,
[36m(head, rank=0, pid=3864)[0m     3.7285099029541016,
[36m(head, rank=0, pid=3864)[0m     3.910430669784546,
[36m(head, rank=0, pid=3864)[0m     3.7221157550811768
[36m(head, rank=0, pid=3864)[0m   ]
[36m(head, rank=0, pid=3864)[0m }
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- All Training Runs Summary ---
[36m(head, rank=0, pid=3864)[0m [
[36m(head, rank=0, pid=3864)[0m   {
[36m(head, rank=0, pid=3864)[0m     "run_id": 1,
[36m(head, rank=0, pid=3864)[0m     "timestamp": "2025-08-03T08:27:34.936349",
[36m(head, rank=0, pid=3864)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(head, rank=0, pid=3864)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3864)[0m     "model_id": "google/gemma-3-12b-it",
[36m(head, rank=0, pid=3864)[0m     "training_status": "completed",
[36m(head, rank=0, pid=3864)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(head, rank=0, pid=3864)[0m     "dataset_load_time": 2.369500160217285,
[36m(head, rank=0, pid=3864)[0m     "model_load_time": 103.40977954864502,
[36m(head, rank=0, pid=3864)[0m     "training_time": 1067.486756324768,
[36m(head, rank=0, pid=3864)[0m     "total_time": 1173.2660360336304,
[36m(head, rank=0, pid=3864)[0m     "error": null,
[36m(head, rank=0, pid=3864)[0m     "num_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m     "total_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "average_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "min_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "max_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "individual_checkpoint_save_times": [
[36m(head, rank=0, pid=3864)[0m       608.5705771446228
[36m(head, rank=0, pid=3864)[0m     ],
[36m(head, rank=0, pid=3864)[0m     "num_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m     "total_batch_sample_time": 0.959824800491333,
[36m(head, rank=0, pid=3864)[0m     "average_batch_sample_time": 0.0959824800491333,
[36m(head, rank=0, pid=3864)[0m     "min_batch_sample_time": 0.03329658508300781,
[36m(head, rank=0, pid=3864)[0m     "max_batch_sample_time": 0.38349366188049316,
[36m(head, rank=0, pid=3864)[0m     "individual_batch_sample_times": [
[36m(head, rank=0, pid=3864)[0m       0.38349366188049316,
[36m(head, rank=0, pid=3864)[0m       0.09346771240234375,
[36m(head, rank=0, pid=3864)[0m       0.15529751777648926,
[36m(head, rank=0, pid=3864)[0m       0.07649517059326172,
[36m(head, rank=0, pid=3864)[0m       0.0690927505493164,
[36m(head, rank=0, pid=3864)[0m       0.03329658508300781,
[36m(head, rank=0, pid=3864)[0m       0.0377354621887207,
[36m(head, rank=0, pid=3864)[0m       0.03791618347167969,
[36m(head, rank=0, pid=3864)[0m       0.03465390205383301,
[36m(head, rank=0, pid=3864)[0m       0.0383758544921875
[36m(head, rank=0, pid=3864)[0m     ],
[36m(head, rank=0, pid=3864)[0m     "num_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m     "total_training_step_time": 326.08466506004333,
[36m(head, rank=0, pid=3864)[0m     "average_training_step_time": 4.076058313250542,
[36m(head, rank=0, pid=3864)[0m     "min_training_step_time": 3.5643906593322754,
[36m(head, rank=0, pid=3864)[0m     "max_training_step_time": 5.390280485153198,
[36m(head, rank=0, pid=3864)[0m     "individual_training_step_times": [
[36m(head, rank=0, pid=3864)[0m       5.390280485153198,
[36m(head, rank=0, pid=3864)[0m       4.06302547454834,
[36m(head, rank=0, pid=3864)[0m       4.382202386856079,
[36m(head, rank=0, pid=3864)[0m       3.6672203540802,
[36m(head, rank=0, pid=3864)[0m       4.705383777618408,
[36m(head, rank=0, pid=3864)[0m       3.8715248107910156,
[36m(head, rank=0, pid=3864)[0m       3.5746030807495117,
[36m(head, rank=0, pid=3864)[0m       3.7102699279785156,
[36m(head, rank=0, pid=3864)[0m       3.943657636642456,
[36m(head, rank=0, pid=3864)[0m       4.688997745513916,
[36m(head, rank=0, pid=3864)[0m       3.9856886863708496,
[36m(head, rank=0, pid=3864)[0m       3.7131998538970947,
[36m(head, rank=0, pid=3864)[0m       3.6947662830352783,
[36m(head, rank=0, pid=3864)[0m       4.99575662612915,
[36m(head, rank=0, pid=3864)[0m       3.807065725326538,
[36m(head, rank=0, pid=3864)[0m       4.077108860015869,
[36m(head, rank=0, pid=3864)[0m       4.203912258148193,
[36m(head, rank=0, pid=3864)[0m       3.735280990600586,
[36m(head, rank=0, pid=3864)[0m       3.95292592048645,
[36m(head, rank=0, pid=3864)[0m       3.7022318840026855,
[36m(head, rank=0, pid=3864)[0m       4.304328441619873,
[36m(head, rank=0, pid=3864)[0m       3.7044484615325928,
[36m(head, rank=0, pid=3864)[0m       4.750295400619507,
[36m(head, rank=0, pid=3864)[0m       3.7217466831207275,
[36m(head, rank=0, pid=3864)[0m       5.039169549942017,
[36m(head, rank=0, pid=3864)[0m       3.6128056049346924,
[36m(head, rank=0, pid=3864)[0m       3.8883819580078125,
[36m(head, rank=0, pid=3864)[0m       3.7290217876434326,
[36m(head, rank=0, pid=3864)[0m       3.793549060821533,
[36m(head, rank=0, pid=3864)[0m       3.7327404022216797,
[36m(head, rank=0, pid=3864)[0m       3.9666316509246826,
[36m(head, rank=0, pid=3864)[0m       4.37441086769104,
[36m(head, rank=0, pid=3864)[0m       4.812607526779175,
[36m(head, rank=0, pid=3864)[0m       3.8874430656433105,
[36m(head, rank=0, pid=3864)[0m       4.024206161499023,
[36m(head, rank=0, pid=3864)[0m       4.084951877593994,
[36m(head, rank=0, pid=3864)[0m       4.515872478485107,
[36m(head, rank=0, pid=3864)[0m       4.446397542953491,
[36m(head, rank=0, pid=3864)[0m       3.9583230018615723,
[36m(head, rank=0, pid=3864)[0m       3.876560926437378,
[36m(head, rank=0, pid=3864)[0m       3.77428936958313,
[36m(head, rank=0, pid=3864)[0m       3.5643906593322754,
[36m(head, rank=0, pid=3864)[0m       4.959347724914551,
[36m(head, rank=0, pid=3864)[0m       3.709028720855713,
[36m(head, rank=0, pid=3864)[0m       3.8909270763397217,
[36m(head, rank=0, pid=3864)[0m       3.9193708896636963,
[36m(head, rank=0, pid=3864)[0m       3.764206886291504,
[36m(head, rank=0, pid=3864)[0m       3.9062976837158203,
[36m(head, rank=0, pid=3864)[0m       4.933987855911255,
[36m(head, rank=0, pid=3864)[0m       4.857526779174805,
[36m(head, rank=0, pid=3864)[0m       3.9013965129852295,
[36m(head, rank=0, pid=3864)[0m       3.7955074310302734,
[36m(head, rank=0, pid=3864)[0m       3.977159261703491,
[36m(head, rank=0, pid=3864)[0m       3.7123513221740723,
[36m(head, rank=0, pid=3864)[0m       4.54076075553894,
[36m(head, rank=0, pid=3864)[0m       3.718093156814575,
[36m(head, rank=0, pid=3864)[0m       5.1283957958221436,
[36m(head, rank=0, pid=3864)[0m       4.330104827880859,
[36m(head, rank=0, pid=3864)[0m       4.081711530685425,
[36m(head, rank=0, pid=3864)[0m       4.141639232635498,
[36m(head, rank=0, pid=3864)[0m       3.7392711639404297,
[36m(head, rank=0, pid=3864)[0m       3.753538131713867,
[36m(head, rank=0, pid=3864)[0m       3.9990527629852295,
[36m(head, rank=0, pid=3864)[0m       4.5087761878967285,
[36m(head, rank=0, pid=3864)[0m       3.767033100128174,
[36m(head, rank=0, pid=3864)[0m       3.706449508666992,
[36m(head, rank=0, pid=3864)[0m       3.9668922424316406,
[36m(head, rank=0, pid=3864)[0m       3.5761165618896484,
[36m(head, rank=0, pid=3864)[0m       4.281715154647827,
[36m(head, rank=0, pid=3864)[0m       4.847369432449341,
[36m(head, rank=0, pid=3864)[0m       3.9940643310546875,
[36m(head, rank=0, pid=3864)[0m       3.906306743621826,
[36m(head, rank=0, pid=3864)[0m       3.716576337814331,
[36m(head, rank=0, pid=3864)[0m       4.178035259246826,
[36m(head, rank=0, pid=3864)[0m       4.095031976699829,
[36m(head, rank=0, pid=3864)[0m       4.029332637786865,
[36m(head, rank=0, pid=3864)[0m       3.9625585079193115,
[36m(head, rank=0, pid=3864)[0m       3.7285099029541016,
[36m(head, rank=0, pid=3864)[0m       3.910430669784546,
[36m(head, rank=0, pid=3864)[0m       3.7221157550811768
[36m(head, rank=0, pid=3864)[0m     ]
[36m(head, rank=0, pid=3864)[0m   }
[36m(head, rank=0, pid=3864)[0m ]
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m --- Timing Summary ---
[36m(head, rank=0, pid=3864)[0m {
[36m(head, rank=0, pid=3864)[0m   "total_runs": 1,
[36m(head, rank=0, pid=3864)[0m   "dataset_loading": {
[36m(head, rank=0, pid=3864)[0m     "dataset_load_count": 1,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_average": 2.369500160217285,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_min": 2.369500160217285,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_max": 2.369500160217285,
[36m(head, rank=0, pid=3864)[0m     "dataset_load_total": 2.369500160217285
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "model_loading": {
[36m(head, rank=0, pid=3864)[0m     "model_load_count": 1,
[36m(head, rank=0, pid=3864)[0m     "model_load_average": 103.40977954864502,
[36m(head, rank=0, pid=3864)[0m     "model_load_min": 103.40977954864502,
[36m(head, rank=0, pid=3864)[0m     "model_load_max": 103.40977954864502,
[36m(head, rank=0, pid=3864)[0m     "model_load_total": 103.40977954864502
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "training": {
[36m(head, rank=0, pid=3864)[0m     "training_count": 1,
[36m(head, rank=0, pid=3864)[0m     "training_average": 1067.486756324768,
[36m(head, rank=0, pid=3864)[0m     "training_min": 1067.486756324768,
[36m(head, rank=0, pid=3864)[0m     "training_max": 1067.486756324768,
[36m(head, rank=0, pid=3864)[0m     "training_total": 1067.486756324768
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "total_run_time": {
[36m(head, rank=0, pid=3864)[0m     "total_count": 1,
[36m(head, rank=0, pid=3864)[0m     "total_average": 1173.2660360336304,
[36m(head, rank=0, pid=3864)[0m     "total_min": 1173.2660360336304,
[36m(head, rank=0, pid=3864)[0m     "total_max": 1173.2660360336304,
[36m(head, rank=0, pid=3864)[0m     "total_total": 1173.2660360336304
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "checkpoint_saving": {
[36m(head, rank=0, pid=3864)[0m     "total_checkpoints_saved": 1,
[36m(head, rank=0, pid=3864)[0m     "total_checkpoint_save_time": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "average_save_time_per_checkpoint": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_times_count": 1,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_min": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_max": 608.5705771446228,
[36m(head, rank=0, pid=3864)[0m     "checkpoint_save_average": 608.5705771446228
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "batch_sampling": {
[36m(head, rank=0, pid=3864)[0m     "total_batch_samples": 10,
[36m(head, rank=0, pid=3864)[0m     "total_batch_sample_time": 0.959824800491333,
[36m(head, rank=0, pid=3864)[0m     "average_sample_time_per_batch": 0.0959824800491333,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_times_count": 10,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_min": 0.03329658508300781,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_max": 0.38349366188049316,
[36m(head, rank=0, pid=3864)[0m     "batch_sample_average": 0.0959824800491333
[36m(head, rank=0, pid=3864)[0m   },
[36m(head, rank=0, pid=3864)[0m   "training_steps": {
[36m(head, rank=0, pid=3864)[0m     "total_training_steps": 80,
[36m(head, rank=0, pid=3864)[0m     "total_training_step_time": 326.08466506004333,
[36m(head, rank=0, pid=3864)[0m     "average_step_time_per_step": 4.076058313250542,
[36m(head, rank=0, pid=3864)[0m     "training_step_times_count": 80,
[36m(head, rank=0, pid=3864)[0m     "training_step_min": 3.5643906593322754,
[36m(head, rank=0, pid=3864)[0m     "training_step_max": 5.390280485153198,
[36m(head, rank=0, pid=3864)[0m     "training_step_average": 4.076058313250542
[36m(head, rank=0, pid=3864)[0m   }
[36m(head, rank=0, pid=3864)[0m }
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1111.16 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 0.82s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 328.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 6.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 103.85s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 103.85s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 103.85s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 103.85s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1111.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1111.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1111.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1111.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 6.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 328.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.16s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 0.82s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1217.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1217.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1217.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1217.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_0.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m JSON OUTPUT FROM MAIN PROCESS
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- Training Run 1 Info (Directory: /checkpoints_s3_mount_cached) ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "run_id": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "timestamp": "2025-08-03T08:27:34.937155",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_status": "completed",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_load_time": 2.3663041591644287,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_load_time": 103.8503475189209,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_time": 1111.1638405323029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_time": 1217.3804922103882,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "error": null,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     345.6942136287689
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_batch_sample_time": 0.8214194774627686,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_batch_sample_time": 0.08214194774627685,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_batch_sample_time": 0.032591819763183594,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_batch_sample_time": 0.1604633331298828,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.09851670265197754,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.14710068702697754,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03578329086303711,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.1604633331298828,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.09282350540161133,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.09884023666381836,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.036348819732666016,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.08258795738220215,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.03636312484741211,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     0.032591819763183594
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "num_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_training_step_time": 328.3628430366516,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "average_training_step_time": 4.104535537958145,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "min_training_step_time": 3.5948586463928223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "max_training_step_time": 6.139479875564575,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "individual_training_step_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     6.139479875564575,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6754250526428223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.382357597351074,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6645524501800537,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.73571515083313,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.871453046798706,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8222997188568115,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.709381341934204,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.258516073226929,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.659143447875977,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.085738897323608,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.712552785873413,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6954658031463623,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.99250602722168,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8028085231781006,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.581614017486572,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.280388832092285,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7358391284942627,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.0957489013671875,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.703045606613159,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.325959205627441,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7018377780914307,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.810964345932007,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.725407600402832,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.955967903137207,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.713411331176758,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.936448335647583,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7276525497436523,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6430604457855225,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.731245279312134,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.094308376312256,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.3725268840789795,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.84004545211792,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8844265937805176,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.04021430015564,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.086487770080566,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.5142130851745605,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.4079272747039795,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.051907062530518,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.881758689880371,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6260952949523926,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7174086570739746,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.168456315994263,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.710951328277588,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9135050773620605,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.927452802658081,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9429471492767334,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9071826934814453,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.931964159011841,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.863835573196411,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8497650623321533,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.798279047012329,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.980240821838379,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6279377937316895,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.658015012741089,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.715871572494507,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     5.082282543182373,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.330277442932129,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.08488130569458,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.118733167648315,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.5948586463928223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.7580764293670654,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.039891242980957,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.41051173210144,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.761596202850342,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.6176373958587646,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.070976972579956,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.658127784729004,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.284108400344849,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.854346752166748,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.065154790878296,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.9043376445770264,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.8594343662261963,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.219435930252075,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.863121271133423,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.031681299209595,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.878950834274292,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.708015203475952,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     4.058187007904053,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     3.718507766723633
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- All Training Runs Summary ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "run_id": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "timestamp": "2025-08-03T08:27:34.937155",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_name": "open-r1/codeforces-cots",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_id": "google/gemma-3-12b-it",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_status": "completed",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "output_dir": "/checkpoints_s3_mount_cached",
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_time": 2.3663041591644287,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_time": 103.8503475189209,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_time": 1111.1638405323029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_time": 1217.3804922103882,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "error": null,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_checkpoint_save_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       345.6942136287689
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_sample_time": 0.8214194774627686,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_batch_sample_time": 0.08214194774627685,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_batch_sample_time": 0.032591819763183594,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_batch_sample_time": 0.1604633331298828,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_batch_sample_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.09851670265197754,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.14710068702697754,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03578329086303711,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.1604633331298828,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.09282350540161133,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.09884023666381836,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.036348819732666016,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.08258795738220215,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.03636312484741211,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       0.032591819763183594
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ],
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "num_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_step_time": 328.3628430366516,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_training_step_time": 4.104535537958145,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "min_training_step_time": 3.5948586463928223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "max_training_step_time": 6.139479875564575,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "individual_training_step_times": [
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       6.139479875564575,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6754250526428223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.382357597351074,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6645524501800537,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.73571515083313,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.871453046798706,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8222997188568115,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.709381341934204,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.258516073226929,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.659143447875977,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.085738897323608,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.712552785873413,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6954658031463623,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.99250602722168,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8028085231781006,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.581614017486572,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.280388832092285,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7358391284942627,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.0957489013671875,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.703045606613159,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.325959205627441,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7018377780914307,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.810964345932007,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.725407600402832,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.955967903137207,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.713411331176758,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.936448335647583,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7276525497436523,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6430604457855225,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.731245279312134,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.094308376312256,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.3725268840789795,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.84004545211792,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8844265937805176,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.04021430015564,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.086487770080566,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.5142130851745605,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.4079272747039795,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.051907062530518,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.881758689880371,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6260952949523926,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7174086570739746,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.168456315994263,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.710951328277588,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9135050773620605,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.927452802658081,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9429471492767334,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9071826934814453,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.931964159011841,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.863835573196411,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8497650623321533,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.798279047012329,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.980240821838379,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6279377937316895,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.658015012741089,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.715871572494507,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       5.082282543182373,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.330277442932129,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.08488130569458,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.118733167648315,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.5948586463928223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.7580764293670654,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.039891242980957,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.41051173210144,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.761596202850342,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.6176373958587646,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.070976972579956,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.658127784729004,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.284108400344849,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.854346752166748,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.065154790878296,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.9043376445770264,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.8594343662261963,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.219435930252075,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.863121271133423,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.031681299209595,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.878950834274292,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.708015203475952,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       4.058187007904053,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m       3.718507766723633
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ]
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m --- Timing Summary ---
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_runs": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "dataset_loading": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_average": 2.3663041591644287,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_min": 2.3663041591644287,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_max": 2.3663041591644287,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "dataset_load_total": 2.3663041591644287
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "model_loading": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_average": 103.8503475189209,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_min": 103.8503475189209,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_max": 103.8503475189209,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "model_load_total": 103.8503475189209
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_average": 1111.1638405323029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_min": 1111.1638405323029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_max": 1111.1638405323029,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_total": 1111.1638405323029
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "total_run_time": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_average": 1217.3804922103882,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_min": 1217.3804922103882,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_max": 1217.3804922103882,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_total": 1217.3804922103882
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "checkpoint_saving": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoints_saved": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_checkpoint_save_time": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_save_time_per_checkpoint": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_times_count": 1,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_min": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_max": 345.6942136287689,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "checkpoint_save_average": 345.6942136287689
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "batch_sampling": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_samples": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_batch_sample_time": 0.8214194774627686,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_sample_time_per_batch": 0.08214194774627685,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_times_count": 10,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_min": 0.032591819763183594,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_max": 0.1604633331298828,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "batch_sample_average": 0.08214194774627685
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   },
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   "training_steps": {
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_steps": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "total_training_step_time": 328.3628430366516,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "average_step_time_per_step": 4.104535537958145,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_times_count": 80,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_min": 3.5948586463928223,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_max": 6.139479875564575,
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m     "training_step_average": 4.104535537958145
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m }
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1214.54 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.21s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.12s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.47s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 328.45s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1214.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1214.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1214.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1214.54s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 328.45s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.12s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.47s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.21s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1218.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1218.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1218.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1218.13s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1215.24 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 328.55s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.40s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1215.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1215.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1215.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1215.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 328.55s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.14s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1218.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1218.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1218.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1218.84s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_7.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1215.81 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.78s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.08s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.32s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.17s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.49s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.42s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.42s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.42s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.42s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.08s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1215.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1215.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1215.81s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1215.81s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.17s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.32s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.78s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1219.31s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1219.31s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1219.31s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1219.31s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_1.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1216.07 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 0.99s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.37s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.86s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.09s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.45s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.36s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.13s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1216.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1216.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1216.07s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1216.07s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.09s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.45s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.86s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.37s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 0.99s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1219.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1219.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1219.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1219.56s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_2.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1216.94 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 1.15s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.50s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.81s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.09s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.32s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1216.98 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 326.81s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.31s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.36s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.13s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1216.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1216.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1216.94s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1216.94s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.09s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.32s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.81s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.12s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.50s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 1.15s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1220.43s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1220.43s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1220.43s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1220.43s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.37s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1216.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1216.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1216.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1216.98s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.31s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 326.81s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.11s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.07s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1220.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1220.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1220.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1220.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_3.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1217.06 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 1.07s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.11s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.48s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 326.03s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.08s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.34s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_3_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.45s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.45s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.45s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.45s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.05s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.05s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1217.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1217.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1217.06s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1217.06s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.08s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.34s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 326.03s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.11s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.48s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 1.07s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1220.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1220.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1220.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1220.55s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1217.34 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 326.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.31s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1217.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1217.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1217.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1217.34s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.31s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 326.19s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1220.93s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1220.93s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1220.93s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1220.93s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1217.61 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 326.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1217.61s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1217.61s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1217.61s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1217.61s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 326.56s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.15s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.58s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.46s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1221.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1221.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1221.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1221.20s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_4.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1215.80 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.67s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.67s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 1.01s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.10s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.55s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 328.11s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.10s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.26s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_4_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_6.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1216.66 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 1.26s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.13s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.50s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 327.28s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.09s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.31s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_6_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 5.50s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 5.50s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 5.50s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 5.50s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 0.96s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 0.96s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 0.96s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 0.96s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1215.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1215.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1215.80s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1215.80s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.56s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 328.11s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.10s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.55s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 1.01s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.67s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.67s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1222.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1222.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1222.26s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1222.26s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.36s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 3.25s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 3.25s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 3.25s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 3.25s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1216.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1216.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1216.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1216.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.09s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.57s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.31s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 327.28s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.03s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.50s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 1.26s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.66s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.66s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1222.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1222.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1222.28s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1222.28s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3864)[0m Chrome trace exported to: /tmp/trace_80_5.json
[36m(head, rank=0, pid=3864)[0m Completed Training in 1218.49 seconds
[36m(head, rank=0, pid=3864)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3864)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   - Total checkpoint save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   - Average save time per checkpoint: 345.67s
[36m(head, rank=0, pid=3864)[0m   - Min save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   - Max save time: 345.67s
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3864)[0m   - Total batch sample time: 1.17s
[36m(head, rank=0, pid=3864)[0m   - Average batch sample time: 0.12s
[36m(head, rank=0, pid=3864)[0m   - Min batch sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   - Max batch sample time: 0.52s
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3864)[0m   - Total training step time: 327.12s
[36m(head, rank=0, pid=3864)[0m   - Average training step time: 4.09s
[36m(head, rank=0, pid=3864)[0m   - Min training step time: 3.61s
[36m(head, rank=0, pid=3864)[0m   - Max training step time: 7.30s
[36m(head, rank=0, pid=3864)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3864)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_5_1_info.json
[36m(head, rank=0, pid=3864)[0m Completed run 1/1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 2.36s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 2.36s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Model Loading Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1.13s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1.13s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average time: 1218.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min time: 1218.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max time: 1218.49s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time: 1218.49s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Training Step Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training steps: 80
[36m(head, rank=0, pid=3864)[0m   â€¢ Average step time per step: 4.09s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min step time: 3.61s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max step time: 7.30s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total training step time: 327.12s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch samples: 10
[36m(head, rank=0, pid=3864)[0m   â€¢ Average sample time per batch: 0.12s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min sample time: 0.04s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max sample time: 0.52s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total batch sample time: 1.17s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoints saved: 1
[36m(head, rank=0, pid=3864)[0m   â€¢ Average save time per checkpoint: 345.67s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max save time: 345.67s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total checkpoint save time: 345.67s
[36m(head, rank=0, pid=3864)[0m 
[36m(head, rank=0, pid=3864)[0m Overall Run Performance:
[36m(head, rank=0, pid=3864)[0m   â€¢ Average total time per run: 1221.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Min total time: 1221.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Max total time: 1221.99s
[36m(head, rank=0, pid=3864)[0m   â€¢ Total time across all runs: 1221.99s
[36m(head, rank=0, pid=3864)[0m ================================================================================
[36m(head, rank=0, pid=3864)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1217.59 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.42s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 326.44s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 3.87s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 3.87s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 3.87s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 3.87s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1217.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1217.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1217.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1217.59s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.08s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.53s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.39s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 326.44s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.42s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1223.82s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1223.82s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1223.82s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1223.82s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Chrome trace exported to: /tmp/trace_80_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed Training in 1224.38 seconds
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total batch sample time: 1.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average batch sample time: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max batch sample time: 0.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Total training step time: 327.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Average training step time: 4.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Min training step time: 3.62s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   - Max training step time: 7.31s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved training info to: /checkpoints_s3_mount_cached/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 2.36s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1.23s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average time: 1224.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min time: 1224.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max time: 1224.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time: 1224.38s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training steps: 80
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average step time per step: 4.09s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min step time: 3.62s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max step time: 7.31s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total training step time: 327.24s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch samples: 10
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average sample time per batch: 0.10s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min sample time: 0.03s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max sample time: 0.51s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total batch sample time: 1.04s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average save time per checkpoint: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total checkpoint save time: 345.69s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m 
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Average total time per run: 1227.97s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Min total time: 1227.97s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Max total time: 1227.97s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m   â€¢ Total time across all runs: 1227.97s
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m ================================================================================
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2703, ip=10.102.30.141)[0m skypilot: cached mount uploaded complete
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount is still uploading to remote
[36m(head, rank=0, pid=3864)[0m skypilot: cached mount uploaded complete
[0m[32mâœ“ Job finished (status: SUCCEEDED).[0m[0m
