# Single-node serving with NVIDIA Dynamo and SGLang.
#
# Usage:
#
#  sky launch -c dynamo nvidia-dynamo.sky.yaml
#
# Optionally override the model:
#
#  sky launch -c dynamo nvidia-dynamo.sky.yaml --env MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct --env HF_TOKEN

resources:
  accelerators: {H100:1, H200:1}
  ports: 8080
  # Use the official NVIDIA Dynamo SGLang runtime image from NGC
  image_id: docker:nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.7.1

envs:
  MODEL_NAME: Qwen/Qwen3-8B
  HF_TOKEN: "" # needed if a model is gated in HF Hub. Pass the value with `--env HF_TOKEN`

run: |
  # Start NATS server with JetStream enabled (required for Dynamo messaging)
  nats-server -js &
  sleep 2

  # Start the Dynamo frontend (HTTP server + router)
  python -m dynamo.frontend --http-port 8080 --store-kv file &

  # Start the SGLang worker
  python -m dynamo.sglang --model $MODEL_NAME --store-kv file

# Kubernetes-specific configuration
config:
  kubernetes:
    pod_config:
      spec:
        containers:
        - securityContext:
            # Run as root to allow SkyPilot to install necessary packages
            runAsUser: 0
            runAsGroup: 0
