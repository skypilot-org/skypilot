name: bert_qa

resources:
    accelerators: H100:1
    
file_mounts:
    /checkpoint:
        name: # NOTE: Fill in your bucket name
        mode: MOUNT
envs:
  WANDB_RESUME: allow

secrets:
  WANDB_API_KEY:

setup: |
    git clone https://github.com/huggingface/transformers.git -b v4.30.1
    cd transformers
    pip install -e .
    cd examples/pytorch/question-answering/
    pip install -r requirements.txt torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113
    pip install wandb

run: |
    export WANDB_RUN_ID=$SKYPILOT_TASK_ID
    cd transformers/examples/pytorch/question-answering/
    python run_qa.py \
    --model_name_or_path bert-base-uncased \
    --dataset_name squad \
    --do_train \
    --do_eval \
    --per_device_train_batch_size 12 \
    --learning_rate 3e-5 \
    --num_train_epochs 50 \
    --max_seq_length 384 \
    --doc_stride 128 \
    --report_to wandb \
    --run_name $SKYPILOT_TASK_ID \
    --output_dir /checkpoint/bert_qa/ \
    --save_total_limit 10 \
    --save_steps 1000
