# Example: Data Processing Task (CPU)
# This SkyPilot task demonstrates CPU-based data processing
# that can be used as part of a Prefect workflow.
#
# Usage with Prefect:
#   from sky_train_flow import run_sky_task
#   run_sky_task(
#       base_path='/path/to/examples/prefect',
#       yaml_path='data_processing.yaml',
#       envs_override={'OUTPUT_BUCKET': 's3://my-bucket'}
#   )

name: data-processing

resources:
  cpus: 4+
  memory: 8+
  # No GPU required for data processing

envs:
  INPUT_PATH: "/data/raw"
  OUTPUT_PATH: "/data/processed"
  NUM_WORKERS: 4

setup: |
  # Install data processing dependencies
  pip install pandas numpy scikit-learn pyarrow
  
  # Create directories
  mkdir -p $INPUT_PATH $OUTPUT_PATH

run: |
  echo "Starting data processing task"
  echo "Input: $INPUT_PATH"
  echo "Output: $OUTPUT_PATH"
  echo "Workers: $NUM_WORKERS"
  
  python -c "
import numpy as np
import pandas as pd
import os

# Generate synthetic dataset
print('Generating synthetic dataset...')
n_samples = 10000
n_features = 50

# Create features
X = np.random.randn(n_samples, n_features)

# Create target (binary classification)
y = (X[:, 0] + X[:, 1] * 2 + np.random.randn(n_samples) * 0.5 > 0).astype(int)

# Create DataFrame
columns = [f'feature_{i}' for i in range(n_features)]
df = pd.DataFrame(X, columns=columns)
df['target'] = y

print(f'Dataset shape: {df.shape}')
print(f'Target distribution: {df[\"target\"].value_counts().to_dict()}')

# Data preprocessing
print('Applying preprocessing...')

# Normalize features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[columns] = scaler.fit_transform(df[columns])

# Save processed data
output_path = os.environ.get('OUTPUT_PATH', '/data/processed')
os.makedirs(output_path, exist_ok=True)
output_file = os.path.join(output_path, 'processed_data.parquet')
df.to_parquet(output_file, index=False)

print(f'Saved processed data to: {output_file}')
print('Data processing complete!')
"
  
  echo "Task completed successfully"
