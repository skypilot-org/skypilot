# Example: GPU Training Task
# This SkyPilot task demonstrates GPU-accelerated training
# that can be orchestrated with Prefect.
#
# Usage with Prefect:
#   from sky_train_flow import run_sky_task
#   run_sky_task(
#       base_path='/path/to/examples/prefect',
#       yaml_path='gpu_training.yaml',
#       envs_override={'NUM_EPOCHS': '10'}
#   )

name: gpu-training

resources:
  accelerators: A10G:1  # Request 1 A10G GPU
  # Alternative GPU options:
  # accelerators: A100:1
  # accelerators: V100:1
  # accelerators: H100:1
  cpus: 4+
  memory: 16+

envs:
  MODEL_NAME: bert-base-uncased
  NUM_EPOCHS: 3
  BATCH_SIZE: 32
  LEARNING_RATE: "0.0001"

setup: |
  # Install dependencies
  pip install torch transformers datasets accelerate
  
  # Verify GPU is available
  python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

run: |
  echo "Starting GPU training task"
  echo "Model: $MODEL_NAME"
  echo "Epochs: $NUM_EPOCHS"
  echo "Batch size: $BATCH_SIZE"
  echo "Learning rate: $LEARNING_RATE"
  
  # Display GPU information
  nvidia-smi
  
  # Example training script (replace with your actual training code)
  python -c "
import torch
import time

print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')

# Simulate training loop
num_epochs = int('$NUM_EPOCHS')
for epoch in range(num_epochs):
    # Simulate epoch training time
    time.sleep(2)
    loss = 0.5 - (0.1 * epoch)
    accuracy = 0.7 + (0.05 * epoch)
    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {loss:.4f}, Accuracy: {accuracy:.2%}')

print('Training complete!')
"
  
  echo "Task completed successfully"
