.. _installation:

Installation
==================

.. note::

    For Macs, macOS >= 10.15 is required to install SkyPilot. Apple Silicon-based devices (e.g. Apple M1) must run :code:`pip uninstall grpcio; conda install -c conda-forge grpcio=1.43.0` prior to installing SkyPilot.


Install SkyPilot using pip:

.. code-block:: console

  $ # SkyPilot requires python >= 3.7. For Apple Silicon, use >= 3.8.
  $ # Recommended: use a new conda env to avoid package conflicts.
  $ conda create -y -n sky python=3.8
  $ conda activate sky

  $ # Choose an extra (default: [aws])
  $ pip install skypilot
  $ # pip install "skypilot[gcp]"
  $ # pip install "skypilot[azure]"
  $ # pip install "skypilot[kubernetes]"
  $ # pip install "skypilot[lambda]"
  $ # pip install "skypilot[ibm]"
  $ # pip install "skypilot[scp]"
  $ # pip install "skypilot[oci]"
  $ # pip install "skypilot[all]"

SkyPilot currently supports these cloud providers: AWS, GCP, Azure, IBM, OCI, SCP, Lambda Cloud, and Cloudflare (for R2 object store).
If you only have access to certain clouds, use any combination of
the pip extras above (e.g., :code:`"[aws,gcp]"`) to reduce the
dependencies installed.


To get the latest features/updates, either install the nightly build:

.. code-block:: console

  $ pip install -U "skypilot-nightly[all]"

or install from source:

.. code-block:: console

  $ git clone https://github.com/skypilot-org/skypilot.git
  $ cd skypilot
  $ pip install ".[all]"



.. note::

    As an alternative to installing SkyPilot on your laptop, we also provide a Docker image as a quick way to try out SkyPilot. See instructions below on running SkyPilot :ref:`in a container <docker-image>`.

.. _cloud-account-setup:

Cloud account setup
-------------------

If you already have cloud access set up on your local machine, run ``sky check`` to :ref:`verify that SkyPilot can properly access your enabled clouds<verify-cloud-access>`.

Otherwise, configure access to at least one cloud, then run ``sky check``:

.. _aws-installation:

Amazon Web Services (AWS)
~~~~~~~~~~~~~~~~~~~~~~~~~~~


To get the **AWS access key** required by :code:`aws configure`, please go to the `AWS IAM Management Console <https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials>`_ and click on the "Access keys" dropdown (detailed instructions `here <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey>`__). The **Default region name [None]:** and **Default output format [None]:** fields are optional and can be left blank to choose defaults.

.. code-block:: console

  $ # Install boto
  $ pip install boto3

  $ # Configure your AWS credentials
  $ aws configure

To use AWS IAM Identity Center (AWS SSO), see :ref:`here<aws-sso>` for instructions.

**Optional**: To create a new AWS user with minimal permissions for SkyPilot, see :ref:`AWS User Creation <cloud-permissions-aws>`.

.. _installation-gcp:

Google Cloud Platform (GCP)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: console

  $ conda install -c conda-forge google-cloud-sdk

  $ gcloud init

  $ # Run this if you don't have a credentials file.
  $ # This will generate ~/.config/gcloud/application_default_credentials.json.
  $ gcloud auth application-default login

.. tip::

  If you are using multiple GCP projects, list all the projects by :code:`gcloud projects list` and activate one by :code:`gcloud config set project <PROJECT_ID>` (see `GCP docs <https://cloud.google.com/sdk/gcloud/reference/config/set>`_).

.. dropdown:: Common GCP installation errors

    Here some commonly encountered errors and their fixes:

    * ``RemoveError: 'requests' is a dependency of conda and cannot be removed from conda's operating environment`` when running :code:`conda install -c conda-forge google-cloud-sdk` --- run :code:`conda update --force conda` first and rerun the command.
    * ``Authorization Error (Error 400: invalid_request)`` with the url generated by :code:`gcloud auth login` --- install the latest version of the `Google Cloud SDK <https://cloud.google.com/sdk/docs/install>`_ (e.g., with :code:`conda install -c conda-forge google-cloud-sdk`) on your local machine (which opened the browser) and rerun the command.

**Optional**: To create and use a long-lived service account on your local machine, see :ref:`here<gcp-service-account>`.

**Optional**: To create a new GCP user with minimal permissions for SkyPilot, see :ref:`GCP User Creation <cloud-permissions-gcp>`.

Azure
~~~~~~~~~

.. code-block:: console

  $ # Login
  $ az login
  $ # Set the subscription to use
  $ az account set -s <subscription_id>

Hint: run ``az account subscription list`` to get a list of subscription IDs under your account.

Lambda Cloud
~~~~~~~~~~~~~~~~~~

`Lambda Cloud <https://lambdalabs.com/>`_ is a cloud provider offering low-cost GPUs. To configure Lambda Cloud access, go to the `API Keys <https://cloud.lambdalabs.com/api-keys>`_ page on your Lambda console to generate a key and then add it to :code:`~/.lambda_cloud/lambda_keys`:

.. code-block:: console

  $ mkdir -p ~/.lambda_cloud
  $ echo "api_key = <your_api_key_here>" > ~/.lambda_cloud/lambda_keys

IBM
~~~~~~~~~

To access IBM's VPC service, store the following fields in ``~/.ibm/credentials.yaml``:

.. code-block:: text

  iam_api_key: <user_personal_api_key>
  resource_group_id: <resource_group_user_is_a_member_of>

- Create a new API key by following `this guide <https://www.ibm.com/docs/en/app-connect/container?topic=servers-creating-cloud-api-key>`__.
- Obtain a resource group's ID from the `web console <https://cloud.ibm.com/account/resource-groups>`_.

.. note::
  Stock images aren't currently providing ML tools out of the box.
  Create private images with the necessary tools (e.g. CUDA), by following the IBM segment in `this documentation <https://github.com/skypilot-org/skypilot/blob/master/docs/source/reference/yaml-spec.rst>`_.

To access IBM's Cloud Object Storage (COS), append the following fields to the credentials file:

.. code-block:: text

  access_key_id: <access_key_id>
  secret_access_key: <secret_key_id>

To get :code:`access_key_id` and :code:`secret_access_key` use the IBM web console:

1. Create/Select a COS instance from the `web console <https://cloud.ibm.com/objectstorage/>`__.
2. From "Service Credentials" tab, click "New Credential" and toggle "Include HMAC Credential".
3. Copy "secret_access_key" and "access_key_id" to file.

Finally, install `rclone <https://rclone.org/>`_ via: ``curl https://rclone.org/install.sh | sudo bash``

.. note::
  :code:`sky check` does not reflect IBM COS's enabled status. :code:`IBM: enabled` only guarantees that IBM VM instances are enabled.

Oracle Cloud Infrastructure (OCI)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To access Oracle Cloud Infrastructure (OCI), setup the credentials by following `this guide <https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm>`__. After completing the steps in the guide, the :code:`~/.oci` folder should contain the following files:

.. code-block:: text

  ~/.oci/config
  ~/.oci/oci_api_key.pem

The :code:`~/.oci/config` file should contain the following fields:

.. code-block:: text

  [DEFAULT]
  user=ocid1.user.oc1..aaaaaaaa
  fingerprint=aa:bb:cc:dd:ee:ff:gg:hh:ii:jj:kk:ll:mm:nn:oo:pp
  tenancy=ocid1.tenancy.oc1..aaaaaaaa
  region=us-sanjose-1
  key_file=~/.oci/oci_api_key.pem

Cloudflare R2
~~~~~~~~~~~~~~~~~~

Cloudflare offers `R2 <https://www.cloudflare.com/products/r2>`_, an S3-compatible object storage without any egress charges.
SkyPilot can download/upload data to R2 buckets and mount them as local filesystem on clusters launched by SkyPilot. To set up R2 support, run:

.. code-block:: console

  $ # Install boto
  $ pip install boto3
  $ # Configure your R2 credentials
  $ AWS_SHARED_CREDENTIALS_FILE=~/.cloudflare/r2.credentials aws configure --profile r2

In the prompt, enter your R2 Access Key ID and Secret Access Key (see `instructions to generate R2 credentials <https://developers.cloudflare.com/r2/data-access/s3-api/tokens/>`_). Select :code:`auto` for the default region and :code:`json` for the default output format.

.. code-block:: text

  AWS Access Key ID [None]: <access_key_id>
  AWS Secret Access Key [None]: <access_key_secret>
  Default region name [None]: auto
  Default output format [None]: json

Next, get your `Account ID <https://developers.cloudflare.com/fundamentals/get-started/basic-tasks/find-account-and-zone-ids/>`_ from your R2 dashboard and store it in :code:`~/.cloudflare/accountid` with:

.. code-block:: console

  $ mkdir -p ~/.cloudflare
  $ echo <YOUR_ACCOUNT_ID_HERE> > ~/.cloudflare/accountid

.. note::

  Support for R2 is in beta. Please report and issues on `Github <https://github.com/skypilot-org/skypilot/issues>`_ or reach out to us on `Slack <http://slack.skypilot.co/>`_.


Samsung Cloud Platform (SCP)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Samsung Cloud Platform(SCP) provides cloud services optimized for enterprise customers. You can learn more about SCP `here <https://cloud.samsungsds.com/>`__.

To configure SCP access, you need access keys and the ID of the project your tasks will run. Go to the `Access Key Management <https://cloud.samsungsds.com/console/#/common/access-key-manage/list?popup=true>`_ page on your SCP console to generate the access keys, and the Project Overview page for the project ID. Then, add them to :code:`~/.scp/scp_credential` by running:

.. code-block:: console

  $ # Create directory if required
  $ mkdir -p ~/.scp
  $ # Add the lines for "access_key", "secret_key", and "project_id" to scp_credential file
  $ echo "access_key = <your_access_key>" >> ~/.scp/scp_credential
  $ echo "secret_key = <your_secret_key>" >> ~/.scp/scp_credential
  $ echo "project_id = <your_project_id>" >> ~/.scp/scp_credential

.. note::

  Multi-node clusters are currently not supported on SCP.

Kubernetes
~~~~~~~~~~

SkyPilot can also run tasks on on-prem or cloud hosted Kubernetes clusters (e.g., EKS, GKE). The only requirement is a valid kubeconfig at :code:`~/.kube/config`.

.. code-block:: console

  $ # Place your kubeconfig at ~/.kube/config
  $ mkdir -p ~/.kube
  $ cp /path/to/kubeconfig ~/.kube/config

See :ref:`SkyPilot on Kubernetes <kubernetes-overview>` for more.

.. _verify-cloud-access:

Verifying cloud access
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

After configuring the desired clouds, you can optionally run :code:`sky check` to verify that credentials are correctly set up:

.. code-block:: console

  $ sky check

This will produce a summary like:

.. code-block:: text

  Checking credentials to enable clouds for SkyPilot.
    AWS: enabled
    GCP: enabled
    Azure: enabled
    Lambda: enabled
    IBM: enabled
    SCP: enabled
    OCI: enabled
    Cloudflare (for R2 object store): enabled

  SkyPilot will use only the enabled clouds to run tasks. To change this, configure cloud credentials, and run sky check.

Requesting quotas for first time users
--------------------------------------

If your cloud account has not been used to launch instances before, the
respective quotas are likely set to zero or a low limit.  This is especially
true for GPU instances.

Please follow :ref:`Requesting Quota Increase <quota>` to check quotas and request quota
increases before proceeding.

.. _docker-image:

Quick alternative: trying in Docker
------------------------------------------------------

As a **quick alternative to installing SkyPilot on your laptop**, we also provide a Docker image with SkyPilot and
its AWS and GCP dependencies installed for users to quickly try out SkyPilot. You can simply run:

.. code-block:: console

  $ docker run -td --name sky --rm -v "$HOME/.sky:/root/.sky:rw" -v "$HOME/.aws:/root/.aws:rw" -v "$HOME/.config/gcloud:/root/.config/gcloud:rw" berkeleyskypilot/skypilot:latest
  $ docker exec -it sky /bin/bash

If your cloud CLIs are already setup, your credentials will be mounted to the
container and you can proceed to :ref:`Quickstart <quickstart>`. Else you can
follow the instructions in :ref:`Cloud account setup <cloud-account-setup>`
inside the container to setup your cloud accounts.

If you exit from the shell in the container, the container will keep running
in the background. You can start a new shell with :code:`docker exec -it sky /bin/bash`.

Once you are done with experimenting with sky, remember to delete any clusters
and storage resources you may have created using the following commands:

.. code-block:: console

  # Run inside the container

  $ sky down -a -y
  $ sky storage delete -a -y

Finally, you can stop the container with:

.. code-block:: console

  $ docker stop sky

.. _shell-completion:

Enabling shell completion
-------------------------

SkyPilot supports shell completion for Bash (Version 4.4 and up), Zsh and Fish. This is only available for :code:`click` versions 8.0 and up (use :code:`pip install click==8.0.4` to install).

To enable shell completion after installing SkyPilot, you will need to modify your shell configuration.
SkyPilot automates this process using the :code:`--install-shell-completion` option, which you should call using the appropriate shell name or :code:`auto`:

.. code-block:: console

  $ sky --install-shell-completion auto
  $ # sky --install-shell-completion zsh
  $ # sky --install-shell-completion bash
  $ # sky --install-shell-completion fish

Shell completion may perform poorly on certain shells and machines.
If you experience any issues after installation, you can use the :code:`--uninstall-shell-completion` option to uninstall it, which you should similarly call using the appropriate shell name or :code:`auto`:

.. code-block:: console

  $ sky --uninstall-shell-completion auto
  $ # sky --uninstall-shell-completion zsh
  $ # sky --uninstall-shell-completion bash
  $ # sky --uninstall-shell-completion fish
