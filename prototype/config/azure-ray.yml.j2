cluster_name: {{cluster_name}}

# The maximum number of workers nodes to launch in addition to the head node.
max_workers: {{num_nodes - 1}}
idle_timeout_minutes: 60

provider:
    type: azure
    location: {{region}}
    # Ref: https://github.com/ray-project/ray/blob/2367a2cb9033913b68b1230316496ae273c25b54/python/ray/autoscaler/_private/_azure/node_provider.py#L87
    # For Azure, ray distinguishes different instances by the resource_group,
    # instead of the cluster_name. This ensures that ray creates new instances
    # for different cluster_name.
    resource_group: {{cluster_name}}-{{region}}
    # Keep (otherwise cannot reuse when re-provisioning).
    # teardown(terminate=True) will override this.
    cache_stopped_nodes: True

auth:
    ssh_user: azureuser

available_node_types:
    ray.head.default:
      resources: {}
      node_config:
        azure_arm_parameters:
            vmSize: {{instance_type}}
            # List images https://docs.microsoft.com/en-us/azure/virtual-machines/linux/cli-ps-findimage
            imagePublisher: microsoft-dsvm
            imageOffer: ubuntu-1804
            imageSku: 1804-gen2
            imageVersion: 21.09.13
            # optionally set priority to use Spot instances
            {%- if use_spot %}
            priority: Spot
            # set a maximum price for spot instances if desired
            # billingProfile:
            #     maxPrice: -1
            {%- endif %}
        # TODO: attach disk
{% if num_nodes > 1 %}
    ray.worker.default:
      min_workers: {{num_nodes - 1}}
      max_workers: {{num_nodes - 1}}
      resources: {}
      node_config:
        azure_arm_parameters:
            vmSize: {{instance_type}}
            # List images https://docs.microsoft.com/en-us/azure/virtual-machines/linux/cli-ps-findimage
            imagePublisher: microsoft-dsvm
            imageOffer: ubuntu-1804
            imageSku: 1804-gen2
            imageVersion: 21.09.13
          {%- if use_spot %}
            priority: Spot
            # set a maximum price for spot instances if desired
            # billingProfile:
            #     maxPrice: -1
          {%- endif %}
{%- endif %}

head_node_type: ray.head.default

# Format: `REMOTE_PATH : LOCAL_PATH`
file_mounts: {
  "{{sky_remote_path}}": "{{sky_local_path}}",
{%- if workdir is not none %}
  "~/sky_workdir": "{{workdir}}",
{%- endif %}
{%- if setup_sh_path is not none %}
  "/tmp/setup.sh": "{{setup_sh_path}}",
{%- endif %}
{%- for remote_path, local_path in file_mounts.items() %}
  "{{remote_path}}": "{{local_path}}",
{%- endfor %}
}

{%- if initialization_commands is not none %}
initialization_commands:
{%- for cmd in initialization_commands %}
  - {{cmd}}
{%- endfor %}
{%- endif %}

# Patterns for files to exclude when running rsync up or rsync down
# rsync_exclude:
#   - "**/.git"
#   - "**/.git/**"

rsync_filter:
  - .gitignore

# List of shell commands to run to set up nodes.
setup_commands:
  # This AMI's system Python is version 2+.
  # _gang_schedule_ray_up() requires this line; do not modify.
  - pip3 install -U ray[default]=={{ray_version}} && mkdir -p ~/sky_workdir && mkdir -p ~/.sky/sky_app && touch ~/.sudo_as_admin_successful
  - pip3 install {{sky_remote_path}}/*.whl && python3 -c "from sky.skylet.ray_patches import patch; patch()" # patch the buggy ray file
{%- if setup_sh_path is not none %}
  - cd ~/sky_workdir && bash /tmp/setup.sh  # FIXME: /tmp is volatile.
{%- endif %}

# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
  - ray stop; ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml {{"--resources='%s'" % custom_resources if custom_resources}}

{%- if num_nodes > 1 %}
worker_start_ray_commands:
  - ray stop; ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076 {{"--resources='%s'" % custom_resources if custom_resources}}
{%- endif %}
