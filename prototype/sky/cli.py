"""The 'sky' command line tool.

Example usage:

  # See available commands.
  >> sky

  # Run a task, described in a yaml file.
  # Provisioning, setup, file syncing are handled.
  >> sky run task.yaml
  >> sky run [-c cluster_name] task.yaml

  # Show the list of tasks and running clusters.
  >> sky status

  # Tear down a specific cluster.
  >> sky down -c cluster_name

  # Tear down all existing clusters.
  >> sky down -a

TODO:
- Add support for local Docker backend.  Currently this module is very coupled
  with CloudVmRayBackend, as seen by the many use of ray commands.

NOTE: the order of command definitions in this file corresponds to how they are
listed in "sky --help".  Take care to put logically connected commands close to
each other.
"""
import os
import time
from typing import List, Optional

import click
import pendulum
import prettytable

import sky
from sky import backends
from sky import global_user_state
from sky.backends import backend as backend_lib
from sky.backends import backend_utils
from sky.backends import cloud_vm_ray_backend

_CLUSTER_FLAG_HELP = """
A cluster name. If provided, either reuse an existing cluster with that name or
provision a new cluster with that name. Otherwise provision a new cluster with
an autogenerated name.
""".strip()

Path = str
Backend = backends.Backend


# TODO: --screen; while uploading ~/.screenrc.
# TODO: skip installing ray to speed up provisioning.
def _create_interactive_node(
        name: str,
        resources: sky.Resources,
        cluster_handle: backend_lib.Backend.ResourceHandle = None,
        backend: Optional[backend_lib.Backend] = None,
        port_forward: Optional[List[int]] = None,
        cluster_name: Optional[str] = None):
    """Creates an interactive session.

    Args:
        name: Name of the sky.Task to create.
        resources: Resources to attach to VM.
        cluster_handle: Cluster YAML file.
        backend: Backend to use.
        port_forward: List of ports to forward.
        cluster_name: Name of the cluster.
    """

    with sky.Dag() as dag:
        # TODO: Add conda environment replication
        # should be setup =
        # 'conda env export | grep -v "^prefix: " > environment.yml'
        # && conda env create -f environment.yml
        task = sky.Task(
            name,
            workdir=os.getcwd(),
            setup=None,
            run='',
        )
        task.set_resources(resources)

    backend = backend() if backend is not None else backends.CloudVmRayBackend()
    backend.register_info(dag=dag)

    dag = sky.optimize(dag)
    task = dag.tasks[0]

    handle = cluster_handle
    if handle is None:
        handle = backend.provision(task,
                                   task.best_resources,
                                   dryrun=False,
                                   stream_logs=True,
                                   cluster_name=cluster_name)

    global_user_state.add_task(task)

    # TODO: cd into workdir immediately on the VM
    # TODO: Delete the temporary cluster config yml (or figure out a way to
    # re-use it)
    attach_options = ''
    if port_forward is not None:
        attach_options = ' '.join(
            [f'--port-forward {port}' for port in port_forward])
    # Disable check, since the returncode could be non-zero if the user Ctrl-D
    backend_utils.run(f'ray attach {attach_options} {handle}', check=False)

    cluster_name = global_user_state.get_cluster_name_from_handle(handle)
    relpath = backend_utils.get_rel_path(handle.cluster_yaml)
    click.echo('The interactive node is still running.')
    click.echo('  To attach to it again:  ', nl=False)
    click.secho(f'ray attach {relpath}', bold=True)
    click.echo('  To tear down the node:  ', nl=False)
    click.secho(f'sky down {cluster_name}', bold=True)


class _NaturalOrderGroup(click.Group):
    """Lists commands in the order they are defined in this script.

    Reference: https://github.com/pallets/click/issues/513
    """

    def list_commands(self, ctx):
        return self.commands.keys()


@click.group(cls=_NaturalOrderGroup)
def cli():
    pass


@cli.command()
@click.argument('yaml_path', required=True, type=str)
@click.option('--cluster',
              '-c',
              default=None,
              type=str,
              help=_CLUSTER_FLAG_HELP)
@click.option('--dryrun',
              '-n',
              default=False,
              type=bool,
              help='If True, do not actually run the job.')
def run(yaml_path: Path, cluster: str, dryrun: bool):
    """Launch a task from a YAML spec (rerun setup if a cluster exists)."""
    with sky.Dag() as dag:
        sky.Task.from_yaml(yaml_path)
    # FIXME: --cluster flag semantics has the following bug.  'sky run -c name
    # x.yml' requiring GCP.  Then change x.yml to requiring AWS.  'sky run -c
    # name x.yml' again.  The GCP cluster is not down'd but should be.  The
    # root cause is due to 'ray up' not dealing with this cross-cloud case (but
    # does correctly deal with in-cloud config changes).
    #
    # This bug also means that the old GCP cluster with the same name is
    # orphaned.  `sky down` would not have an entry pointing to that handle, so
    # would only down the NEW cluster.
    #
    # To fix all of the above, fix/circumvent the bug that 'ray up' not downing
    # old cloud's cluster with the same name.
    sky.execute(dag, dryrun=dryrun, stream_logs=True, cluster_name=cluster)


@cli.command()
@click.argument('yaml_path', required=True, type=str)
@click.option('--cluster',
              '-c',
              required=True,
              type=str,
              help='Name of the existing cluster to execute a task on.')
def exec(yaml_path: Path, cluster: str):  # pylint: disable=redefined-builtin
    """Execute a task from a YAML spec on a cluster (skip setup).

    \b
    Actions performed by this command only include:
      - workdir syncing
      - executing the task's run command
    `sky exec` is thus typically faster than `sky run`, provided a cluster
    already exists.

    All setup steps (provisioning, setup commands, file mounts syncing) are
    skipped.  If any of those specifications changed, this command will not
    reflect those changes.  To ensure a cluster's setup is up to date, use `sky
    run` instead.

    Typical workflow:

      # First command: set up the cluster once.

      >> sky run -c name app.yaml

    \b
      # Starting iterative development...
      # For example, modify local workdir code.
      # Future commands: simply execute the task on the launched cluster.

      >> sky exec -c name app.yaml

      # Simply do "sky run" again if anything other than Task.run is modified:

      >> sky run -c name app.yaml

    """
    handle = global_user_state.get_handle_from_cluster_name(cluster)
    if handle is None:
        raise click.BadParameter(f'Cluster \'{cluster}\' not found.  '
                                 'Use `sky run` to provision first.')
    with sky.Dag() as dag:
        sky.Task.from_yaml(yaml_path)
    sky.execute(dag,
                handle=handle,
                stages=[
                    sky.execution.Stage.SYNC_WORKDIR,
                    sky.execution.Stage.EXEC,
                ])


@cli.command()
def status():
    """Show launched clusters and tasks."""

    tasks_status = global_user_state.get_tasks()
    clusters_status = global_user_state.get_clusters()

    task_table = prettytable.PrettyTable()
    task_table.field_names = ['TASK ID', 'TASK NAME', 'LAUNCHED']
    for task_status in tasks_status:
        launched_at = task_status['launched_at']
        duration = pendulum.now().subtract(seconds=time.time() - launched_at)
        task_table.add_row([
            task_status['id'],
            task_status['name'],
            duration.diff_for_humans(),
        ])

    cluster_table = prettytable.PrettyTable()
    cluster_table.field_names = ['CLUSTER NAME', 'LAUNCHED']
    for cluster_status in clusters_status:
        launched_at = cluster_status['launched_at']
        duration = pendulum.now().subtract(seconds=time.time() - launched_at)
        cluster_table.add_row([
            cluster_status['name'],
            duration.diff_for_humans(),
        ])

    click.echo(f'Tasks\n{task_table}')
    click.echo()
    click.echo(f'Clusters\n{cluster_table}')


@cli.command()
@click.argument('cluster', required=False)
@click.option('--all',
              '-a',
              default=None,
              is_flag=True,
              help='Tear down all existing clusters.')
def down(cluster: str, all: Optional[bool]):  # pylint: disable=redefined-builtin
    """Tear down cluster(s).

    CLUSTER is the name of the cluster to tear down.  If both CLUSTER and --all
    are supplied, the latter takes precedence.

    Accelerators (e.g., TPU) that are part of the cluster will be deleted too.

    Examples:

      \b
      # Tear down a specific cluster.
      sky down cluster_name

      \b
      # Tear down all existing clusters.
      sky down -a
    """
    name = cluster
    downall = all
    if name is None and downall is None:
        raise click.UsageError(
            'sky down requires either a cluster name (see `sky status`) '
            'or --all.')

    to_down = []
    if name is not None:
        handle = global_user_state.get_handle_from_cluster_name(name)
        if handle is not None:
            to_down = [{'name': name, 'handle': handle}]
    if downall:
        to_down = global_user_state.get_clusters()
        if name is not None:
            print('Both --all and --cluster specified for sky down. '
                  'Letting --all take effect.')
            name = None
    if not to_down:
        if name is not None:
            print(f'Cluster {name} is not found (see `sky status`).')
        else:
            print('No existing clusters found (see `sky status`).')

    # FIXME: Assumes a specific backend.
    backend = cloud_vm_ray_backend.CloudVmRayBackend()
    for record in to_down:  # TODO: parallelize.
        name = record['name']
        handle = record['handle']
        backend.teardown(handle)
        global_user_state.remove_cluster(name)
        click.secho(f'Tearing down cluster {name}...done.', fg='green')


@cli.command()
@click.argument('cluster', required=False)
@click.option('--port-forward',
              '-p',
              multiple=True,
              default=[],
              type=int,
              required=False,
              help='Port to be forwarded. To forward multiple ports, '
              'use this option multiple times.')
def ssh(cluster: str, port_forward: Optional[List[int]]):
    """ssh to the cluster CLUSTER.

    CLUSTER is the name of the cluster to attach.  If CLUSTER is not supplied,
    the last cluster will be attached.

    Examples:

      \b
      # ssh to a specific cluster.
      sky ssh cluster_name

      \b
      # Port forward.
      sky ssh --port-forward 8080 --port-forward 4650 cluster_name
      sky ssh -p 8080 -p 4650 cluster_name
    """
    # FIXME: make TPU part of handles; so that this kills TPUs too.
    name = cluster

    to_ssh = name
    if to_ssh is None:
        launched_clusters = global_user_state.get_clusters()
        if len(launched_clusters) == 0:
            raise click.UsageError(
                'No launched clusters found (see `sky status`).')
        to_ssh = sorted(launched_clusters, key=lambda x: x['launched_at'])[-1]
    handle = global_user_state.get_handle_from_cluster_name(to_ssh)

    if handle is None:
        raise click.UsageError(
            f'Cluster {to_ssh} is not found (see `sky status`).')

    # FIXME: Assumes a specific backend.
    _create_interactive_node(name,
                             sky.Resources(),
                             handle,
                             port_forward=port_forward)


@click.argument('task_id', required=False, type=str)
@click.option('--all',
              '-a',
              default=None,
              is_flag=True,
              help='Cancel all tasks.')
def cancel(task_id: str, all: Optional[bool]):  # pylint: disable=redefined-builtin
    """Cancel task(s).

    TASK_ID is the id of the task to cancel.  If both TASK_ID and --all are
    supplied, the latter takes precedence.

    Examples:

      \b
      sky cancel task_id
      sky cancel -a
    """
    downall = all
    if task_id is None and downall is None:
        raise click.UsageError(
            'sky cancel requires either a task id (see `sky status`) '
            'or --all.')
    to_down = []
    if task_id is not None:
        to_down = [task_id]
    if downall:
        records = global_user_state.get_tasks()
        to_down = [r['id'] for r in records]
        if task_id is not None:
            print('Both --all and TASK_ID specified for sky cancel. '
                  'Letting --all take effect.')
            task_id = None
    if not to_down:
        if task_id is not None:
            print(f'Task {task_id} is not found (see `sky status`).')
        else:
            print('No existing tasks found (see `sky status`).')
        return
    # TODO: Current implementation is blocking and will wait for the task to
    # complete.  If this is changed to non-blocking, then we will need a way to
    # kill async tasks with ray exec.
    for tid in to_down:
        global_user_state.remove_task(tid)
    click.secho('Done.', fg='green')


@cli.command()
@click.option('--cluster',
              '-c',
              default=None,
              type=str,
              help=_CLUSTER_FLAG_HELP)
@click.option('--port-forward',
              '-p',
              multiple=True,
              default=[],
              type=int,
              required=False,
              help='Port to be forwarded. To forward multiple ports, '
              'use this option multiple times.')
def gpunode(cluster: str, port_forward: Optional[List[int]]):
    """Launches an interactive GPU node.

    Automatically syncs current working directory.

    Examples:

      \b
      # start gpunode
      sky gpunode

      # creating a gpunode with name `cluster` or connecting to existed node.
      sky gpunode -c cluster_name

      \b
      # Port forward.
      sky gpunode --port-forward 8080 --port-forward 4650 cluster_name
      sky gpunode -p 8080 -p 4650 cluster_name
    """
    # TODO: Sync code files between local and interactive node (watch rsync?)
    handle = None
    if cluster is not None:
        handle = global_user_state.get_handle_from_cluster_name(cluster)

    _create_interactive_node('gpunode',
                             {sky.Resources(sky.AWS(), accelerators='V100')},
                             cluster_handle=handle,
                             port_forward=port_forward,
                             cluster_name=cluster)


@cli.command()
@click.option('--cluster',
              '-c',
              default=None,
              type=str,
              help=_CLUSTER_FLAG_HELP)
@click.option('--port-forward',
              '-p',
              multiple=True,
              default=[],
              type=int,
              required=False,
              help='Port to be forwarded. To forward multiple ports, '
              'use this option multiple times.')
def cpunode(cluster: str, port_forward: Optional[List[int]]):
    """Launches an interactive CPU node.

    Automatically syncs current working directory.

     Examples:

      \b
      # start cpunode
      sky cpunode

      # creating a cpunode with name `cluster` or connecting to existed node.
      sky cpunode -c cluster_name

      \b
      # Port forward.
      sky cpunode --port-forward 8080 --port-forward 4650 cluster_name
      sky cpunode -p 8080 -p 4650 cluster_name
    """
    handle = None
    if cluster is not None:
        handle = global_user_state.get_handle_from_cluster_name(cluster)

    _create_interactive_node('cpunode', {sky.Resources(sky.AWS())},
                             cluster_handle=handle,
                             port_forward=port_forward,
                             cluster_name=cluster)


def main():
    return cli()


if __name__ == '__main__':
    main()
