# VeRL GRPO Training with Job Groups
#
# This example demonstrates distributed RL training using VeRL with SkyPilot job groups.
# It separates auxiliary services (data, reward, retrieval) from VeRL's GPU training.
#
# Architecture:
#   - data-server (auxiliary): Serves GSM8K math prompts
#   - reward-server (auxiliary): Verifies math answers for reward computation
#   - retrieval-server (auxiliary): FAISS retrieval for tool-augmented training
#   - verl-trainer (primary): VeRL GRPO training with external reward function
#
# Primary/Auxiliary Behavior:
#   The verl-trainer is the primary task. When training completes, all auxiliary
#   services are terminated after a 10-second grace period.
#
# Usage:
#   sky jobs launch llm/verl-jobgroup/verl-grpo-jobgroup.yaml
#
#   # With WandB logging
#   sky jobs launch llm/verl-jobgroup/verl-grpo-jobgroup.yaml --secret WANDB_API_KEY
#
# Service Discovery:
#   - data-server-0.${SKYPILOT_JOBGROUP_NAME}:8000
#   - reward-server-0.${SKYPILOT_JOBGROUP_NAME}:8001
#   - retrieval-server-0.${SKYPILOT_JOBGROUP_NAME}:8002
---
name: verl-grpo
execution: parallel
primary_tasks: [verl-trainer]
termination_delay: 10s

---
# Data Server: Serves math prompts from GSM8K dataset
name: data-server
resources:
  cpus: 4
  memory: 16+
  infra: kubernetes

file_mounts:
  /code: llm/verl-jobgroup/code

setup: |
  echo "=== Data Server Setup ==="
  uv pip install fastapi uvicorn datasets --system

run: |
  echo "Starting data server..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Data API at http://data-server-0.${SKYPILOT_JOBGROUP_NAME}:8000"

  cd /code
  python data_server.py --port 8000

---
# Reward Server: Verifies math answers against ground truth
name: reward-server
resources:
  cpus: 4
  memory: 8+
  infra: kubernetes

file_mounts:
  /code: llm/verl-jobgroup/code

setup: |
  echo "=== Reward Server Setup ==="
  uv pip install fastapi uvicorn sympy --system

run: |
  echo "Starting reward server..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Reward API at http://reward-server-0.${SKYPILOT_JOBGROUP_NAME}:8001"

  cd /code
  python reward_server.py --port 8001

---
# Retrieval Server: FAISS-based Wikipedia retrieval for tool calling
name: retrieval-server
resources:
  cpus: 16+
  memory: 64+
  infra: kubernetes

envs:
  RETRIEVAL_TOPK: 3
  RETRIEVER_NAME: e5
  RETRIEVER_MODEL: intfloat/e5-base-v2

setup: |
  echo "=== Retrieval Server Setup ==="

  # Python environment
  uv venv --python 3.10 --seed
  source .venv/bin/activate

  # Install dependencies
  uv pip install torch --index-url https://download.pytorch.org/whl/cpu
  uv pip install transformers datasets huggingface_hub
  uv pip install faiss-cpu
  uv pip install uvicorn fastapi uvloop==0.21.0

  # Download Wikipedia corpus and FAISS index
  echo "Downloading Wikipedia corpus and FAISS index..."
  export save_path=~/dataset
  mkdir -p $save_path

  huggingface-cli download maknee/wiki-18-subsets wiki-18-100k.jsonl.gz --repo-type=dataset --local-dir $save_path
  huggingface-cli download maknee/wiki-18-subsets e5_Flat-100k.index --repo-type=dataset --local-dir $save_path

  # Move files to expected locations
  mv $save_path/wiki-18-100k.jsonl.gz $save_path/wiki-18.jsonl.gz
  mv $save_path/e5_Flat-100k.index $save_path/e5_Flat.index

  # Decompress
  gzip -d $save_path/wiki-18.jsonl.gz -f

  # Clone VERL for retrieval server code
  git clone https://github.com/volcengine/verl.git
  cd verl
  git checkout v0.6.0

  # Patch for CPU-only usage
  sed -i 's/^\(\s*\)\(model\.cuda()\)/\1# \2/' \
    examples/sglang_multiturn/search_r1_like/local_dense_retriever/retrieval_server.py
  sed -i 's/^\(\s*\)\(inputs = {k: v\.cuda() for k, v in inputs\.items()}\)/\1# \2/' \
    examples/sglang_multiturn/search_r1_like/local_dense_retriever/retrieval_server.py

  echo "Setup complete!"

run: |
  echo "Starting retrieval server..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Retrieval API at http://retrieval-server-0.${SKYPILOT_JOBGROUP_NAME}:8002"

  source .venv/bin/activate

  save_path=~/dataset
  index_file=$save_path/e5_Flat.index
  corpus_file=$save_path/wiki-18.jsonl

  cd verl
  python examples/sglang_multiturn/search_r1_like/local_dense_retriever/retrieval_server.py \
    --index_path $index_file \
    --corpus_path $corpus_file \
    --topk $RETRIEVAL_TOPK \
    --retriever_name $RETRIEVER_NAME \
    --retriever_model $RETRIEVER_MODEL \
    --port 8002

---
# VeRL Trainer: GRPO training with external services
name: verl-trainer
num_nodes: 1
resources:
  accelerators: H100:1
  memory: 128+
  infra: kubernetes
  image_id: docker:verlai/verl:app-verl0.6-transformers4.56.1-sglang0.5.2-mcore0.13.0-te2.2
  ports:
    - 8265  # Ray dashboard

config:
  docker:
    run_options:
      - --cap-add=SYS_PTRACE
      - --ipc=host
      - --shm-size=16g

envs:
  MODEL_NAME: Qwen/Qwen2.5-3B-Instruct
  TOTAL_EPOCHS: 1
  TOTAL_STEPS: 100
  TRAIN_BATCH_SIZE: 256
  VAL_BATCH_SIZE: 128
  SAVE_FREQ: 20
  TEST_FREQ: 10
  WANDB_PROJECT_NAME: verl-jobgroup
  WANDB_EXPERIMENT_NAME: grpo-math-training
  CHECKPOINT_BUCKET_NAME: verl-jobgroup-checkpoints

file_mounts:
  /code: llm/verl-jobgroup/code
  /checkpoints:
    name: ${CHECKPOINT_BUCKET_NAME}
    mode: MOUNT

secrets:
  WANDB_API_KEY: ""

setup: |
  rm -f ~/.pip/pip.conf
  rm -f ~/.config/pip/pip.conf

  set -e
  echo "=== VeRL Trainer Setup ==="

  # System dependencies
  sudo apt update && sudo apt install -y iproute2

  # Python environment
  uv venv --python 3.10 --seed
  source .venv/bin/activate

  # Clone VERL
  rm -rf verl
  git clone https://github.com/volcengine/verl.git
  cd verl
  git checkout v0.6.0

  # Install dependencies
  uv pip install "torch==2.8.*" torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
  uv pip install "https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.8cxx11abiFALSE-cp310-cp310-linux_x86_64.whl"
  uv pip install -v -e .
  uv pip install wheel packaging
  uv pip install -r ./requirements_sglang.txt
  uv pip install uvloop==0.21.0 httpx

  # Prepare dataset
  echo "Preparing GSM8K dataset..."
  python3 examples/data_preprocess/gsm8k.py

  # Copy custom reward function
  cp /code/verl_reward_function.py examples/

  echo "Setup complete!"

run: |
  set -e
  echo "=== VeRL GRPO Training ==="
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Node rank: ${SKYPILOT_NODE_RANK} / ${SKYPILOT_NUM_NODES}"

  # Service endpoints via job group DNS
  DATA_SERVER="data-server-0.${SKYPILOT_JOBGROUP_NAME}:8000"
  REWARD_SERVER="reward-server-0.${SKYPILOT_JOBGROUP_NAME}:8001"
  RETRIEVAL_SERVER="retrieval-server-0.${SKYPILOT_JOBGROUP_NAME}:8002"

  echo "External services:"
  echo "  Data server: http://${DATA_SERVER}"
  echo "  Reward server: http://${REWARD_SERVER}"
  echo "  Retrieval server: http://${RETRIEVAL_SERVER}"

  # Export for custom reward function
  export REWARD_SERVER_URL="http://${REWARD_SERVER}"
  export RETRIEVAL_SERVER_URL="http://${RETRIEVAL_SERVER}"

  # Network configuration
  NETWORK_INTERFACE=$(ip route get 8.8.8.8 | grep -oP 'dev \K\S+')
  export GLOO_SOCKET_IFNAME=$NETWORK_INTERFACE
  export NCCL_SOCKET_IFNAME=$NETWORK_INTERFACE
  export TORCH_MULTIPROCESSING_SHARING_STRATEGY=file_system

  source .venv/bin/activate
  cd verl
  export PYTHONPATH="$(pwd):$PYTHONPATH"

  # Wait for services to be ready
  echo "Waiting for auxiliary services..."
  max_retries=60
  retry_count=0

  while [ $retry_count -lt $max_retries ]; do
    data_ok=$(curl -s -o /dev/null -w "%{http_code}" "http://${DATA_SERVER}/health" 2>/dev/null || echo "000")
    reward_ok=$(curl -s -o /dev/null -w "%{http_code}" "http://${REWARD_SERVER}/health" 2>/dev/null || echo "000")

    if [ "$data_ok" = "200" ] && [ "$reward_ok" = "200" ]; then
      echo "All services ready!"
      break
    fi
    echo "Waiting... (data: $data_ok, reward: $reward_ok)"
    retry_count=$((retry_count+1))
    sleep 5
  done

  # WandB login (optional)
  if [ -n "$WANDB_API_KEY" ]; then
    echo "Logging into Weights & Biases..."
    python3 -c "import wandb; wandb.login(relogin=True, key='$WANDB_API_KEY')"
  fi

  HEAD_IP=$(echo "$SKYPILOT_NODE_IPS" | head -n1)
  NUM_NODES=$SKYPILOT_NUM_NODES
  NUM_GPUS_PER_NODE=$SKYPILOT_NUM_GPUS_PER_NODE

  if [ "$SKYPILOT_NODE_RANK" == "0" ]; then
    echo "Starting Ray head node..."
    ray start --head --disable-usage-stats --port=6379 --dashboard-host=0.0.0.0 --dashboard-port=8265

    # Wait for workers
    if [ "$NUM_NODES" -gt 1 ]; then
      echo "Waiting for $NUM_NODES nodes to connect..."
      retry_count=0
      while [ $retry_count -lt 30 ]; do
        connected_nodes=$(ray status 2>/dev/null | grep -c "node_" || echo "0")
        if [ "$connected_nodes" -ge "$NUM_NODES" ]; then
          echo "All $NUM_NODES nodes connected"
          break
        fi
        retry_count=$((retry_count+1))
        sleep 10
      done
    fi

    ray status

    # Configure logging
    if [ -n "$WANDB_API_KEY" ]; then
      LOGGER_CONFIG='["console","wandb"]'
      WANDB_ARGS="trainer.project_name=$WANDB_PROJECT_NAME trainer.experiment_name=$WANDB_EXPERIMENT_NAME"
    else
      LOGGER_CONFIG='["console"]'
      WANDB_ARGS=""
    fi

    ulimit -n 65535

    echo "Starting GRPO training..."

    # Run VeRL GRPO training
    # Using GSM8K dataset with math verification rewards
    python3 -m verl.trainer.main_ppo \
      algorithm.adv_estimator=grpo \
      data.train_files=$HOME/data/gsm8k/train.parquet \
      data.val_files=$HOME/data/gsm8k/test.parquet \
      data.train_batch_size=$TRAIN_BATCH_SIZE \
      data.val_batch_size=$VAL_BATCH_SIZE \
      data.max_prompt_length=512 \
      data.max_response_length=1024 \
      actor_rollout_ref.model.path=$MODEL_NAME \
      actor_rollout_ref.actor.optim.lr=1e-6 \
      actor_rollout_ref.model.use_remove_padding=True \
      actor_rollout_ref.actor.ppo_mini_batch_size=64 \
      actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8 \
      actor_rollout_ref.actor.use_kl_loss=True \
      actor_rollout_ref.actor.kl_loss_coef=0.001 \
      actor_rollout_ref.model.enable_gradient_checkpointing=True \
      actor_rollout_ref.actor.fsdp_config.param_offload=False \
      actor_rollout_ref.actor.fsdp_config.model_dtype=bfloat16 \
      actor_rollout_ref.rollout.tensor_model_parallel_size=1 \
      actor_rollout_ref.rollout.name=sglang \
      actor_rollout_ref.rollout.gpu_memory_utilization=0.4 \
      actor_rollout_ref.rollout.n=4 \
      actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=8 \
      algorithm.use_kl_in_reward=False \
      trainer.critic_warmup=0 \
      trainer.val_before_train=False \
      trainer.logger="$LOGGER_CONFIG" \
      $WANDB_ARGS \
      trainer.n_gpus_per_node=$NUM_GPUS_PER_NODE \
      trainer.nnodes=$NUM_NODES \
      trainer.save_freq=$SAVE_FREQ \
      trainer.test_freq=$TEST_FREQ \
      trainer.total_epochs=$TOTAL_EPOCHS \
      trainer.total_training_steps=$TOTAL_STEPS \
      trainer.default_local_dir=/checkpoints

    echo "Training complete!"

    # Merge checkpoints
    if [ -f /checkpoints/latest_checkpointed_iteration.txt ]; then
      LATEST_STEP=$(cat /checkpoints/latest_checkpointed_iteration.txt)
      CHECKPOINT_DIR="/checkpoints/global_step_${LATEST_STEP}/actor"

      echo "Merging model checkpoints..."
      python -m verl.model_merger merge \
        --backend fsdp \
        --tie-word-embedding \
        --local_dir ${CHECKPOINT_DIR} \
        --target_dir /checkpoints/hf_model

      echo "Model saved to /checkpoints/hf_model"
    fi

  else
    # Worker node
    echo "Worker node connecting to head at $HEAD_IP:6379..."
    sleep 15
    ray start --address $HEAD_IP:6379 --disable-usage-stats
    echo "Worker node connected"
    sleep infinity
  fi
