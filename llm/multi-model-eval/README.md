# Multi-Model Evaluation Example

Compare multiple trained models side-by-side using Promptfoo and SkyPilot.

## Architecture Overview

```
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   models_config.yaml â”‚
                            â”‚  (Your Model Specs)  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ evaluate_models â”‚
                              â”‚   .py           â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚    SkyPilot Python SDK    â”‚
                         â”‚  â€¢ Task.from_yaml()       â”‚
                         â”‚  â€¢ Parallel launching     â”‚
                         â”‚  â€¢ Cloud abstraction      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                 â”‚                                 â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ SkyPilot â”‚                    â”‚ SkyPilot  â”‚                    â”‚ SkyPilot  â”‚
â”‚ Cluster  â”‚                    â”‚ Cluster   â”‚                    â”‚ Cluster   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model 1  â”‚                    â”‚ Model 2   â”‚                    â”‚ Model 3   â”‚
â”‚ â€¢ vLLM   â”‚                    â”‚ â€¢ vLLM    â”‚                    â”‚ â€¢ vLLM    â”‚
â”‚ â€¢ GPU    â”‚                    â”‚ â€¢ GPU     â”‚                    â”‚ â€¢ GPU     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                                â”‚                                â”‚
     â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
     â”‚         â”‚             Model Sources                    â”‚        â”‚
     â”‚         â”‚  â€¢ HuggingFace Hub (public models)          â”‚        â”‚
     â”‚         â”‚  â€¢ S3/GCS Buckets (custom checkpoints)      â”‚        â”‚
     â”‚         â”‚  â€¢ SkyPilot Volumes (fast model loading)    â”‚        â”‚
     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
     â”‚                                                                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚ OpenAI-compatible APIs
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Promptfoo     â”‚
                          â”‚  â€¢ Evaluation   â”‚
                          â”‚  â€¢ Comparison   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Results View   â”‚
                          â”‚ (Side-by-side)  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components:

1. **SkyPilot SDK**: Orchestrates the entire deployment
   - Loads serving configuration from YAML template
   - Launches multiple clusters in parallel
   - Handles cloud resources and GPU allocation

2. **SkyPilot Clusters**: Each model runs on its own cluster
   - Automatic GPU provisioning based on model size
   - vLLM for high-performance inference
   - OpenAI-compatible API endpoints

3. **Flexible Model Sources**: 
   - HuggingFace Hub for public models
   - Cloud buckets (S3/GCS) for custom checkpoints
   - SkyPilot Volumes for fast repeated access

## Quick Start

```bash
# 1. Install dependencies
pip install skypilot[all] pyyaml
npm install -g promptfoo

# 2. Configure models (edit models_config.yaml)
# 3. Run evaluation
python evaluate_models.py
```

## Project Structure

```
multi-model-eval/
â”œâ”€â”€ evaluate_models.py      # Main script
â”œâ”€â”€ models_config.yaml      # Your model configurations
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ serve-model.yaml    # vLLM serving template
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ test_setup.sh       # Check dependencies
â””â”€â”€ README.md
```

## Model Configuration

Edit `models_config.yaml` to specify your models:

```yaml
models:
  # HuggingFace Hub model
  - name: "llama2-base"
    source: "huggingface"
    model_id: "meta-llama/Llama-2-7b-chat-hf"
    accelerators: "L4:1"
    
  # Custom model from S3
  - name: "my-finetuned-model"
    source: "s3://my-bucket/models/llama2-finance"
    accelerators: "L4:1"
    
  # Model from SkyPilot volume
  - name: "mistral-custom"
    source: "volume://model-checkpoints/mistral-7b"
    accelerators: "A10:1"

# Cleanup clusters after evaluation
cleanup_on_complete: true
```

## How It Works

1. **Configure Models**: Edit `models_config.yaml` with your model sources
2. **Launch with SkyPilot**: The script uses SkyPilot SDK to deploy each model on its own GPU cluster
3. **Evaluate with Promptfoo**: All models receive the same test prompts
4. **Compare Results**: View outputs side-by-side in the Promptfoo UI

## Model Sources

- **HuggingFace**: Any public model from the Hub
- **S3/GCS**: Your trained models in cloud storage
- **Volumes**: Models stored in SkyPilot volumes for fast loading

## GPU Selection

Common configurations:
- `"L4:1"` - Good for 7B models
- `"A10:1"` - Good for 7-13B models  
- `"A100:1"` - For larger models
- `"A100-80GB:1"` - For 70B+ models

## Example Output

```
ğŸ¯ Multi-Model Evaluation
=========================

ğŸ“‹ Launching 3 models...

ğŸš€ Launching llama2-base...
âœ… Launched eval-llama2-base
ğŸ“¡ Endpoint: http://34.125.23.45:8000/v1

ğŸš€ Launching my-finetuned-model...
âœ… Launched eval-my-finetuned-model
ğŸ“¡ Endpoint: http://35.223.12.89:8000/v1

âœ… Successfully launched 2 models

ğŸ“ Created evaluation config for 2 models

ğŸ” Running evaluation...
âœ… Evaluation complete!

View results: promptfoo view
```

## Tips

- Models run on port 8000 (no configuration needed)
- Launch happens in parallel for speed
- Results saved to `results.json`
- View detailed comparison with `promptfoo view`

## Troubleshooting

```bash
# Check dependencies
./scripts/test_setup.sh

# View model logs
sky logs eval-<model-name>

# List running clusters
sky status

# Manually cleanup
sky down -a
```