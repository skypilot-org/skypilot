envs:
  MODEL_SIZE: 8B
  HF_TOKEN:
  # DATASET: yahma/alpaca-cleaned
  # Use your own dataset with alpaca format
  # DATASET: gbharti/finance-alpaca
  # Change this to your own checkpoint bucket
  CHECKPOINT_BUCKET_NAME: sky-llama-3.1-checkpoints
  ADDITIONAL_ARGS: ""

file_mounts:
  ~/output:
    name: $CHECKPOINT_BUCKET_NAME

resources:
  accelerators: A100:8
  use_spot: true

file_mounts:
  /configs: ./configs

setup: |
  pip install torch torchvision

  # Install torch tune from source for the latest Llama-3.1 model
  git clone https://github.com/pytorch/torchtune.git || true
  cd torchtune
  pip install -e .
  # pip install torchtune
  
  tune download meta-llama/Meta-Llama-3.1-${MODEL_SIZE}-Instruct \
    --hf-token $HF_TOKEN \
    --output-dir /tmp/Meta-Llama-3.1-${MODEL_SIZE}-Instruct \
    --ignore-patterns "original/consolidated*"

run: |
  tune run --nproc_per_node $SKYPILOT_NUM_GPUS_PER_NODE \
    lora_finetune_distributed \
    --config /configs/${MODEL_SIZE}-lora.yaml $ADDITIONAL_ARGS

  mkdir -p ~/output/$MODEL_SIZE-lora
  rsync -Pavz /tmp/Meta-Llama-3.1-${MODEL_SIZE}-Instruct ~/output/$MODEL_SIZE-lora
  cp /tmp/lora_finetune_output ~/output/$MODEL_SIZE-lora/
