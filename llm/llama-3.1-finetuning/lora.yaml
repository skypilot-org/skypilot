# LoRA finetuning Meta Llama-3.1 on any of your own infra.
#
# Usage:
#
#  HF_TOKEN=xxx sky launch lora.yaml -c llama31 --env HF_TOKEN
#
# To finetune a 70B model:  
#
#  HF_TOKEN=xxx sky launch lora.yaml -c llama31-70 --env HF_TOKEN --env MODEL_SIZE=70B

envs:
  MODEL_SIZE: 8B
  HF_TOKEN:
  # DATASET: yahma/alpaca-cleaned
  # Use your own dataset with alpaca format
  # DATASET: gbharti/finance-alpaca
  # Change this to your own checkpoint bucket
  CHECKPOINT_BUCKET_NAME: sky-llama-3.1-checkpoints
  ADDITIONAL_ARGS: ""

file_mounts:
  ~/output:
    name: $CHECKPOINT_BUCKET_NAME
    # Optionally, specify the store to enforce to use one of the stores below:
    #   r2/azure/gcs/s3/cos
    # store: r2

resources:
  accelerators: A100:8
  disk_tier: best
  use_spot: true

file_mounts:
  /configs: ./configs

setup: |
  pip install torch torchvision

  # Install torch tune from source for the latest Llama-3.1 model
  git clone https://github.com/pytorch/torchtune.git || true
  cd torchtune
  pip install -e .
  # pip install torchtune
  
  tune download meta-llama/Meta-Llama-3.1-${MODEL_SIZE}-Instruct \
    --hf-token $HF_TOKEN \
    --output-dir /tmp/Meta-Llama-3.1-${MODEL_SIZE}-Instruct \
    --ignore-patterns "original/consolidated*"

run: |
  tune run --nproc_per_node $SKYPILOT_NUM_GPUS_PER_NODE \
    lora_finetune_distributed \
    --config /configs/${MODEL_SIZE}-lora.yaml $ADDITIONAL_ARGS

  mkdir -p ~/output/$MODEL_SIZE-lora
  rsync -Pavz /tmp/Meta-Llama-3.1-${MODEL_SIZE}-Instruct ~/output/$MODEL_SIZE-lora
  cp /tmp/lora_finetune_output ~/output/$MODEL_SIZE-lora/
