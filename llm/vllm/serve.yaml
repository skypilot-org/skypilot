resources:
  accelerators: A100-80GB:8

setup: |
  conda activate vllm
  if [ $? -ne 0 ]; then
    conda create -n vllm python=3.9 -y
    conda activate vllm
  fi

  git clone https://github.com/vllm-project/vllm.git || true

  cd vllm
  pip list | grep vllm || pip install .
  pip install gradio


run: |
  conda activate vllm
  echo "Downloading model..."
  python -u -c "from transformers import AutoModelForCausalLM; AutoModelForCausalLM.from_pretrained('${MODEL_NAME}')"

  echo 'Starting vllm api server...'
  python -m vllm.entrypoints.api_server \
    --model $MODEL_NAME \
    --tensor-parallel-size $SKYPILOT_NUM_GPUS_PER_NODE &

  sleep 10

  echo 'Starting gradio server...'
  python vllm/examples/gradio_webserver.py

envs:
  MODEL_NAME: lmsys/vicuna-13b-v1.3
