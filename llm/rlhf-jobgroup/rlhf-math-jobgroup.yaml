# RLHF Math Training with Job Groups
#
# This example demonstrates a distributed RLHF architecture using SkyPilot job groups.
# It trains an LLM on mathematical reasoning using GRPO (Group Relative Policy Optimization)
# with verifiable rewards.
#
# Architecture:
#   - data-server: Serves GSM8K math prompts
#   - rollout-server (x2): vLLM instances + load balancer on head node
#   - reward-server: Verifies math answers against ground truth
#   - replay-buffer: Stores experience tuples for sampling
#   - ppo-trainer: Orchestrates GRPO training across multiple nodes
#
# Load Balancing:
#   The head node of rollout-server runs both vLLM and a router that
#   load-balances requests across all vLLM instances using round-robin.
#   The trainer connects to the router endpoint on port 8010.
#
# Usage:
#   sky jobs launch llm/rlhf-jobgroup/rlhf-math-jobgroup.yaml
#
# The components communicate over the job group network using DNS names:
#   - data-server-0.${SKYPILOT_JOBGROUP_NAME}:8000
#   - rollout-server-0.${SKYPILOT_JOBGROUP_NAME}:8010 (load balanced endpoint)
#   - rollout-server-0.${SKYPILOT_JOBGROUP_NAME}:8001 (vLLM backend 1)
#   - rollout-server-1.${SKYPILOT_JOBGROUP_NAME}:8001 (vLLM backend 2)
#   - reward-server-0.${SKYPILOT_JOBGROUP_NAME}:8002
#   - replay-buffer-0.${SKYPILOT_JOBGROUP_NAME}:8003
---
name: rlhf-math
placement: SAME_INFRA
execution: parallel

---
# Data Server: Serves math prompts from GSM8K dataset
name: data-server
resources:
  cpus: 4
  memory: 16+
  infra: kubernetes/coreweave

file_mounts:
  /code: llm/rlhf-jobgroup/code

setup: |
  pip install fastapi uvicorn datasets

run: |
  echo "Starting data server..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "This server provides math prompts at http://data-server-0.${SKYPILOT_JOBGROUP_NAME}:8000"

  cd /code
  python data_server.py --port 8000

---
# Rollout Servers: Multiple vLLM instances with load balancer on head node
# Using num_nodes=2 to create rollout-server-0 and rollout-server-1
# Head node (rank 0) runs both vLLM and the router for load balancing
name: rollout-server
num_nodes: 2
resources:
  accelerators: H100:1
  memory: 32+
  infra: kubernetes/coreweave

file_mounts:
  /code: llm/rlhf-jobgroup/code

envs:
  MODEL_NAME: Qwen/Qwen2.5-0.5B-Instruct

setup: |
  pip install vllm
  # Router dependencies (only needed on head node but installed everywhere for simplicity)
  pip install fastapi uvicorn httpx

run: |
  echo "Starting rollout server with vLLM..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Node rank: ${SKYPILOT_NODE_RANK} / ${SKYPILOT_NUM_NODES}"
  echo "Model: ${MODEL_NAME}"
  echo "vLLM API available at http://rollout-server-${SKYPILOT_NODE_RANK}.${SKYPILOT_JOBGROUP_NAME}:8001/v1"

  # Start vLLM in background
  vllm serve ${MODEL_NAME} \
    --host 0.0.0.0 \
    --port 8001 \
    --max-model-len 2048 \
    --gpu-memory-utilization 0.8 &
  VLLM_PID=$!

  # On head node, also run the router for load balancing
  if [ "${SKYPILOT_NODE_RANK}" == "0" ]; then
    echo "Head node: starting load balancer router..."

    # Build backend list for all rollout servers
    BACKENDS=""
    for i in $(seq 0 $((SKYPILOT_NUM_NODES - 1))); do
      if [ -n "$BACKENDS" ]; then
        BACKENDS="${BACKENDS},"
      fi
      BACKENDS="${BACKENDS}rollout-server-${i}.${SKYPILOT_JOBGROUP_NAME}:8001"
    done

    echo "Load balancing across: ${BACKENDS}"
    echo "Router API available at http://rollout-server-0.${SKYPILOT_JOBGROUP_NAME}:8010/v1"

    # Wait for vLLM backends to start
    sleep 60

    cd /code
    python rollout_router.py --port 8010 --backends "${BACKENDS}" &
    ROUTER_PID=$!

    # Wait for both processes
    wait $VLLM_PID $ROUTER_PID
  else
    # Worker nodes just run vLLM
    wait $VLLM_PID
  fi

---
# Reward Server: Verifies math answers against ground truth
name: reward-server
resources:
  cpus: 4
  memory: 8+
  infra: kubernetes/coreweave

file_mounts:
  /code: llm/rlhf-jobgroup/code

setup: |
  pip install fastapi uvicorn

run: |
  echo "Starting reward server..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Reward API at http://reward-server-0.${SKYPILOT_JOBGROUP_NAME}:8002"

  cd /code
  python reward_server.py --port 8002

---
# Replay Buffer: Stores experience tuples for training
name: replay-buffer
resources:
  cpus: 4
  memory: 16+
  infra: kubernetes/coreweave

file_mounts:
  /code: llm/rlhf-jobgroup/code

setup: |
  pip install fastapi uvicorn

run: |
  echo "Starting replay buffer server..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Replay Buffer API at http://replay-buffer-0.${SKYPILOT_JOBGROUP_NAME}:8003"

  cd /code
  python replay_buffer.py --port 8003 --capacity 10000

---
# PPO Trainer: Multi-node GRPO training
name: ppo-trainer
resources:
  accelerators: H100:1
  memory: 32+
  infra: kubernetes/coreweave
num_nodes: 2

envs:
  MODEL_NAME: Qwen/Qwen2.5-0.5B-Instruct
  NUM_EPOCHS: 3
  BATCH_SIZE: 4

file_mounts:
  /code: llm/rlhf-jobgroup/code

setup: |
  pip install torch transformers accelerate httpx

run: |
  echo "Starting GRPO trainer..."
  echo "JobGroup: ${SKYPILOT_JOBGROUP_NAME}"
  echo "Node rank: ${SKYPILOT_NODE_RANK} / ${SKYPILOT_NUM_NODES}"

  # Service discovery via job group DNS
  # The rollout head node provides load balancing across all vLLM instances
  DATA_SERVER="data-server-0.${SKYPILOT_JOBGROUP_NAME}:8000"
  ROLLOUT_SERVER="rollout-server-0.${SKYPILOT_JOBGROUP_NAME}:8010"
  REWARD_SERVER="reward-server-0.${SKYPILOT_JOBGROUP_NAME}:8002"
  REPLAY_BUFFER="replay-buffer-0.${SKYPILOT_JOBGROUP_NAME}:8003"

  echo "Data server: ${DATA_SERVER}"
  echo "Rollout server (load balanced): ${ROLLOUT_SERVER}"
  echo "Reward server: ${REWARD_SERVER}"
  echo "Replay buffer: ${REPLAY_BUFFER}"

  # Wait for services to be ready
  echo "Waiting for services to be available..."
  sleep 30

  # Only run training on rank 0 (coordinator)
  if [ "${SKYPILOT_NODE_RANK}" == "0" ]; then
    echo "Starting training on coordinator node..."
    cd /code
    python trainer.py \
      --data-server ${DATA_SERVER} \
      --rollout-server ${ROLLOUT_SERVER} \
      --reward-server ${REWARD_SERVER} \
      --replay-buffer ${REPLAY_BUFFER} \
      --model ${MODEL_NAME} \
      --batch-size ${BATCH_SIZE} \
      --num-epochs ${NUM_EPOCHS}
  else
    echo "Worker node ${SKYPILOT_NODE_RANK} ready for distributed training"
    # In a full implementation, worker nodes would join distributed training
    # For this demo, they just wait
    sleep infinity
  fi
