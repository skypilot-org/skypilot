"""The 'sky' command line tool.

Example usage:

  # See available commands.
  >> sky

  # Run a task, described in a yaml file.
  # Provisioning, setup, file syncing are handled.
  >> sky launch task.yaml
  >> sky launch [-c cluster_name] task.yaml

  # Show the list of running clusters.
  >> sky status

  # Tear down a specific cluster.
  >> sky down cluster_name

  # Tear down all existing clusters.
  >> sky down -a

TODO:
- Add support for local Docker backend.  Currently this module is very coupled
  with CloudVmRayBackend, as seen by the many use of ray commands.

NOTE: the order of command definitions in this file corresponds to how they are
listed in "sky --help".  Take care to put logically connected commands close to
each other.
"""
import functools
import getpass
import os
import shlex
import sys
import time
import typing
from typing import Any, List, Optional, Tuple
import yaml

import click
import colorama
import pendulum
from rich import progress as rich_progress

import sky
from sky import backends
from sky import check as sky_check
from sky import global_user_state
from sky import sky_logging
from sky import clouds
from sky import data
from sky.backends import backend_utils
from sky.backends import cloud_vm_ray_backend
from sky.clouds import service_catalog
from sky.skylet import job_lib
from sky.skylet import util_lib

if typing.TYPE_CHECKING:
    from sky.backends import backend as backend_lib

logger = sky_logging.init_logger(__name__)

_CLUSTER_FLAG_HELP = """\
A cluster name. If provided, either reuse an existing cluster with that name or
provision a new cluster with that name. Otherwise provision a new cluster with
an autogenerated name."""
_INTERACTIVE_NODE_TYPES = ('cpunode', 'gpunode', 'tpunode')
_INTERACTIVE_NODE_DEFAULT_RESOURCES = {
    'cpunode': sky.Resources(cloud=None,
                             instance_type=None,
                             accelerators=None,
                             use_spot=False),
    'gpunode': sky.Resources(cloud=None,
                             instance_type=None,
                             accelerators={'K80': 1},
                             use_spot=False),
    'tpunode': sky.Resources(cloud=sky.GCP(),
                             instance_type=None,
                             accelerators={'tpu-v3-8': 1},
                             accelerator_args={'tf_version': '2.5.0'},
                             use_spot=False),
}


def _truncate_long_string(s: str, max_length: int = 35) -> str:
    if len(s) <= max_length:
        return s
    splits = s.split(' ')
    if len(splits[0]) > max_length:
        return splits[0][:max_length] + '...'  # Use 'â€¦'?
    # Truncate on word boundary.
    i = 0
    total = 0
    for i, part in enumerate(splits):
        total += len(part)
        if total >= max_length:
            break
    return ' '.join(splits[:i]) + ' ...'


def _get_cloud(cloud: str) -> Optional[clouds.Cloud]:
    """Check if cloud is registered and return cloud object."""
    if cloud is not None and cloud not in clouds.CLOUD_REGISTRY:
        raise click.UsageError(
            f'Cloud \'{cloud}\' is not supported. '
            f'Supported clouds: {list(clouds.CLOUD_REGISTRY.keys())}')
    return clouds.CLOUD_REGISTRY.get(cloud)


def _get_glob_clusters(clusters: List[str]) -> List[str]:
    """Returns a list of clusters that match the glob pattern."""
    glob_clusters = []
    for cluster in clusters:
        glob_cluster = global_user_state.get_glob_cluster_names(cluster)
        if len(glob_cluster) == 0:
            print(f'Cluster {cluster} not found.')
        glob_clusters.extend(glob_cluster)
    return list(set(glob_clusters))


def _interactive_node_cli_command(cli_func):
    """Click command decorator for interactive node commands."""
    assert cli_func.__name__ in _INTERACTIVE_NODE_TYPES, cli_func.__name__

    cluster_option = click.option('--cluster',
                                  '-c',
                                  default=None,
                                  type=str,
                                  required=False,
                                  help=_CLUSTER_FLAG_HELP)
    port_forward_option = click.option(
        '--port-forward',
        '-p',
        multiple=True,
        default=[],
        type=int,
        required=False,
        help=('Port to be forwarded. To forward multiple ports, '
              'use this option multiple times.'))
    screen_option = click.option('--screen',
                                 default=False,
                                 is_flag=True,
                                 help='If true, attach using screen.')
    tmux_option = click.option('--tmux',
                               default=False,
                               is_flag=True,
                               help='If true, attach using tmux.')
    cloud_option = click.option('--cloud',
                                default=None,
                                type=str,
                                help='Cloud provider to use.')
    instance_type_option = click.option('--instance-type',
                                        '-t',
                                        default=None,
                                        type=str,
                                        help='Instance type to use.')
    gpus = click.option('--gpus',
                        default=None,
                        type=str,
                        help=('Type and number of GPUs to use '
                              '(e.g., --gpus=V100:8 or --gpus=V100).'))
    tpus = click.option(
        '--tpus',
        default=None,
        type=str,
        help=('Type and number of TPUs to use (e.g., --tpus=tpu-v3-8:4 or '
              '--tpus=tpu-v3-8).'))

    spot_option = click.option('--spot',
                               default=None,
                               is_flag=True,
                               help='If true, use spot instances.')

    disk_size = click.option('--disk-size',
                             default=None,
                             type=int,
                             required=False,
                             help=('OS disk size in GBs.'))
    no_confirm = click.option('--yes',
                              '-y',
                              is_flag=True,
                              default=False,
                              required=False,
                              help='Skip confirmation prompt.')

    click_decorators = [
        cli.command(cls=_DocumentedCodeCommand),
        cluster_option,
        no_confirm,
        port_forward_option,

        # Resource options
        *([cloud_option] if cli_func.__name__ != 'tpunode' else []),
        instance_type_option,
        *([gpus] if cli_func.__name__ == 'gpunode' else []),
        *([tpus] if cli_func.__name__ == 'tpunode' else []),
        spot_option,

        # Attach options
        screen_option,
        tmux_option,
        disk_size,
    ]
    decorator = functools.reduce(lambda res, f: f(res),
                                 reversed(click_decorators), cli_func)

    return decorator


def _default_interactive_node_name(node_type: str):
    """Returns a deterministic name to refer to the same node."""
    # FIXME: this technically can collide in Azure/GCP with another
    # same-username user.  E.g., sky-gpunode-ubuntu.  Not a problem on AWS
    # which is the current cloud for interactive nodes.
    assert node_type in _INTERACTIVE_NODE_TYPES, node_type
    return f'sky-{node_type}-{getpass.getuser()}'


def _infer_interactive_node_type(resources: sky.Resources):
    """Determine interactive node type from resources."""
    accelerators = resources.accelerators
    cloud = resources.cloud
    if accelerators:
        # We only support homogenous accelerators for now.
        assert len(accelerators) == 1, resources
        acc, _ = list(accelerators.items())[0]
        is_gcp = cloud is not None and cloud.is_same_cloud(sky.GCP())
        if is_gcp and 'tpu' in acc:
            return 'tpunode'
        return 'gpunode'
    return 'cpunode'


def _check_interactive_node_resources_match(
        node_type: str,
        resources: sky.Resources,
        launched_resources: sky.Resources,
        user_requested_resources: Optional[bool] = False) -> None:
    """Check matching resources when reusing an existing cluster.

    The only exception is when [cpu|tpu|gpu]node -c cluster_name is used with no
    additional arguments, then login succeeds.

    Args:
        node_type: Type of interactive node.
        resources: Resources to attach to VM.
        launched_resources: Existing launched resources associated with cluster.
        user_requested_resources: If true, user requested resources explicitly.
    """
    # In the case where the user specifies no cloud, we infer the cloud from
    # the launched resources before performing the check.
    # e.g. user launches sky gpunode --gpus V100 creates an AWS(p3.2xlarge)
    # but when the resource check will fail because is_same_resources expects
    # resources.cloud and handle.launched_resources to match.
    if resources.cloud is None:
        assert launched_resources.cloud is not None, launched_resources
        resources = resources.copy(cloud=launched_resources.cloud)

    # TODO: Check for same number of launched_nodes if multi-node support is
    # added for gpu/cpu/tpunode.
    inferred_node_type = _infer_interactive_node_type(launched_resources)
    node_type_match = inferred_node_type == node_type
    launched_resources_match = resources.is_same_resources(launched_resources)
    no_resource_requests = not user_requested_resources  # e.g. sky gpunode
    if not (node_type_match and
            (no_resource_requests or launched_resources_match)):
        raise click.UsageError(
            'Resources cannot change for an existing cluster.\n'
            f'Existing: {inferred_node_type} with {launched_resources}\n'
            f'Requested: {node_type} with {resources}\n')


# TODO: skip installing ray to speed up provisioning.
def _create_and_ssh_into_node(
    node_type: str,
    resources: sky.Resources,
    cluster_name: str,
    backend: Optional['backend_lib.Backend'] = None,
    port_forward: Optional[List[int]] = None,
    session_manager: Optional[str] = None,
    user_requested_resources: Optional[bool] = False,
    no_confirm: bool = False,
):
    """Creates and attaches to an interactive node.

    Args:
        node_type: Type of the interactive node: { 'cpunode', 'gpunode' }.
        resources: Resources to attach to VM.
        cluster_name: a cluster name to identify the interactive node.
        backend: the Backend to use (currently only CloudVmRayBackend).
        port_forward: List of ports to forward.
        session_manager: Attach session manager: { 'screen', 'tmux' }.
        user_requested_resources: If true, user requested resources explicitly.
        no_confirm: If true, skips confirmation prompt presented to user.
    """
    assert node_type in _INTERACTIVE_NODE_TYPES, node_type
    assert session_manager in (None, 'screen', 'tmux'), session_manager
    with sky.Dag() as dag:
        # TODO: Add conda environment replication
        # should be setup =
        # 'conda env export | grep -v "^prefix: " > environment.yml'
        # && conda env create -f environment.yml
        task = sky.Task(
            node_type,
            workdir=None,
            setup=None,
            run='',
        )
        task.set_resources(resources)

    backend = backend if backend is not None else backends.CloudVmRayBackend()
    handle = global_user_state.get_handle_from_cluster_name(cluster_name)
    if handle is not None:
        # Avoid reusing clusters with requested resource mismatches.
        _check_interactive_node_resources_match(node_type, resources,
                                                handle.launched_resources,
                                                user_requested_resources)
    if handle is None or handle.head_ip is None:
        # head_ip would be None if previous provisioning failed.

        # This handles stopped interactive nodes where they are restarted by
        # skipping sky start and directly calling sky [cpu|tpu|gpu]node.
        cluster_status = backend_utils.get_cluster_status_with_refresh(
            cluster_name)
        if cluster_status == global_user_state.ClusterStatus.STOPPED:
            assert handle.launched_resources is not None, handle
            to_provision = None
            task.set_resources(handle.launched_resources)
            task.num_nodes = handle.launched_nodes
            if not no_confirm:
                click.confirm(
                    f'Restarting the stopped cluster {cluster_name!r}. '
                    'Proceed?',
                    default=True,
                    abort=True,
                    show_default=True)
        else:
            dag = sky.optimize(dag)
            task = dag.tasks[0]
            backend.register_info(dag=dag)
            to_provision = task.best_resources
            if handle is None and not no_confirm:
                # Only show the confirmation prompt if the cluster is not
                # in the clusters table.
                click.confirm('Launching a new cluster. Proceed?',
                              default=True,
                              abort=True,
                              show_default=True)

        handle = backend.provision(task,
                                   to_provision=to_provision,
                                   dryrun=False,
                                   stream_logs=True,
                                   cluster_name=cluster_name)

    # Use ssh rather than 'ray attach' to suppress ray messages, speed up
    # connection, and for allowing adding 'cd workdir' in the future.
    # Disable check, since the returncode could be non-zero if the user Ctrl-D.
    commands = []
    if session_manager == 'screen':
        commands += ['screen', '-D', '-R']
    elif session_manager == 'tmux':
        commands += ['tmux', 'attach', '||', 'tmux', 'new']
    backend.run_on_head(handle,
                        commands,
                        port_forward=port_forward,
                        ssh_mode=backend_utils.SshMode.LOGIN)
    cluster_name = global_user_state.get_cluster_name_from_handle(handle)

    click.echo('To attach to it again:  ', nl=False)
    if cluster_name == _default_interactive_node_name(node_type):
        option = ''
    else:
        option = f' -c {cluster_name}'
    click.secho(f'sky {node_type}{option}', bold=True)
    click.echo('To stop the node:\t', nl=False)
    click.secho(f'sky stop {cluster_name}', bold=True)
    click.echo('To tear down the node:\t', nl=False)
    click.secho(f'sky down {cluster_name}', bold=True)
    click.echo('To upload a folder:\t', nl=False)
    click.secho(f'rsync -rP /local/path {cluster_name}:/remote/path', bold=True)
    click.echo('To download a folder:\t', nl=False)
    click.secho(f'rsync -rP {cluster_name}:/remote/path /local/path', bold=True)


def _check_yaml(entrypoint: str) -> bool:
    """Checks if entrypoint is a readable YAML file."""
    is_yaml = True
    shell_splits = shlex.split(entrypoint)
    yaml_file_provided = len(shell_splits) == 1 and \
        (shell_splits[0].endswith('yaml') or shell_splits[0].endswith('.yml'))
    try:
        with open(entrypoint, 'r') as f:
            try:
                config = yaml.safe_load(f)
                if isinstance(config, str):
                    # 'sky exec cluster ./my_script.sh'
                    is_yaml = False
            except yaml.YAMLError as e:
                if yaml_file_provided:
                    logger.debug(e)
                    invalid_reason = ('contains an invalid configuration. '
                                      ' Please check syntax.')
                is_yaml = False
    except OSError:
        if yaml_file_provided:
            entry_point_path = os.path.expanduser(entrypoint)
            if not os.path.exists(entry_point_path):
                invalid_reason = ('does not exist. Please check if the path'
                                  ' is correct.')
            elif not os.path.isfile(entry_point_path):
                invalid_reason = ('is not a file. Please check if the path'
                                  ' is correct.')
            else:
                invalid_reason = ('yaml.safe_load() failed. Please check if the'
                                  ' path is correct.')
        is_yaml = False
    if not is_yaml:
        if yaml_file_provided:
            click.confirm(
                f'{entrypoint!r} looks like a yaml path but {invalid_reason}\n'
                'It will be treated as a command to be run remotely. Continue?',
                abort=True)
    return is_yaml


class _NaturalOrderGroup(click.Group):
    """Lists commands in the order they are defined in this script.

    Reference: https://github.com/pallets/click/issues/513
    """

    def list_commands(self, ctx):
        return self.commands.keys()


class _DocumentedCodeCommand(click.Command):
    """Corrects help strings for documented commands such that --help displays
    properly and code blocks are rendered in the official web documentation.
    """

    def get_help(self, ctx):
        help_str = ctx.command.help
        ctx.command.help = help_str.replace('.. code-block:: bash\n', '\b')
        return super().get_help(ctx)


@click.group(cls=_NaturalOrderGroup)
def cli():
    pass


@cli.command(cls=_DocumentedCodeCommand)
@click.argument('entrypoint', required=True, type=str, nargs=-1)
@click.option('--cluster',
              '-c',
              default=None,
              type=str,
              help=_CLUSTER_FLAG_HELP)
@click.option('--dryrun',
              default=False,
              is_flag=True,
              help='If True, do not actually run the job.')
@click.option('--detach-run',
              '-d',
              default=False,
              is_flag=True,
              help='If True, run setup first (blocking), '
              'then detach from the job\'s execution.')
@click.option('--docker',
              'backend_name',
              flag_value=backends.LocalDockerBackend.NAME,
              default=False,
              help='If used, runs locally inside a docker container.')
@click.option(
    '--workdir',
    required=False,
    type=click.Path(exists=True, file_okay=False),
    help=('If specified, sync this dir to the remote working directory, '
          'where the task will be invoked. '
          'Overrides the "workdir" config in the YAML if both are supplied.'))
@click.option(
    '--cloud',
    required=False,
    type=str,
    help='The cloud to use. If specified, override the "resources.cloud".')
@click.option(
    '--gpus',
    required=False,
    type=str,
    help=('Type and number of GPUs to use. Example values: '
          '"V100:8", "V100" (short for a count of 1), or "V100:0.5" '
          '(fractional counts are supported by the scheduling framework). '
          'If a new cluster is being launched by this command, this is the '
          'resources to provision. If an existing cluster is being reused, this'
          ' is seen as the task demand, which must fit the cluster\'s total '
          'resources and is used for scheduling the task. '
          'Overrides the "accelerators" '
          'config in the YAML if both are supplied.'))
@click.option('--num-nodes',
              required=False,
              type=int,
              help=('Number of nodes to launch and to execute the task on. '
                    'Overrides the "num_nodes" config in the YAML if both are '
                    'supplied.'))
@click.option(
    '--use-spot/--no-use-spot',
    required=False,
    default=None,
    help=('Whether to request spot instances. If specified, override the '
          '"resources.use_spot".'))
@click.option('--name',
              '-n',
              required=False,
              type=str,
              help=('Task name. Overrides the "name" '
                    'config in the YAML if both are supplied.'))
@click.option('--disk-size',
              default=None,
              type=int,
              required=False,
              help=('OS disk size in GBs.'))
@click.option('--yes',
              '-y',
              is_flag=True,
              default=False,
              required=False,
              help='Skip confirmation prompt.')
def launch(
    entrypoint: str,
    cluster: Optional[str],
    dryrun: bool,
    detach_run: bool,
    backend_name: Optional[str],
    workdir: Optional[str],
    cloud: Optional[str],
    gpus: Optional[str],
    num_nodes: Optional[int],
    use_spot: Optional[bool],
    name: Optional[str],
    disk_size: Optional[int],
    yes: bool,
):
    """Launch a task from a YAML or a command (rerun setup if cluster exists).

    If ENTRYPOINT points to a valid YAML file, it is read in as the task
    specification. Otherwise, it is interpreted as a bash command.

    In both cases, the commands are run under the task's workdir (if specified)
    and they undergo job queue scheduling.
    """
    if backend_name is None:
        backend_name = backends.CloudVmRayBackend.NAME

    entrypoint = ' '.join(entrypoint)
    is_yaml = _check_yaml(entrypoint)
    if is_yaml:
        # Treat entrypoint as a yaml.
        click.secho('Task from YAML spec: ', fg='yellow', nl=False)
    else:
        # Treat entrypoint as a bash command.
        click.secho('Task from command: ', fg='yellow', nl=False)
    click.secho(entrypoint, bold=True)

    if not yes:
        # Prompt if (1) --cluster is None, or (2) cluster doesn't exist, or (3)
        # it exists but is STOPPED.
        maybe_status = backend_utils.get_cluster_status_with_refresh(cluster)
        prompt = None
        if maybe_status is None:
            prompt = 'Launching a new cluster. Proceed?'
        elif maybe_status == global_user_state.ClusterStatus.STOPPED:
            prompt = f'Restarting the stopped cluster {cluster!r}. Proceed?'
        if prompt is not None:
            click.confirm(prompt, default=True, abort=True, show_default=True)

    with sky.Dag() as dag:
        if is_yaml:
            task = sky.Task.from_yaml(entrypoint)
        else:
            task = sky.Task(name='sky-cmd', run=entrypoint)
            task.set_resources({sky.Resources()})
        # Override.
        if workdir is not None:
            task.workdir = workdir

        assert len(task.resources) == 1
        old_resources = list(task.resources)[0]

        override_params = {}
        if cloud is not None:
            override_params['cloud'] = _get_cloud(cloud)
        if gpus is not None:
            override_params['accelerators'] = gpus

        if use_spot is not None:
            override_params['use_spot'] = use_spot
        if disk_size is not None:
            override_params['disk_size'] = disk_size

        new_resources = old_resources.copy(**override_params)
        task.set_resources({new_resources})

        if num_nodes is not None:
            task.num_nodes = num_nodes
        if name is not None:
            task.name = name

    if cluster is not None:
        click.secho(f'Running task on cluster {cluster}...', fg='yellow')

    if backend_name == backends.LocalDockerBackend.NAME:
        backend = backends.LocalDockerBackend()
    elif backend_name == backends.CloudVmRayBackend.NAME:
        backend = backends.CloudVmRayBackend()
    else:
        raise ValueError(f'{backend_name} backend is not supported.')

    sky.launch(dag,
               dryrun=dryrun,
               stream_logs=True,
               cluster_name=cluster,
               detach_run=detach_run,
               backend=backend)


@cli.command(cls=_DocumentedCodeCommand)
@click.argument('cluster', required=True, type=str)
@click.argument('entrypoint', required=True, type=str, nargs=-1)
@click.option('--detach-run',
              '-d',
              default=False,
              is_flag=True,
              help='If True, run setup first (blocking), '
              'then detach from the job\'s execution.')
@click.option(
    '--workdir',
    required=False,
    type=click.Path(exists=True, file_okay=False),
    help=('If specified, sync this dir to the remote working directory, '
          'where the task will be invoked. '
          'Overrides the "workdir" config in the YAML if both are supplied.'))
@click.option(
    '--gpus',
    required=False,
    type=str,
    help=('Task demand: Type and number of GPUs to use. Example values: '
          '"V100:8", "V100" (short for a count of 1), or "V100:0.5" '
          '(fractional counts are supported by the scheduling framework). '
          'This is used for scheduling the task, so it must fit the '
          'cluster\'s total resources. Overrides the "accelerators" '
          'config in the YAML if both are supplied.'))
@click.option('--num-nodes',
              required=False,
              type=int,
              help=('Task demand: Number of nodes to execute the task on. '
                    'Overrides the "num_nodes" config in the YAML if both are '
                    'supplied.'))
@click.option('--name',
              '-n',
              required=False,
              type=str,
              help=('Task name. Overrides the "name" '
                    'config in the YAML if both are supplied.'))
# pylint: disable=redefined-builtin
def exec(
    cluster: str,
    entrypoint: str,
    detach_run: bool,
    workdir: Optional[str],
    gpus: Optional[str],
    num_nodes: Optional[int],
    name: Optional[str],
):
    """Execute a task or a command on a cluster (skip setup).

    If ENTRYPOINT points to a valid YAML file, it is read in as the task
    specification. Otherwise, it is interpreted as a bash command.

    \b
    Execution and scheduling behavior:
    \b
    - If ENTRYPOINT is a YAML, or if it is a command with a resource demand
      flag specified (`--gpus` or `--num-nodes`): it is treated as a proper
      task that will undergo job queue scheduling, respecting its resource
      requirement. It can be executed on any node of th cluster with enough
      resources.
    - Otherwise (if ENTRYPOINT is a command and no resource demand flag
      specified), it is treated as an inline command, to be executed only on
      the head node of the cluster. This is useful for monitoring commands
      (e.g., gpustat, htop).

    In both cases, the commands are run under the task's workdir (if specified).

    \b
    Actions performed by `sky exec`:
    \b
    - workdir syncing, if:
      - ENTRYPOINT is a YAML, and `workdir` is specified inside; OR
      - ENTRYPOINT is a command, and flag `--workdir=<local_path>` is supplied.
    - executing the specified task's `run` commands / the bash command.

    `sky exec` is thus typically faster than `sky launch`, provided a cluster
    already exists.

    All setup steps (provisioning, setup commands, file mounts syncing) are
    skipped.  If any of those specifications changed, this command will not
    reflect those changes.  To ensure a cluster's setup is up to date, use `sky
    launch` instead.

    Typical workflow:

    .. code-block:: bash

        # First command: set up the cluster once.
        sky launch -c mycluster app.yaml

    .. code-block:: bash

        # For iterative development, simply execute the task on the launched
        # cluster.
        sky exec mycluster app.yaml

    .. code-block:: bash

        # Do "sky launch" again if anything other than Task.run is modified:
        sky launch -c mycluster app.yaml

    Advanced use cases:

    .. code-block:: bash

        # Pass in commands for execution
        sky exec mycluster -- echo Hello World

    """
    entrypoint = ' '.join(entrypoint)
    handle = global_user_state.get_handle_from_cluster_name(cluster)
    if handle is None:
        raise click.BadParameter(f'Cluster \'{cluster}\' not found.  '
                                 'Use `sky launch` to provision first.')
    backend = backend_utils.get_backend_from_handle(handle)
    resource_demand_specified = gpus is not None or num_nodes is not None

    with sky.Dag() as dag:
        if _check_yaml(entrypoint):
            # Treat entrypoint as a yaml file
            click.secho('Task from YAML spec: ', fg='yellow', nl=False)
            click.secho(entrypoint, bold=True)
            task = sky.Task.from_yaml(entrypoint)
        else:
            # Treat entrypoint as a bash command.
            click.secho('Task from command: ', fg='yellow', nl=False)
            click.secho(entrypoint, bold=True)
            task = sky.Task(name='sky-cmd', run=entrypoint)
            task.set_resources({sky.Resources()})

            if isinstance(backend, backends.CloudVmRayBackend):
                # Run inline commands directly on head node if the resources are
                # not set. User should take the responsibility to not overload
                # the cluster.
                if not resource_demand_specified:
                    if workdir is not None:
                        backend.sync_workdir(handle, workdir)
                    backend.run_on_head(
                        handle,
                        entrypoint,
                        stream_logs=True,
                        # Allocate a pseudo-terminal to disable output buffering
                        ssh_mode=backend_utils.SshMode.INTERACTIVE,
                        under_remote_workdir=True,
                        redirect_stdout_stderr=False)
                    return

        # Override.
        if workdir is not None:
            task.workdir = workdir
        if gpus is not None:
            assert len(task.resources) == 1
            old_resources = list(task.resources)[0]
            copied = old_resources.copy(accelerators=gpus)
            task.set_resources({copied})
        if num_nodes is not None:
            task.num_nodes = num_nodes
        if name is not None:
            task.name = name

    click.secho(f'Executing task on cluster {cluster}...', fg='yellow')
    sky.exec(dag, backend=backend, cluster_name=cluster, detach_run=detach_run)


def _readable_time_duration(start_time: int):
    duration = pendulum.now().subtract(seconds=time.time() - start_time)
    diff = duration.diff_for_humans()
    diff = diff.replace('second', 'sec')
    diff = diff.replace('minute', 'min')
    diff = diff.replace('hour', 'hr')
    return diff


@cli.command()
@click.option('--all',
              '-a',
              default=False,
              is_flag=True,
              required=False,
              help='Show all information in full.')
@click.option('--refresh',
              '-r',
              default=False,
              is_flag=True,
              required=False,
              help='Query remote clusters for their latest autostop settings.')
def status(all: bool, refresh: bool):  # pylint: disable=redefined-builtin
    """Show clusters."""
    # TODO(zhwu): Update the information for auto-stop clusters.
    show_all = all
    clusters_status = backend_utils.get_clusters(refresh)
    columns = [
        'NAME',
        'LAUNCHED',
        'RESOURCES',
        'STATUS',
        'AUTOSTOP',
        'COMMAND',
    ]

    if all:
        columns.extend([
            'HOURLY_PRICE',
            'REGION',
        ])

    cluster_table = util_lib.create_table(columns)

    for cluster_status in clusters_status:
        launched_at = cluster_status['launched_at']
        handle = cluster_status['handle']
        resources_str = '<initializing>'
        if isinstance(handle, backends.LocalDockerBackend.ResourceHandle):
            resources_str = 'docker'
        elif isinstance(handle, backends.CloudVmRayBackend.ResourceHandle):
            if (handle.launched_nodes is not None and
                    handle.launched_resources is not None):
                launched_resource_str = str(handle.launched_resources)
                if not show_all:
                    launched_resource_str = _truncate_long_string(
                        launched_resource_str)
                resources_str = (f'{handle.launched_nodes}x '
                                 f'{launched_resource_str}')
        else:
            raise ValueError(f'Unknown handle type {type(handle)} encountered.')
        autostop_str = '-'
        if cluster_status['autostop'] >= 0:
            # TODO(zhwu): check the status of the autostop cluster.
            autostop_str = str(cluster_status['autostop']) + ' min'
        row = [
            # NAME
            cluster_status['name'],
            # LAUNCHED
            _readable_time_duration(launched_at),
            # RESOURCES
            resources_str,
            # STATUS
            cluster_status['status'].value,
            # AUTOSTOP
            autostop_str,
            # COMMAND
            cluster_status['last_use']
            if show_all else _truncate_long_string(cluster_status['last_use']),
        ]
        if all:
            hourly_cost = handle.launched_resources.get_cost(3600) \
                * handle.launched_nodes
            price_str = f'$ {hourly_cost:.3f}'
            region = handle.get_cluster_region()
            row.extend([
                # HOURLY PRICE
                price_str,
                # REGION
                region,
            ])
        cluster_table.add_row(row)
    if clusters_status:
        click.echo(cluster_table)
    else:
        click.echo('No existing clusters.')


@cli.command()
@click.option('--all-users',
              '-a',
              default=False,
              is_flag=True,
              required=False,
              help='Show all users\' information in full.')
@click.option('--skip-finished',
              '-s',
              default=False,
              is_flag=True,
              required=False,
              help='Show only pending/running jobs\' information.')
@click.argument('clusters', required=False, type=str, nargs=-1)
def queue(clusters: Tuple[str], skip_finished: bool, all_users: bool):
    """Show the job queue for cluster(s)."""
    click.secho('Fetching and parsing job queue...', fg='yellow')
    all_jobs = not skip_finished

    username = getpass.getuser()
    if all_users:
        username = None
    code = job_lib.JobLibCodeGen.show_jobs(username, all_jobs)

    if clusters:
        clusters = _get_glob_clusters(clusters)
        handles = [
            global_user_state.get_handle_from_cluster_name(c) for c in clusters
        ]
    else:
        cluster_infos = global_user_state.get_clusters()
        clusters = [c['name'] for c in cluster_infos]
        handles = [c['handle'] for c in cluster_infos]

    unsupported_clusters = []
    for cluster, handle in zip(clusters, handles):
        if handle is None:
            print(f'Cluster {cluster} was not found. Skipping.')
            continue
        backend = backend_utils.get_backend_from_handle(handle)
        if isinstance(backend, backends.LocalDockerBackend):
            # LocalDockerBackend does not support job queues
            unsupported_clusters.append(cluster)
            continue
        cluster_status = backend_utils.get_cluster_status_with_refresh(cluster)
        if cluster_status != global_user_state.ClusterStatus.UP:
            print(f'Cluster {cluster} is not up. Skipping.')
            continue
        _show_job_queue_on_cluster(cluster, handle, backend, code)
    if unsupported_clusters:
        click.secho(
            f'Note: Job queues are not supported on clusters: '
            f'{", ".join(unsupported_clusters)}',
            fg='yellow')


def _show_job_queue_on_cluster(cluster: str, handle: Optional[Any],
                               backend: 'backend_lib.Backend', code: str):
    click.echo(f'\nSky Job Queue of Cluster {cluster}')
    if handle.head_ip is None:
        click.echo(
            f'Cluster {cluster} has been stopped or not properly set up. '
            'Please re-launch it with `sky launch` to view the job queue.')
        return

    returncode, job_table, stderr = backend.run_on_head(handle,
                                                        code,
                                                        require_outputs=True)
    if returncode != 0:
        click.echo(stderr)
        click.secho(f'Failed to get job queue on cluster {cluster}.', fg='red')
    click.echo(f'{job_table}')


@cli.command()
@click.option(
    '--sync-down',
    '-s',
    is_flag=True,
    default=False,
    help='Sync down the logs of the job (This is useful for distributed jobs to'
    'download separate log for each job from all the workers).')
@click.option(
    '--status',
    is_flag=True,
    default=False,
    help=('If specified, do not show logs but exit with a status code for the '
          'job\'s status: 0 for succeeded, or 1 for all other statuses.'))
@click.argument('cluster', required=True, type=str)
@click.argument('job_id', required=True, type=str)
def logs(cluster: str, job_id: str, sync_down: bool, status: bool):  # pylint: disable=redefined-outer-name
    """Tail the log of a job."""
    cluster_name = cluster
    handle = global_user_state.get_handle_from_cluster_name(cluster_name)
    if handle is None:
        raise click.BadParameter(f'Cluster \'{cluster_name}\' not found'
                                 ' (see `sky status`).')
    if isinstance(handle, backends.LocalDockerBackend.ResourceHandle):
        raise click.UsageError('Sky logs is not available with '
                               'LocalDockerBackend.')
    cluster_status = backend_utils.get_cluster_status_with_refresh(cluster_name)
    if cluster_status != global_user_state.ClusterStatus.UP:
        click.secho(
            f'Cluster {cluster_name} (status: {cluster_status}) '
            'is not up.',
            fg='red')
        return
    backend = backend_utils.get_backend_from_handle(handle)

    if sync_down and status:
        raise click.UsageError(
            'Both --sync_down and --status are specified '
            '(ambiguous). To fix: specify at most one of them.')

    if sync_down:
        click.secho('Syncing down logs to local...', fg='yellow')
        backend.sync_down_logs(handle, job_id)
    elif status:
        # FIXME(zongheng,zhwu): non-existent job ids throw:
        # TypeError: expected str, bytes or os.PathLike object, not tuple
        job_status = backend.get_job_status(handle, job_id)
        if job_status == job_lib.JobStatus.SUCCEEDED:
            sys.exit(0)
        else:
            click.secho(f'Status failed for job {job_id}', fg='red')
            sys.exit(1)
    else:
        backend.tail_logs(handle, job_id)


@cli.command()
@click.argument('cluster', required=True, type=str)
@click.option('--all',
              '-a',
              default=False,
              is_flag=True,
              required=False,
              help='Cancel all jobs.')
@click.argument('jobs', required=False, type=int, nargs=-1)
def cancel(cluster: str, all: bool, jobs: List[int]):  # pylint: disable=redefined-builtin
    """Cancel job(s)."""
    if len(jobs) == 0 and not all:
        raise click.UsageError(
            'sky cancel requires either a job id '
            f'(see `sky queue {cluster} -s`) or the --all flag.')

    handle = global_user_state.get_handle_from_cluster_name(cluster)
    if handle is None:
        raise click.BadParameter(f'Cluster {cluster!r} not found'
                                 ' (see `sky status`).')
    backend = backend_utils.get_backend_from_handle(handle)
    if not isinstance(backend, backends.CloudVmRayBackend):
        raise click.UsageError(
            'Job cancelling is only supported for '
            f'{backends.CloudVmRayBackend.NAME}, but cluster {cluster!r} '
            f'is created by {backend.NAME}.')
    # Check the status of the cluster.
    cluster_status = backend_utils.get_cluster_status_with_refresh(cluster)
    if cluster_status != global_user_state.ClusterStatus.UP:
        click.secho(f'Cluster {cluster} (status: {cluster_status}) '
                    'is not up...skipped.')
        return

    if all:
        click.secho(f'Cancelling all jobs on cluster {cluster}...', fg='yellow')
        jobs = None
    else:
        jobs_str = ', '.join(map(str, jobs))
        click.secho(f'Cancelling jobs ({jobs_str}) on cluster {cluster}...',
                    fg='yellow')

    code = job_lib.JobLibCodeGen.cancel_jobs(jobs)

    returncode, _, stderr = backend.run_on_head(handle,
                                                code,
                                                stream_logs=False,
                                                require_outputs=True)
    backend_utils.handle_returncode(
        returncode, code, f'Failed to cancel jobs on cluster {cluster}.',
        stderr)


@cli.command(cls=_DocumentedCodeCommand)
@click.argument('clusters', nargs=-1, required=False)
@click.option('--all',
              '-a',
              default=None,
              is_flag=True,
              help='Tear down all existing clusters.')
@click.option('--yes',
              '-y',
              is_flag=True,
              default=False,
              required=False,
              help='Skip confirmation prompt.')
def stop(
    clusters: Tuple[str],
    all: Optional[bool],  # pylint: disable=redefined-builtin
    yes: bool,
):
    """Stop cluster(s).

    CLUSTER is the name (or glob pattern) of the cluster to stop.  If both
    CLUSTER and --all are supplied, the latter takes precedence.

    Stopping a cluster does not lose data on the attached disks (billing for
    the instances will stop while the disks will still be charged).  Those
    disks will be reattached when restarting the cluster.

    Currently, spot-instance clusters cannot be stopped.

    Examples:

    .. code-block:: bash

        # Stop a specific cluster.
        sky stop cluster_name

    .. code-block:: bash

        # Stop multiple clusters.
        sky stop cluster1 cluster2

    .. code-block:: bash

        # Stop down all clusters with prefix 'cluster'
        sky stop "cluster*"

    .. code-block:: bash

        # Stop all existing clusters.
        sky stop -a

    """
    _terminate_or_stop_clusters(clusters,
                                apply_to_all=all,
                                terminate=False,
                                no_confirm=yes)


@cli.command(cls=_DocumentedCodeCommand)
@click.argument('clusters', nargs=-1, required=False)
@click.option('--all',
              '-a',
              default=None,
              is_flag=True,
              help='Tear down all existing clusters.')
@click.option('--idle-minutes',
              '-i',
              type=int,
              default=None,
              required=False,
              help='Set the idle minutes before auto-stopping the cluster.')
@click.option('--cancel',
              default=False,
              is_flag=True,
              required=False,
              help='Cancel the auto-stopping.')
def autostop(
        clusters: Tuple[str],
        all: Optional[bool],  # pylint: disable=redefined-builtin
        idle_minutes: Optional[int],
        cancel: bool,  # pylint: disable=redefined-outer-name
):
    """Schedule or cancel auto-stopping for cluster(s).

    CLUSTERS are the name (or glob pattern) of the clusters to stop.  If both
    CLUSTERS and --all are supplied, the latter takes precedence.

    --idle-minutes is the number of minutes of idleness (no pending/running
    jobs) after which the cluster will be stopped automatically.

    --cancel will cancel the autostopping. If the cluster was not scheduled
    autostop, this will do nothing to autostop.

    If --idle-minutes and --cancel are not specified, default to 5 minutes.

    Examples:

    .. code-block:: bash

        # Set auto stopping for a specific cluster.
        sky autostop cluster_name -i 60

        # Cancel auto stopping for a specific cluster.
        sky autostop cluster_name --cancel
    .. code-block:: bash

    """
    if cancel and idle_minutes is not None:
        raise click.UsageError(
            'Only one of --idle-minutes and --cancel should be specified. '
            f'cancel: {cancel}, idle_minutes: {idle_minutes}')
    if cancel:
        idle_minutes = -1
    elif idle_minutes is None:
        idle_minutes = 5
    _terminate_or_stop_clusters(clusters,
                                apply_to_all=all,
                                terminate=False,
                                no_confirm=True,
                                idle_minutes_to_autostop=idle_minutes)


@cli.command(cls=_DocumentedCodeCommand)
@click.argument('clusters', nargs=-1, required=True)
@click.option('--yes',
              '-y',
              is_flag=True,
              default=False,
              required=False,
              help='Skip confirmation prompt.')
def start(clusters: Tuple[str], yes: bool):
    """Restart cluster(s).

    If a cluster is previously stopped (status == STOPPED) or failed in
    provisioning/a task's setup (status == INIT), this command will attempt to
    start the cluster.  (In the second case, any failed setup steps are not
    performed and only a request to start the machines is attempted.)

    Note that auto-failover provisioning is not used when restarting stopped
    clusters. They will be started on the same cloud and region that was chosen
    before.

    If a cluster is already in an UP status, this command has no effect on it.

    Examples:

    .. code-block:: bash

      # Restart a specific cluster.
      sky start cluster_name

    .. code-block:: bash

      # Restart multiple clusters.
      sky start cluster1 cluster2

    """
    to_start = []
    if clusters:
        # Get GLOB cluster names
        clusters = _get_glob_clusters(clusters)

        for name in clusters:
            cluster_status = backend_utils.get_cluster_status_with_refresh(name)
            # A cluster may have one of the following states:
            #
            #  STOPPED - ok to restart
            #    (currently, only AWS/GCP non-spot clusters can be in this
            #    state)
            #
            #  UP - skipped, see below
            #
            #  INIT - ok to restart:
            #    1. It can be a failed-to-provision cluster, so it isn't up
            #      (Ex: gpunode --gpus=A100:8).  Running `sky start` enables
            #      retrying the provisioning - without setup steps being
            #      completed. (Arguably the original command that failed should
            #      be used instead; but using start isn't harmful - after it
            #      gets provisioned successfully the user can use the original
            #      command).
            #
            #    2. It can be an up cluster that failed one of the setup steps.
            #      This way 'sky start' can change its status to UP, enabling
            #      'sky ssh' to debug things (otherwise `sky ssh` will fail an
            #      INIT state cluster due to head_ip not being cached).
            #
            #      This can be replicated by adding `exit 1` to Task.setup.
            if cluster_status == global_user_state.ClusterStatus.UP:
                # An UP cluster; skipping 'sky start' because:
                #  1. For a really up cluster, this has no effects (ray up -y
                #    --no-restart) anyway.
                #  2. A cluster may show as UP but is manually stopped in the
                #    UI.  If Azure/GCP: ray autoscaler doesn't support reusing,
                #    so 'sky start existing' will actually launch a new
                #    cluster with this name, leaving the original cluster
                #    zombied (remains as stopped in the cloud's UI).
                #
                #    This is dangerous and unwanted behavior!
                print(f'Cluster {name} already has status UP.')
                continue
            assert cluster_status in (
                global_user_state.ClusterStatus.INIT,
                global_user_state.ClusterStatus.STOPPED), cluster_status
            to_start.append({
                'name': name,
                'handle': global_user_state.get_handle_from_cluster_name(name)
            })
    if not to_start:
        return
    # FIXME: Assumes a specific backend.
    backend = cloud_vm_ray_backend.CloudVmRayBackend()

    if not yes:
        cluster_str = 'clusters' if len(to_start) > 1 else 'cluster'
        cluster_list = ', '.join([r['name'] for r in to_start])
        click.confirm(
            f'Restarting {len(to_start)} {cluster_str}: '
            f'{cluster_list}. Proceed?',
            default=True,
            abort=True,
            show_default=True)

    for record in to_start:
        name = record['name']
        handle = record['handle']
        with sky.Dag():
            dummy_task = sky.Task().set_resources(handle.launched_resources)
            dummy_task.num_nodes = handle.launched_nodes
        backend.provision(dummy_task,
                          to_provision=handle.launched_resources,
                          dryrun=False,
                          stream_logs=True,
                          cluster_name=name)
        click.secho(f'Cluster {name} started.', fg='green')


@cli.command(cls=_DocumentedCodeCommand)
@click.argument('clusters', nargs=-1, required=False)
@click.option('--all',
              '-a',
              default=None,
              is_flag=True,
              help='Tear down all existing clusters.')
@click.option('--yes',
              '-y',
              is_flag=True,
              default=False,
              required=False,
              help='Skip confirmation prompt.')
@click.option('--purge',
              '-p',
              is_flag=True,
              default=False,
              required=False,
              help='Ignore cloud provider errors (if any); '
              'useful for cleaning up manually deleted cluster(s).')
def down(
    clusters: Tuple[str],
    all: Optional[bool],  # pylint: disable=redefined-builtin
    yes: bool,
    purge: bool,
):
    """Tear down cluster(s).

    CLUSTER is the name of the cluster (or glob pattern) to tear down.  If both
    CLUSTER and --all are supplied, the latter takes precedence.

    Terminating a cluster will delete all associated resources (all billing
    stops), and any data on the attached disks will be lost.

    Accelerators (e.g., TPU) that are part of the cluster will be deleted too.

    Examples:

    .. code-block:: bash

        # Tear down a specific cluster.
        sky down cluster_name

    .. code-block:: bash

        # Tear down multiple clusters.
        sky down cluster1 cluster2

    .. code-block:: bash

        # Tear down all clusters with prefix 'cluster'
        sky down "cluster*"

    .. code-block:: bash

        # Tear down all existing clusters.
        sky down -a

    """
    _terminate_or_stop_clusters(clusters,
                                apply_to_all=all,
                                terminate=True,
                                no_confirm=yes,
                                purge=purge)


def _terminate_or_stop_clusters(
        names: Tuple[str],
        apply_to_all: Optional[bool],
        terminate: bool,
        no_confirm: bool,
        purge: bool = False,
        idle_minutes_to_autostop: Optional[int] = None) -> None:
    """Terminates or (auto-)stops a cluster (or all clusters)."""
    assert idle_minutes_to_autostop is None or (not terminate and no_confirm), (
        idle_minutes_to_autostop, terminate, no_confirm)
    command = 'down' if terminate else 'stop'
    if not names and apply_to_all is None:
        raise click.UsageError(
            f'sky {command} requires either a cluster name (see `sky status`) '
            'or --all.')

    to_down = []
    if len(names) > 0:
        names = _get_glob_clusters(names)
        for name in names:
            handle = global_user_state.get_handle_from_cluster_name(name)
            to_down.append({'name': name, 'handle': handle})
    if apply_to_all:
        to_down = global_user_state.get_clusters()
        if len(names) > 0:
            print(f'Both --all and cluster(s) specified for sky {command}. '
                  'Letting --all take effect.')
            names = []
    if not to_down and not names:
        print('Cluster(s) not found (see `sky status`).')
        return

    if not no_confirm:
        teardown_verb = 'Terminating' if terminate else 'Stopping'
        cluster_str = 'clusters' if len(to_down) > 1 else 'cluster'
        cluster_list = ', '.join([r['name'] for r in to_down])
        click.confirm(
            f'{teardown_verb} {len(to_down)} {cluster_str}: '
            f'{cluster_list}. Proceed?',
            default=True,
            abort=True,
            show_default=True)

    operation = 'Terminating' if terminate else 'Stopping'
    if idle_minutes_to_autostop is not None:
        verb = 'Scheduling' if idle_minutes_to_autostop >= 0 else 'Cancelling'
        operation = f'{verb} auto-stop on'
    plural = 's' if len(to_down) > 1 else ''
    progress = rich_progress.Progress(transient=True)
    task = progress.add_task(
        f'[bold cyan]{operation} {len(to_down)} cluster{plural}[/]',
        total=len(to_down))

    def _terminate_or_stop(record):
        name = record['name']
        handle = record['handle']
        backend = backend_utils.get_backend_from_handle(handle)
        if (isinstance(backend, backends.CloudVmRayBackend) and
                handle.launched_resources.use_spot and not terminate):
            # Disable spot instances to be stopped.
            # TODO(suquark): enable GCP+spot to be stopped in the future.
            message = (
                f'{colorama.Fore.GREEN}Stopping cluster {name}... skipped.'
                f'{colorama.Style.RESET_ALL}\n'
                '  The spot instances may lose attached volumes.\n'
                '  To terminate the cluster, run: '
                f'{colorama.Style.BRIGHT}sky down {name}'
                f'{colorama.Style.RESET_ALL}')
        elif idle_minutes_to_autostop is not None:
            cluster_status = backend_utils.get_cluster_status_with_refresh(name)
            if not isinstance(backend, backends.CloudVmRayBackend):
                message = (f'{colorama.Fore.GREEN}{operation} cluster '
                           f'{name}... skipped{colorama.Style.RESET_ALL}'
                           '\n  Auto-stopping is only supported by backend: '
                           f'{backends.CloudVmRayBackend.NAME}')
            else:
                if cluster_status != global_user_state.ClusterStatus.UP:
                    message = (
                        f'{colorama.Fore.GREEN}{operation} cluster '
                        f'{name} (status: {cluster_status.value})... skipped'
                        f'{colorama.Style.RESET_ALL}'
                        '\n  Auto-stop can only be run on '
                        f'{global_user_state.ClusterStatus.UP.value} cluster.')
                else:
                    backend.set_autostop(handle, idle_minutes_to_autostop)
                    message = (
                        f'{colorama.Fore.GREEN}{operation} '
                        f'cluster {name}...done{colorama.Style.RESET_ALL}')
                    if idle_minutes_to_autostop >= 0:
                        message += (
                            f'\n  The cluster will be stopped after '
                            f'{idle_minutes_to_autostop} minutes of idleness.'
                            '\n  To cancel the autostop, run: '
                            f'{colorama.Style.BRIGHT}'
                            f'sky autostop {name} --cancel'
                            f'{colorama.Style.RESET_ALL}')
        else:
            success = backend.teardown(handle, terminate=terminate, purge=purge)
            if success:
                message = (
                    f'{colorama.Fore.GREEN}{operation} cluster {name}...done.'
                    f'{colorama.Style.RESET_ALL}')
                if not terminate:
                    message += ('\n  To restart the cluster, run: '
                                f'{colorama.Style.BRIGHT}sky start {name}'
                                f'{colorama.Style.RESET_ALL}')
            else:
                message = (
                    f'{colorama.Fore.RED}{operation} cluster {name}...failed. '
                    'Please check the logs and try again.'
                    f'{colorama.Style.RESET_ALL}')
        progress.stop()
        click.echo(message)
        progress.update(task, advance=1)
        progress.start()

    with progress:
        backend_utils.run_in_parallel(_terminate_or_stop, to_down)
        progress.live.transient = False


@_interactive_node_cli_command
def gpunode(cluster: str, yes: bool, port_forward: Optional[List[int]],
            cloud: Optional[str], instance_type: Optional[str],
            gpus: Optional[str], spot: Optional[bool], screen: Optional[bool],
            tmux: Optional[bool], disk_size: Optional[int]):
    """Launch or attach to an interactive GPU node.

    Example:

    .. code-block:: bash

        # Launch a default gpunode.
        sky gpunode

    .. code-block:: bash

        # Do work, then log out. The node is kept running. Attach back to the
        # same node and do more work.
        sky gpunode

    .. code-block:: bash

        # Create many interactive nodes by assigning names via --cluster (-c).
        sky gpunode -c node0
        sky gpunode -c node1

    .. code-block:: bash

        # Port forward.
        sky gpunode --port-forward 8080 --port-forward 4650 -c cluster_name
        sky gpunode -p 8080 -p 4650 -c cluster_name

    .. code-block:: bash

        # Sync current working directory to ~/workdir on the node.
        rsync -r . cluster_name:~/workdir

    """
    # TODO: Factor out the shared logic below for [gpu|cpu|tpu]node.
    if screen and tmux:
        raise click.UsageError('Cannot use both screen and tmux.')

    session_manager = None
    if screen or tmux:
        session_manager = 'tmux' if tmux else 'screen'
    name = cluster
    if name is None:
        name = _default_interactive_node_name('gpunode')

    user_requested_resources = not (cloud is None and instance_type is None and
                                    gpus is None and spot is None)
    default_resources = _INTERACTIVE_NODE_DEFAULT_RESOURCES['gpunode']
    cloud_provider = _get_cloud(cloud)
    if gpus is None and instance_type is None:
        # Use this request if both gpus and instance_type are not specified.
        gpus = default_resources.accelerators
        instance_type = default_resources.instance_type
    if spot is None:
        spot = default_resources.use_spot
    resources = sky.Resources(cloud=cloud_provider,
                              instance_type=instance_type,
                              accelerators=gpus,
                              use_spot=spot,
                              disk_size=disk_size)

    _create_and_ssh_into_node(
        'gpunode',
        resources,
        cluster_name=name,
        port_forward=port_forward,
        session_manager=session_manager,
        user_requested_resources=user_requested_resources,
        no_confirm=yes,
    )


@_interactive_node_cli_command
def cpunode(cluster: str, yes: bool, port_forward: Optional[List[int]],
            cloud: Optional[str], instance_type: Optional[str],
            spot: Optional[bool], screen: Optional[bool], tmux: Optional[bool],
            disk_size: Optional[int]):
    """Launch or attach to an interactive CPU node.

    Example:

    .. code-block:: bash

        # Launch a default cpunode.
        sky cpunode

    .. code-block:: bash

        # Do work, then log out. The node is kept running. Attach back to the
        # same node and do more work.
        sky cpunode

    .. code-block:: bash

        # Create many interactive nodes by assigning names via --cluster (-c).
        sky cpunode -c node0
        sky cpunode -c node1

    .. code-block:: bash

        # Port forward.
        sky cpunode --port-forward 8080 --port-forward 4650 -c cluster_name
        sky cpunode -p 8080 -p 4650 -c cluster_name

    .. code-block:: bash

        # Sync current working directory to ~/workdir on the node.
        rsync -r . cluster_name:~/workdir

    """
    if screen and tmux:
        raise click.UsageError('Cannot use both screen and tmux.')

    session_manager = None
    if screen or tmux:
        session_manager = 'tmux' if tmux else 'screen'
    name = cluster
    if name is None:
        name = _default_interactive_node_name('cpunode')

    user_requested_resources = not (cloud is None and instance_type is None and
                                    spot is None)
    default_resources = _INTERACTIVE_NODE_DEFAULT_RESOURCES['cpunode']
    cloud_provider = _get_cloud(cloud)
    if instance_type is None:
        instance_type = default_resources.instance_type
    if spot is None:
        spot = default_resources.use_spot
    resources = sky.Resources(cloud=cloud_provider,
                              instance_type=instance_type,
                              use_spot=spot,
                              disk_size=disk_size)

    _create_and_ssh_into_node(
        'cpunode',
        resources,
        cluster_name=name,
        port_forward=port_forward,
        session_manager=session_manager,
        user_requested_resources=user_requested_resources,
        no_confirm=yes,
    )


@_interactive_node_cli_command
def tpunode(cluster: str, yes: bool, port_forward: Optional[List[int]],
            instance_type: Optional[str], tpus: Optional[str],
            spot: Optional[bool], screen: Optional[bool], tmux: Optional[bool],
            disk_size: Optional[int]):
    """Launch or attach to an interactive TPU node.

    Example:

    .. code-block:: bash

        # Launch a default tpunode.
        sky tpunode

    .. code-block:: bash

        # Do work, then log out. The node is kept running. Attach back to the
        # same node and do more work.
        sky tpunode

    .. code-block:: bash

        # Create many interactive nodes by assigning names via --cluster (-c).
        sky tpunode -c node0
        sky tpunode -c node1

    .. code-block:: bash

        # Port forward.
        sky tpunode --port-forward 8080 --port-forward 4650 -c cluster_name
        sky tpunode -p 8080 -p 4650 -c cluster_name

    .. code-block:: bash

        # Sync current working directory to ~/workdir on the node.
        rsync -r . cluster_name:~/workdir

    """
    if screen and tmux:
        raise click.UsageError('Cannot use both screen and tmux.')

    session_manager = None
    if screen or tmux:
        session_manager = 'tmux' if tmux else 'screen'
    name = cluster
    if name is None:
        name = _default_interactive_node_name('tpunode')

    user_requested_resources = not (instance_type is None and tpus is None and
                                    spot is None)
    default_resources = _INTERACTIVE_NODE_DEFAULT_RESOURCES['tpunode']
    if instance_type is None:
        instance_type = default_resources.instance_type
    if tpus is None:
        tpus = default_resources.accelerators
    if spot is None:
        spot = default_resources.use_spot
    resources = sky.Resources(cloud=sky.GCP(),
                              instance_type=instance_type,
                              accelerators=tpus,
                              use_spot=spot,
                              disk_size=disk_size)

    _create_and_ssh_into_node(
        'tpunode',
        resources,
        cluster_name=name,
        port_forward=port_forward,
        session_manager=session_manager,
        user_requested_resources=user_requested_resources,
        no_confirm=yes,
    )


@cli.command()
def check():
    """Determine the set of clouds available to use.

    This checks access credentials for AWS, Azure and GCP; on failure, it shows
    the reason and suggests correction steps. Sky tasks will only run on clouds
    that you have access to.
    """
    sky_check.check()


@cli.command()
@click.argument('gpu_name', required=False)
@click.option('--all',
              '-a',
              is_flag=True,
              default=False,
              help='Show details of all GPU/TPU/accelerator offerings.')
@click.option('--cloud',
              default=None,
              type=str,
              help='Cloud provider to query.')
def show_gpus(gpu_name: Optional[str], all: bool, cloud: Optional[str]):  # pylint: disable=redefined-builtin
    """Show supported GPU/TPU/accelerators.

    To show the detailed information of a GPU/TPU type (which clouds offer it,
    the quantity in each VM type, etc.), use `sky show-gpus <gpu>`.

    To show all GPUs, including less common ones and their detailed
    information, use `sky show-gpus --all`.

    NOTE: The price displayed for each instance type is the lowest across all
    regions for both on-demand and spot instances.
    """
    show_all = all
    if show_all and gpu_name is not None:
        raise click.UsageError('--all is only allowed without a GPU name.')

    def _list_to_str(lst):
        return ', '.join([str(e) for e in lst])

    def _output():
        gpu_table = util_lib.create_table(
            ['NVIDIA_GPU', 'AVAILABLE_QUANTITIES'])
        tpu_table = util_lib.create_table(
            ['GOOGLE_TPU', 'AVAILABLE_QUANTITIES'])
        other_table = util_lib.create_table(
            ['OTHER_GPU', 'AVAILABLE_QUANTITIES'])

        if gpu_name is None:
            result = service_catalog.list_accelerator_counts(gpus_only=True,
                                                             clouds=cloud)
            # NVIDIA GPUs
            for gpu in service_catalog.get_common_gpus():
                if gpu in result:
                    gpu_table.add_row([gpu, _list_to_str(result.pop(gpu))])
            yield from gpu_table.get_string()

            # Google TPUs
            for tpu in service_catalog.get_tpus():
                if tpu in result:
                    tpu_table.add_row([tpu, _list_to_str(result.pop(tpu))])
            if len(tpu_table.get_string()) > 0:
                yield '\n\n'
            yield from tpu_table.get_string()

            # Other GPUs
            if show_all:
                yield '\n\n'
                for gpu, qty in sorted(result.items()):
                    other_table.add_row([gpu, _list_to_str(qty)])
                yield from other_table.get_string()
            else:
                return

        # Show detailed accelerator information
        result = service_catalog.list_accelerators(gpus_only=True,
                                                   name_filter=gpu_name,
                                                   clouds=cloud)
        if len(result) == 0:
            yield f'Resources \'{gpu_name}\' not found. '
            yield 'Try \'sky show-gpus --all\' '
            yield 'to show available accelerators.'
        import pandas as pd  # pylint: disable=import-outside-toplevel
        for i, (gpu, items) in enumerate(result.items()):
            accelerator_table = util_lib.create_table([
                'GPU',
                'QTY',
                'CLOUD',
                'INSTANCE_TYPE',
                'HOST_MEMORY',
                'HOURLY_PRICE',
                'HOURLY_SPOT_PRICE',
            ])
            for item in items:
                instance_type_str = item.instance_type if not pd.isna(
                    item.instance_type) else '(attachable)'
                mem_str = f'{item.memory:.0f}GB' if item.memory > 0 else '-'
                price_str = f'$ {item.price:.3f}' if not pd.isna(
                    item.price) else '-'
                spot_price_str = f'$ {item.spot_price:.3f}' if not pd.isna(
                    item.spot_price) else '-'
                accelerator_table.add_row([
                    item.accelerator_name, item.accelerator_count, item.cloud,
                    instance_type_str, mem_str, price_str, spot_price_str
                ])

            if i != 0 or gpu_name is None:
                yield '\n\n'
            yield from accelerator_table.get_string()

    if show_all:
        click.echo_via_pager(_output())
    else:
        for out in _output():
            click.echo(out, nl=False)
        click.echo()


@cli.group(cls=_NaturalOrderGroup)
def storage():
    """Storage related commands."""
    pass


@storage.command('ls', cls=_DocumentedCodeCommand)
def storage_ls():
    """List storage objects created."""
    storage_stat = global_user_state.get_storage()
    storage_table = util_lib.create_table([
        'NAME',
        'CREATED',
        'STORE',
        'COMMAND',
        'STATUS',
    ])

    for row in storage_stat:
        launched_at = row['launched_at']
        storage_table.add_row([
            # NAME
            row['name'],
            # LAUNCHED
            _readable_time_duration(launched_at),
            # CLOUDS
            ', '.join([s.value for s in row['handle'].sky_stores.keys()]),
            # COMMAND
            row['last_use'],
            # STATUS
            row['status'].value,
        ])
    if storage_stat:
        click.echo(storage_table)
    else:
        click.echo('No existing storage.')


@storage.command('delete', cls=_DocumentedCodeCommand)
@click.option('--all',
              '-a',
              default=False,
              is_flag=True,
              required=False,
              help='Used with delete; Delete all storages.')
@click.argument('name', required=False, type=str, nargs=-1)
def storage_delete(all: bool, name: str):  # pylint: disable=redefined-builtin
    """Delete storage objects.

    Example:

    .. code-block:: bash

        # Delete two storage objects
        sky storage delete imagenet cifar10

    .. code-block:: bash

        # Delete all storage objects
        sky storage delete -a
    """
    if all:
        click.echo('Deleting all storage objects...')
        storages = global_user_state.get_storage()
        for row in storages:
            store_object = data.Storage(name=row['name'],
                                        source=row['handle'].source,
                                        sync_on_reconstruction=False)
            store_object.delete()
    elif name:
        for n in name:
            handle = global_user_state.get_handle_from_storage_name(n)
            if handle is None:
                click.echo(f'Storage name {n} not found.')
            else:
                click.echo(f'Deleting storage object {n}...')
                store_object = data.Storage(name=handle.storage_name,
                                            source=handle.source,
                                            sync_on_reconstruction=False)
                store_object.delete()
    else:
        raise click.ClickException(
            'Must pass in \'-a/--all\' or storage names to \'sky '
            'storage delete\'.')


def main():
    return cli()


if __name__ == '__main__':
    main()
