# auth.yaml
envs:
  MODEL_NAME: Qwen/Qwen3-0.6B

secrets:
  AUTH_TOKEN: # TODO: Fill with your own auth token (a random string), or use --secret to pass.

service:
  readiness_probe:
    path: /v1/models
    headers:
      Authorization: Bearer $AUTH_TOKEN
    initial_delay_seconds: 1800
  replicas: 1

resources:
  accelerators: L4
  cpus: 7+
  memory: 20+
  ports: 8087

setup: |
  uv venv --python 3.10 --seed
  source .venv/bin/activate
  # Pin transformers to avoid incompatibility with vLLM 0.10.0
  # See: https://github.com/volcengine/verl/issues/4337
  uv pip install transformers==4.57.3
  uv pip install vllm==0.10.0
  uv pip install openai

run: |
  source .venv/bin/activate
  export PATH=$PATH:/sbin
  vllm serve $MODEL_NAME --trust-remote-code \
    --host 0.0.0.0 --port 8087 \
    --api-key $AUTH_TOKEN
